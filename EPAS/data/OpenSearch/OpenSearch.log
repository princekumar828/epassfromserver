Failing 0 failureEntries
Failing 1 failureEntries
Failing 2 failureEntries
Failing 3 failureEntries
Failing 4 failureEntries
Failing 5 failureEntries
Failing 6 failureEntries
Failing 7 failureEntries
Failing 8 failureEntries
Failing 9 failureEntries
Failing 10 failureEntries
Failing 11 failureEntries
Failing 12 failureEntries
Failing 13 failureEntries
Failing 14 failureEntries
Node names : clusterManager= clusterManagerNode1 primary= primaryNode1 replica= replicaNode1
Node names : clusterManager= clusterManagerNode2 primary= primaryNode2 replica= replicaNode2
Node names : clusterManager= clusterManagerNode3 primary= primaryNode3 replica= replicaNode3
Node names : clusterManager= clusterManagerNode4 primary= primaryNode4 replica= replicaNode4
Node names : clusterManager= clusterManagerNode5 primary= primaryNode5 replica= replicaNode5
Node names : clusterManager= clusterManagerNode6 primary= primaryNode6 replica= replicaNode6
Node names : clusterManager= clusterManagerNode7 primary= primaryNode7 replica= replicaNode7
Node names : clusterManager= clusterManagerNode8 primary= primaryNode8 replica= replicaNode8
Node names : clusterManager= clusterManagerNode9 primary= primaryNode9 replica= replicaNode9
Node names : clusterManager= clusterManagerNode10 primary= primaryNode10 replica= replicaNode10
Node names : clusterManager= clusterManagerA primary= primaryA replica= replicaA
Node names : clusterManager= clusterManagerB primary= primaryB replica= replicaB
Node names : clusterManager= clusterManagerC primary= primaryC replica= replicaC
Node names : clusterManager= clusterManagerD primary= primaryD replica= replicaD
Node names : clusterManager= clusterManagerE primary= primaryE replica= replicaE
Target throughput = 100 ops / s
Target throughput = 250 ops / s
Target throughput = 75 ops / s
Target throughput = 150 ops / s
Target throughput = 300 ops / s
Target throughput = 50 ops / s
Target throughput = 200 ops / s
Target throughput = 125 ops / s
Target throughput = 275 ops / s
Target throughput = 175 ops / s
Target throughput = 225 ops / s
Target throughput = 325 ops / s
Target throughput = 350 ops / s
Target throughput = 400 ops / s
Target throughput = 425 ops / s
Exception during periodic field data cache cleanup: java.lang.NullPointerException
Exception during periodic field data cache cleanup: java.io.IOException
Exception during periodic field data cache cleanup: java.sql.SQLException
Exception during periodic field data cache cleanup: java.lang.OutOfMemoryError
Exception during periodic field data cache cleanup: java.lang.ClassNotFoundException
Exception during periodic field data cache cleanup: java.lang.IllegalArgumentException
Exception during periodic field data cache cleanup: java.lang.ArrayIndexOutOfBoundsException
Exception during periodic field data cache cleanup: java.lang.ArithmeticException
Exception during periodic field data cache cleanup: java.util.ConcurrentModificationException
Exception during periodic field data cache cleanup: java.lang.SecurityException
Exception during periodic field data cache cleanup: java.net.SocketTimeoutException
Exception during periodic field data cache cleanup: java.net.MalformedURLException
Exception during periodic field data cache cleanup: javax.xml.parsers.ParserConfigurationException
Exception during periodic field data cache cleanup: org.xml.sax.SAXException
Exception during periodic field data cache cleanup: javax.crypto.BadPaddingException
cleaning temporary file [log.txt]
cleaning temporary file [temp.db]
cleaning temporary file [cache.dat]
cleaning temporary file [backup.zip]
cleaning temporary file [error.log]
cleaning temporary file [temp.docx]
cleaning temporary file [cache.jpg]
cleaning temporary file [backup.tar.gz]
cleaning temporary file [error.csv]
cleaning temporary file [temp.pdf]
cleaning temporary file [cache.png]
cleaning temporary file [backup.rar]
cleaning temporary file [error.xml]
cleaning temporary file [temp.xlsx]
cleaning temporary file [cache.gif]
script: backup.sh stdout: Backup completed successfully stderr: None
script: install.py stdout: Installing package foo stderr: Permission denied
script: test.rb stdout: Running 10 tests stderr: Test 3 failed
script: update.sh stdout: Updating system files stderr: Error: disk full
script: compile.c stdout: Compiling source code stderr: Warning: unused variable
script: scan.py stdout: Scanning for viruses stderr: Virus found in file bar.exe
script: clean.sh stdout: Cleaning temporary files stderr: None
script: run.java stdout: Executing main method stderr: Exception in thread "main" java.lang.NullPointerException
script: analyze.R stdout: Analyzing data set stderr: Error in read.csv("data.csv") : file not found
script: deploy.sh stdout: Deploying application to server stderr: Connection refused
script: sort.pl stdout: Sorting input data stderr: None
script: ping.sh stdout: Pinging host 192.168.0.1 stderr: Host unreachable
script: convert.py stdout: Converting image format stderr: Invalid argument
script: check.sh stdout: Checking file integrity stderr: Checksum mismatch
script: extract.sh stdout: Extracting archive file stderr: Archive corrupted
Unknown benchmark type [cpu]
Unknown benchmark type [memory]
Unknown benchmark type [disk]
Unknown benchmark type [network]
Unknown benchmark type [gpu]
Unknown benchmark type [io]
Unknown benchmark type [flops]
Unknown benchmark type [latency]
Unknown benchmark type [throughput]
Unknown benchmark type [bandwidth]
Unknown benchmark type [power]
Unknown benchmark type [temperature]
Unknown benchmark type [cache]
Unknown benchmark type [encryption]
Unknown benchmark type [compression]
--> nodeWithPrimary: node1
--> nodeWithPrimary: node2
--> nodeWithPrimary: node3
--> nodeWithPrimary: node4
--> nodeWithPrimary: node5
--> nodeWithPrimary: node6
--> nodeWithPrimary: node7
--> nodeWithPrimary: node8
--> nodeWithPrimary: node9
--> nodeWithPrimary: node10
--> nodeWithPrimary: node11
--> nodeWithPrimary: node12
--> nodeWithPrimary: node13
--> nodeWithPrimary: node14
--> nodeWithPrimary: node15
timed out [30s] while waiting for removal of decommissioned nodes [node-1, node-2, node-3]
timed out [10s] while waiting for removal of decommissioned nodes [node-4]
timed out [60s] while waiting for removal of decommissioned nodes [node-5, node-6]
timed out [15s] while waiting for removal of decommissioned nodes [node-7, node-8, node-9, node-10]
timed out [45s] while waiting for removal of decommissioned nodes [node-11, node-12]
timed out [20s] while waiting for removal of decommissioned nodes [node-13, node-14, node-15]
timed out [50s] while waiting for removal of decommissioned nodes [node-16, node-17]
timed out [25s] while waiting for removal of decommissioned nodes [node-18, node-19, node-20]
timed out [40s] while waiting for removal of decommissioned nodes [node-21]
timed out [5s] while waiting for removal of decommissioned nodes [node-22, node-23, node-24]
timed out [35s] while waiting for removal of decommissioned nodes [node-25, node-26, node-27]
timed out [55s] while waiting for removal of decommissioned nodes [node-28, node-29]
timed out [70s] while waiting for removal of decommissioned nodes [node-30]
timed out [80s] while waiting for removal of decommissioned nodes [node-31, node-32]
timed out [90s] while waiting for removal of decommissioned nodes [node-33, node-34, node-35]
store cannot be marked as corrupted java.lang.NullPointerException
store cannot be marked as corrupted java.io.IOException
store cannot be marked as corrupted java.lang.IllegalArgumentException
store cannot be marked as corrupted java.lang.ClassNotFoundException
store cannot be marked as corrupted java.lang.OutOfMemoryError
store cannot be marked as corrupted java.lang.StackOverflowError
store cannot be marked as corrupted java.util.ConcurrentModificationException
store cannot be marked as corrupted java.lang.UnsupportedOperationException
store cannot be marked as corrupted java.nio.file.NoSuchFileException
store cannot be marked as corrupted java.sql.SQLException
store cannot be marked as corrupted java.lang.SecurityException
store cannot be marked as corrupted java.net.SocketTimeoutException
store cannot be marked as corrupted java.lang.ArithmeticException
store cannot be marked as corrupted java.util.zip.ZipException
store cannot be marked as corrupted java.time.DateTimeException
instance web-01 with tags web, prod, us-east-1 is added to discovery
instance db-02 with tags db, test, us-west-2 is added to discovery
instance app-03 with tags app, dev, eu-central-1 is added to discovery
instance web-04 with tags web, prod, ap-southeast-1 is added to discovery
instance db-05 with tags db, test, ca-central-1 is added to discovery
instance app-06 with tags app, dev, sa-east-1 is added to discovery
instance web-07 with tags web, prod, af-south-1 is added to discovery
instance db-08 with tags db, test, me-south-1 is added to discovery
instance app-09 with tags app, dev, ap-northeast-1 is added to discovery
instance web-10 with tags web, prod, eu-west-1 is added to discovery
instance db-11 with tags db, test, ap-south-1 is added to discovery
instance app-12 with tags app, dev, us-east-2 is added to discovery
instance web-13 with tags web, prod, eu-north-1 is added to discovery
instance db-14 with tags db, test, ap-east-1 is added to discovery
instance app-15 with tags app, dev, eu-west-2 is added to discovery
failed to notify ClusterStateListener java.lang.NullPointerException
failed to notify ClusterStateListener org.elasticsearch.ElasticsearchException: cluster block exception
failed to notify ClusterStateListener java.net.SocketTimeoutException: Read timed out
failed to notify ClusterStateListener org.elasticsearch.transport.NodeDisconnectedException: [node-1][127.0.0.1:9300][cluster:monitor/state] disconnected
failed to notify ClusterStateListener java.io.IOException: No space left on device
failed to notify ClusterStateListener org.elasticsearch.cluster.coordination.FailedToCommitClusterStateException: publication failed
failed to notify ClusterStateListener java.lang.IllegalStateException: index [test] version not supported
failed to notify ClusterStateListener org.elasticsearch.action.UnavailableShardsException: [test][0] primary shard is not active
failed to notify ClusterStateListener org.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException: failed to process cluster event (create-index [test], cause [api]) within 30s
failed to notify ClusterStateListener org.elasticsearch.indices.IndexClosedException: closed
failed to notify ClusterStateListener org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [<http_request>] would be [123456789/117.7mb], which is larger than the limit of [104857600/100mb]
failed to notify ClusterStateListener org.elasticsearch.rest.action.RestActionListener$1.onFailure(RestActionListener.java:48)
failed to notify ClusterStateListener org.elasticsearch.xpack.security.authc.AuthenticationService$AuditableTransportRequest.anonymousAccessDenied(AuthenticationService.java:566)
failed to notify ClusterStateListener org.elasticsearch.xpack.watcher.execution.ExecutionService$WatchExecutionTask.run(ExecutionService.java:413)
failed to notify ClusterStateListener org.elasticsearch.xpack.monitoring.exporter.ExportException$ExportBulk$ExportBulkItem.<init>(ExportException.java:120)
unregistering node-1 after connection close and marking as disconnected
unregistering node-7 after connection close and marking as disconnected
unregistering node-12 after connection close and marking as disconnected
unregistering node-3 after connection close and marking as disconnected
unregistering node-9 after connection close and marking as disconnected
unregistering node-15 after connection close and marking as disconnected
unregistering node-2 after connection close and marking as disconnected
unregistering node-8 after connection close and marking as disconnected
unregistering node-13 after connection close and marking as disconnected
unregistering node-4 after connection close and marking as disconnected
unregistering node-10 after connection close and marking as disconnected
unregistering node-16 after connection close and marking as disconnected
unregistering node-5 after connection close and marking as disconnected
unregistering node-11 after connection close and marking as disconnected
unregistering node-6 after connection close and marking as disconnected
kill the node [0] of the primary shard for the relocating replica
kill the node [1] of the primary shard for the relocating replica
kill the node [2] of the primary shard for the relocating replica
kill the node [3] of the primary shard for the relocating replica
kill the node [4] of the primary shard for the relocating replica
kill the node [5] of the primary shard for the relocating replica
kill the node [6] of the primary shard for the relocating replica
kill the node [7] of the primary shard for the relocating replica
kill the node [8] of the primary shard for the relocating replica
kill the node [9] of the primary shard for the relocating replica
kill the node [10] of the primary shard for the relocating replica
kill the node [11] of the primary shard for the relocating replica
kill the node [12] of the primary shard for the relocating replica
kill the node [13] of the primary shard for the relocating replica
kill the node [14] of the primary shard for the relocating replica
--> state before failing shards: [STARTED]
--> state before failing shards: [RELOCATING]
--> state before failing shards: [INITIALIZING]
--> state before failing shards: [UNASSIGNED]
--> state before failing shards: [FAILED]
--> state before failing shards: [RECOVERING]
--> state before failing shards: [STALE]
--> state before failing shards: [DELETED]
--> state before failing shards: [RESTORING]
--> state before failing shards: [SNAPSHOT]
--> state before failing shards: [REPLICA]
--> state before failing shards: [PRIMARY]
--> state before failing shards: [SHUTDOWN]
--> state before failing shards: [INVALID]
--> state before failing shards: [UNKNOWN]
--> state before failing shards: green
--> state before failing shards: yellow
--> state before failing shards: red
--> state before failing shards: initializing
--> state before failing shards: relocating
--> state before failing shards: unassigned
--> state before failing shards: started
--> state before failing shards: recovering
--> state before failing shards: closed
--> state before failing shards: open
--> state before failing shards: frozen
--> state before failing shards: blocked
--> state before failing shards: throttled
--> state before failing shards: delayed
--> state before failing shards: failed
create an allocation with [5] initial primary recoveries and [2] concurrent recoveries
create an allocation with [3] initial primary recoveries and [4] concurrent recoveries
create an allocation with [7] initial primary recoveries and [1] concurrent recoveries
create an allocation with [4] initial primary recoveries and [3] concurrent recoveries
create an allocation with [6] initial primary recoveries and [2] concurrent recoveries
create an allocation with [8] initial primary recoveries and [1] concurrent recoveries
create an allocation with [2] initial primary recoveries and [5] concurrent recoveries
create an allocation with [9] initial primary recoveries and [1] concurrent recoveries
create an allocation with [10] initial primary recoveries and [1] concurrent recoveries
create an allocation with [1] initial primary recoveries and [6] concurrent recoveries
create an allocation with [11] initial primary recoveries and [1] concurrent recoveries
create an allocation with [12] initial primary recoveries and [1] concurrent recoveries
create an allocation with [13] initial primary recoveries and [1] concurrent recoveries
create an allocation with [14] initial primary recoveries and [1] concurrent recoveries
create an allocation with [15] initial primary recoveries and [1] concurrent recoveries
create an allocation with [5] initial primary recoveries and [2] concurrent recoveries
create an allocation with [3] initial primary recoveries and [4] concurrent recoveries
create an allocation with [7] initial primary recoveries and [1] concurrent recoveries
create an allocation with [4] initial primary recoveries and [3] concurrent recoveries
create an allocation with [6] initial primary recoveries and [2] concurrent recoveries
create an allocation with [8] initial primary recoveries and [1] concurrent recoveries
create an allocation with [2] initial primary recoveries and [5] concurrent recoveries
create an allocation with [9] initial primary recoveries and [1] concurrent recoveries
create an allocation with [10] initial primary recoveries and [1] concurrent recoveries
create an allocation with [1] initial primary recoveries and [6] concurrent recoveries
Snapshot Path [/home/user1/Desktop/snapshot1.png]
Snapshot Path [/var/log/snapshot2.jpg]
Snapshot Path [C:\Users\user2\Pictures\snapshot3.bmp]
Snapshot Path [/mnt/usb/snapshot4.gif]
Snapshot Path [D:\Documents\snapshot5.tif]
Snapshot Path [/opt/snapshot6.pdf]
Snapshot Path [E:\Downloads\snapshot7.zip]
Snapshot Path [/tmp/snapshot8.dat]
Snapshot Path [F:\Music\snapshot9.mp3]
Snapshot Path [/etc/snapshot10.conf]
Snapshot Path [G:\Videos\snapshot11.mp4]
Snapshot Path [/root/snapshot12.key]
Snapshot Path [H:\Games\snapshot13.sav]
Snapshot Path [/usr/local/snapshot14.txt]
Snapshot Path [I:\Backup\snapshot15.bak]
Snapshot Path [/home/user1/Documents/project1]
Snapshot Path [/var/log/syslog]
Snapshot Path [/mnt/usb1/backup.zip]
Snapshot Path [/opt/software/bin/run.sh]
Snapshot Path [/tmp/file.txt]
Snapshot Path [/etc/hosts]
Snapshot Path [/root/.bashrc]
Snapshot Path [/dev/sda1]
Snapshot Path [/usr/local/lib/libfoo.so]
Snapshot Path [/media/cdrom/install.iso]
Snapshot Path [/proc/cpuinfo]
Snapshot Path [/boot/grub/grub.cfg]
Snapshot Path [/srv/http/index.html]
Snapshot Path [/run/user/1000/gvfs/smb-share:server=example.com,share=public/file.docx]
Snapshot Path [/data/db/mongo.log]
--> using storage_class [auto]
--> using storage_class [extern]
--> using storage_class [static]
--> using storage_class [register]
--> using storage_class [mutable]
--> using storage_class [thread_local]
--> using storage_class [auto static]
--> using storage_class [extern register]
--> using storage_class [static mutable]
--> using storage_class [register thread_local]
--> using storage_class [auto extern]
--> using storage_class [static register]
--> using storage_class [mutable thread_local]
--> using storage_class [auto mutable]
--> using storage_class [extern thread_local]
--> using storage_class [auto]
--> using storage_class [extern]
--> using storage_class [static]
--> using storage_class [register]
--> using storage_class [mutable]
--> using storage_class [thread_local]
--> using storage_class [near]
--> using storage_class [far]
--> using storage_class [const]
--> using storage_class [volatile]
--> using storage_class [inline]
--> using storage_class [friend]
--> using storage_class [virtual]
--> using storage_class [explicit]
--> using storage_class [constexpr]
--> shrinking index [100] to [50]
--> shrinking index [200] to [100]
--> shrinking index [300] to [150]
--> shrinking index [400] to [200]
--> shrinking index [500] to [250]
--> shrinking index [600] to [300]
--> shrinking index [700] to [350]
--> shrinking index [800] to [400]
--> shrinking index [900] to [450]
--> shrinking index [1000] to [500]
--> shrinking index [1100] to [550]
--> shrinking index [1200] to [600]
--> shrinking index [1300] to [650]
--> shrinking index [1400] to [700]
--> shrinking index [1500] to [750]
--> shrinking index [100] to [50]
--> shrinking index [200] to [100]
--> shrinking index [300] to [150]
--> shrinking index [400] to [200]
--> shrinking index [500] to [250]
--> shrinking index [600] to [300]
--> shrinking index [700] to [350]
--> shrinking index [800] to [400]
--> shrinking index [900] to [450]
--> shrinking index [1000] to [500]
--> shrinking index [1100] to [550]
--> shrinking index [1200] to [600]
--> shrinking index [1300] to [650]
--> shrinking index [1400] to [700]
--> shrinking index [1500] to [750]
no image files loaded
no audio files loaded
no video files loaded
no text files loaded
no PDF files loaded
no XML files loaded
no JSON files loaded
no HTML files loaded
no CSS files loaded
no JS files loaded
no fonts loaded
no icons loaded
no plugins loaded
no scripts loaded
no image files loaded
no audio files loaded
no video files loaded
no text files loaded
no font files loaded
no script files loaded
no style files loaded
no data files loaded
no config files loaded
no log files loaded
no cache files loaded
no backup files loaded
no temp files loaded
no document files loaded
Using Hadoop authentication method: [KERBEROS]
Using Hadoop authentication method: [SIMPLE]
Using Hadoop authentication method: [TOKEN]
Using Hadoop authentication method: [LDAP]
Using Hadoop authentication method: [OAUTH2]
Using Hadoop authentication method: [SAML]
Using Hadoop authentication method: [CUSTOM]
Using Hadoop authentication method: [NONE]
Using Hadoop authentication method: [KMS]
Using Hadoop authentication method: [SPNEGO]
Using Hadoop authentication method: [PAM]
Using Hadoop authentication method: [JWT]
Using Hadoop authentication method: [AZUREAD]
Using Hadoop authentication method: [AWSIAM]
Using Hadoop authentication method: [GCPID]
[shard1] [snapshot1] deleting pre-existing file [data1.txt]
[shard2] [snapshot2] deleting pre-existing file [data2.txt]
[shard3] [snapshot3] deleting pre-existing file [data3.txt]
[shard4] [snapshot4] deleting pre-existing file [data4.txt]
[shard5] [snapshot5] deleting pre-existing file [data5.txt]
[shard6] [snapshot6] deleting pre-existing file [data6.txt]
[shard7] [snapshot7] deleting pre-existing file [data7.txt]
[shard8] [snapshot8] deleting pre-existing file [data8.txt]
[shard9] [snapshot9] deleting pre-existing file [data9.txt]
[shard10] [snapshot10] deleting pre-existing file [data10.txt]
[shard11] [snapshot11] deleting pre-existing file [config1.xml]
[shard12] [snapshot12] deleting pre-existing file [config2.xml]
[shard13] [snapshot13] deleting pre-existing file [config3.xml]
[shard14] [snapshot14] deleting pre-existing file [config4.xml]
[shard15] [snapshot15] deleting pre-existing file [config5.xml]
Swapping active namenodes: [nn1] to standby and [nn2] to active
Swapping active namenodes: [nn3] to standby and [nn4] to active
Swapping active namenodes: [nn5] to standby and [nn6] to active
Swapping active namenodes: [nn7] to standby and [nn8] to active
Swapping active namenodes: [nn9] to standby and [nn10] to active
Swapping active namenodes: [nn11] to standby and [nn12] to active
Swapping active namenodes: [nn13] to standby and [nn14] to active
Swapping active namenodes: [nn15] to standby and [nn16] to active
Swapping active namenodes: [nn17] to standby and [nn18] to active
Swapping active namenodes: [nn19] to standby and [nn20] to active
Swapping active namenodes: [nn21] to standby and [nn22] to active
Swapping active namenodes: [nn23] to standby and [nn24] to active
Swapping active namenodes: [nn25] to standby and [nn26] to active
Swapping active namenodes: [nn27] to standby and [nn28] to active
Swapping active namenodes: [nn29] to standby and [nn30] to active
--> failed shard [2] on node [node-1]
--> failed shard [5] on node [node-3]
--> failed shard [7] on node [node-2]
--> failed shard [4] on node [node-4]
--> failed shard [1] on node [node-5]
--> failed shard [8] on node [node-6]
--> failed shard [3] on node [node-7]
--> failed shard [6] on node [node-8]
--> failed shard [9] on node [node-9]
--> failed shard [10] on node [node-10]
--> failed shard [11] on node [node-11]
--> failed shard [12] on node [node-12]
--> failed shard [13] on node [node-13]
--> failed shard [14] on node [node-14]
--> failed shard [15] on node [node-15]
Dfs phase failed java.lang.NullPointerException
Dfs phase failed java.io.IOException: Connection reset by peer
Dfs phase failed org.apache.hadoop.ipc.RemoteException: File does not exist
Dfs phase failed java.lang.OutOfMemoryError: Java heap space
Dfs phase failed java.lang.InterruptedException: Task cancelled
Dfs phase failed org.apache.hadoop.security.AccessControlException: Permission denied
Dfs phase failed java.io.FileNotFoundException: No such file or directory
Dfs phase failed org.apache.hadoop.mapred.TaskAttemptListenerImpl$TaskInProgressNotFoundException: TaskAttemptId not found
Dfs phase failed java.net.SocketTimeoutException: Read timed out
Dfs phase failed org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist
Dfs phase failed java.lang.IllegalArgumentException: Invalid input format
Dfs phase failed org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory already exists
Dfs phase failed java.util.concurrent.ExecutionException: Task failed
Dfs phase failed org.apache.hadoop.mapred.InvalidJobConfException: Invalid job configuration
Dfs phase failed java.lang.ClassNotFoundException: Class not found
full cache clear, reason [memory overflow]
full cache clear, reason [manual trigger]
full cache clear, reason [cache corruption]
full cache clear, reason [system reboot]
full cache clear, reason [cache expiration]
full cache clear, reason [configuration change]
full cache clear, reason [cache eviction policy]
full cache clear, reason [cache size limit reached]
full cache clear, reason [cache update failure]
full cache clear, reason [cache invalidation request]
full cache clear, reason [cache dependency change]
full cache clear, reason [cache maintenance mode]
full cache clear, reason [cache error detected]
full cache clear, reason [cache performance issue]
full cache clear, reason [cache migration process]
12 tombstones purged from the cluster state. Previous tombstone size: 56 . Current tombstone size: 44 .
7 tombstones purged from the cluster state. Previous tombstone size: 34 . Current tombstone size: 27 .
9 tombstones purged from the cluster state. Previous tombstone size: 45 . Current tombstone size: 36 .
10 tombstones purged from the cluster state. Previous tombstone size: 50 . Current tombstone size: 40 .
8 tombstones purged from the cluster state. Previous tombstone size: 40 . Current tombstone size: 32 .
11 tombstones purged from the cluster state. Previous tombstone size: 52 . Current tombstone size: 41 .
6 tombstones purged from the cluster state. Previous tombstone size: 30 . Current tombstone size: 24 .
13 tombstones purged from the cluster state. Previous tombstone size: 60 . Current tombstone size: 47 .
5 tombstones purged from the cluster state. Previous tombstone size: 28 . Current tombstone size: 23 .
14 tombstones purged from the cluster state. Previous tombstone size: 64 . Current tombstone size: 50 .
4 tombstones purged from the cluster state. Previous tombstone size: 24 . Current tombstone size: 20 .
15 tombstones purged from the cluster state. Previous tombstone size: 68 . Current tombstone size: 53 .
3 tombstones purged from the cluster state. Previous tombstone size: 20 . Current tombstone size: 17 .
16 tombstones purged from the cluster state. Previous tombstone size: 72 . Current tombstone size: 56 .
2 tombstones purged from the cluster state. Previous tombstone size: 16 . Current tombstone size: 14 .
exception thrown by listener while notifying on ack timeout java.lang.NullPointerException
exception thrown by listener while notifying on ack timeout java.io.IOException
exception thrown by listener while notifying on ack timeout java.net.SocketTimeoutException
exception thrown by listener while notifying on ack timeout java.lang.IllegalStateException
exception thrown by listener while notifying on ack timeout java.util.ConcurrentModificationException
exception thrown by listener while notifying on ack timeout java.lang.ClassCastException
exception thrown by listener while notifying on ack timeout java.lang.NumberFormatException
exception thrown by listener while notifying on ack timeout java.lang.ArrayIndexOutOfBoundsException
exception thrown by listener while notifying on ack timeout java.lang.StringIndexOutOfBoundsException
exception thrown by listener while notifying on ack timeout java.lang.ArithmeticException
exception thrown by listener while notifying on ack timeout java.lang.UnsupportedOperationException
exception thrown by listener while notifying on ack timeout java.lang.NoSuchMethodException
exception thrown by listener while notifying on ack timeout java.lang.NoSuchFieldException
exception thrown by listener while notifying on ack timeout java.lang.SecurityException
exception thrown by listener while notifying on ack timeout java.lang.OutOfMemoryError
fetching snapshot shard size for snapshotShard_1
fetching snapshot shard size for snapshotShard_2
fetching snapshot shard size for snapshotShard_3
fetching snapshot shard size for snapshotShard_4
fetching snapshot shard size for snapshotShard_5
fetching snapshot shard size for snapshotShard_6
fetching snapshot shard size for snapshotShard_7
fetching snapshot shard size for snapshotShard_8
fetching snapshot shard size for snapshotShard_9
fetching snapshot shard size for snapshotShard_10
fetching snapshot shard size for snapshotShard_11
fetching snapshot shard size for snapshotShard_12
fetching snapshot shard size for snapshotShard_13
fetching snapshot shard size for snapshotShard_14
fetching snapshot shard size for snapshotShard_15
failed to close engine Error: null pointer exception
failed to close engine Error: out of memory
failed to close engine Error: invalid state
failed to close engine Error: connection refused
failed to close engine Error: timeout
failed to close engine Error: permission denied
failed to close engine Error: file not found
failed to close engine Error: index out of bounds
failed to close engine Error: unsupported operation
failed to close engine Error: illegal argument
failed to close engine Error: interrupted exception
failed to close engine Error: io exception
failed to close engine Error: class not found
failed to close engine Error: no such method
failed to close engine Error: assertion error
Hadoop security enabled: [true]
Hadoop security enabled: [false]
Hadoop security enabled: [null]
Hadoop security enabled: [error]
Hadoop security enabled: [unknown]
Hadoop security enabled: [yes]
Hadoop security enabled: [no]
Hadoop security enabled: [on]
Hadoop security enabled: [off]
Hadoop security enabled: [1]
Hadoop security enabled: [0]
Hadoop security enabled: [-1]
Hadoop security enabled: [N/A]
Hadoop security enabled: [undefined]
Hadoop security enabled: [not set]
--> index [0] documents
--> index [1] documents
--> index [2] documents
--> index [3] documents
--> index [4] documents
--> index [5] documents
--> index [6] documents
--> index [7] documents
--> index [8] documents
--> index [9] documents
--> index [10] documents
--> index [11] documents
--> index [12] documents
--> index [13] documents
--> index [14] documents
--> Indexing 100 operations in iteration # 1
--> Indexing 50 operations in iteration # 2
--> Indexing 75 operations in iteration # 3
--> Indexing 25 operations in iteration # 4
--> Indexing 150 operations in iteration # 5
--> Indexing 80 operations in iteration # 6
--> Indexing 60 operations in iteration # 7
--> Indexing 40 operations in iteration # 8
--> Indexing 120 operations in iteration # 9
--> Indexing 90 operations in iteration # 10
--> Indexing 30 operations in iteration # 11
--> Indexing 70 operations in iteration # 12
--> Indexing 110 operations in iteration # 13
--> Indexing 20 operations in iteration # 14
--> Indexing 140 operations in iteration # 15
can't find relocation source node for shard [0] because it is assigned to an unknown node [node-1].
can't find relocation source node for shard [1] because it is assigned to an unknown node [node-2].
can't find relocation source node for shard [2] because it is assigned to an unknown node [node-3].
can't find relocation source node for shard [3] because it is assigned to an unknown node [node-4].
can't find relocation source node for shard [4] because it is assigned to an unknown node [node-5].
can't find relocation source node for shard [5] because it is assigned to an unknown node [node-6].
can't find relocation source node for shard [6] because it is assigned to an unknown node [node-7].
can't find relocation source node for shard [7] because it is assigned to an unknown node [node-8].
can't find relocation source node for shard [8] because it is assigned to an unknown node [node-9].
can't find relocation source node for shard [9] because it is assigned to an unknown node [node-10].
can't find relocation source node for shard [10] because it is assigned to an unknown node [node-11].
can't find relocation source node for shard [11] because it is assigned to an unknown node [node-12].
can't find relocation source node for shard [12] because it is assigned to an unknown node [node-13].
can't find relocation source node for shard [13] because it is assigned to an unknown node [node-14].
can't find relocation source node for shard [14] because it is assigned to an unknown node [node-15].
shard locally recovered up to 0.95
shard locally recovered up to 0.87
shard locally recovered up to 0.76
shard locally recovered up to 0.92
shard locally recovered up to 0.81
shard locally recovered up to 0.99
shard locally recovered up to 0.73
shard locally recovered up to 0.88
shard locally recovered up to 0.79
shard locally recovered up to 0.90
shard locally recovered up to 0.85
shard locally recovered up to 0.93
shard locally recovered up to 0.74
shard locally recovered up to 0.97
shard locally recovered up to 0.83
applied reroute. active shards: p [12], t [24], init shards: [3], relocating: [1]
applied reroute. active shards: p [15], t [30], init shards: [2], relocating: [0]
applied reroute. active shards: p [10], t [20], init shards: [4], relocating: [2]
applied reroute. active shards: p [13], t [26], init shards: [1], relocating: [3]
applied reroute. active shards: p [11], t [22], init shards: [5], relocating: [1]
applied reroute. active shards: p [14], t [28], init shards: [2], relocating: [2]
applied reroute. active shards: p [9], t [18], init shards: [3], relocating: [3]
applied reroute. active shards: p [16], t [32], init shards: [0], relocating: [0]
applied reroute. active shards: p [8], t [16], init shards: [6], relocating: [2]
applied reroute. active shards: p [17], t [34], init shards: [1], relocating: [1]
applied reroute. active shards: p [7], t [14], init shards: [4], relocating: [4]
applied reroute. active shards: p [18], t [36], init shards: [0], relocating: [2]
applied reroute. active shards: p [6], t [12], init shards: [5], relocating: [3]
Lock files count: 3
Lock files count: 0
Lock files count: 5
Lock files count: 2
Lock files count: 1
Lock files count: 4
Lock files count: 6
Lock files count: 7
Lock files count: 8
Lock files count: 9
Lock files count: 10
Lock files count: 11
Lock files count: 12
Lock files count: 13
Lock files count: 14
Fetch phase failed java.lang.NullPointerException
Fetch phase failed java.io.IOException: Connection reset by peer
Fetch phase failed java.lang.OutOfMemoryError: Java heap space
Fetch phase failed org.apache.spark.SparkException: Task failed while writing rows
Fetch phase failed java.sql.SQLException: Invalid column name
Fetch phase failed java.lang.IllegalArgumentException: Invalid input format
Fetch phase failed org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block
Fetch phase failed java.net.SocketTimeoutException: Read timed out
Fetch phase failed org.apache.kafka.common.errors.TimeoutException: Failed to update metadata
Fetch phase failed java.lang.ClassNotFoundException: com.example.MyClass
Fetch phase failed java.lang.SecurityException: Access denied
Fetch phase failed org.json.JSONException: A JSONArray text must start with '['
Fetch phase failed java.lang.ArithmeticException: / by zero
Fetch phase failed org.xml.sax.SAXParseException: Premature end of file
Fetch phase failed java.util.concurrent.ExecutionException: java.lang.RuntimeException
The exception from response processor [QueryRewrite] in the search pipeline [WebSearch] was ignored java.lang.NullPointerException
The exception from response processor [SpellCheck] in the search pipeline [ImageSearch] was ignored java.io.IOException
The exception from response processor [Ranking] in the search pipeline [VideoSearch] was ignored java.lang.IllegalArgumentException
The exception from response processor [Filtering] in the search pipeline [NewsSearch] was ignored java.lang.ClassCastException
The exception from response processor [SnippetGeneration] in the search pipeline [WebSearch] was ignored java.lang.OutOfMemoryError
The exception from response processor [FacetExtraction] in the search pipeline [ImageSearch] was ignored java.lang.IndexOutOfBoundsException
The exception from response processor [QueryExpansion] in the search pipeline [VideoSearch] was ignored java.lang.UnsupportedOperationException
The exception from response processor [Personalization] in the search pipeline [NewsSearch] was ignored java.lang.SecurityException
The exception from response processor [QueryRewrite] in the search pipeline [ImageSearch] was ignored java.net.SocketTimeoutException
The exception from response processor [SpellCheck] in the search pipeline [VideoSearch] was ignored java.net.MalformedURLException
The exception from response processor [Ranking] in the search pipeline [NewsSearch] was ignored java.sql.SQLException
The exception from response processor [Filtering] in the search pipeline [WebSearch] was ignored java.util.NoSuchElementException
The exception from response processor [SnippetGeneration] in the search pipeline [ImageSearch] was ignored java.util.ConcurrentModificationException
The exception from response processor [FacetExtraction] in the search pipeline [VideoSearch] was ignored java.util.MissingResourceException
The exception from response processor [QueryExpansion] in the search pipeline [NewsSearch] was ignored java.util.regex.PatternSyntaxException
omit writing dangling indices state for index [product] as index is deallocated on this node
omit writing dangling indices state for index [user] as index is deallocated on this node
omit writing dangling indices state for index [order] as index is deallocated on this node
omit writing dangling indices state for index [inventory] as index is deallocated on this node
omit writing dangling indices state for index [review] as index is deallocated on this node
omit writing dangling indices state for index [blog] as index is deallocated on this node
omit writing dangling indices state for index [news] as index is deallocated on this node
omit writing dangling indices state for index [comment] as index is deallocated on this node
omit writing dangling indices state for index [category] as index is deallocated on this node
omit writing dangling indices state for index [tag] as index is deallocated on this node
omit writing dangling indices state for index [post] as index is deallocated on this node
omit writing dangling indices state for index [media] as index is deallocated on this node
omit writing dangling indices state for index [page] as index is deallocated on this node
omit writing dangling indices state for index [event] as index is deallocated on this node
omit writing dangling indices state for index [contact] as index is deallocated on this node
Using concurrent aggregation processor over segments (experimental) for request with context id 5f4d3c2b
Using concurrent aggregation processor over segments (experimental) for request with context id 9a7b6e4d
Using concurrent aggregation processor over segments (experimental) for request with context id 3e2f1d9c
Using concurrent aggregation processor over segments (experimental) for request with context id 6c5b4a3d
Using concurrent aggregation processor over segments (experimental) for request with context id 8d7f6e5c
Using concurrent aggregation processor over segments (experimental) for request with context id 4b3a2c1d
Using concurrent aggregation processor over segments (experimental) for request with context id 7e6d5c4b
Using concurrent aggregation processor over segments (experimental) for request with context id 2a1f3e2d
Using concurrent aggregation processor over segments (experimental) for request with context id 5c4b3a6e
Using concurrent aggregation processor over segments (experimental) for request with context id 9d8f7e6c
Using concurrent aggregation processor over segments (experimental) for request with context id 3c2d1f4e
Using concurrent aggregation processor over segments (experimental) for request with context id 6e5c4b3a
Using concurrent aggregation processor over segments (experimental) for request with context id 8f7e6d5c
Using concurrent aggregation processor over segments (experimental) for request with context id 4a3b2c1e
Using concurrent aggregation processor over segments (experimental) for request with context id 7d6c5b4a
Caught exception while waiting for ES to exit java.lang.InterruptedException
Caught exception while waiting for ES to exit java.io.IOException
Caught exception while waiting for ES to exit java.util.concurrent.TimeoutException
Caught exception while waiting for ES to exit java.lang.NullPointerException
Caught exception while waiting for ES to exit java.lang.IllegalStateException
Caught exception while waiting for ES to exit java.net.SocketException
Caught exception while waiting for ES to exit java.lang.SecurityException
Caught exception while waiting for ES to exit java.lang.IllegalArgumentException
Caught exception while waiting for ES to exit java.lang.ClassNotFoundException
Caught exception while waiting for ES to exit java.lang.NoSuchMethodException
Caught exception while waiting for ES to exit java.lang.RuntimeException
Caught exception while waiting for ES to exit java.sql.SQLException
Caught exception while waiting for ES to exit java.lang.OutOfMemoryError
Caught exception while waiting for ES to exit java.lang.StackOverflowError
Caught exception while waiting for ES to exit java.lang.AssertionError
forced refresh failed after interval change java.lang.NullPointerException
forced refresh failed after interval change java.io.IOException: Connection reset
forced refresh failed after interval change java.lang.IllegalArgumentException: Invalid interval
forced refresh failed after interval change java.util.concurrent.TimeoutException
forced refresh failed after interval change java.lang.InterruptedException
forced refresh failed after interval change java.net.SocketException: Broken pipe
forced refresh failed after interval change java.lang.OutOfMemoryError
forced refresh failed after interval change java.lang.SecurityException: Permission denied
forced refresh failed after interval change java.lang.ClassNotFoundException: com.example.RefreshService
forced refresh failed after interval change java.lang.NoSuchMethodError: com.example.RefreshService.refresh()
forced refresh failed after interval change java.lang.RuntimeException: Unexpected error
forced refresh failed after interval change java.lang.AssertionError: Assertion failed
forced refresh failed after interval change java.lang.StackOverflowError
forced refresh failed after interval change java.lang.Error: Unresolved compilation problem
forced refresh failed after interval change java.lang.IncompatibleClassChangeError
timed out after [10s] resolving host [www.google.com]
timed out after [5s] resolving host [www.facebook.com]
timed out after [15s] resolving host [www.amazon.com]
timed out after [7s] resolving host [www.wikipedia.org]
timed out after [12s] resolving host [www.netflix.com]
timed out after [8s] resolving host [www.twitter.com]
timed out after [9s] resolving host [www.instagram.com]
timed out after [6s] resolving host [www.youtube.com]
timed out after [11s] resolving host [www.microsoft.com]
timed out after [13s] resolving host [www.apple.com]
timed out after [14s] resolving host [www.bing.com]
timed out after [4s] resolving host [www.reddit.com]
timed out after [3s] resolving host [www.github.com]
timed out after [16s] resolving host [www.linkedin.com]
Expected [4] total children, [2] are running and [1] are finished [SUCCESS]
Expected [6] total children, [3] are running and [2] are finished [FAILURE]
Expected [5] total children, [1] are running and [4] are finished [SUCCESS]
Expected [3] total children, [0] are running and [3] are finished [SUCCESS]
Expected [7] total children, [4] are running and [2] are finished [RUNNING]
Expected [8] total children, [5] are running and [1] are finished [RUNNING]
Expected [9] total children, [6] are running and [0] are finished [RUNNING]
Expected [10] total children, [7] are running and [1] are finished [RUNNING]
Expected [11] total children, [8] are running and [0] are finished [RUNNING]
Expected [12] total children, [9] are running and [1] are finished [RUNNING]
Expected [13] total children, [10] are running and [0] are finished [RUNNING]
Expected [14] total children, [11] are running and [1] are finished [RUNNING]
Expected [15] total children, [12] are running and [0] are finished [RUNNING]
Expected [16] total children, [13] are running and [1] are finished [RUNNING]
inter 1 significant: 0.05
inter 2 significant: 0.01
inter 3 significant: 0.03
inter 4 significant: 0.07
inter 5 significant: 0.02
inter 6 significant: 0.04
inter 7 significant: 0.06
inter 8 significant: 0.08
inter 9 significant: 0.09
inter 10 significant: 0.1
inter 11 significant: 0.11
inter 12 significant: 0.12
inter 13 significant: 0.13
inter 14 significant: 0.14
inter 15 significant: 0.15
-> Failed rolling back user_123
-> Failed rolling back order_456
-> Failed rolling back product_789
-> Failed rolling back session_101
-> Failed rolling back cart_112
-> Failed rolling back comment_134
-> Failed rolling back payment_156
-> Failed rolling back review_178
-> Failed rolling back inventory_190
-> Failed rolling back shipment_202
-> Failed rolling back coupon_214
-> Failed rolling back wishlist_226
-> Failed rolling back subscription_238
-> Failed rolling back profile_250
-> Failed rolling back message_262
--> indexing with id [a1b2c3], and routing [d4e5f6]
--> indexing with id [x9y8z7], and routing [w6v5u4]
--> indexing with id [m3n4o5], and routing [p6q7r8]
--> indexing with id [h7i8j9], and routing [k0l1m2]
--> indexing with id [s4t5u6], and routing [v7w8x9]
--> indexing with id [b2c3d4], and routing [e5f6g7]
--> indexing with id [y8z9a0], and routing [b1c2d3]
--> indexing with id [n4o5p6], and routing [q7r8s9]
--> indexing with id [i8j9k0], and routing [l1m2n3]
--> indexing with id [t5u6v7], and routing [w8x9y0]
--> indexing with id [c3d4e5], and routing [f6g7h8]
--> indexing with id [z9a0b1], and routing [c2d3e4]
--> indexing with id [o5p6q7], and routing [r8s9t0]
--> indexing with id [j9k0l1], and routing [m2n3o4]
--> indexing with id [u6v7w8], and routing [x9y0z1]
iteration [1] - shard failures: [ShardSearchFailure{reason=org.elasticsearch.index.query.QueryShardException: No mapping found for [price] in order to sort on, index=products, shardId=[products][0], nodeId=Qz7UFZa2QZ6Z4f0QW6f2LA}]
iteration [2] - shard failures: []
iteration [3] - shard failures: [ShardSearchFailure{reason=org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed, index=null, shardId=null, nodeId=null}]
iteration [4] - shard failures: []
iteration [5] - shard failures: [ShardSearchFailure{reason=org.elasticsearch.index.IndexNotFoundException: no such index [users], index=users, shardId=null, nodeId=null}]
iteration [6] - shard failures: []
iteration [7] - shard failures: [ShardSearchFailure{reason=org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [<http_request>] would be [1024817667/977.1mb], which is larger than the limit of [986061209/940.3mb], real usage: [1024817667/977.1mb], new bytes reserved: [0/0b], usages [request=0/0b, fielddata=33200/32.4kb, in_flight_requests=1024785467/977.1mb, model_inference=0/0b, accounting=0/0b], index=null, shardId=null, nodeId=null}]
iteration [8] - shard failures: []
iteration [9] - shard failures: [ShardSearchFailure{reason=org.elasticsearch.ElasticsearchTimeoutException: Timeout waiting for task., index=null, shardId=null, nodeId=null}]
iteration [10] - shard failures: []
iteration [11] - shard failures: [ShardSearchFailure{reason=org.elasticsearch.transport.RemoteTransportException: [node-1][127.0.0.1:9300][indices:data/read/search[phase/query]], index=null, shardId=null, nodeId=null}, ShardSearchFailure{reason=org.elasticsearch.transport.RemoteTransportException: [node-2][127.0.0.1:9301][indices:data/read/search[phase/query]], index=null, shardId=null, nodeId=null}]
iteration [12] - shard failures: []
iteration [13] - shard failures: [ShardSearchFailure{reason=org.elasticsearch.search.query.QueryPhaseExecutionException: Query Failed; nested exception is org.apache.lucene.index.CorruptIndexException: codec footer mismatch (file truncated?): actual footer=-1985229329 vs expected footer=-1071082520 (resource=MMapIndexInput(path="/var/lib/elasticsearch/nodes/0/indices/Zc9lLJHwQkqT8sKeC8vLNg/0/index/_3.cfs") [_3.fdt]), index=my_index, shardId=[my_index][2], nodeId=UHJjxL5rQgqz4f0QW6f2LA}]
iteration [14] - shard failures: []
iteration [15] - shard failures: [ShardSearchFailure{reason=java.lang.IllegalArgumentException: Fielddata is disabled on text fields by default. Set fielddata=true on [name] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory., index=my_index, shardId=[my_index][3], nodeId=UHJjxL5rQgqz4f0QW6f2LA}]
--> healing disconnect1 and disconnect2
--> healing disconnect2 and disconnect1
--> healing disconnect1 and disconnect1
--> healing disconnect2 and disconnect2
--> healing disconnect1 and null
--> healing null and disconnect2
--> healing null and null
--> healing disconnect1 and undefined
--> healing undefined and disconnect2
--> healing undefined and undefined
--> healing disconnect1 and error
--> healing error and disconnect2
--> healing error and error
--> healing disconnect1 and timeout
--> healing timeout and disconnect2
error while reading request for trace purposes java.io.IOException: Connection reset by peer
error while reading request for trace purposes java.lang.NullPointerException: Request body is null
error while reading request for trace purposes java.net.SocketTimeoutException: Read timed out
error while reading request for trace purposes java.lang.IllegalArgumentException: Invalid request format
error while reading request for trace purposes javax.net.ssl.SSLHandshakeException: No appropriate protocol
error while reading request for trace purposes org.json.JSONException: A JSONObject text must begin with '{'
error while reading request for trace purposes java.io.EOFException: End of input at line 1 column 1 path $
error while reading request for trace purposes java.lang.OutOfMemoryError: Java heap space
error while reading request for trace purposes java.lang.SecurityException: Permission denied
error while reading request for trace purposes java.io.FileNotFoundException: No such file or directory
error while reading request for trace purposes java.net.URISyntaxException: Illegal character in path
error while reading request for trace purposes java.util.zip.ZipException: invalid entry CRC
error while reading request for trace purposes org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 1; Content is not allowed in prolog.
error while reading request for trace purposes java.lang.ClassNotFoundException: com.example.RequestHandler
error while reading request for trace purposes java.lang.StackOverflowError
using dynamic transport addresses [localhost:8080]
using dynamic transport addresses [192.168.1.100:3000]
using dynamic transport addresses [mydomain.com:443]
using dynamic transport addresses [10.0.0.1:80]
using dynamic transport addresses [172.16.0.2:22]
using dynamic transport addresses [127.0.0.1:8000]
using dynamic transport addresses [example.com:8081]
using dynamic transport addresses [192.168.0.101:5000]
using dynamic transport addresses [localhost:3001]
using dynamic transport addresses [10.0.0.2:443]
using dynamic transport addresses [172.16.0.3:21]
using dynamic transport addresses [127.0.0.1:9000]
using dynamic transport addresses [example.com:8082]
using dynamic transport addresses [192.168.1.102:4000]
using dynamic transport addresses [localhost:3002]
Path 2 [/home/user/documents]
Path 2 [/var/log/syslog]
Path 2 [C:\Windows\System32]
Path 2 [/usr/local/bin/python3]
Path 2 [D:\Games\Steam]
Path 2 [/etc/hosts]
Path 2 [C:\Users\Alice\Pictures]
Path 2 [/opt/apache-tomcat-9.0.54]
Path 2 [E:\Music\iTunes]
Path 2 [/dev/sda1]
Path 2 [C:\Program Files\Java\jdk-17.0.1]
Path 2 [/tmp/cache]
Path 2 [D:\Videos\Movies]
Path 2 [/root/.ssh/id_rsa]
Path 2 [E:\Books\PDF]
Removing node from cluster info: node-1
Removing node from cluster info: node-2
Removing node from cluster info: node-3
Removing node from cluster info: node-4
Removing node from cluster info: node-5
Removing node from cluster info: node-6
Removing node from cluster info: node-7
Removing node from cluster info: node-8
Removing node from cluster info: node-9
Removing node from cluster info: node-10
Removing node from cluster info: node-11
Removing node from cluster info: node-12
Removing node from cluster info: node-13
Removing node from cluster info: node-14
Removing node from cluster info: node-15
Iterated 10 time for 1633022400000 using {interval=1d, offset=0, timeZone=UTC}
Iterated 20 time for 1633108800000 using {interval=12h, offset=0, timeZone=UTC}
Iterated 15 time for 1633195200000 using {interval=8h, offset=0, timeZone=UTC}
Iterated 12 time for 1633281600000 using {interval=6h, offset=0, timeZone=UTC}
Iterated 18 time for 1633368000000 using {interval=4h, offset=0, timeZone=UTC}
Iterated 16 time for 1633454400000 using {interval=3h, offset=0, timeZone=UTC}
Iterated 14 time for 1633540800000 using {interval=2h, offset=0, timeZone=UTC}
Iterated 11 time for 1633627200000 using {interval=90m, offset=0, timeZone=UTC}
Iterated 13 time for 1633713600000 using {interval=60m, offset=0, timeZone=UTC}
Iterated 17 time for 1633800000000 using {interval=45m, offset=0, timeZone=UTC}
Iterated 9 time for 1633886400000 using {interval=30m, offset=0, timeZone=UTC}
Iterated 19 time for 1633972800000 using {interval=20m, offset=0, timeZone=UTC}
Iterated 21 time for 1634059200000 using {interval=15m, offset=0, timeZone=UTC}
Iterated 23 time for 1634145600000 using {interval=10m, offset=0, timeZone=UTC}
Iterated 25 time for 1634232000000 using {interval=5m, offset=0, timeZone=UTC}
cannot close blob store java.io.IOException: Stream closed
cannot close blob store java.lang.NullPointerException: Blob store is null
cannot close blob store java.nio.file.AccessDeniedException: Permission denied
cannot close blob store java.util.concurrent.TimeoutException: Operation timed out
cannot close blob store org.elasticsearch.common.blobstore.BlobStoreException: Failed to delete blob
cannot close blob store org.elasticsearch.common.blobstore.BlobStoreException: Blob store is already closed
cannot close blob store org.elasticsearch.common.blobstore.BlobStoreException: Blob store is corrupted
cannot close blob store org.elasticsearch.common.blobstore.BlobStoreException: Blob store is not initialized
cannot close blob store org.elasticsearch.common.blobstore.BlobStoreException: Blob store is read-only
cannot close blob store org.elasticsearch.common.blobstore.BlobStoreException: Blob store is full
cannot close blob store org.elasticsearch.common.blobstore.BlobStoreException: Blob store is offline
cannot close blob store org.elasticsearch.common.blobstore.BlobStoreException: Blob store is locked
cannot close blob store org.elasticsearch.common.blobstore.BlobStoreException: Blob store is incompatible
cannot close blob store org.elasticsearch.common.blobstore.BlobStoreException: Blob store is outdated
cannot close blob store org.elasticsearch.common.blobstore.BlobStoreException: Blob store is unavailable
top warming took [1.2ms]
top warming took [2.5ms]
top warming took [3.1ms]
top warming took [4.3ms]
top warming took [5.6ms]
top warming took [6.8ms]
top warming took [7.9ms]
top warming took [9.2ms]
top warming took [10.4ms]
top warming took [11.7ms]
top warming took [12.9ms]
top warming took [14.1ms]
top warming took [15.3ms]
top warming took [16.6ms]
top warming took [17.8ms]
Hole intersections (0.5, 0.3): [0.2, 0.4, 0.6, 0.8]
Hole intersections (1.2, -0.7): [-0.3, -0.1, 0.1, 0.3]
Hole intersections (-0.4, 0.9): [0.6, 0.8, 1.0, 1.2]
Hole intersections (0.7, -1.3): [-1.6, -1.4, -1.2, -1.0]
Hole intersections (-1.1, 1.4): [1.2, 1.6, 2.0, 2.4]
Hole intersections (1.5, 0.6): [0.4, 0.8, 1.2, 1.6]
Hole intersections (-0.9, -0.5): [-1.2, -0.8, -0.4, 0]
Hole intersections (0.3, 1.7): [1.4, 1.8, 2.2, 2.6]
Hole intersections (-1.4, -1): [-1.8, -1.6, -1.4, -1]
Hole intersections (1, -0.9): [-1.3, -1.1, -0.9, -0.7]
Hole intersections (-0.6, 0): [-0.4, -0, 0, 0]
Hole intersections (0, -1): [-1, -8, -6, -4]
Hole intersections (-1, -5): [-1, -75, -5, -25]
Hole intersections (5, 75): [.25, 5, 75, 875]
Hole intersections (-75, -50): [-100, -75, -50, -25]
Explanation for [name] / [123] / [John Smith]: [Matched on first and last name]
Explanation for [age] / [456] / [25]: [Matched on exact value]
Explanation for [gender] / [789] / [male]: [Matched on exact value]
Explanation for [address] / [1011] / [123 Main Street, San Jose, CA]: [Matched on street name and city]
Explanation for [phone] / [1213] / [(408) 555-1234]: [Matched on area code and last four digits]
Explanation for [email] / [1415] / [john.smith@example.com]: [Matched on username and domain name]
Explanation for [occupation] / [1617] / [Software Engineer]: [Matched on partial value]
Explanation for [hobby] / [1819] / [cricket]: [Matched on exact value]
Explanation for [education] / [2021] / [Bachelor of Science in Computer Science]: [Matched on degree and major]
Explanation for [salary] / [2223] / [$100,000]: [Matched on range]
Explanation for [marital status] / [2425] / [single]: [Matched on exact value]
Explanation for [pets] / [2627] / [dog]: [Matched on exact value]
Explanation for [favorite color] / [2829] / [blue]: [Matched on exact value]
Explanation for [favorite movie] / [3031] / [The Matrix]: [Matched on title]
Adding 3 nodes and performing rerouting
Adding 5 nodes and performing rerouting
Adding 2 nodes and performing rerouting
Adding 4 nodes and performing rerouting
Adding 6 nodes and performing rerouting
Adding 7 nodes and performing rerouting
Adding 8 nodes and performing rerouting
Adding 9 nodes and performing rerouting
Adding 10 nodes and performing rerouting
Adding 11 nodes and performing rerouting
Adding 12 nodes and performing rerouting
Adding 13 nodes and performing rerouting
Adding 14 nodes and performing rerouting
Adding 15 nodes and performing rerouting
Adding 16 nodes and performing rerouting
checking warningOption= true and warnings= ["Invalid input", "File not found"]
checking warningOption= false and warnings= []
checking warningOption= true and warnings= ["Network error", "Timeout"]
checking warningOption= false and warnings= ["Memory leak"]
checking warningOption= true and warnings= ["Syntax error", "Division by zero"]
checking warningOption= false and warnings= ["Access denied", "Permission denied"]
checking warningOption= true and warnings= ["Null pointer exception", "Index out of bounds"]
checking warningOption= false and warnings= ["Disk full", "Corrupted file"]
checking warningOption= true and warnings= ["Unresolved reference", "Type mismatch"]
checking warningOption= false and warnings= ["Unexpected end of file", "Invalid format"]
checking warningOption= true and warnings= ["Stack overflow", "Recursion limit exceeded"]
checking warningOption= false and warnings= ["Key error", "Value error"]
checking warningOption= true and warnings= ["Name error", "Attribute error"]
checking warningOption= false and warnings= ["IO error", "Broken pipe"]
checking warningOption= true and warnings= ["Assertion error", "Runtime error"]
unexpected failure occurred during decommission status update java.lang.NullPointerException
unexpected failure occurred during decommission status update java.io.IOException: Connection reset by peer
unexpected failure occurred during decommission status update org.springframework.dao.DataAccessException: SQL Error: 1064, SQLState: 42000
unexpected failure occurred during decommission status update java.lang.IllegalStateException: Cannot update status of a non-existent node
unexpected failure occurred during decommission status update java.lang.OutOfMemoryError: Java heap space
unexpected failure occurred during decommission status update java.net.SocketTimeoutException: Read timed out
unexpected failure occurred during decommission status update org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /decommission/node1
unexpected failure occurred during decommission status update java.lang.InterruptedException: Thread interrupted while waiting for lock
unexpected failure occurred during decommission status update java.util.concurrent.ExecutionException: java.lang.RuntimeException: Decommission failed
unexpected failure occurred during decommission status update javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure
unexpected failure occurred during decommission status update org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /decommission/node2. Name node is in safe mode.
unexpected failure occurred during decommission status update java.lang.SecurityException: Permission denied for user admin to perform action delete on resource /decommission/node3
unexpected failure occurred during decommission status update java.lang.ClassNotFoundException: com.example.DecommissionService
unexpected failure occurred during decommission status update java.lang.NoSuchMethodError: com.example.DecommissionService.updateStatus(Ljava/lang/String;Ljava/lang/String;)V
unexpected failure occurred during decommission status update java.lang.StackOverflowError
[0] [1] Loading store metadata using index commit [2]
[3] [4] Loading store metadata using index commit [5]
[6] [7] Loading store metadata using index commit [8]
[9] [10] Loading store metadata using index commit [11]
[12] [13] Loading store metadata using index commit [14]
[15] [16] Loading store metadata using index commit [17]
[18] [19] Loading store metadata using index commit [20]
[21] [22] Loading store metadata using index commit [23]
[24] [25] Loading store metadata using index commit [26]
[27] [28] Loading store metadata using index commit [29]
[30] [31] Loading store metadata using index commit [32]
[33] [34] Loading store metadata using index commit [35]
[36] [37] Loading store metadata using index commit [38]
[39] [40] Loading store metadata using index commit [41]
[42] [43] Loading store metadata using index commit [44]
--> routed search on index [products] visited [5] shards for routing [category:electronics] and got hits [23]
--> routed search on index [news] visited [3] shards for routing [date:2023-10-27] and got hits [12]
--> routed search on index [users] visited [4] shards for routing [name:alice] and got hits [1]
--> routed search on index [books] visited [6] shards for routing [author:rowling] and got hits [7]
--> routed search on index [movies] visited [2] shards for routing [genre:comedy] and got hits [15]
--> routed search on index [blogs] visited [8] shards for routing [tag:microsoft] and got hits [9]
--> routed search on index [recipes] visited [7] shards for routing [ingredient:chocolate] and got hits [13]
--> routed search on index [sports] visited [4] shards for routing [team:lakers] and got hits [11]
--> routed search on index [music] visited [3] shards for routing [artist:beyonce] and got hits [8]
--> routed search on index [events] visited [5] shards for routing [location:redmond] and got hits [6]
--> routed search on index [jobs] visited [6] shards for routing [salary:>100000] and got hits [10]
--> routed search on index [reviews] visited [7] shards for routing [rating:>4.5] and got hits [14]
--> routed search on index [tweets] visited [2] shards for routing [#bingbotrocks!] and got hits [17]
--> primary store after force merge [segments_1, segments_2, segments_3, segments.gen, write.lock]
--> primary store after force merge [segments_4, segments_5, segments_6, segments.gen, write.lock]
--> primary store after force merge [segments_7, segments_8, segments_9, segments.gen, write.lock]
--> primary store after force merge [segments_10, segments_11, segments_12, segments.gen, write.lock]
--> primary store after force merge [segments_13, segments_14, segments_15, segments.gen, write.lock]
--> primary store after force merge [segments_16, segments_17, segments_18, segments.gen, write.lock]
--> primary store after force merge [segments_19, segments_20, segments_21, segments.gen, write.lock]
--> primary store after force merge [segments_22, segments_23, segments_24, segments.gen, write.lock]
--> primary store after force merge [segments_25, segments_26, segments_27, segments.gen, write.lock]
--> primary store after force merge [segments_28, segments_29, segments_30, segments.gen, write.lock]
--> primary store after force merge [segments_31, segments_32, segments_33, segments.gen, write.lock]
--> primary store after force merge [segments_34, segments_35, segments_36, segments.gen, write.lock]
--> primary store after force merge [segments_37, segments_38, segments_39, segments.gen, write.lock]
--> primary store after force merge [segments_40, segments_41, segments_42, segments.gen, write.lock]
--> primary store after force merge [segments_43, segments_44, segments_45, segments.gen, write.lock]
--> deleting index [users]
--> deleting index [products]
--> deleting index [orders]
--> deleting index [reviews]
--> deleting index [categories]
--> deleting index [customers]
--> deleting index [invoices]
--> deleting index [inventory]
--> deleting index [sales]
--> deleting index [employees]
--> deleting index [suppliers]
--> deleting index [messages]
--> deleting index [logs]
--> deleting index [settings]
--> deleting index [reports]
--> create snapshot my_repo : daily_backup
--> create snapshot test_repo : bug_fix
--> create snapshot demo_repo : new_feature
--> create snapshot music_repo : playlist_update
--> create snapshot photo_repo : image_edit
--> create snapshot game_repo : save_state
--> create snapshot work_repo : project_report
--> create snapshot blog_repo : post_draft
--> create snapshot video_repo : clip_trim
--> create snapshot book_repo : chapter_review
--> create snapshot art_repo : sketch_refine
--> create snapshot code_repo : version_control
--> create snapshot math_repo : problem_solve
--> create snapshot food_repo : recipe_share
--> create snapshot travel_repo : trip_plan
VERBOSE custom metadata names: [index-graveyard, ingest-geoip, ingest-user-agent]
VERBOSE custom metadata names: [ml, index-lifecycle-history, license]
VERBOSE custom metadata names: [snapshot_deletions, transforms, watcher]
VERBOSE custom metadata names: [ilm-history-2-000001, ml-config, rollup]
VERBOSE custom metadata names: [autoscaling, data-streams-stats, enrich]
VERBOSE custom metadata names: [slm-history-2-000001, ml-meta, security-tokens-7]
VERBOSE custom metadata names: [ilm-history-1-000001, ml-state, security-tokens-6]
VERBOSE custom metadata names: [slm-history-1-000001, ml-stats, security-tokens-5]
VERBOSE custom metadata names: [index-graveyard, ml-inference, security-tokens-4]
VERBOSE custom metadata names: [ml-anomalies-, ml-notifications-000001, security-tokens-3]
VERBOSE custom metadata names: [ml-anomalies-shared, ml-results-write-accessor, security-tokens-2]
VERBOSE custom metadata names: [ml-meta-write-accessor, ml-results-read-accessor, security-tokens-1]
VERBOSE custom metadata names: [ml-config-write-accessor, ml-results-write-accessor, security-tokens-0]
VERBOSE custom metadata names: [ml-config-read-accessor, ml-results-read-accessor, security-tokens-default]
VERBOSE custom metadata names: [ml-inference-write-accessor, ml-results-write-accessor, security-tokens-default]
delaying recovery of [0] as it is not listed as assigned to target node [node-1]
delaying recovery of [1] as it is not listed as assigned to target node [node-2]
delaying recovery of [2] as it is not listed as assigned to target node [node-3]
delaying recovery of [3] as it is not listed as assigned to target node [node-4]
delaying recovery of [4] as it is not listed as assigned to target node [node-5]
delaying recovery of [5] as it is not listed as assigned to target node [node-6]
delaying recovery of [6] as it is not listed as assigned to target node [node-7]
delaying recovery of [7] as it is not listed as assigned to target node [node-8]
delaying recovery of [8] as it is not listed as assigned to target node [node-9]
delaying recovery of [9] as it is not listed as assigned to target node [node-10]
delaying recovery of [10] as it is not listed as assigned to target node [node-11]
delaying recovery of [11] as it is not listed as assigned to target node [node-12]
delaying recovery of [12] as it is not listed as assigned to target node [node-13]
delaying recovery of [13] as it is not listed as assigned to target node [node-14]
delaying recovery of [14] as it is not listed as assigned to target node [node-15]
failed to access searcher manager java.lang.NullPointerException
failed to access searcher manager java.io.IOException: Connection refused
failed to access searcher manager java.lang.IllegalStateException: Searcher manager is closed
failed to access searcher manager java.lang.InterruptedException: Thread interrupted
failed to access searcher manager java.util.concurrent.TimeoutException: Timeout waiting for searcher manager
failed to access searcher manager org.apache.lucene.index.IndexNotFoundException: no segments* file found in ...
failed to access searcher manager org.apache.lucene.store.LockObtainFailedException: Lock held by another process
failed to access searcher manager org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) ...
failed to access searcher manager org.apache.lucene.search.QueryTimeoutException: Query exceeded maximum time allowed
failed to access searcher manager org.apache.lucene.index.MergePolicy$MergeException: IOException while merging segments
failed to access searcher manager java.lang.OutOfMemoryError: Java heap space
failed to access searcher manager java.lang.StackOverflowError
failed to access searcher manager java.lang.UnsupportedOperationException: This operation is not supported by this searcher manager
failed to access searcher manager java.lang.SecurityException: Access denied by security policy
failed to access searcher manager java.lang.ClassCastException: Cannot cast ... to ...
not removing node [1] as it holds a primary with no replacement
not removing node [5] as it holds a primary with no replacement
not removing node [7] as it holds a primary with no replacement
not removing node [10] as it holds a primary with no replacement
not removing node [12] as it holds a primary with no replacement
not removing node [15] as it holds a primary with no replacement
not removing node [17] as it holds a primary with no replacement
not removing node [20] as it holds a primary with no replacement
not removing node [23] as it holds a primary with no replacement
not removing node [25] as it holds a primary with no replacement
not removing node [28] as it holds a primary with no replacement
not removing node [30] as it holds a primary with no replacement
not removing node [32] as it holds a primary with no replacement
not removing node [35] as it holds a primary with no replacement
not removing node [37] as it holds a primary with no replacement
0 failed to load shard path, trying to remove leftover
1 failed to load shard path, trying to remove leftover
2 failed to load shard path, trying to remove leftover
3 failed to load shard path, trying to remove leftover
4 failed to load shard path, trying to remove leftover
5 failed to load shard path, trying to remove leftover
6 failed to load shard path, trying to remove leftover
7 failed to load shard path, trying to remove leftover
8 failed to load shard path, trying to remove leftover
9 failed to load shard path, trying to remove leftover
10 failed to load shard path, trying to remove leftover
11 failed to load shard path, trying to remove leftover
12 failed to load shard path, trying to remove leftover
13 failed to load shard path, trying to remove leftover
14 failed to load shard path, trying to remove leftover
failed to invoke on store created NullPointerException
failed to invoke on store created TimeoutException
failed to invoke on store created IOException
failed to invoke on store created OutOfMemoryError
failed to invoke on store created SecurityException
failed to invoke on store created IllegalArgumentException
failed to invoke on store created ClassNotFoundException
failed to invoke on store created AssertionError
failed to invoke on store created UnsupportedOperationException
failed to invoke on store created SQLException
failed to invoke on store created NumberFormatException
failed to invoke on store created IndexOutOfBoundsException
failed to invoke on store created ConcurrentModificationException
failed to invoke on store created NoSuchMethodException
failed to invoke on store created NoClassDefFoundError
verification of shards for 0 succeeded, but block finalization already occurred (possibly for another block) [false]
verification of shards for 1 succeeded, but block finalization already occurred (possibly for another block) [true]
verification of shards for 2 succeeded, but block finalization already occurred (possibly for another block) [false]
verification of shards for 3 succeeded, but block finalization already occurred (possibly for another block) [true]
verification of shards for 4 succeeded, but block finalization already occurred (possibly for another block) [false]
verification of shards for 5 succeeded, but block finalization already occurred (possibly for another block) [true]
verification of shards for 6 succeeded, but block finalization already occurred (possibly for another block) [false]
verification of shards for 7 succeeded, but block finalization already occurred (possibly for another block) [true]
verification of shards for 8 succeeded, but block finalization already occurred (possibly for another block) [false]
verification of shards for 9 succeeded, but block finalization already occurred (possibly for another block) [true]
verification of shards for 10 succeeded, but block finalization already occurred (possibly for another block) [false]
verification of shards for 11 succeeded, but block finalization already occurred (possibly for another block) [true]
verification of shards for 12 succeeded, but block finalization already occurred (possibly for another block) [false]
verification of shards for 13 succeeded, but block finalization already occurred (possibly for another block) [true]
verification of shards for 14 succeeded, but block finalization already occurred (possibly for another block) [false]
building cluster state with weighted routing weights [0.5]
building cluster state with weighted routing weights [0.8]
building cluster state with weighted routing weights [0.2]
building cluster state with weighted routing weights [0.6]
building cluster state with weighted routing weights [0.4]
building cluster state with weighted routing weights [0.9]
building cluster state with weighted routing weights [0.3]
building cluster state with weighted routing weights [0.7]
building cluster state with weighted routing weights [1.0]
building cluster state with weighted routing weights [0.1]
building cluster state with weighted routing weights [0.55]
building cluster state with weighted routing weights [0.75]
building cluster state with weighted routing weights [0.25]
building cluster state with weighted routing weights [0.65]
building cluster state with weighted routing weights [0.35]
weights are same, not updating weighted routing weights [0.5] in metadata
weights are same, not updating weighted routing weights [0.25] in metadata
weights are same, not updating weighted routing weights [0.75] in metadata
weights are same, not updating weighted routing weights [0.1] in metadata
weights are same, not updating weighted routing weights [0.9] in metadata
weights are same, not updating weighted routing weights [0.4] in metadata
weights are same, not updating weighted routing weights [0.6] in metadata
weights are same, not updating weighted routing weights [0.2] in metadata
weights are same, not updating weighted routing weights [0.8] in metadata
weights are same, not updating weighted routing weights [0.3] in metadata
weights are same, not updating weighted routing weights [0.7] in metadata
weights are same, not updating weighted routing weights [0.15] in metadata
weights are same, not updating weighted routing weights [0.85] in metadata
weights are same, not updating weighted routing weights [0.05] in metadata
weights are same, not updating weighted routing weights [0.95] in metadata
failed to prepare/warm NullPointerException
failed to prepare/warm IOException
failed to prepare/warm OutOfMemoryError
failed to prepare/warm SQLException
failed to prepare/warm ClassNotFoundException
failed to prepare/warm IllegalArgumentException
failed to prepare/warm IndexOutOfBoundsException
failed to prepare/warm AssertionError
failed to prepare/warm NumberFormatException
failed to prepare/warm SecurityException
failed to prepare/warm FileNotFoundException
failed to prepare/warm InterruptedException
failed to prepare/warm TimeoutException
failed to prepare/warm MalformedURLException
failed to prepare/warm UnsupportedOperationException
Reading input stream [index_1] of length - [1024]
Reading input stream [index_2] of length - [2048]
Reading input stream [index_3] of length - [512]
Reading input stream [index_4] of length - [4096]
Reading input stream [index_5] of length - [256]
Reading input stream [index_6] of length - [8192]
Reading input stream [index_7] of length - [128]
Reading input stream [index_8] of length - [16384]
Reading input stream [index_9] of length - [64]
Reading input stream [index_10] of length - [32768]
Reading input stream [index_11] of length - [32]
Reading input stream [index_12] of length - [65536]
Reading input stream [index_13] of length - [16]
Reading input stream [index_14] of length - [131072]
Reading input stream [index_15] of length - [8]
Bulk [e3f1] completed in 12 milliseconds
Bulk [a4b2] completed in 15 milliseconds
Bulk [c5d3] completed in 9 milliseconds
Bulk [f6e4] completed in 11 milliseconds
Bulk [g7h5] completed in 13 milliseconds
Bulk [i8j6] completed in 10 milliseconds
Bulk [k9l7] completed in 14 milliseconds
Bulk [m0n8] completed in 8 milliseconds
Bulk [o1p9] completed in 16 milliseconds
Bulk [q2r0] completed in 7 milliseconds
Bulk [s3t1] completed in 17 milliseconds
Bulk [u4v2] completed in 6 milliseconds
Bulk [w5x3] completed in 18 milliseconds
Bulk [y6z4] completed in 5 milliseconds
Bulk [a7b5] completed in 19 milliseconds
Executing bulk [e5f6a3] with 100 requests
Executing bulk [4d2c9b] with 50 requests
Executing bulk [9a7b4c] with 200 requests
Executing bulk [6f3e8d] with 75 requests
Executing bulk [b8c5a6] with 150 requests
Executing bulk [3d9e7f] with 25 requests
Executing bulk [c4a2b9] with 125 requests
Executing bulk [7f6e3c] with 175 requests
Executing bulk [a5b3d8] with 300 requests
Executing bulk [d8c6a4] with 400 requests
Executing bulk [2e9f7b] with 350 requests
Executing bulk [f7a5c3] with 450 requests
Executing bulk [5c2d9a] with 500 requests
Executing bulk [8b4e6d] with 550 requests
Executing bulk [c9a2f4] with 600 requests
write indexing buffer to disk for shard [0] to free up its [1.2 GB] indexing buffer
write indexing buffer to disk for shard [3] to free up its [512 MB] indexing buffer
write indexing buffer to disk for shard [7] to free up its [2.4 GB] indexing buffer
write indexing buffer to disk for shard [1] to free up its [768 MB] indexing buffer
write indexing buffer to disk for shard [4] to free up its [1.6 GB] indexing buffer
write indexing buffer to disk for shard [8] to free up its [3.2 GB] indexing buffer
write indexing buffer to disk for shard [2] to free up its [640 MB] indexing buffer
write indexing buffer to disk for shard [5] to free up its [1.8 GB] indexing buffer
write indexing buffer to disk for shard [9] to free up its [4 GB] indexing buffer
write indexing buffer to disk for shard [6] to free up its [2 GB] indexing buffer
write indexing buffer to disk for shard [10] to free up its [4.8 GB] indexing buffer
write indexing buffer to disk for shard [11] to free up its [5.6 GB] indexing buffer
write indexing buffer to disk for shard [12] to free up its [6.4 GB] indexing buffer
write indexing buffer to disk for shard [13] to free up its [7.2 GB] indexing buffer
write indexing buffer to disk for shard [14] to free up its [8 GB] indexing buffer
Couldn't mark store corrupted java.io.IOException
Couldn't mark store corrupted java.lang.NullPointerException
Couldn't mark store corrupted java.nio.file.FileSystemException
Couldn't mark store corrupted java.sql.SQLException
Couldn't mark store corrupted java.lang.IllegalArgumentException
Couldn't mark store corrupted java.lang.OutOfMemoryError
Couldn't mark store corrupted java.lang.ClassNotFoundException
Couldn't mark store corrupted java.net.SocketException
Couldn't mark store corrupted java.util.ConcurrentModificationException
Couldn't mark store corrupted java.lang.SecurityException
Couldn't mark store corrupted java.lang.NoSuchMethodError
Couldn't mark store corrupted java.lang.StackOverflowError
Couldn't mark store corrupted java.util.zip.ZipException
Couldn't mark store corrupted java.lang.UnsupportedOperationException
Couldn't mark store corrupted java.time.DateTimeException
IndexingPressure memory is adjusted twice org.elasticsearch.index.shard.IndexShard.close(IndexShard.java:1185)
IndexingPressure memory is adjusted twice org.elasticsearch.indices.IndicesService.deleteIndex(IndicesService.java:797)
IndexingPressure memory is adjusted twice org.elasticsearch.index.engine.Engine.close(Engine.java:1734)
IndexingPressure memory is adjusted twice org.elasticsearch.index.IndexService.closeShard(IndexService.java:457)
IndexingPressure memory is adjusted twice org.elasticsearch.index.translog.Translog.close(Translog.java:561)
IndexingPressure memory is adjusted twice org.elasticsearch.index.store.Store.close(Store.java:419)
IndexingPressure memory is adjusted twice org.elasticsearch.index.mapper.MapperService.close(MapperService.java:783)
IndexingPressure memory is adjusted twice org.elasticsearch.index.analysis.AnalysisRegistry.close(AnalysisRegistry.java:584)
IndexingPressure memory is adjusted twice org.elasticsearch.index.cache.query.QueryCache.close(QueryCache.java:91)
IndexingPressure memory is adjusted twice org.elasticsearch.index.cache.bitset.BitsetFilterCache.close(BitsetFilterCache.java:262)
IndexingPressure memory is adjusted twice org.elasticsearch.index.fielddata.IndexFieldDataService.close(IndexFieldDataService.java:174)
IndexingPressure memory is adjusted twice org.elasticsearch.index.similarity.SimilarityService.close(SimilarityService.java:151)
IndexingPressure memory is adjusted twice org.elasticsearch.index.seqno.RetentionLeaseSyncer.close(RetentionLeaseSyncer.java:113)
IndexingPressure memory is adjusted twice org.elasticsearch.index.seqno.ReplicationTracker.close(ReplicationTracker.java:379)
IndexingPressure memory is adjusted twice org.elasticsearch.common.util.concurrent.ReleasableLock.close(ReleasableLock.java:83)
node: [1], most available: total disk: 500 GB, available disk: 300 GB / least available: total disk: 100 GB, available disk: 10 GB
node: [2], most available: total disk: 400 GB, available disk: 250 GB / least available: total disk: 200 GB, available disk: 50 GB
node: [3], most available: total disk: 600 GB, available disk: 400 GB / least available: total disk: 300 GB, available disk: 100 GB
node: [4], most available: total disk: 800 GB, available disk: 600 GB / least available: total disk: 400 GB, available disk: 150 GB
node: [5], most available: total disk: 700 GB, available disk: 500 GB / least available: total disk: 350 GB, available disk: 120 GB
node: [6], most available: total disk: 900 GB, available disk: 700 GB / least available: total disk: 450 GB, available disk: 200 GB
node: [7], most available: total disk: 1000 GB, available disk: 800 GB / least available: total disk: 500 GB, available disk: 250 GB
node: [8], most available: total disk: 1100 GB, available disk: 900 GB / least available: total disk: 550 GB, available disk: 300 GB
node: [9], most available: total disk: 1200 GB, available disk: 1000 GB / least available: total disk: 600 GB, available disk: 350 GB
Repository [my-app] closed during cool-down period
Repository [test-data] closed during cool-down period
Repository [config] closed during cool-down period
Repository [docs] closed during cool-down period
Repository [images] closed during cool-down period
Repository [scripts] closed during cool-down period
Repository [models] closed during cool-down period
Repository [logs] closed during cool-down period
Repository [backup] closed during cool-down period
Repository [demo] closed during cool-down period
Repository [utils] closed during cool-down period
Repository [samples] closed during cool-down period
Repository [reports] closed during cool-down period
Repository [assets] closed during cool-down period
Repository [cache] closed during cool-down period
put repository [user-profile]
put repository [product-catalog]
put repository [order-history]
put repository [shopping-cart]
put repository [inventory-management]
put repository [customer-feedback]
put repository [payment-processing]
put repository [shipping-tracking]
put repository [recommendation-engine]
put repository [analytics-dashboard]
put repository [security-logs]
put repository [error-reports]
put repository [backup-files]
put repository [email-templates]
put repository [web-design]
Running SortTask with 10 warmup iterations and 100 iterations.
Running SearchTask with 5 warmup iterations and 50 iterations.
Running MergeTask with 20 warmup iterations and 200 iterations.
Running FilterTask with 15 warmup iterations and 150 iterations.
Running MapTask with 8 warmup iterations and 80 iterations.
Running ReduceTask with 12 warmup iterations and 120 iterations.
Running ShuffleTask with 6 warmup iterations and 60 iterations.
Running JoinTask with 18 warmup iterations and 180 iterations.
Running GroupTask with 9 warmup iterations and 90 iterations.
Running AggregateTask with 7 warmup iterations and 70 iterations.
Running ScanTask with 11 warmup iterations and 110 iterations.
Running SplitTask with 13 warmup iterations and 130 iterations.
Running CountTask with 14 warmup iterations and 140 iterations.
Running SumTask with 16 warmup iterations and 160 iterations.
Running AverageTask with 17 warmup iterations and 170 iterations.
Start iteration [0]
Start iteration [1]
Start iteration [2]
Start iteration [3]
Start iteration [4]
Start iteration [5]
Start iteration [6]
Start iteration [7]
Start iteration [8]
Start iteration [9]
Start iteration [10]
Start iteration [11]
Start iteration [12]
Start iteration [13]
Start iteration [14]
snapshot shard size for shard1 : 1024 bytes
snapshot shard size for shard2 : 2048 bytes
snapshot shard size for shard3 : 4096 bytes
snapshot shard size for shard4 : 8192 bytes
snapshot shard size for shard5 : 16384 bytes
snapshot shard size for shard6 : 32768 bytes
snapshot shard size for shard7 : 65536 bytes
snapshot shard size for shard8 : 131072 bytes
snapshot shard size for shard9 : 262144 bytes
snapshot shard size for shard10 : 524288 bytes
snapshot shard size for shard11 : 1048576 bytes
snapshot shard size for shard12 : 2097152 bytes
snapshot shard size for shard13 : 4194304 bytes
snapshot shard size for shard14 : 8388608 bytes
snapshot shard size for shard15 : 16777216 bytes
executing IndexCreationTask for [create index [test]] against cluster state version [1]
executing IndexCreationTask for [delete index [test]] against cluster state version [2]
executing IndexCreationTask for [create index [demo]] against cluster state version [3]
executing IndexCreationTask for [delete index [demo]] against cluster state version [4]
executing IndexCreationTask for [create index [foo]] against cluster state version [5]
executing IndexCreationTask for [delete index [foo]] against cluster state version [6]
executing IndexCreationTask for [create index [bar]] against cluster state version [7]
executing IndexCreationTask for [delete index [bar]] against cluster state version [8]
executing IndexCreationTask for [create index [baz]] against cluster state version [9]
executing IndexCreationTask for [delete index [baz]] against cluster state version [10]
executing IndexCreationTask for [create index [qux]] against cluster state version [11]
executing IndexCreationTask for [delete index [qux]] against cluster state version [12]
executing IndexCreationTask for [create index [quux]] against cluster state version [13]
executing IndexCreationTask for [delete index [quux]] against cluster state version [14]
executing IndexCreationTask for [create index [corge]] against cluster state version [15]
ERROR : from file: C:\Users\John\Documents\report.txt , exception is: java.io.FileNotFoundException
INFO : from file: /home/mary/images/logo.png , exception is: None
DEBUG : from file: /var/log/system.log , exception is: java.lang.SecurityException
WARN : from file: D:\Games\save.dat , exception is: java.io.IOException
TRACE : from file: /tmp/test.csv , exception is: java.lang.NullPointerException
FATAL : from file: C:\Windows\system32\config\system , exception is: java.lang.OutOfMemoryError
ERROR : from file: /etc/passwd , exception is: java.nio.file.AccessDeniedException
INFO : from file: /usr/local/bin/hello.sh , exception is: None
DEBUG : from file: C:\Program Files\Java\jdk-11\bin\java.exe , exception is: java.lang.UnsupportedClassVersionError
WARN : from file: /dev/null , exception is: java.io.EOFException
TRACE : from file: /opt/data.json , exception is: org.json.JSONException
FATAL : from file: D:\Music\song.mp3 , exception is: java.lang.StackOverflowError
ERROR : from file: /home/bob/.bashrc , exception is: java.io.InvalidClassException
INFO : from file: C:\Users\Alice\Desktop\resume.docx , exception is: None
DEBUG : from file: /var/www/html/index.html , exception is: javax.servlet.ServletException
--> restoring snapshot_20211025_145949
--> restoring snapshot_20211024_230015
--> restoring snapshot_20211023_081237
--> restoring snapshot_20211022_174512
--> restoring snapshot_20211021_092645
--> restoring snapshot_20211020_203058
--> restoring snapshot_20211019_110433
--> restoring snapshot_20211018_221946
--> restoring snapshot_20211017_133321
--> restoring snapshot_20211016_044804
--> restoring snapshot_20211015_160139
--> restoring snapshot_20211014_071552
--> restoring snapshot_20211013_182905
--> restoring snapshot_20211012_094240
File report.pdf was not deleted and is not pending delete, attempting delete again...
File image.jpg was not deleted and is not pending delete, attempting delete again...
File data.csv was not deleted and is not pending delete, attempting delete again...
File music.mp3 was not deleted and is not pending delete, attempting delete again...
File video.mp4 was not deleted and is not pending delete, attempting delete again...
File document.docx was not deleted and is not pending delete, attempting delete again...
File archive.zip was not deleted and is not pending delete, attempting delete again...
File script.py was not deleted and is not pending delete, attempting delete again...
File presentation.pptx was not deleted and is not pending delete, attempting delete again...
File spreadsheet.xlsx was not deleted and is not pending delete, attempting delete again...
File game.exe was not deleted and is not pending delete, attempting delete again...
File code.java was not deleted and is not pending delete, attempting delete again...
File resume.pdf was not deleted and is not pending delete, attempting delete again...
File photo.png was not deleted and is not pending delete, attempting delete again...
File email.eml was not deleted and is not pending delete, attempting delete again...
[3] primaries should be still started but [2] other primaries should be unassigned
[5] primaries should be still started but [4] other primaries should be unassigned
[1] primaries should be still started but [0] other primaries should be unassigned
[4] primaries should be still started but [3] other primaries should be unassigned
[2] primaries should be still started but [1] other primaries should be unassigned
[6] primaries should be still started but [5] other primaries should be unassigned
[7] primaries should be still started but [6] other primaries should be unassigned
[8] primaries should be still started but [7] other primaries should be unassigned
[9] primaries should be still started but [8] other primaries should be unassigned
[10] primaries should be still started but [9] other primaries should be unassigned
[11] primaries should be still started but [10] other primaries should be unassigned
[12] primaries should be still started but [11] other primaries should be unassigned
[13] primaries should be still started but [12] other primaries should be unassigned
[14] primaries should be still started but [13] other primaries should be unassigned
[15] primaries should be still started but [14] other primaries should be unassigned
failEngine threw exception class not found
failEngine threw exception join failed
failEngine threw exception loop terminated
failEngine threw exception array out of bounds
failEngine threw exception server error
failEngine threw exception null pointer
failEngine threw exception file not found
failEngine threw exception connection refused
failEngine threw exception invalid argument
failEngine threw exception format error
failEngine threw exception timeout
failEngine threw exception memory leak
failEngine threw exception division by zero
failEngine threw exception stack overflow
merge [_0] starting..., merging [3] segments, [1000] docs, [10 MB] size, into [15 MB] estimated_size
merge [_1] starting..., merging [5] segments, [2000] docs, [20 MB] size, into [25 MB] estimated_size
merge [_2] starting..., merging [4] segments, [1500] docs, [15 MB] size, into [18 MB] estimated_size
merge [_3] starting..., merging [6] segments, [2500] docs, [25 MB] size, into [30 MB] estimated_size
merge [_4] starting..., merging [2] segments, [500] docs, [5 MB] size, into [6 MB] estimated_size
merge [_5] starting..., merging [7] segments, [3000] docs, [30 MB] size, into [35 MB] estimated_size
merge [_6] starting..., merging [8] segments, [3500] docs, [35 MB] size, into [40 MB] estimated_size
merge [_7] starting..., merging [9] segments, [4000] docs, [40 MB] size, into [45 MB] estimated_size
merge [_8] starting..., merging [10] segments, [4500] docs, [45 MB] size, into [50 MB] estimated_size
merge [_9] starting..., merging [11] segments, [5000] docs, [50 MB] size, into [55 MB] estimated_size
merge [_10] starting..., merging [12] segments, [5500] docs, [55 MB] size, into [60 MB] estimated_size
merge [_11] starting..., merging [13] segments, [6000] docs, [60 MB] size, into [65 MB] estimated_size
Streams received for blob image.jpg
Streams received for blob video.mp4
Streams received for blob document.pdf
Streams received for blob music.mp3
Streams received for blob archive.zip
Streams received for blob presentation.pptx
Streams received for blob spreadsheet.xlsx
Streams received for blob code.py
Streams received for blob game.exe
Streams received for blob report.docx
Streams received for blob data.csv
Streams received for blob logo.png
Streams received for blob animation.gif
Streams received for blob ebook.epub
Streams received for blob podcast.m4a
numberOfEntries: 0
numberOfEntries: 1
numberOfEntries: 2
numberOfEntries: 3
numberOfEntries: 4
numberOfEntries: 5
numberOfEntries: 6
numberOfEntries: 7
numberOfEntries: 8
numberOfEntries: 9
numberOfEntries: 10
numberOfEntries: 11
numberOfEntries: 12
numberOfEntries: 13
numberOfEntries: 14
error while listing local files, recovering as if there are none java.io.FileNotFoundException: /home/user/data.txt (No such file or directory)
error while listing local files, recovering as if there are none java.nio.file.AccessDeniedException: /root/secret.txt
error while listing local files, recovering as if there are none java.lang.NullPointerException: null
error while listing local files, recovering as if there are none java.io.IOException: Stream closed
error while listing local files, recovering as if there are none java.nio.file.NoSuchFileException: /tmp/cache.dat
error while listing local files, recovering as if there are none java.lang.SecurityException: Permission denied
error while listing local files, recovering as if there are none java.io.EOFException: End of input
error while listing local files, recovering as if there are none java.util.zip.ZipException: invalid entry size (expected 1234 but got 5678 bytes)
error while listing local files, recovering as if there are none java.net.SocketTimeoutException: Read timed out
error while listing local files, recovering as if there are none java.lang.OutOfMemoryError: Java heap space
error while listing local files, recovering as if there are none java.nio.charset.MalformedInputException: Input length = 1
error while listing local files, recovering as if there are none org.xml.sax.SAXParseException; lineNumber: 10; columnNumber: 20; The element type "foo" must be terminated by the matching end-tag "</foo>".
error while listing local files, recovering as if there are none javax.crypto.BadPaddingException: Given final block not properly padded
error while listing local files, recovering as if there are none java.lang.ClassNotFoundException: com.example.MyClass
error while listing local files, recovering as if there are none java.lang.IllegalArgumentException: Invalid argument
Checking sha for app.jar
Checking sha for utils.jar
Checking sha for config.jar
Checking sha for data.jar
Checking sha for test.jar
Checking sha for web.jar
Checking sha for core.jar
Checking sha for api.jar
Checking sha for lib.jar
Checking sha for gui.jar
Checking sha for math.jar
Checking sha for security.jar
Checking sha for logging.jar
Checking sha for network.jar
Checking sha for io.jar
Component [0]:
Component [1]:
Component [2]:
Component [3]:
Component [4]:
Component [5]:
Component [6]:
Component [7]:
Component [8]:
Component [9]:
Component [10]:
Component [11]:
Component [12]:
Component [13]:
Component [14]:
set locally applied cluster state to version 12
set locally applied cluster state to version 7
set locally applied cluster state to version 15
set locally applied cluster state to version 9
set locally applied cluster state to version 10
set locally applied cluster state to version 13
set locally applied cluster state to version 8
set locally applied cluster state to version 11
set locally applied cluster state to version 14
set locally applied cluster state to version 6
set locally applied cluster state to version 16
set locally applied cluster state to version 5
set locally applied cluster state to version 4
set locally applied cluster state to version 3
set locally applied cluster state to version 2
success count = 12 , error count = 3
success count = 8 , error count = 5
success count = 15 , error count = 0
success count = 10 , error count = 2
success count = 9 , error count = 4
success count = 11 , error count = 1
success count = 7 , error count = 6
success count = 13 , error count = 2
success count = 14 , error count = 1
success count = 6 , error count = 7
success count = 16 , error count = 0
success count = 5 , error count = 8
success count = 4 , error count = 9
success count = 3 , error count = 10
success count = 2 , error count = 11
WARN refreshing cluster info rejected [timeout] java.net.SocketTimeoutException
DEBUG refreshing cluster info rejected [shut down] java.lang.IllegalStateException
WARN refreshing cluster info rejected [invalid response] org.apache.http.ProtocolException
DEBUG refreshing cluster info rejected [shut down] java.io.IOException
WARN refreshing cluster info rejected [connection refused] java.net.ConnectException
DEBUG refreshing cluster info rejected [shut down] java.lang.InterruptedException
WARN refreshing cluster info rejected [no route to host] java.net.NoRouteToHostException
DEBUG refreshing cluster info rejected [shut down] java.lang.NullPointerException
WARN refreshing cluster info rejected [internal server error] org.apache.http.HttpException
DEBUG refreshing cluster info rejected [shut down] java.lang.SecurityException
WARN refreshing cluster info rejected [bad request] org.apache.http.client.ClientProtocolException
DEBUG refreshing cluster info rejected [shut down] java.lang.IllegalArgumentException
WARN refreshing cluster info rejected [not found] org.apache.http.client.HttpResponseException
DEBUG refreshing cluster info rejected [shut down] java.lang.ClassNotFoundException
Output_simulate_15: WARN refreshing cluster info rejected [forbidden] org.apache.http.auth.AuthenticationException
indexing [1000] docs after setting number of replicas to 0
indexing [250] docs after setting number of replicas to 0
indexing [5000] docs after setting number of replicas to 0
indexing [750] docs after setting number of replicas to 0
indexing [3000] docs after setting number of replicas to 0
indexing [1500] docs after setting number of replicas to 0
indexing [200] docs after setting number of replicas to 0
indexing [4000] docs after setting number of replicas to 0
indexing [600] docs after setting number of replicas to 0
indexing [3500] docs after setting number of replicas to 0
indexing [1200] docs after setting number of replicas to 0
indexing [300] docs after setting number of replicas to 0
indexing [4500] docs after setting number of replicas to 0
indexing [900] docs after setting number of replicas to 0
indexing [2500] docs after setting number of replicas to 0
Delete index commit [commit=soft-deletes,generation=42]
Delete index commit [commit=point-in-time,generation=17]
Delete index commit [commit=snapshot,generation=29]
Delete index commit [commit=translog,generation=35]
Delete index commit [commit=merge-policy,generation=12]
Delete index commit [commit=flush,generation=27]
Delete index commit [commit=recovery,generation=19]
Delete index commit [commit=rollback,generation=23]
Delete index commit [commit=retention-lease,generation=31]
Delete index commit [commit=force-merge,generation=14]
Delete index commit [commit=refresh,generation=18]
Delete index commit [commit=reindex,generation=26]
Delete index commit [commit=update,generation=21]
Delete index commit [commit=create,generation=11]
Delete index commit [commit=delete,generation=16]
position (0) of edge 1 : 2
position (1) of edge 2 : 4
position (2) of edge 3 : 6
position (3) of edge 4 : 8
position (4) of edge 5 : 10
position (5) of edge 6 : 12
position (6) of edge 7 : 14
position (7) of edge 8 : 16
position (8) of edge 9 : 18
position (9) of edge 10 : 20
position (10) of edge 11 : 22
position (11) of edge 12 : 24
position (12) of edge 13 : 26
position (13) of edge 14 : 28
position (14) of edge 15 : 30
From: 1001 with Version: 7.2.1 to: 2002 with Version: 7.3.0
From: 1002 with Version: 7.2.0 to: 2003 with Version: 7.3.1
From: 1003 with Version: 7.1.9 to: 2004 with Version: 7.2.9
From: 1004 with Version: 7.1.8 to: 2005 with Version: 7.2.8
From: 1005 with Version: 7.1.7 to: 2006 with Version: 7.2.7
From: 1006 with Version: 7.1.6 to: 2007 with Version: 7.2.6
From: 1007 with Version: 7.1.5 to: 2008 with Version: 7.2.5
From: 1008 with Version: 7.1.4 to: 2009 with Version: 7.2.4
From: 1009 with Version: 7.1.3 to: 2010 with Version: 7.2.3
From: 1010 with Version: 7.1.2 to: 2011 with Version: 7.2.2
From: 1011 with Version: 7.1.1 to: 2012 with Version: 7.2.1
From: 1012 with Version: 7.1.0 to: 2013 with Version: 7.2.0
From: 1013 with Version: 6.9.9 to: 2014 with Version: 6.9.8
readBlob(image.jpg) from position [0] with length [1024]
readBlob(video.mp4) from position [2048] with length [unlimited]
readBlob(document.pdf) from position [512] with length [256]
readBlob(audio.mp3) from position [4096] with length [1024]
readBlob(archive.zip) from position [8192] with length [unlimited]
readBlob(icon.png) from position [0] with length [64]
readBlob(script.js) from position [128] with length [512]
readBlob(style.css) from position [256] with length [512]
readBlob(database.db) from position [16384] with length [unlimited]
readBlob(report.docx) from position [1024] with length [2048]
readBlob(presentation.pptx) from position [3072] with length [4096]
readBlob(song.wav) from position [5120] with length [unlimited]
readBlob(animation.gif) from position [0] with length [8192]
readBlob(code.py) from position [64] with length [256]
readBlob(chart.xlsx) from position [2048] with length [1024]
Keys in 'before' map: ["name", "age", "gender"]
Keys in 'before' map: ["id", "status", "timestamp"]
Keys in 'before' map: ["title", "author", "price"]
Keys in 'before' map: ["username", "password", "email"]
Keys in 'before' map: ["city", "state", "country"]
Keys in 'before' map: ["product", "quantity", "cost"]
Keys in 'before' map: ["student", "grade", "subject"]
Keys in 'before' map: ["color", "shape", "size"]
Keys in 'before' map: ["animal", "type", "weight"]
Keys in 'before' map: ["song", "artist", "genre"]
Keys in 'before' map: ["movie", "director", "rating"]
Keys in 'before' map: ["book", "publisher", "year"]
Keys in 'before' map: ["food", "calories", "nutrition"]
Keys in 'before' map: ["car", "model", "mileage"]
Keys in 'before' map: ["flower", "scent", "season"]
processing new index repositories for state version [1.0.0]
processing new index repositories for state version [2.3.4]
processing new index repositories for state version [3.1.2]
processing new index repositories for state version [4.0.1]
processing new index repositories for state version [5.2.6]
processing new index repositories for state version [6.4.3]
processing new index repositories for state version [7.5.8]
processing new index repositories for state version [8.6.7]
processing new index repositories for state version [9.8.5]
processing new index repositories for state version [10.9.4]
processing new index repositories for state version [11.10.3]
processing new index repositories for state version [12.11.2]
processing new index repositories for state version [13.12.1]
processing new index repositories for state version [14.13.0]
processing new index repositories for state version [15.14.9]
no shard copies found for shard id [0] for node attribute with weight zero
no shard copies found for shard id [1] for node attribute with weight zero
no shard copies found for shard id [2] for node attribute with weight zero
no shard copies found for shard id [3] for node attribute with weight zero
no shard copies found for shard id [4] for node attribute with weight zero
no shard copies found for shard id [5] for node attribute with weight zero
no shard copies found for shard id [6] for node attribute with weight zero
no shard copies found for shard id [7] for node attribute with weight zero
no shard copies found for shard id [8] for node attribute with weight zero
no shard copies found for shard id [9] for node attribute with weight zero
no shard copies found for shard id [10] for node attribute with weight zero
no shard copies found for shard id [11] for node attribute with weight zero
no shard copies found for shard id [12] for node attribute with weight zero
no shard copies found for shard id [13] for node attribute with weight zero
no shard copies found for shard id [14] for node attribute with weight zero
exception on open FileNotFoundException
exception on open NullPointerException
exception on open IOException
exception on open OutOfMemoryError
exception on open ClassNotFoundException
exception on open SQLException
exception on open RuntimeException
exception on open NumberFormatException
exception on open IndexOutOfBoundsException
exception on open AssertionError
exception on open SecurityException
exception on open IllegalArgumentException
exception on open MalformedURLException
exception on open ZipException
exception on open InterruptedException
failed to close reader java.io.IOException
failed to close reader java.lang.NullPointerException
failed to close reader java.nio.channels.ClosedChannelException
failed to close reader org.apache.lucene.index.CorruptIndexException
failed to close reader java.net.SocketTimeoutException
failed to close reader java.lang.IllegalStateException
failed to close reader org.elasticsearch.ElasticsearchException
failed to close reader java.util.concurrent.ExecutionException
failed to close reader java.lang.InterruptedException
failed to close reader org.apache.http.client.ClientProtocolException
failed to close reader java.io.FileNotFoundException
failed to close reader java.lang.OutOfMemoryError
failed to close reader javax.net.ssl.SSLHandshakeException
failed to close reader org.xml.sax.SAXException
failed to close reader java.io.EOFException
Failed to create working dir using hard links. Falling back to copy java.io.IOException: Permission denied
Failed to create working dir using hard links. Falling back to copy org.apache.commons.io.FileExistsException: Destination '/tmp/workdir' already exists
Failed to create working dir using hard links. Falling back to copy java.nio.file.FileSystemException: /home/user/workdir -> /tmp/workdir: Invalid cross-device link
Failed to create working dir using hard links. Falling back to copy java.lang.NullPointerException: Source path is null
Failed to create working dir using hard links. Falling back to copy java.io.FileNotFoundException: Source '/home/user/workdir' does not exist
Failed to create working dir using hard links. Falling back to copy java.lang.IllegalArgumentException: Source '/home/user/workdir' is not a directory
Failed to create working dir using hard links. Falling back to copy java.lang.SecurityException: Access denied to '/tmp/workdir'
Failed to create working dir using hard links. Falling back to copy org.apache.commons.io.IOExceptionWithCause: Unable to delete file: /tmp/workdir/file.txt
Failed to create working dir using hard links. Falling back to copy java.nio.file.DirectoryNotEmptyException: /tmp/workdir
Failed to create working dir using hard links. Falling back to copy java.io.IOException: No space left on device
Failed to create working dir using hard links. Falling back to copy java.nio.file.NoSuchFileException: /home/user/workdir/file.txt
Failed to create working dir using hard links. Falling back to copy org.apache.commons.io.FileUtils$FileDeleteStrategy$ForceFileDeleteStrategy$1: Unable to force delete file: /tmp/workdir/file.txt
Failed to create working dir using hard links. Falling back to copy java.nio.file.AccessDeniedException: /home/user/workdir/file.txt
Failed to create working dir using hard links. Falling back to copy java.lang.InterruptedException: Operation interrupted by user
Failed to create working dir using hard links. Falling back to copy java.io.IOException: Too many open files
[snapshot-20211029] [my-repo] restoring to [shard-0] ...
[snapshot-20211101] [test-repo] restoring to [shard-1] ...
[snapshot-20211031] [backup-repo] restoring to [shard-2] ...
[snapshot-20211102] [demo-repo] restoring to [shard-3] ...
[snapshot-20211028] [archive-repo] restoring to [shard-4] ...
[snapshot-20211103] [data-repo] restoring to [shard-5] ...
[snapshot-20211030] [log-repo] restoring to [shard-6] ...
[snapshot-20211104] [config-repo] restoring to [shard-7] ...
[snapshot-20211027] [report-repo] restoring to [shard-8] ...
[snapshot-20211105] [audit-repo] restoring to [shard-9] ...
[snapshot-20211026] [index-repo] restoring to [shard-10] ...
[snapshot-20211106] [search-repo] restoring to [shard-11] ...
[snapshot-20211025] [doc-repo] restoring to [shard-12] ...
[snapshot-20211107] [media-repo] restoring to [shard-13] ...
[snapshot-20211024] [image-repo] restoring to [shard-14] ...
Validating JSON [config.json]
Validating JSON [data.json]
Validating JSON [schema.json]
Validating JSON [users.json]
Validating JSON [settings.json]
Validating JSON [products.json]
Validating JSON [orders.json]
Validating JSON [inventory.json]
Validating JSON [report.json]
Validating JSON [profile.json]
Validating JSON [messages.json]
Validating JSON [contacts.json]
Validating JSON [events.json]
Validating JSON [tasks.json]
Validating JSON [logs.json]
All data files tlogFiles_20211029_1345.csv
All data files tlogFiles_20211028_2312.csv
All data files tlogFiles_20211027_0930.csv
All data files tlogFiles_20211026_1456.csv
All data files tlogFiles_20211025_2109.csv
All data files tlogFiles_20211024_1743.csv
All data files tlogFiles_20211023_1027.csv
All data files tlogFiles_20211022_1324.csv
All data files tlogFiles_20211021_2245.csv
All data files tlogFiles_20211020_0815.csv
All data files tlogFiles_20211019_1432.csv
All data files tlogFiles_20211018_2018.csv
All data files tlogFiles_20211017_1654.csv
All data files tlogFiles_20211016_0912.csv
All data files tlogFiles_20211015_1239.csv
performing [C], v [1], seq# [0], term [1]
performing [D], v [2], seq# [1], term [2]
performing [U], v [3], seq# [2], term [3]
performing [I], v [4], seq# [3], term [4]
performing [R], v [5], seq# [4], term [5]
performing [C], v [6], seq# [5], term [6]
performing [D], v [7], seq# [6], term [7]
performing [U], v [8], seq# [7], term [8]
performing [I], v [9], seq# [8], term [9]
performing [R], v [10], seq# [9], term [10]
performing [C], v [11], seq# [10], term [11]
performing [D], v [12], seq# [11], term [12]
performing [U], v [13], seq# [12], term [13]
performing [I], v [14], seq# [13], term [14]
can not get list of azure nodes: [java.net.UnknownHostException: azure.com]. Returning empty list of nodes.
can not get list of azure nodes: [java.lang.NullPointerException]. Returning empty list of nodes.
can not get list of azure nodes: [java.io.IOException: Connection timed out]. Returning empty list of nodes.
can not get list of azure nodes: [java.security.AccessControlException: Access denied]. Returning empty list of nodes.
can not get list of azure nodes: [java.lang.IllegalArgumentException: Invalid node name]. Returning empty list of nodes.
can not get list of azure nodes: [java.lang.OutOfMemoryError: Java heap space]. Returning empty list of nodes.
can not get list of azure nodes: [java.lang.ClassNotFoundException: com.azure.core.AzureNode]. Returning empty list of nodes.
can not get list of azure nodes: [java.lang.UnsupportedOperationException: Operation not supported]. Returning empty list of nodes.
can not get list of azure nodes: [java.util.concurrent.TimeoutException: Timeout waiting for node response]. Returning empty list of nodes.
can not get list of azure nodes: [java.net.SocketException: Socket closed]. Returning empty list of nodes.
can not get list of azure nodes: [java.net.ConnectException: Connection refused]. Returning empty list of nodes.
can not get list of azure nodes: [java.net.MalformedURLException: Invalid URL]. Returning empty list of nodes.
can not get list of azure nodes: [java.lang.RuntimeException: Unexpected error]. Returning empty list of nodes.
can not get list of azure nodes: [java.lang.NoClassDefFoundError: com/azure/core/AzureNode]. Returning empty list of nodes.
can not get list of azure nodes: [java.lang.Error: Unresolved compilation problem]. Returning empty list of nodes.
refreshing cluster info in background [config changed]
refreshing cluster info in background [periodic update]
refreshing cluster info in background [node added]
refreshing cluster info in background [node removed]
refreshing cluster info in background [load balancing]
refreshing cluster info in background [error recovery]
refreshing cluster info in background [manual trigger]
refreshing cluster info in background [health check]
refreshing cluster info in background [scaling up]
refreshing cluster info in background [scaling down]
refreshing cluster info in background [maintenance mode]
refreshing cluster info in background [rebooting]
refreshing cluster info in background [migration]
refreshing cluster info in background [backup]
refreshing cluster info in background [restore]
failed to write candidates java.io.IOException
failed to write candidates java.lang.NullPointerException
failed to write candidates java.sql.SQLException
failed to write candidates java.lang.OutOfMemoryError
failed to write candidates java.net.SocketTimeoutException
failed to write candidates java.lang.IllegalArgumentException
failed to write candidates java.io.FileNotFoundException
failed to write candidates java.lang.ClassNotFoundException
failed to write candidates java.lang.ArrayIndexOutOfBoundsException
failed to write candidates java.lang.SecurityException
failed to write candidates java.util.ConcurrentModificationException
failed to write candidates java.lang.UnsupportedOperationException
failed to write candidates java.lang.NumberFormatException
failed to write candidates java.util.NoSuchElementException
failed to write candidates java.lang.StackOverflowError
Could not find a readable index-N file in a non-empty shard snapshot directory [/var/lib/elasticsearch/nodes/0/indices/8f7yQ6xwQ9m7F4vGtq9Ocg/0]
Could not find a readable index-N file in a non-empty shard snapshot directory [C:\Users\Administrator\elasticsearch-7.15.2\data\nodes\0\indices\X3vz7aLrQIqjZqfKFH6nWw\1]
Could not find a readable index-N file in a non-empty shard snapshot directory [/home/ubuntu/elasticsearch/data/nodes/0/indices/Lhj8n5NkQgWx9fz3JkYg4A/2]
Could not find a readable index-N file in a non-empty shard snapshot directory [/mnt/elasticsearch/nodes/0/indices/cBvz9aLrTIqjZqfKFH6nWw/3]
Could not find a readable index-N file in a non-empty shard snapshot directory [D:\elasticsearch\data\nodes\0\indices\yf7yQ6xwS9m7F4vGtq9Ocg/4]
Could not find a readable index-N file in a non-empty shard snapshot directory [/opt/elasticsearch/nodes/0/indices/h3vz7aLrQIqjZqfKFH6nWw/5]
Could not find a readable index-N file in a non-empty shard snapshot directory [/usr/local/elasticsearch/data/nodes/0/indices/Nhj8n5NkQgWx9fz3JkYg4A/6]
Could not find a readable index-N file in a non-empty shard snapshot directory [E:\elasticsearch-7.15.2\data\nodes\0\indices\aBvz9aLrTIqjZqfKFH6nWw/7]
Could not find a readable index-N file in a non-empty shard snapshot directory [/data/elasticsearch/nodes/0/indices/zf7yQ6xwS9m7F4vGtq9Ocg/8]
Could not find a readable index-N file in a non-empty shard snapshot directory [F:\Users\elasticsearch\data\nodes\0\indices\k3vz7aLrQIqjZqfKFH6nWw/9]
Could not find a readable index-N file in a non-empty shard snapshot directory [/var/opt/elasticsearch/nodes/0/indices/Rhj8n5NkQgWx9fz3JkYg4A/10]
Could not find a readable index-N file in a non-empty shard snapshot directory [G:\elasticsearch-7.15.2\data\nodes\0\indices\dBvz9aLrTIqjZqfKFH6nWw/11]
Could not find a readable index-N file in a non-empty shard snapshot directory [/tmp/elasticsearch/nodes/0/indices/wf7yQ6xwS9m7F4vGtq9Ocg/12]
Could not find a readable index-N file in a non-empty shard snapshot directory [H:\Users\Administrator\elasticsearch\data\nodes\0\indices\n3vz7aLrQIqjZqfKFH6nWw/13]
Could not find a readable index-N file in a non-empty shard snapshot directory [/root/elasticsearch/data/nodes/0/indices/Vhj8n5NkQgWx9fz3JkYg4A/14]
create 2 indices with [5] no replicas, and wait till all are allocated
create 2 indices with [3] no replicas, and wait till all are allocated
create 2 indices with [7] no replicas, and wait till all are allocated
create 2 indices with [4] no replicas, and wait till all are allocated
create 2 indices with [6] no replicas, and wait till all are allocated
create 2 indices with [8] no replicas, and wait till all are allocated
create 2 indices with [9] no replicas, and wait till all are allocated
create 2 indices with [10] no replicas, and wait till all are allocated
create 2 indices with [11] no replicas, and wait till all are allocated
create 2 indices with [12] no replicas, and wait till all are allocated
create 2 indices with [13] no replicas, and wait till all are allocated
create 2 indices with [14] no replicas, and wait till all are allocated
create 2 indices with [15] no replicas, and wait till all are allocated
create 2 indices with [16] no replicas, and wait till all are allocated
create 2 indices with [17] no replicas, and wait till all are allocated
shard_1 becoming primary of index_1 with missing lease: [term=2, version=3, source=peer recovery]
shard_2 becoming primary of index_2 with missing lease: [term=4, version=5, source=replica allocation]
shard_3 becoming primary of index_3 with missing lease: [term=1, version=2, source=primary promotion]
shard_4 becoming primary of index_4 with missing lease: [term=3, version=4, source=forced update]
shard_5 becoming primary of index_5 with missing lease: [term=5, version=6, source=shard started]
shard_6 becoming primary of index_6 with missing lease: [term=2, version=3, source=recovery from store]
shard_7 becoming primary of index_7 with missing lease: [term=4, version=5, source=relocation]
shard_8 becoming primary of index_8 with missing lease: [term=1, version=2, source=create index]
shard_9 becoming primary of index_9 with missing lease: [term=3, version=4, source=create snapshot]
shard_10 becoming primary of index_10 with missing lease: [term=5, version=6, source=create restore]
shard_11 becoming primary of index_11 with missing lease: [term=2, version=3, source=create alias]
shard_12 becoming primary of index_12 with missing lease: [term=4, version=5, source=create template]
shard_13 becoming primary of index_13 with missing lease: [term=1, version=2, source=create mapping]
shard_14 becoming primary of index_14 with missing lease: [term=3, version=4, source=create settings]
shard_15 becoming primary of index_15 with missing lease: [term=5, version=6, source=create rollover]
connecting to nodes of cluster state with version 1.2.3
connecting to nodes of cluster state with version 2.0.0
connecting to nodes of cluster state with version 1.1.5
connecting to nodes of cluster state with version 2.1.4
connecting to nodes of cluster state with version 1.3.2
connecting to nodes of cluster state with version 2.0.1
connecting to nodes of cluster state with version 1.2.4
connecting to nodes of cluster state with version 2.1.3
connecting to nodes of cluster state with version 1.3.1
connecting to nodes of cluster state with version 2.0.2
connecting to nodes of cluster state with version 1.1.6
connecting to nodes of cluster state with version 2.1.5
connecting to nodes of cluster state with version 1.3.3
connecting to nodes of cluster state with version 2.0.3
connecting to nodes of cluster state with version 1.2.5
[1] [a3b5] Processing [file1.txt]
[2] [c4d6] Processing [file2.txt]
[3] [e5f7] Processing [file3.txt]
[4] [g6h8] Processing [file4.txt]
[5] [i7j9] Processing [file5.txt]
[6] [k8l0] Processing [file6.txt]
[7] [m9n1] Processing [file7.txt]
[8] [o0p2] Processing [file8.txt]
[9] [q1r3] Processing [file9.txt]
[10] [s2t4] Processing [file10.txt]
[11] [u3v5] Processing [file11.txt]
[12] [w4x6] Processing [file12.txt]
[13] [y5z7] Processing [file13.txt]
[14] [a6b8] Processing [file14.txt]
[15] [c7d9] Processing [file15.txt]
Opening Lucene index at /home/user/index
Opening Lucene index at C:\Users\user\Documents\index
Opening Lucene index at /var/lib/lucene/index
Opening Lucene index at /mnt/data/index
Opening Lucene index at /opt/lucene/index
Opening Lucene index at C:\Program Files\Lucene\index
Opening Lucene index at /tmp/index
Opening Lucene index at /usr/local/lucene/index
Opening Lucene index at C:\Temp\index
Opening Lucene index at /home/user/Desktop/index
Opening Lucene index at C:\Users\user\Desktop\index
Opening Lucene index at /media/user/USB/index
Opening Lucene index at C:\Windows\System32\index
Opening Lucene index at /dev/null/index
Opening Lucene index at /etc/lucene/index
--> new primary is on version 1.2.3 : node-01
--> new primary is on version 2.0.0 : node-05
--> new primary is on version 1.3.4 : node-03
--> new primary is on version 1.2.5 : node-02
--> new primary is on version 2.1.0 : node-06
--> new primary is on version 1.4.3 : node-04
--> new primary is on version 2.0.1 : node-07
--> new primary is on version 1.3.5 : node-08
--> new primary is on version 1.2.6 : node-09
--> new primary is on version 2.1.1 : node-10
--> new primary is on version 1.4.4 : node-11
--> new primary is on version 2.0.2 : node-12
--> new primary is on version 1.3.6 : node-13
--> new primary is on version 1.2.7 : node-14
--> new primary is on version 2.1.2 : node-15
--> healing 10 HP
--> healing 25 MP
--> healing 15 SP
--> healing 5 HP and 5 MP
--> healing 20 HP and 10 SP
--> healing 30 MP and 15 SP
--> healing 50 HP
--> healing 75 MP
--> healing 40 SP
--> healing 10 HP, 10 MP and 10 SP
--> healing 15 HP and 20 MP
--> healing 20 HP and 25 SP
--> healing 25 MP and 30 SP
--> healing 100 HP
--> healing 100 MP
--> num relocations to get balance: 5
--> num relocations to get balance: 12
--> num relocations to get balance: 8
--> num relocations to get balance: 3
--> num relocations to get balance: 9
--> num relocations to get balance: 6
--> num relocations to get balance: 10
--> num relocations to get balance: 4
--> num relocations to get balance: 7
--> num relocations to get balance: 11
--> num relocations to get balance: 2
--> num relocations to get balance: 13
--> num relocations to get balance: 1
--> num relocations to get balance: 14
--> num relocations to get balance: 15
adding [3] nodes
adding [5] nodes
adding [2] nodes
adding [4] nodes
adding [6] nodes
adding [7] nodes
adding [8] nodes
adding [9] nodes
adding [10] nodes
adding [12] nodes
adding [15] nodes
adding [20] nodes
adding [25] nodes
adding [30] nodes
adding [50] nodes
no tags for this instance but we asked for tags. webserver-01 won't be part of the cluster.
no tags for this instance but we asked for tags. database-03 won't be part of the cluster.
no tags for this instance but we asked for tags. loadbalancer-02 won't be part of the cluster.
no tags for this instance but we asked for tags. appserver-04 won't be part of the cluster.
no tags for this instance but we asked for tags. backup-01 won't be part of the cluster.
no tags for this instance but we asked for tags. analytics-02 won't be part of the cluster.
no tags for this instance but we asked for tags. firewall-01 won't be part of the cluster.
no tags for this instance but we asked for tags. proxy-03 won't be part of the cluster.
no tags for this instance but we asked for tags. mailserver-02 won't be part of the cluster.
no tags for this instance but we asked for tags. dns-01 won't be part of the cluster.
no tags for this instance but we asked for tags. storage-04 won't be part of the cluster.
no tags for this instance but we asked for tags. monitor-03 won't be part of the cluster.
no tags for this instance but we asked for tags. vpn-02 won't be part of the cluster.
no tags for this instance but we asked for tags. ftpserver-01 won't be part of the cluster.
no tags for this instance but we asked for tags. chatbot-04 won't be part of the cluster.
index processing pending deletes
index-1 processing pending deletes
index-2 processing pending deletes
index-3 processing pending deletes
index-4 processing pending deletes
index-5 processing pending deletes
index-6 processing pending deletes
index-7 processing pending deletes
index-8 processing pending deletes
index-9 processing pending deletes
index-10 processing pending deletes
index-11 processing pending deletes
index-12 processing pending deletes
index-13 processing pending deletes
index-14 processing pending deletes
--> consuming settings map
--> consuming settings map[0]
--> consuming settings map["name"]
--> consuming settings map.size()
--> consuming settings map.values()
--> consuming settings map.clear()
--> consuming settings map.containsKey("key")
--> consuming settings map.put("key", "value")
--> consuming settings map.remove("key")
--> consuming settings map.entrySet()
--> consuming settings map.get("key")
--> consuming settings map.isEmpty()
--> consuming settings map.keySet()
--> consuming settings map.replace("key", "value")
--> consuming settings map.toString()
expected SearchPhaseException: [Failed to execute phase [query], all shards failed]
expected SearchPhaseException: [No active shards]
expected SearchPhaseException: [SearchContext missing for id [1234]]
expected SearchPhaseException: [Timeout waiting for task]
expected SearchPhaseException: [Invalid query syntax]
expected SearchPhaseException: [Index not found]
expected SearchPhaseException: [Too many clauses in boolean query]
expected SearchPhaseException: [Circuit breaking exception]
expected SearchPhaseException: [Script error]
expected SearchPhaseException: [Remote transport exception]
expected SearchPhaseException: [Parse failure]
expected SearchPhaseException: [Query shard exception]
expected SearchPhaseException: [Shard not available]
expected SearchPhaseException: [Illegal argument exception]
expected SearchPhaseException: [Null pointer exception]
opensearch_port is defined with 9200
opensearch_port is defined with 9300
opensearch_port is defined with 9400
opensearch_port is defined with 9500
opensearch_port is defined with 9600
opensearch_port is defined with 9700
opensearch_port is defined with 9800
opensearch_port is defined with 9900
opensearch_port is defined with 10000
opensearch_port is defined with 10100
opensearch_port is defined with 10200
opensearch_port is defined with 10300
opensearch_port is defined with 10400
opensearch_port is defined with 10500
opensearch_port is defined with 10600
SearchPhaseException: [Failed to execute phase [query], all shards failed]
SearchPhaseException: [Failed to execute phase [fetch], shard [0] failed]
SearchPhaseException: [Failed to execute phase [dfs], total failure]
SearchPhaseException: [Failed to execute phase [query], shard [1] returned an exception]
SearchPhaseException: [Failed to execute phase [fetch], shard [2] timed out]
SearchPhaseException: [Failed to execute phase [dfs], shard [3] not available]
SearchPhaseException: [Failed to execute phase [query], shard [4] rejected execution]
SearchPhaseException: [Failed to execute phase [fetch], shard [5] corrupted data]
SearchPhaseException: [Failed to execute phase [dfs], shard [6] index not found]
SearchPhaseException: [Failed to execute phase [query], shard [7] null pointer exception]
SearchPhaseException: [Failed to execute phase [fetch], shard [8] out of memory error]
SearchPhaseException: [Failed to execute phase [dfs], shard [9] network error]
SearchPhaseException: [Failed to execute phase [query], shard [-1] unknown error]
SearchPhaseException: [Failed to execute phase [fetch], no shards available]
SearchPhaseException: [Failed to execute phase [dfs], cluster state not recovered]
Adding 5 nodes
Adding 12 nodes
Adding 8 nodes
Adding 10 nodes
Adding 6 nodes
Adding 9 nodes
Adding 7 nodes
Adding 11 nodes
Adding 4 nodes
Adding 13 nodes
Adding 14 nodes
Adding 3 nodes
Adding 15 nodes
Adding 2 nodes
Adding 16 nodes
engine closed [overheating]
engine closed [low fuel]
engine closed [maintenance mode]
engine closed [user request]
engine closed [error code 404]
engine closed [power outage]
engine closed [system update]
engine closed [security breach]
engine closed [collision detected]
engine closed [idle timeout]
engine closed [low oil pressure]
engine closed [high RPM]
engine closed [sensor failure]
engine closed [network disconnect]
engine closed [emergency shutdown]
--> waiting for block to kick in on clusterManagerNode-1
--> waiting for block to kick in on clusterManagerNode-5
--> waiting for block to kick in on clusterManagerNode-9
--> waiting for block to kick in on clusterManagerNode-12
--> waiting for block to kick in on clusterManagerNode-3
--> waiting for block to kick in on clusterManagerNode-7
--> waiting for block to kick in on clusterManagerNode-10
--> waiting for block to kick in on clusterManagerNode-14
--> waiting for block to kick in on clusterManagerNode-2
--> waiting for block to kick in on clusterManagerNode-6
--> waiting for block to kick in on clusterManagerNode-8
--> waiting for block to kick in on clusterManagerNode-11
--> waiting for block to kick in on clusterManagerNode-13
--> waiting for block to kick in on clusterManagerNode-4
--> waiting for block to kick in on clusterManagerNode-15
Exception occurred while getting segment files java.io.FileNotFoundException: /data/segments/segment_1.dat (No such file or directory)
Exception occurred while getting segment files java.lang.NullPointerException: Attempt to invoke virtual method 'int SegmentFile.getSize()' on a null object reference
Exception occurred while getting segment files java.io.IOException: Stream closed
Exception occurred while getting segment files java.lang.OutOfMemoryError: Failed to allocate a 524288 byte allocation with 4194304 free bytes and 4MB until OOM
Exception occurred while getting segment files java.lang.SecurityException: Permission denied for /data/segments/segment_2.dat
Exception occurred while getting segment files java.util.zip.ZipException: invalid entry size (expected 4096 but got 512 bytes)
Exception occurred while getting segment files java.lang.IllegalArgumentException: Segment file name must start with 'segment_'
Exception occurred while getting segment files java.io.EOFException: End of input at line 1 column 1 path $
Exception occurred while getting segment files java.net.SocketTimeoutException: Read timed out
Exception occurred while getting segment files java.nio.file.AccessDeniedException: /data/segments/segment_3.dat
Exception occurred while getting segment files java.lang.ClassCastException: SegmentFile cannot be cast to SegmentFileImpl
Exception occurred while getting segment files java.util.concurrent.ExecutionException: java.lang.RuntimeException: Segment file corrupted
Exception occurred while getting segment files org.json.JSONException: Value <!DOCTYPE of type java.lang.String cannot be converted to JSONObject
Exception occurred while getting segment files javax.net.ssl.SSLHandshakeException: Handshake failed
Exception occurred while getting segment files java.lang.ArrayIndexOutOfBoundsException: length=10; index=10
--> starting [node 1] ...
--> starting [node 2] ...
--> starting [node 3] ...
--> starting [node 4] ...
--> starting [node 5] ...
--> starting [node 6] ...
--> starting [node 7] ...
--> starting [node 8] ...
--> starting [node 9] ...
--> starting [node 10] ...
--> starting [node 11] ...
--> starting [node 12] ...
--> starting [node 13] ...
--> starting [node 14] ...
Failed to execute NodeStatsAction for ClusterInfoUpdateJob java.lang.NullPointerException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob java.net.SocketTimeoutException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob java.io.IOException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob org.elasticsearch.ElasticsearchException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob java.lang.OutOfMemoryError
Failed to execute NodeStatsAction for ClusterInfoUpdateJob java.lang.IllegalArgumentException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob java.util.concurrent.ExecutionException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob org.elasticsearch.cluster.block.ClusterBlockException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob java.lang.InterruptedException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob org.elasticsearch.transport.NodeNotConnectedException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob java.lang.SecurityException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob java.lang.ClassNotFoundException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob org.elasticsearch.action.FailedNodeException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob java.lang.NoSuchMethodError
Failed to execute NodeStatsAction for ClusterInfoUpdateJob java.lang.StackOverflowError
Unassigning task 1001 with allocation id 5a7b9c
Unassigning task 2002 with allocation id 3d4e6f
Unassigning task 3003 with allocation id 1f2g3h
Unassigning task 4004 with allocation id 9i8j7k
Unassigning task 5005 with allocation id 7k6l5m
Unassigning task 6006 with allocation id 5m4n3o
Unassigning task 7007 with allocation id 3o2p1q
Unassigning task 8008 with allocation id 1q2r3s
Unassigning task 9009 with allocation id 3s4t5u
Unassigning task 1010 with allocation id 5u6v7w
Unassigning task 1111 with allocation id 7w8x9y
Unassigning task 1212 with allocation id 9y0z1a
Unassigning task 1313 with allocation id a1b2c3
Unassigning task 1414 with allocation id c3d4e5
Unassigning task 1515 with allocation id e5f6g7
AGG COLLECTION MODE: OFF
AGG COLLECTION MODE: ON
AGG COLLECTION MODE: AUTO
AGG COLLECTION MODE: MANUAL
AGG COLLECTION MODE: PERIODIC
AGG COLLECTION MODE: EVENT-DRIVEN
AGG COLLECTION MODE: THRESHOLD-BASED
AGG COLLECTION MODE: ADAPTIVE
AGG COLLECTION MODE: HYBRID
AGG COLLECTION MODE: RANDOM
AGG COLLECTION MODE: OPTIMAL
AGG COLLECTION MODE: DEFAULT
AGG COLLECTION MODE: CUSTOM
AGG COLLECTION MODE: PREDICTIVE
AGG COLLECTION MODE: REACTIVE
failed to remove weighted routing metadata from cluster state java.lang.NullPointerException
failed to remove weighted routing metadata from cluster state java.io.IOException: Connection reset by peer
failed to remove weighted routing metadata from cluster state java.lang.IllegalArgumentException: Cluster name must not be null
failed to remove weighted routing metadata from cluster state java.lang.IllegalStateException: Cluster state is not initialized
failed to remove weighted routing metadata from cluster state java.util.concurrent.TimeoutException: Timed out waiting for cluster state update
failed to remove weighted routing metadata from cluster state org.elasticsearch.ElasticsearchException: Failed to execute cluster state update task
failed to remove weighted routing metadata from cluster state org.elasticsearch.cluster.block.ClusterBlockException: Cluster blocked by [SERVICE_UNAVAILABLE/1/state not recovered / initialized]
failed to remove weighted routing metadata from cluster state org.elasticsearch.transport.RemoteTransportException: [node-1][127.0.0.1:9300][cluster:admin/routing/update]
failed to remove weighted routing metadata from cluster state org.elasticsearch.index.IndexNotFoundException: no such index [test]
failed to remove weighted routing metadata from cluster state org.elasticsearch.action.support.replication.ReplicationOperation$RetryOnPrimaryException: Retries exhausted
failed to remove weighted routing metadata from cluster state org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [<transport_request>] would be [123456789/117.7mb], which is larger than the limit of [12345678/11.7mb]
failed to remove weighted routing metadata from cluster state org.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException: failed to process cluster event (update_routing_table) within 30s
failed to remove weighted routing metadata from cluster state org.elasticsearch.cluster.coordination.FailedToCommitClusterStateException: publication failed
failed to remove weighted routing metadata from cluster state org.elasticsearch.action.UnavailableShardsException: [test][0] primary shard is not active Timeout
failed to remove weighted routing metadata from cluster state org.elasticsearch.rest.RestStatus$StatusExceptionMapper$1@7f31245a
Engine is already closed. java.lang.IllegalStateException: Cannot execute task: the task is already running.
Engine is already closed. java.io.IOException: Stream closed
Engine is already closed. java.lang.NullPointerException: Attempt to invoke virtual method 'void com.example.Engine.stop()' on a null object reference
Engine is already closed. java.lang.RuntimeException: Unable to stop service com.example.EngineService: java.lang.IllegalMonitorStateException
Engine is already closed. java.util.concurrent.RejectedExecutionException: Task com.example.EngineTask@4f8b8b8 rejected from java.util.concurrent.ThreadPoolExecutor@7a6f1f6[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 5]
Engine is already closed. java.lang.InterruptedException: sleep interrupted
Engine is already closed. java.lang.SecurityException: Permission denied (missing INTERNET permission?)
Engine is already closed. java.net.SocketException: Socket closed
Engine is already closed. java.lang.IllegalArgumentException: Invalid engine state: CLOSED
Engine is already closed. java.util.NoSuchElementException: No element left in the engine queue
Engine is already closed. java.lang.ClassCastException: com.example.Engine cannot be cast to com.example.OtherEngine
Engine is already closed. java.lang.UnsupportedOperationException: This operation is not supported by the engine
Engine is already closed. java.lang.Error: Unresolved compilation problem
Engine is already closed. java.lang.OutOfMemoryError: Failed to allocate a 16 byte allocation with 0 free bytes and 3GB until OOM
Engine is already closed. android.os.NetworkOnMainThreadException
updated node1 already in denylist
updated node7 already in denylist
updated node3 already in denylist
updated node9 already in denylist
updated node5 already in denylist
updated node2 already in denylist
updated node8 already in denylist
updated node4 already in denylist
updated node6 already in denylist
updated node10 already in denylist
updated node12 already in denylist
updated node11 already in denylist
updated node13 already in denylist
updated node15 already in denylist
--> restoring snapshot [snapshot1]
--> restoring snapshot [snapshot2]
--> restoring snapshot [snapshot3]
--> restoring snapshot [snapshot4]
--> restoring snapshot [snapshot5]
--> restoring snapshot [snapshot6]
--> restoring snapshot [snapshot7]
--> restoring snapshot [snapshot8]
--> restoring snapshot [snapshot9]
--> restoring snapshot [snapshot10]
--> restoring snapshot [snapshot11]
--> restoring snapshot [snapshot12]
--> restoring snapshot [snapshot13]
--> restoring snapshot [snapshot14]
--> restoring snapshot [snapshot15]
sending notification for completed task [upload] with id [a3b5c7]
sending notification for completed task [download] with id [f9d2e4]
sending notification for completed task [delete] with id [c6b4a2]
sending notification for completed task [edit] with id [d8f6b3]
sending notification for completed task [share] with id [e7g5c4]
sending notification for completed task [copy] with id [b4d6f8]
sending notification for completed task [move] with id [a5c7e9]
sending notification for completed task [rename] with id [f8d4b6]
sending notification for completed task [create] with id [g7e5c3]
sending notification for completed task [archive] with id [c9f3a6]
sending notification for completed task [restore] with id [d6b8f4]
sending notification for completed task [sync] with id [e5c4g7]
sending notification for completed task [print] with id [b3a7f9]
sending notification for completed task [scan] with id [c4b6d8]
sending notification for completed task [email] with id [f7e3g5]
extracted content: {"title": "How to generate simulated logs", "body": "The log consists of the constant Template and the abstract variable Parameter..."}
extracted content: {"name": "John Smith", "email": "john.smith@example.com", "phone": "+1-234-567-8901"}
extracted content: {"type": "IMAGE", "url": "https://example.com/image.jpg", "size": "1024x768"}
extracted content: {"product": "iPhone 14", "price": "$999.99", "rating": "4.5/5"}
extracted content: {"date": "2023-10-24", "time": "01:50:57 GMT+00:00", "location": "Redmond, Washington, United States"}
extracted content: {"query": "a dragon", "type":"IMAGE", "actionTag":"generative_image"}
extracted content: {"message": "Hello, this is Bing. How can I help?", "sender": "assistant", "receiver": "user"}
extracted content: {"book": "Harry Potter and the Philosopher's Stone", "author": "J.K. Rowling", "genre": "fantasy"}
extracted content: {"song": "Let It Go", "artist": "Idina Menzel", "album": "Frozen"}
extracted content: {"code": "#include <stdio.h>\nint main() {\n  printf(\"Hello, world!\");\n  return 0;\n}", "language": "C"}
extracted content: {"weather": {"temperature": "15C", "humidity": "75%", "wind": "10 km/h"}, "forecast": {"sunny": true, "rainy": false, "snowy": false}}
extracted content: {"poem": ["Two roads diverged in a yellow wood,",
extracted content: {"tweet": "@Bing Thank you for helping me with my homework!",
extracted content: {"movie": "The Matrix",
extracted content: {"animal": "panda",
failed to invoke on store closed java.lang.IllegalStateException
failed to invoke on store closed java.io.IOException
failed to invoke on store closed java.lang.NullPointerException
failed to invoke on store closed java.util.ConcurrentModificationException
failed to invoke on store closed java.lang.InterruptedException
failed to invoke on store closed java.lang.RuntimeException
failed to invoke on store closed java.sql.SQLException
failed to invoke on store closed java.net.SocketException
failed to invoke on store closed java.lang.ClassNotFoundException
failed to invoke on store closed java.lang.NoSuchMethodException
failed to invoke on store closed java.lang.IllegalArgumentException
failed to invoke on store closed java.lang.ArrayIndexOutOfBoundsException
failed to invoke on store closed java.lang.OutOfMemoryError
failed to invoke on store closed java.lang.StackOverflowError
failed to invoke on store closed java.lang.SecurityException
processing [file.txt]: execute
processing [image.jpg]: execute
processing [video.mp4]: execute
processing [data.csv]: execute
processing [script.py]: execute
processing [report.docx]: execute
processing [music.mp3]: execute
processing [archive.zip]: execute
processing [game.exe]: execute
processing [email.eml]: execute
processing [web.html]: execute
processing [map.kml]: execute
processing [slide.pptx]: execute
processing [code.java]: execute
processing [book.pdf]: execute
--> done cluster health, status GREEN
--> done cluster health, status YELLOW
--> done cluster health, status RED
--> done cluster health, status UNKNOWN
--> done cluster health, status PARTIAL
--> done cluster health, status OK
--> done cluster health, status WARN
--> done cluster health, status ERROR
--> done cluster health, status CRITICAL
--> done cluster health, status DEGRADED
--> done cluster health, status RECOVERING
--> done cluster health, status STABLE
--> done cluster health, status UNSTABLE
--> done cluster health, status FAILING
--> done cluster health, status OFFLINE
parsing: doc1.pdf
parsing: doc2.docx
parsing: doc3.txt
parsing: doc4.pptx
parsing: doc5.xlsx
parsing: doc6.html
parsing: doc7.rtf
parsing: doc8.odt
parsing: doc9.csv
parsing: doc10.xml
parsing: doc11.json
parsing: doc12.md
parsing: doc13.epub
parsing: doc14.zip
parsing: doc15.jpg
--> using initial block settings {width: 100, height: 200, color: red}
--> using initial block settings {width: 50, height: 50, color: blue}
--> using initial block settings {width: 150, height: 100, color: green}
--> using initial block settings {width: 200, height: 200, color: yellow}
--> using initial block settings {width: 75, height: 150, color: purple}
--> using initial block settings {width: 100, height: 100, color: black}
--> using initial block settings {width: 125, height: 250, color: orange}
--> using initial block settings {width: 80, height: 120, color: pink}
--> using initial block settings {width: 180, height: 180, color: brown}
--> using initial block settings {width: 60, height: 80, color: white}
--> using initial block settings {width: 140, height: 140, color: gray}
--> using initial block settings {width: 90, height: 210, color: cyan}
--> using initial block settings {width: 110, height: 90, color: magenta}
--> using initial block settings {width: 160, height: 160, color: lime}
--> using initial block settings {width: 70, height: 190, color: navy}
committing writer with commit data [id: 1234, size: 256 KB, timestamp: 1623423432]
committing writer with commit data [id: 5678, size: 512 KB, timestamp: 1623423435]
committing writer with commit data [id: 9101, size: 128 KB, timestamp: 1623423437]
committing writer with commit data [id: 1121, size: 64 KB, timestamp: 1623423440]
committing writer with commit data [id: 3141, size: 1024 KB, timestamp: 1623423442]
committing writer with commit data [id: 5161, size: 256 KB, timestamp: 1623423445]
committing writer with commit data [id: 7181, size: 512 KB, timestamp: 1623423447]
committing writer with commit data [id: 9202, size: 128 KB, timestamp: 1623423450]
committing writer with commit data [id: 1222, size: 64 KB, timestamp: 1623423452]
committing writer with commit data [id: 3242, size: 1024 KB, timestamp: 1623423455]
committing writer with commit data [id: 5262, size: 256 KB, timestamp: 1623423457]
committing writer with commit data [id: 7282, size: 512 KB, timestamp: 1623423460]
committing writer with commit data [id: 9303, size: 128 KB, timestamp: 1623423462]
committing writer with commit data [id: 1323, size: 64 KB, timestamp: 1623423465]
committing writer with commit data [id: 3343, size: 1024 KB, timestamp: 1623423467]
not running recovery with id [a3b5c7] - can not find it (probably finished)
not running recovery with id [f9d2e4] - can not find it (probably finished)
not running recovery with id [6c8a1b] - can not find it (probably finished)
not running recovery with id [4e7f3d] - can not find it (probably finished)
not running recovery with id [9b6d4c] - can not find it (probably finished)
not running recovery with id [0a2f5e] - can not find it (probably finished)
not running recovery with id [3d6a9c] - can not find it (probably finished)
not running recovery with id [8e5b7d] - can not find it (probably finished)
not running recovery with id [1c4f8b] - can not find it (probably finished)
not running recovery with id [7a3d6e] - can not find it (probably finished)
not running recovery with id [5b2e9f] - can not find it (probably finished)
not running recovery with id [2f1c7a] - can not find it (probably finished)
not running recovery with id [d8e4b6] - can not find it (probably finished)
not running recovery with id [b7d3e8] - can not find it (probably finished)
not running recovery with id [e6c2f9] - can not find it (probably finished)
shard: 0 size: 10GB reserved: 2GB
shard: 1 size: 8GB reserved: 1.5GB
shard: 2 size: 12GB reserved: 3GB
shard: 3 size: 9GB reserved: 2.2GB
shard: 4 size: 11GB reserved: 2.8GB
shard: 5 size: 7GB reserved: 1.2GB
shard: 6 size: 13GB reserved: 3.5GB
shard: 7 size: 10GB reserved: 2.5GB
shard: 8 size: 9GB reserved: 2.1GB
shard: 9 size: 11GB reserved: 2.9GB
shard: A size: 8GB reserved: 1.7GB
shard: B size: 12GB reserved: 3.2GB
shard: C size: 10GB reserved: 2.4GB
shard: D size: 9GB reserved: 2.3GB
shard: E size: 11GB reserved: 3.1GB
[task1]: rethrottling to [5] requests per second
[task2]: rethrottling to [10] requests per second
[task3]: rethrottling to [7] requests per second
[task4]: rethrottling to [8] requests per second
[task5]: rethrottling to [6] requests per second
[task6]: rethrottling to [9] requests per second
[task7]: rethrottling to [4] requests per second
[task8]: rethrottling to [3] requests per second
[task9]: rethrottling to [2] requests per second
[task10]: rethrottling to [1] requests per second
[task11]: rethrottling to [11] requests per second
[task12]: rethrottling to [12] requests per second
[task13]: rethrottling to [13] requests per second
[task14]: rethrottling to [14] requests per second
[task15]: rethrottling to [15] requests per second
delaying recovery due to missing mapping changes java.lang.NullPointerException
delaying recovery due to missing mapping changes org.elasticsearch.index.mapper.MapperParsingException
delaying recovery due to missing mapping changes java.io.IOException
delaying recovery due to missing mapping changes org.elasticsearch.cluster.metadata.MetadataIndexTemplateService$IndexTemplateValidationException
delaying recovery due to missing mapping changes org.elasticsearch.index.IndexNotFoundException
delaying recovery due to missing mapping changes org.elasticsearch.common.xcontent.XContentParseException
delaying recovery due to missing mapping changes org.elasticsearch.index.mapper.MergeMappingException
delaying recovery due to missing mapping changes org.elasticsearch.index.shard.IllegalIndexShardStateException
delaying recovery due to missing mapping changes org.elasticsearch.indices.InvalidIndexNameException
delaying recovery due to missing mapping changes org.elasticsearch.ElasticsearchException
delaying recovery due to missing mapping changes org.elasticsearch.index.engine.EngineException
delaying recovery due to missing mapping changes org.elasticsearch.index.translog.TranslogCorruptedException
delaying recovery due to missing mapping changes org.elasticsearch.cluster.block.ClusterBlockException
delaying recovery due to missing mapping changes org.elasticsearch.action.UnavailableShardsException
delaying recovery due to missing mapping changes org.elasticsearch.rest.RestStatus$ServiceUnavailable
Returning 5 merges for end of upgrade
Returning 12 merges for end of upgrade
Returning 8 merges for end of upgrade
Returning 3 merges for end of upgrade
Returning 10 merges for end of upgrade
Returning 6 merges for end of upgrade
Returning 9 merges for end of upgrade
Returning 4 merges for end of upgrade
Returning 7 merges for end of upgrade
Returning 11 merges for end of upgrade
Returning 2 merges for end of upgrade
Returning 13 merges for end of upgrade
Returning 14 merges for end of upgrade
Ensure generation [0] that is the basis for this write exists in [metadata.name()]
Ensure generation [1] that is the basis for this write exists in [user_data]
Ensure generation [2] that is the basis for this write exists in [config.json]
Ensure generation [3] that is the basis for this write exists in [logs.txt]
Ensure generation [4] that is the basis for this write exists in [cache.db]
Ensure generation [5] that is the basis for this write exists in [metadata.name()]
Ensure generation [6] that is the basis for this write exists in [settings.ini]
Ensure generation [7] that is the basis for this write exists in [backup.zip]
Ensure generation [8] that is the basis for this write exists in [metadata.name()]
Ensure generation [9] that is the basis for this write exists in [index.html]
Ensure generation [10] that is the basis for this write exists in [metadata.name()]
Ensure generation [11] that is the basis for this write exists in [data.csv]
Ensure generation [12] that is the basis for this write exists in [images.png]
Ensure generation [13] that is the basis for this write exists in [metadata.name()]
Ensure generation [14] that is the basis for this write exists in [script.py]
now throttling indexing: numMergesInFlight= 3 , maxNumMerges= 5
now throttling indexing: numMergesInFlight= 4 , maxNumMerges= 6
now throttling indexing: numMergesInFlight= 2 , maxNumMerges= 4
now throttling indexing: numMergesInFlight= 5 , maxNumMerges= 7
now throttling indexing: numMergesInFlight= 6 , maxNumMerges= 8
now throttling indexing: numMergesInFlight= 1 , maxNumMerges= 3
now throttling indexing: numMergesInFlight= 7 , maxNumMerges= 9
now throttling indexing: numMergesInFlight= 8 , maxNumMerges= 10
now throttling indexing: numMergesInFlight= 9 , maxNumMerges= 11
now throttling indexing: numMergesInFlight= 10 , maxNumMerges= 12
now throttling indexing: numMergesInFlight= 11 , maxNumMerges= 13
now throttling indexing: numMergesInFlight= 12 , maxNumMerges= 14
now throttling indexing: numMergesInFlight= 13 , maxNumMerges= 15
now throttling indexing: numMergesInFlight= 14 , maxNumMerges= 16
now throttling indexing: numMergesInFlight= 15 , maxNumMerges= 17
put internal repository [user][profile]
put internal repository [product][image]
put internal repository [order][invoice]
put internal repository [comment][text]
put internal repository [review][rating]
put internal repository [cart][item]
put internal repository [coupon][code]
put internal repository [payment][method]
put internal repository [category][name]
put internal repository [tag][keyword]
put internal repository [customer][email]
put internal repository [wishlist][product_id]
put internal repository [inventory][stock]
put internal repository [shipment][tracking_number]
put internal repository [refund][reason]
unable to resolve default zone from metadata server for GCE discovery service java.net.UnknownHostException: metadata.google.internal
unable to resolve default zone from metadata server for GCE discovery service com.google.cloud.compute.ComputeException: Error reading the response from metadata server
unable to resolve default zone from metadata server for GCE discovery service java.io.IOException: Connection refused
unable to resolve default zone from metadata server for GCE discovery service java.lang.IllegalArgumentException: Invalid zone name
unable to resolve default zone from metadata server for GCE discovery service com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden
unable to resolve default zone from metadata server for GCE discovery service java.net.SocketTimeoutException: Read timed out
unable to resolve default zone from metadata server for GCE discovery service com.google.cloud.compute.ComputeException: The resource 'projects/my-project/zones/default' was not found
unable to resolve default zone from metadata server for GCE discovery service java.lang.NullPointerException
unable to resolve default zone from metadata server for GCE discovery service com.google.api.client.http.HttpResponseException: 404 Not Found
unable to resolve default zone from metadata server for GCE discovery service java.net.MalformedURLException: no protocol: /computeMetadata/v1/instance/zone
unable to resolve default zone from metadata server for GCE discovery service com.google.cloud.compute.ComputeException: Error getting access token for service account
unable to resolve default zone from metadata server for GCE discovery service java.net.ConnectException: Connection timed out
unable to resolve default zone from metadata server for GCE discovery service java.lang.SecurityException: Access denied
unable to resolve default zone from metadata server for GCE discovery service com.google.api.client.googleapis.json.GoogleJsonResponseException: 429 Too Many Requests
unable to resolve default zone from metadata server for GCE discovery service java.io.EOFException
using preference dark mode
using preference metric system
using preference English language
using preference auto-save
using preference high contrast
using preference notifications on
using preference voice control
using preference keyboard shortcuts
using preference cloud sync
using preference low battery mode
using preference privacy settings
using preference bookmarks
using preference history
using preference incognito mode
using preference accessibility features
Schema: {"type": "object", "properties": {"name": {"type": "string"}, "age": {"type": "integer"}}}
Schema: {"type": "array", "items": {"type": "number"}}
Schema: {"type": "string", "pattern": "[a-z]+"}
Schema: {"type": "boolean"}
Schema: {"type": "null"}
Schema: {"type": "object", "properties": {"id": {"type": "string", "format": "uuid"}, "email": {"type": "string", "format": "email"}}}
Schema: {"type": "array", "items": {"type": "object", "properties": {"name": {"type": "string"}, "score": {"type": "integer"}}}}
Schema: {"type": "string", "enum": ["red", "green", "blue"]}
Schema: {"type": "number", "minimum": 0, "maximum": 100}
Schema: {"type": "object", "properties": {"title": {"type": "string"}, "author": {"type": "string"}, "datePublished": {"type": "string", "format": "date"}}}
Schema: {"type": "array", "items": {"type": "string"}, "minItems": 1, "maxItems": 5, "uniqueItems": true}
Schema: {"type": "string", "$ref":"#/definitions/name"}
Schema: {"type":"object","definitions":{"name":{"type":"string","pattern":"[A-Z][a-z]+"}},"properties":{"firstName":{"$ref":"#/definitions/name"},"lastName":{"$ref":"#/definitions/name"}}}
Schema: {"type":"number","multipleOf" : 5}
Schema: {"anyOf":[{"type":"string"},{"type":"number"}]}
--> creating repository my-app at /home/user/projects/my-app
--> creating repository blog at /var/www/html/blog
--> creating repository test-repo at /tmp/test-repo
--> creating repository hello-world at /home/user/Desktop/hello-world
--> creating repository data-analysis at /opt/data-analysis
--> creating repository game-engine at /home/user/Documents/game-engine
--> creating repository music-player at /media/user/Music/music-player
--> creating repository calculator at /home/user/Downloads/calculator
--> creating repository chat-bot at /home/user/chat-bot
--> creating repository weather-app at /home/user/weather-app
--> creating repository portfolio at /var/www/html/portfolio
--> creating repository image-editor at /home/user/Pictures/image-editor
--> creating repository todo-list at /home/user/todo-list
--> creating repository password-manager at /home/user/password-manager
--> creating repository covid-tracker at /opt/covid-tracker
RepositoriesStatsArchive have been cleared. Removed stats: [totalCommits, totalBranches, totalIssues]
RepositoriesStatsArchive have been cleared. Removed stats: [totalStars, totalForks, totalPullRequests]
RepositoriesStatsArchive have been cleared. Removed stats: [totalContributors, totalLanguages, totalWatchers]
RepositoriesStatsArchive have been cleared. Removed stats: [totalSize, totalFiles, totalLines]
RepositoriesStatsArchive have been cleared. Removed stats: [totalViews, totalClones, totalUniqueVisitors]
RepositoriesStatsArchive have been cleared. Removed stats: [totalDownloads, totalReleases, totalTags]
RepositoriesStatsArchive have been cleared. Removed stats: [totalComments, totalReviews, totalMerges]
RepositoriesStatsArchive have been cleared. Removed stats: [totalIssuesClosed, totalPullRequestsClosed, totalBranchesMerged]
RepositoriesStatsArchive have been cleared. Removed stats: [totalCommitsPerDay, totalCommitsPerWeek, totalCommitsPerMonth]
RepositoriesStatsArchive have been cleared. Removed stats: [totalStarsPerDay, totalStarsPerWeek, totalStarsPerMonth]
RepositoriesStatsArchive have been cleared. Removed stats: [totalForksPerDay, totalForksPerWeek, totalForksPerMonth]
RepositoriesStatsArchive have been cleared. Removed stats: [totalPullRequestsPerDay, totalPullRequestsPerWeek, totalPullRequestsPerMonth]
RepositoriesStatsArchive have been cleared. Removed stats: [totalIssuesPerDay, totalIssuesPerWeek, totalIssuesPerMonth]
RepositoriesStatsArchive have been cleared. Removed stats: [totalContributorsPerDay, totalContributorsPerWeek, totalContributorsPerMonth]
RepositoriesStatsArchive have been cleared. Removed stats: [totalLanguagesPerDay, totalLanguagesPerWeek, totalLanguagesPerMonth]
search type is image
search type is video
search type is news
search type is web
search type is map
search type is shopping
search type is academic
search type is music
search type is social
search type is local
search type is travel
search type is sports
search type is health
search type is finance
search type is books
index products is closed, no need to wait for shards, ignoring
index users is closed, no need to wait for shards, ignoring
index orders is closed, no need to wait for shards, ignoring
index news is closed, no need to wait for shards, ignoring
index events is closed, no need to wait for shards, ignoring
index reviews is closed, no need to wait for shards, ignoring
index blogs is closed, no need to wait for shards, ignoring
index books is closed, no need to wait for shards, ignoring
index movies is closed, no need to wait for shards, ignoring
index music is closed, no need to wait for shards, ignoring
index games is closed, no need to wait for shards, ignoring
index photos is closed, no need to wait for shards, ignoring
index videos is closed, no need to wait for shards, ignoring
index podcasts is closed, no need to wait for shards, ignoring
index articles is closed, no need to wait for shards, ignoring
refreshing cluster info [config changed]
refreshing cluster info [periodic update]
refreshing cluster info [node added]
refreshing cluster info [node removed]
refreshing cluster info [node failed]
refreshing cluster info [load balanced]
refreshing cluster info [manual trigger]
refreshing cluster info [recovery mode]
refreshing cluster info [maintenance mode]
refreshing cluster info [scaling up]
refreshing cluster info [scaling down]
refreshing cluster info [network issue]
refreshing cluster info [security update]
refreshing cluster info [data migration]
refreshing cluster info [performance optimization]
Keytab Length: 1024
Keytab Length: 2048
Keytab Length: 512
Keytab Length: 4096
Keytab Length: 768
Keytab Length: 1536
Keytab Length: 256
Keytab Length: 3072
Keytab Length: 128
Keytab Length: 8192
Keytab Length: 640
Keytab Length: 2304
Keytab Length: 384
Keytab Length: 4608
Keytab Length: 192
writing out of dangling indices state for index [test-1] completed after [0 ms]
writing out of dangling indices state for index [demo-2] completed after [0 ms]
writing out of dangling indices state for index [prod-3] completed after [0 ms]
writing out of dangling indices state for index [test-4] completed after [-1 ms]
writing out of dangling indices state for index [demo-5] completed after [-2 ms]
writing out of dangling indices state for index [prod-6] completed after [-3 ms]
writing out of dangling indices state for index [test-7] completed after [-4 ms]
writing out of dangling indices state for index [demo-8] completed after [-5 ms]
writing out of dangling indices state for index [prod-9] completed after [-6 ms]
writing out of dangling indices state for index [test-10] completed after [-7 ms]
writing out of dangling indices state for index [demo-11] completed after [-8 ms]
writing out of dangling indices state for index [prod-12] completed after [-9 ms]
writing out of dangling indices state for index [test-13] completed after [-10 ms]
writing out of dangling indices state for index [demo-14] completed after [-11 ms]
writing out of dangling indices state for index [prod-15] completed after [-12 ms]
bulk failure 0
bulk failure 1
bulk failure 2
bulk failure 3
bulk failure 4
bulk failure 5
bulk failure 6
bulk failure 7
bulk failure 8
bulk failure 9
bulk failure 10
bulk failure 11
bulk failure 12
bulk failure 13
bulk failure 14
--> all shards allocated, replica that should be promoted: startedReplica[0]
--> all shards allocated, replica that should be promoted: startedReplica[1]
--> all shards allocated, replica that should be promoted: startedReplica[2]
--> all shards allocated, replica that should be promoted: startedReplica[3]
--> all shards allocated, replica that should be promoted: startedReplica[4]
--> all shards allocated, replica that should be promoted: startedReplica[5]
--> all shards allocated, replica that should be promoted: startedReplica[6]
--> all shards allocated, replica that should be promoted: startedReplica[7]
--> all shards allocated, replica that should be promoted: startedReplica[8]
--> all shards allocated, replica that should be promoted: startedReplica[9]
--> all shards allocated, replica that should be promoted: startedReplica[10]
--> all shards allocated, replica that should be promoted: startedReplica[11]
--> all shards allocated, replica that should be promoted: startedReplica[12]
--> all shards allocated, replica that should be promoted: startedReplica[13]
--> all shards allocated, replica that should be promoted: startedReplica[14]
task [backup] timed out after [10 minutes]
task [update] timed out after [5 seconds]
task [scan] timed out after [30 minutes]
task [sync] timed out after [15 seconds]
task [download] timed out after [2 minutes]
task [upload] timed out after [1 minute]
task [print] timed out after [20 seconds]
task [copy] timed out after [3 minutes]
task [delete] timed out after [10 seconds]
task [install] timed out after [5 minutes]
task [uninstall] timed out after [2 seconds]
task [encrypt] timed out after [15 minutes]
task [decrypt] timed out after [10 minutes]
task [compress] timed out after [1 minute]
task [decompress] timed out after [30 seconds]
using endpoint [https://api.example.com] and region [us-east-1]
using endpoint [http://localhost:8080] and region [local]
using endpoint [https://service.example.net] and region [eu-west-2]
using endpoint [http://192.168.0.1:3000] and region [custom]
using endpoint [https://api.example.org] and region [ap-southeast-1]
using endpoint [http://example.com:8000] and region [us-west-2]
using endpoint [https://service.example.io] and region [eu-central-1]
using endpoint [http://127.0.0.1:5000] and region [local]
using endpoint [https://api.example.co.uk] and region [eu-west-1]
using endpoint [http://10.0.0.1:4000] and region [custom]
using endpoint [https://service.example.com.au] and region [ap-southeast-2]
using endpoint [http://example.net:9000] and region [us-east-2]
using endpoint [https://api.example.in] and region [ap-south-1]
using endpoint [http://localhost:3000] and region [local]
using endpoint [https://service.example.ca] and region [ca-central-1]
Using concurrent search over segments (experimental) for request with context id 5f3a7b9c
Using concurrent search over segments (experimental) for request with context id 8d4c2e1a
Using concurrent search over segments (experimental) for request with context id 2a6f9d7e
Using concurrent search over segments (experimental) for request with context id 9b3c4f6a
Using concurrent search over segments (experimental) for request with context id 6e7d8c2b
Using concurrent search over segments (experimental) for request with context id 3f4a6b8c
Using concurrent search over segments (experimental) for request with context id 7c8d9e3a
Using concurrent search over segments (experimental) for request with context id 4b5a7c9d
Using concurrent search over segments (experimental) for request with context id 1a2b3c4d
Using concurrent search over segments (experimental) for request with context id c9d8e7f6
Using concurrent search over segments (experimental) for request with context id f6e5d4c3
Using concurrent search over segments (experimental) for request with context id b8a7c6d5
Using concurrent search over segments (experimental) for request with context id d5c6b7a8
Using concurrent search over segments (experimental) for request with context id a9b8c7d6
Using concurrent search over segments (experimental) for request with context id e4f5d6c7
[blog][0] starting recovery to node-1
[news][3] starting recovery to node-4
[shop][2] starting recovery to node-3
[forum][1] starting recovery to node-2
[wiki][4] starting recovery to node-5
[video][0] starting recovery to node-1
[social][3] starting recovery to node-4
[game][2] starting recovery to node-3
[music][1] starting recovery to node-2
[photo][4] starting recovery to node-5
[mail][0] starting recovery to node-1
[chat][3] starting recovery to node-4
[book][2] starting recovery to node-3
[map][1] starting recovery to node-2
[web][4] starting recovery to node-5
Keys to remove: [a, b, c]
Keys to remove: [x, y, z]
Keys to remove: [foo, bar, baz]
Keys to remove: [1, 2, 3]
Keys to remove: [red, green, blue]
Keys to remove: [cat, dog, bird]
Keys to remove: [apple, banana, orange]
Keys to remove: [name, age, gender]
Keys to remove: [true, false, null]
Keys to remove: [hello, world, bye]
Keys to remove: [pi, e, phi]
Keys to remove: [A, B, C]
Keys to remove: [i, j, k]
Keys to remove: [star, moon, sun]
Keys to remove: [one, two, three]
Failed to serialize repository data java.io.NotSerializableException: com.example.model.User
Failed to serialize repository data java.lang.NullPointerException: null
Failed to serialize repository data java.io.IOException: Stream closed
Failed to serialize repository data java.lang.IllegalArgumentException: Invalid repository name
Failed to serialize repository data java.io.FileNotFoundException: /data/repo.dat (No such file or directory)
Failed to serialize repository data java.lang.ClassNotFoundException: com.example.repository.Repository
Failed to serialize repository data java.io.InvalidClassException: com.example.model.User; incompatible types for field age
Failed to serialize repository data java.lang.OutOfMemoryError: Java heap space
Failed to serialize repository data java.io.EOFException: Unexpected end of stream
Failed to serialize repository data java.lang.SecurityException: Permission denied
Failed to serialize repository data java.io.WriteAbortedException: Writing aborted; java.io.NotSerializableException: com.example.model.Address
Failed to serialize repository data java.lang.StackOverflowError: null
Failed to serialize repository data java.io.UTFDataFormatException: Malformed input around byte 10
Failed to serialize repository data java.lang.InternalError: Unexpected exception thrown by ObjectOutputStream.writeUnshared
Failed to serialize repository data java.io.OptionalDataException: OptionalDataException
Done Balancing after [5] iterations. State: Stable
Done Balancing after [3] iterations. State: Degraded
Done Balancing after [7] iterations. State: Recovering
Done Balancing after [4] iterations. State: Critical
Done Balancing after [6] iterations. State: Optimal
Done Balancing after [8] iterations. State: Unstable
Done Balancing after [2] iterations. State: Healthy
Done Balancing after [9] iterations. State: Failed
Done Balancing after [10] iterations. State: Unknown
Done Balancing after [1] iterations. State: Normal
Done Balancing after [11] iterations. State: Warning
Done Balancing after [12] iterations. State: Error
Done Balancing after [13] iterations. State: Offline
Done Balancing after [14] iterations. State: Online
Done Balancing after [15] iterations. State: Maintenance
The exception from request processor [QueryParser] in the search pipeline [default] was ignored java.lang.IllegalArgumentException
The exception from request processor [SpellChecker] in the search pipeline [suggestions] was ignored java.io.IOException
The exception from request processor [Ranker] in the search pipeline [relevance] was ignored java.lang.NullPointerException
The exception from request processor [Faceter] in the search pipeline [navigation] was ignored java.util.ConcurrentModificationException
The exception from request processor [Highlighter] in the search pipeline [presentation] was ignored java.lang.OutOfMemoryError
The exception from request processor [Filter] in the search pipeline [security] was ignored java.lang.SecurityException
The exception from request processor [Aggregator] in the search pipeline [analytics] was ignored java.sql.SQLException
The exception from request processor [Transformer] in the search pipeline [customization] was ignored java.lang.ClassCastException
The exception from request processor [Validator] in the search pipeline [validation] was ignored java.lang.IllegalStateException
The exception from request processor [Logger] in the search pipeline [logging] was ignored java.io.FileNotFoundException
The exception from request processor [Crawler] in the search pipeline [indexing] was ignored org.apache.http.HttpException
The exception from request processor [Tokenizer] in the search pipeline [language] was ignored org.apache.lucene.analysis.Analyzer$TokenStreamComponents
The exception from request processor [Stemmer] in the search pipeline [language] was ignored org.tartarus.snowball.SnowballProgram
The exception from request processor [Synonymizer] in the search pipeline [language] was ignored org.apache.lucene.search.spell.SuggestWord
The exception from request processor [Lemmatizer] in the search pipeline [language] was ignored edu.stanford.nlp.process.Morphology
history is retained by [0]
history is retained by [1]
history is retained by [2]
history is retained by [3]
history is retained by [4]
history is retained by [5]
history is retained by [6]
history is retained by [7]
history is retained by [8]
history is retained by [9]
history is retained by [10]
history is retained by [11]
history is retained by [12]
history is retained by [13]
history is retained by [14]
using explicit ec2 endpoint [ec2.us-east-1.amazonaws.com]
using explicit ec2 endpoint [ec2.ap-southeast-2.amazonaws.com]
using explicit ec2 endpoint [ec2.eu-west-1.amazonaws.com]
using explicit ec2 endpoint [ec2.sa-east-1.amazonaws.com]
using explicit ec2 endpoint [ec2.ca-central-1.amazonaws.com]
using explicit ec2 endpoint [ec2.cn-north-1.amazonaws.com.cn]
using explicit ec2 endpoint [ec2.us-gov-west-1.amazonaws.com]
using explicit ec2 endpoint [ec2.us-gov-east-1.amazonaws.com]
using explicit ec2 endpoint [ec2.af-south-1.amazonaws.com]
using explicit ec2 endpoint [ec2.eu-south-1.amazonaws.com]
using explicit ec2 endpoint [ec2.me-south-1.amazonaws.com]
using explicit ec2 endpoint [ec2.ap-northeast-3.amazonaws.com]
using explicit ec2 endpoint [ec2.ap-east-1.amazonaws.com]
using explicit ec2 endpoint [ec2.eu-north-1.amazonaws.com]
using explicit ec2 endpoint [ec2.ap-northeast-1.amazonaws.com]
iteration [1] - successful shards: 5 (expected 5)
iteration [2] - successful shards: 4 (expected 5)
iteration [3] - successful shards: 5 (expected 5)
iteration [4] - successful shards: 3 (expected 5)
iteration [5] - successful shards: 5 (expected 5)
iteration [6] - successful shards: 4 (expected 5)
iteration [7] - successful shards: 2 (expected 5)
iteration [8] - successful shards: 5 (expected 5)
iteration [9] - successful shards: 3 (expected 5)
iteration [10] - successful shards: 4 (expected 5)
iteration [11] - successful shards: 1 (expected 5)
iteration [12] - successful shards: 5 (expected 5)
iteration [13] - successful shards: 4 (expected 5)
iteration [14] - successful shards: 2 (expected 5)
Overwriting password to: 123456
Overwriting password to: qwerty
Overwriting password to: password
Overwriting password to: abcdef
Overwriting password to: iloveyou
Overwriting password to: 654321
Overwriting password to: asdfgh
Overwriting password to: letmein
Overwriting password to: zxcvbn
Overwriting password to: trustno1
Overwriting password to: dragon
Overwriting password to: monkey
Overwriting password to: shadow
Overwriting password to: master
Overwriting password to: sunshine
failed to send failure response due to timeout
failed to send failure response connection refused
failed to send failure response with code 500
failed to send failure response invalid request
failed to send failure response no such method
failed to send failure response out of memory
failed to send failure response with code 404
failed to send failure response internal server error
failed to send failure response due to network error
failed to send failure response with code 403
failed to send failure response bad gateway
failed to send failure response due to socket error
failed to send failure response with code 400
failed to send failure response service unavailable
updated weighted routing weights [0.3, 0.4, 0.3] in metadata
updated weighted routing weights [0.5, 0.2, 0.3] in metadata
updated weighted routing weights [0.25, 0.25, 0.5] in metadata
updated weighted routing weights [0.4, 0.4, 0.2] in metadata
updated weighted routing weights [0.1, 0.6, 0.3] in metadata
updated weighted routing weights [0.2, 0.5, 0.3] in metadata
updated weighted routing weights [0.6, 0.2, 0.2] in metadata
updated weighted routing weights [0.3, 0.3, 0.4] in metadata
updated weighted routing weights [0.4, 0.2, 0.4] in metadata
updated weighted routing weights [0.2, 0.4, 0.4] in metadata
updated weighted routing weights [0.5, 0.3, 0.2] in metadata
updated weighted routing weights [0.2, 0.3, 0.5] in metadata
updated weighted routing weights [0.3, 0.5, 0.2] in metadata
updated weighted routing weights [0.4, 0.3, 0.3] in metadata
updated weighted routing weights [0.1, 0.4, 0.5] in metadata
localcheckpoint 0 , global 0
localcheckpoint 1 , global 1
localcheckpoint 2 , global 2
localcheckpoint 3 , global 3
localcheckpoint 4 , global 4
localcheckpoint 5 , global 5
localcheckpoint 6 , global 6
localcheckpoint 7 , global 7
localcheckpoint 8 , global 8
localcheckpoint 9 , global 9
localcheckpoint 10 , global 10
localcheckpoint 11 , global 11
localcheckpoint 12 , global 12
localcheckpoint 13 , global 13
localcheckpoint 14 , global 14
Failed to read data , from file: /home/user/data.csv , exception is: java.io.FileNotFoundException
Invalid input format , from file: /var/log/messages , exception is: java.lang.NumberFormatException
Connection timed out , from file: /etc/hosts , exception is: java.net.SocketTimeoutException
Access denied , from file: /root/.bashrc , exception is: java.nio.file.AccessDeniedException
File not found , from file: /tmp/test.txt , exception is: java.io.IOException
Parsing error , from file: /opt/config.json , exception is: org.json.JSONException
Unsupported encoding , from file: /usr/local/bin/script.sh , exception is: java.io.UnsupportedEncodingException
Out of memory , from file: /dev/null , exception is: java.lang.OutOfMemoryError
Null pointer , from file: /home/user/null.java , exception is: java.lang.NullPointerException
Array index out of bounds , from file: /home/user/array.java , exception is: java.lang.ArrayIndexOutOfBoundsException
Class not found , from file: /home/user/class.java , exception is: java.lang.ClassNotFoundException
Illegal argument , from file: /home/user/argument.java , exception is: java.lang.IllegalArgumentException
Division by zero , from file: /home/user/division.java , exception is: java.lang.ArithmeticException
No such element , from file: /home/user/element.java , exception is: java.util.NoSuchElementException
Concurrent modification , from file: /home/user/modification.java , exception is: java.util.ConcurrentModificationException
Unable to archive the repository stats [daily] as the archive is full.
Unable to archive the repository stats [weekly] as the archive is full.
Unable to archive the repository stats [monthly] as the archive is full.
Unable to archive the repository stats [yearly] as the archive is full.
Unable to archive the repository stats [hourly] as the archive is full.
Unable to archive the repository stats [user] as the archive is full.
Unable to archive the repository stats [project] as the archive is full.
Unable to archive the repository stats [branch] as the archive is full.
Unable to archive the repository stats [commit] as the archive is full.
Unable to archive the repository stats [pull_request] as the archive is full.
Unable to archive the repository stats [issue] as the archive is full.
Unable to archive the repository stats [comment] as the archive is full.
Unable to archive the repository stats [star] as the archive is full.
Unable to archive the repository stats [fork] as the archive is full.
Unable to archive the repository stats [clone] as the archive is full.
failed to sync translog java.io.IOException: No space left on device
failed to sync translog org.elasticsearch.index.translog.TranslogCorruptedException: translog corrupted
failed to sync translog java.lang.IllegalStateException: translog closed
failed to sync translog org.elasticsearch.index.engine.EngineException: failed to create new translog file
failed to sync translog java.nio.file.AccessDeniedException: /var/lib/elasticsearch/nodes/0/indices/translog-1.tlog
failed to sync translog org.elasticsearch.cluster.block.ClusterBlockException: blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];
failed to sync translog java.net.SocketTimeoutException: Read timed out
failed to sync translog org.elasticsearch.index.shard.IndexShardClosedException: CurrentState[CLOSED] Closed
failed to sync translog org.elasticsearch.transport.NodeDisconnectedException: [node-1][127.0.0.1:9300][indices:data/write/bulk[s]] disconnected
failed to sync translog org.elasticsearch.action.UnavailableShardsException: [index-1][0] primary shard is not active Timeout
failed to sync translog java.lang.OutOfMemoryError: Java heap space
failed to sync translog org.elasticsearch.index.translog.TranslogGenerationMismatchException: expected generation 1 but got 2
failed to sync translog org.elasticsearch.index.engine.VersionConflictEngineException: [doc-1]: version conflict, current version [2] is different than the one provided [1]
failed to sync translog org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [<transport_request>] would be [123456789/117.7mb], which is larger than the limit of [104857600/100mb]
failed to sync translog org.elasticsearch.ElasticsearchException: unknown error occurred while syncing translog
Resetting repository generation tracker because we failed to read generation [3] java.io.FileNotFoundException
Resetting repository generation tracker because we failed to read generation [7] java.io.IOException
Resetting repository generation tracker because we failed to read generation [5] java.nio.file.NoSuchFileException
Resetting repository generation tracker because we failed to read generation [9] java.io.EOFException
Resetting repository generation tracker because we failed to read generation [4] java.nio.file.AccessDeniedException
Resetting repository generation tracker because we failed to read generation [8] java.io.InterruptedIOException
Resetting repository generation tracker because we failed to read generation [6] java.nio.file.FileSystemException
Resetting repository generation tracker because we failed to read generation [2] java.io.SyncFailedException
Resetting repository generation tracker because we failed to read generation [1] java.io.UTFDataFormatException
Resetting repository generation tracker because we failed to read generation [10] java.io.StreamCorruptedException
Resetting repository generation tracker because we failed to read generation [12] java.io.InvalidClassException
Resetting repository generation tracker because we failed to read generation [11] java.io.NotSerializableException
Resetting repository generation tracker because we failed to read generation [13] java.io.OptionalDataException
Resetting repository generation tracker because we failed to read generation [14] java.io.WriteAbortedException
Resetting repository generation tracker because we failed to read generation [15] java.io.ObjectStreamException
Timed out waiting for process to exit java.lang.OutOfMemoryError
Timed out waiting for process to exit java.net.SocketTimeoutException
Timed out waiting for process to exit java.io.IOException
Timed out waiting for process to exit java.lang.InterruptedException
Timed out waiting for process to exit java.lang.NullPointerException
Timed out waiting for process to exit java.util.concurrent.TimeoutException
Timed out waiting for process to exit java.lang.IllegalStateException
Timed out waiting for process to exit java.lang.IllegalArgumentException
Timed out waiting for process to exit java.lang.ClassNotFoundException
Timed out waiting for process to exit java.lang.NoSuchMethodError
Timed out waiting for process to exit java.lang.SecurityException
Timed out waiting for process to exit java.sql.SQLException
Timed out waiting for process to exit java.lang.RuntimeException
Timed out waiting for process to exit java.lang.StackOverflowError
Timed out waiting for process to exit java.lang.AssertionError
Unexpected failure NullPointerException
Unexpected failure IOException
Unexpected failure OutOfMemoryError
Unexpected failure ArrayIndexOutOfBoundsException
Unexpected failure ArithmeticException
Unexpected failure ClassNotFoundException
Unexpected failure NumberFormatException
Unexpected failure AssertionError
Unexpected failure StackOverflowError
Unexpected failure FileNotFoundException
Unexpected failure SQLException
Unexpected failure SecurityException
Unexpected failure IllegalArgumentException
Unexpected failure IllegalStateException
Unexpected failure ConcurrentModificationException
[metadata.name()] Found stale index [indexSnId]. Cleaning it up
[User] Found stale index [123]. Cleaning it up
[Product] Found stale index [456]. Cleaning it up
[Order] Found stale index [789]. Cleaning it up
[Customer] Found stale index [1011]. Cleaning it up
[Invoice] Found stale index [1213]. Cleaning it up
[Payment] Found stale index [1415]. Cleaning it up
[Review] Found stale index [1617]. Cleaning it up
[Category] Found stale index [1819]. Cleaning it up
[Cart] Found stale index [2021]. Cleaning it up
[Wishlist] Found stale index [2223]. Cleaning it up
[Account] Found stale index [2425]. Cleaning it up
[Address] Found stale index [2627]. Cleaning it up
[Shipping] Found stale index [2829]. Cleaning it up
[Discount] Found stale index [3031]. Cleaning it up
Query timed out, invalidating cache entry for request on shard [1]: GET /users/123
Query timed out, invalidating cache entry for request on shard [5]: POST /orders/456
Query timed out, invalidating cache entry for request on shard [3]: PUT /products/789
Query timed out, invalidating cache entry for request on shard [2]: DELETE /comments/101
Query timed out, invalidating cache entry for request on shard [4]: PATCH /reviews/112
Query timed out, invalidating cache entry for request on shard [6]: HEAD /images/134
Query timed out, invalidating cache entry for request on shard [7]: OPTIONS /settings/156
Query timed out, invalidating cache entry for request on shard [8]: CONNECT /streams/178
Query timed out, invalidating cache entry for request on shard [9]: TRACE /logs/190
Query timed out, invalidating cache entry for request on shard [10]: SEARCH /products?name=abc
the published hash [0x12345678] of the consistent secure setting [cluster.name] differs from the locally computed one [0x87654321]
the published hash [0xabcdef12] of the consistent secure setting [xpack.security.enabled] differs from the locally computed one [0x12fedcba]
the published hash [0xdeadbeef] of the consistent secure setting [path.data] differs from the locally computed one [0xfeebdaed]
the published hash [0xcafebabe] of the consistent secure setting [network.host] differs from the locally computed one [0xbebafeca]
the published hash [0xfaceb00c] of the consistent secure setting [discovery.seed_hosts] differs from the locally computed one [0xc00bcefa]
the published hash [0xbadcafe1] of the consistent secure setting [node.name] differs from the locally computed one [0x1efacdba]
the published hash [0xfeedface] of the consistent secure setting [http.port] differs from the locally computed one [0xcefadeed]
the published hash [0xc001d00d] of the consistent secure setting [transport.port] differs from the locally computed one [0xd00dc001]
the published hash [0xbaadf00d] of the consistent secure setting [cluster.initial_master_nodes] differs from the locally computed one [0xd00dfaad]
the published hash [0xdeadc0de] of the consistent secure setting [bootstrap.memory_lock] differs from the locally computed one [0xec0cdaed]
the published hash [0xf00dfade] of the consistent secure setting [path.logs] differs from the locally computed one [0xedfadf00]
the published hash [0xbeefcace] of the consistent secure setting [node.attr.zone] differs from the locally computed one [0xcecaefbe]
the published hash [0xcab005e5] of the consistent secure setting [node.attr.rack] differs from the locally computed one [0xe505b0ca]
the published hash [0xb16b00b5] of the consistent secure setting [node.attr.size] differs from the locally computed one [0xb50bb6b1]
the published hash [0xdeadf00d] of the consistent secure setting [node.attr.color] differs from the locally computed one [0xd00fdaed]
Generated password: 8fGh%3kL
Generated password: 4!mN@7wQ
Generated password: zXc2*1vB
Generated password: 9rT#6yUo
Generated password: hJk7&5dS
Generated password: 3eF$8aZr
Generated password: nMl0^9gT
Generated password: 5pQ%4wEi
Generated password: cVb1*2nM
Generated password: 7uI#6oPj
Generated password: kLm8&3fG
Generated password: 1zA$0xSd
Generated password: mNj9^7hK
Generated password: 6yU%5tRi
Generated password: vBn2*4xZ
IndicesStatsAction timed out for ClusterInfoUpdateJob java.net.SocketTimeoutException: Read timed out
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.cluster.block.ClusterBlockException: blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];
IndicesStatsAction timed out for ClusterInfoUpdateJob java.io.IOException: Failed to obtain node lock, is the following location writable?: [/var/lib/elasticsearch]
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.transport.NodeDisconnectedException: [node-1][127.0.0.1:9300][cluster:monitor/stats] disconnected
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.ElasticsearchException: failed to refresh store stats
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [<transport_request>] would be [123456789/117.7mb], which is larger than the limit of [123456789/117.7mb], real usage: [123456789/117.7mb], new bytes reserved: [0/0b], usages [request=0/0b, fielddata=12345/12kb, in_flight_requests=12345/12kb, model_inference=0/0b, accounting=12345/12kb]
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.action.NoShardAvailableActionException: No shard available for [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@12345678]
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException: failed to process cluster event (put-mapping) within 30s
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.index.IndexNotFoundException: no such index [test]
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: rejected execution of org.elasticsearch.transport.TransportService$7@12345678 on EsThreadPoolExecutor[name = node-1/write, queue capacity = 200, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@12345678[Running, pool size = 4, active threads = 4, queued tasks = 200, completed tasks = 12345]]
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.index.engine.VersionConflictEngineException: [test][1]: version conflict, required seqNo [1234], primary term [1]. current document has seqNo [1235] and primary term [1]
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.indices.IndexClosedException: closed
IndicesStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.rest.action.RestActions$NodesResponseRestListener.onFailure(RestActions.java:123): Failed to execute IndicesStatsAction for ClusterInfoUpdateJob
IndicesStatsAction timed out for ClusterInfoUpdateJob java.lang.IllegalArgumentException: Fielddata is disabled on text fields by default. Set fielddata=true on [message] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory.
Skipping unknown custom object with type "user"
Skipping unknown custom object with type "product"
Skipping unknown custom object with type "order"
Skipping unknown custom object with type "review"
Skipping unknown custom object with type "cart"
Skipping unknown custom object with type "coupon"
Skipping unknown custom object with type "address"
Skipping unknown custom object with type "payment"
Skipping unknown custom object with type "shipment"
Skipping unknown custom object with type "inventory"
Skipping unknown custom object with type "category"
Skipping unknown custom object with type "tag"
Skipping unknown custom object with type "wishlist"
Skipping unknown custom object with type "recommendation"
Skipping unknown custom object with type "feedback"
--> Allow indexer to index [185] documents
--> Allow indexer to index [256] documents
--> Allow indexer to index [312] documents
--> Allow indexer to index [78] documents
--> Allow indexer to index [532] documents
--> Allow indexer to index [409] documents
--> Allow indexer to index [143] documents
--> Allow indexer to index [600] documents
--> Allow indexer to index [267] documents
--> Allow indexer to index [95] documents
--> Allow indexer to index [201] documents
--> Allow indexer to index [543] documents
--> Allow indexer to index [367] documents
--> Allow indexer to index [124] documents
--> Allow indexer to index [478] documents
Done Cluster Health, status clusterHealth.getStatus()=UP
Done Cluster Health, status clusterHealth.getStatus()=DOWN
Done Cluster Health, status clusterHealth.getStatus()=ERROR
Done Cluster Health, status clusterHealth.getStatus()=OK
Done Cluster Health, status clusterHealth.getStatus()=DEGRADED
Done Cluster Health, status clusterHealth.getStatus()=RECOVERING
Done Cluster Health, status clusterHealth.getStatus()=MAINTENANCE
Done Cluster Health, status clusterHealth.getStatus()=UNKNOWN
Done Cluster Health, status clusterHealth.getStatus()=UNSTABLE
Done Cluster Health, status clusterHealth.getStatus()=OFFLINE
Done Cluster Health, status clusterHealth.getStatus()=NORMAL
Done Cluster Health, status clusterHealth.getStatus()=PARTIAL
Done Cluster Health, status clusterHealth.getStatus()=SUSPENDED
Done Cluster Health, status clusterHealth.getStatus()=CRITICAL
Done Cluster Health, status clusterHealth.getStatus()=STANDBY
Failure when trying to load missing version information from snapshot metadata [NullPointerException]
Failure when trying to load missing version information from snapshot metadata [FileNotFoundException]
Failure when trying to load missing version information from snapshot metadata [ConnectionTimeoutException]
Failure when trying to load missing version information from snapshot metadata [DatabaseException]
Failure when trying to load missing version information from snapshot metadata [PermissionDeniedException]
Failure when trying to load missing version information from snapshot metadata [OutOfMemoryError]
Failure when trying to load missing version information from snapshot metadata [InvalidArgumentException]
Failure when trying to load missing version information from snapshot metadata [NetworkError]
Failure when trying to load missing version information from snapshot metadata [ServiceUnavailableException]
Failure when trying to load missing version information from snapshot metadata [RuntimeError]
Failure when trying to load missing version information from snapshot metadata [InvalidDataException]
Failure when trying to load missing version information from snapshot metadata [AccessViolation]
Failure when trying to load missing version information from snapshot metadata [ResourceExhausted]
Failure when trying to load missing version information from snapshot metadata [SecurityBreach]
Failure when trying to load missing version information from snapshot metadata [DiskFullException]
no index mapper found for field: [name] returning default postings format
no index mapper found for field: [age] returning default postings format
no index mapper found for field: [address] returning default postings format
no index mapper found for field: [email] returning default postings format
no index mapper found for field: [phone] returning default postings format
no index mapper found for field: [gender] returning default postings format
no index mapper found for field: [salary] returning default postings format
no index mapper found for field: [department] returning default postings format
no index mapper found for field: [title] returning default postings format
no index mapper found for field: [skills] returning default postings format
no index mapper found for field: [interests] returning default postings format
no index mapper found for field: [education] returning default postings format
no index mapper found for field: [experience] returning default postings format
no index mapper found for field: [references] returning default postings format
no index mapper found for field: [awards] returning default postings format
[0] store not initialized prior to closing shard, nothing to close
[1] store not initialized prior to closing shard, nothing to close
[2] store not initialized prior to closing shard, nothing to close
[3] store not initialized prior to closing shard, nothing to close
[4] store not initialized prior to closing shard, nothing to close
[5] store not initialized prior to closing shard, nothing to close
[6] store not initialized prior to closing shard, nothing to close
[7] store not initialized prior to closing shard, nothing to close
[8] store not initialized prior to closing shard, nothing to close
[9] store not initialized prior to closing shard, nothing to close
[10] store not initialized prior to closing shard, nothing to close
[11] store not initialized prior to closing shard, nothing to close
[12] store not initialized prior to closing shard, nothing to close
[13] store not initialized prior to closing shard, nothing to close
[14] store not initialized prior to closing shard, nothing to close
Not caching repository data of size [623KB] for repository [test-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [1.2MB] for repository [demo-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [789KB] for repository [prod-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [512KB] for repository [dev-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [2.3MB] for repository [backup-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [1.5MB] for repository [archive-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [678KB] for repository [config-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [1.8MB] for repository [data-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [945KB] for repository [docs-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [1.1MB] for repository [code-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [543KB] for repository [logs-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [2.1MB] for repository [media-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [712KB] for repository [assets-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [1.6MB] for repository [temp-repo] because it is larger than 500KB in serialized size
Not caching repository data of size [856KB] for repository [user-repo] because it is larger than 500KB in serialized size
failed to invoke after index created callback java.lang.NullPointerException
failed to invoke after index created callback org.springframework.beans.factory.BeanCreationException
failed to invoke after index created callback java.io.IOException
failed to invoke after index created callback java.lang.IllegalArgumentException
failed to invoke after index created callback org.hibernate.HibernateException
failed to invoke after index created callback java.lang.ClassNotFoundException
failed to invoke after index created callback java.sql.SQLException
failed to invoke after index created callback java.lang.OutOfMemoryError
failed to invoke after index created callback java.lang.StackOverflowError
failed to invoke after index created callback javax.validation.ConstraintViolationException
failed to invoke after index created callback org.springframework.dao.DataAccessException
failed to invoke after index created callback java.net.SocketTimeoutException
failed to invoke after index created callback java.lang.SecurityException
failed to invoke after index created callback org.springframework.web.client.HttpClientErrorException
failed to invoke after index created callback java.util.concurrent.ExecutionException
Added extra jar commons-io-2.8.0.jar to /lib
Added extra jar log4j-1.2.17.jar to /bin
Added extra jar gson-2.8.6.jar to /src
Added extra jar junit-4.13.2.jar to /test
Added extra jar mysql-connector-java-8.0.26.jar to /config
Added extra jar apache-commons-lang3-3.12.0.jar to /utils
Added extra jar spring-boot-2.5.5.jar to /webapp
Added extra jar hibernate-core-5.5.7.Final.jar to /persistence
Added extra jar slf4j-api-1.7.32.jar to /logging
Added extra jar jackson-databind-2.13.0.jar to /json
Added extra jar guava-31.0.1-jre.jar to /collections
Added extra jar poi-5.0.0.jar to /excel
Added extra jar jsoup-1.14.3.jar to /html
Added extra jar lucene-core-8.10.1.jar to /search
Added extra jar joda-time-2.10.12.jar to /time
Successfully loaded all snapshot's version information for [a1b2c3d4, e5f6g7h8, i9j0k1l2] from snapshot metadata
Successfully loaded all snapshot's version information for [m3n4o5p6, q7r8s9t0, u1v2w3x4] from snapshot metadata
Successfully loaded all snapshot's version information for [y5z6a7b8, c9d0e1f2, g3h4i5j6] from snapshot metadata
Successfully loaded all snapshot's version information for [k7l8m9n0, o1p2q3r4, s5t6u7v8] from snapshot metadata
Successfully loaded all snapshot's version information for [w9x0y1z2, a3b4c5d6, e7f8g9h0] from snapshot metadata
Successfully loaded all snapshot's version information for [i1j2k3l4, m5n6o7p8, q9r0s1t2] from snapshot metadata
Successfully loaded all snapshot's version information for [u3v4w5x6, y7z8a9b0, c1d2e3f4] from snapshot metadata
Successfully loaded all snapshot's version information for [q5r6s7t8, u9v0w1x2, y3z4a5b6] from snapshot metadata
Successfully loaded all snapshot's version information for [e5f6g7h8, i9j0k1l2, m3n4o5p6] from snapshot metadata
Successfully loaded all snapshot's version information for [s7t8u9v0, w1x2y3z4, a5b6c7d8] from snapshot metadata
Successfully loaded all snapshot's version information for [g9h0i1j2, k3l4m5n6, o7p8q9r0] from snapshot metadata
Successfully loaded all snapshot's version information for [y1z2a3b4, c5d6e7f8, g9h0i1j2] from snapshot metadata
Successfully loaded all snapshot's version information for [o3p4q5r6, s7t8u9v0, w1x2y3z4] from snapshot metadata
Successfully loaded all snapshot's version information for [c7d8e9f0, g1h2i3j4, k5l6m7n8] from snapshot metadata
Successfully loaded all snapshot's version information for [w3x4y5z6, a7b8c9d0, e1f2g3h4] from snapshot metadata
more than the allowed 85.0% used disk threshold ( 86.7% used) on node [node-1], preventing allocation
more than the allowed 90.0% used disk threshold ( 91.2% used) on node [node-5], preventing allocation
more than the allowed 80.0% used disk threshold ( 81.5% used) on node [node-3], preventing allocation
more than the allowed 95.0% used disk threshold ( 96.3% used) on node [node-7], preventing allocation
more than the allowed 75.0% used disk threshold ( 76.8% used) on node [node-2], preventing allocation
more than the allowed 88.0% used disk threshold ( 89.4% used) on node [node-4], preventing allocation
more than the allowed 92.0% used disk threshold ( 93.1% used) on node [node-6], preventing allocation
more than the allowed 82.0% used disk threshold ( 83.7% used) on node [node-8], preventing allocation
more than the allowed 78.0% used disk threshold ( 79.6% used) on node [node-9], preventing allocation
more than the allowed 84.0% used disk threshold ( 85.3% used) on node [node-10], preventing allocation
more than the allowed 86.0% used disk threshold ( 87.9% used) on node [node-11], preventing allocation
more than the allowed 94.0% used disk threshold ( 95.2% used) on node [node-12], preventing allocation
more than the allowed 76.0% used disk threshold ( 77.4% used) on node [node-13], preventing allocation
more than the allowed 83.0% used disk threshold ( 84.6% used) on node [node-14], preventing allocation
more than the allowed 81.0% used disk threshold ( 82.8% used) on node [node-15], preventing allocation
warmed bitset for [user_id], took [3.2 ms]
warmed bitset for [product_id], took [5.6 ms]
warmed bitset for [order_id], took [4.1 ms]
warmed bitset for [category_id], took [6.7 ms]
warmed bitset for [review_id], took [2.9 ms]
warmed bitset for [user_id AND product_id], took [7.3 ms]
warmed bitset for [user_id OR order_id], took [8.4 ms]
warmed bitset for [product_id AND category_id], took [9.2 ms]
warmed bitset for [order_id OR review_id], took [10.1 ms]
warmed bitset for [category_id AND review_id], took [11.5 ms]
warmed bitset for [user_id AND NOT product_id], took [12.3 ms]
warmed bitset for [product_id OR NOT order_id], took [13.4 ms]
warmed bitset for [order_id AND NOT category_id], took [14.2 ms]
warmed bitset for [category_id OR NOT review_id], took [15.6 ms]
warmed bitset for [review_id AND NOT user_id], took [16.7 ms]
--> Hit[0] 1234 Explanation: product of:
--> Hit[0] 5678 Explanation: sum of:
--> Hit[0] 9012 Explanation: max of:
--> Hit[0] 3456 Explanation: min of:
--> Hit[0] 7890 Explanation: average of:
--> Hit[0] 4321 Explanation: difference of:
--> Hit[0] 8765 Explanation: quotient of:
--> Hit[0] 1098 Explanation: remainder of:
--> Hit[0] 6543 Explanation: square of:
--> Hit[0] 2109 Explanation: square root of:
--> Hit[0] 5432 Explanation: power of:
--> Hit[0] 1987 Explanation: logarithm of:
--> Hit[0] 7654 Explanation: sine of:
--> Hit[0] 3210 Explanation: cosine of:
--> Hit[0] 9876 Explanation: tangent of:
Query phase failed java.lang.NullPointerException
Query phase failed java.io.IOException: Connection reset
Query phase failed org.elasticsearch.ElasticsearchException: Cluster block exception
Query phase failed java.lang.IllegalArgumentException: Invalid query syntax
Query phase failed java.util.concurrent.TimeoutException: Query timed out
Query phase failed org.elasticsearch.index.IndexNotFoundException: Index not found
Query phase failed java.lang.OutOfMemoryError: Java heap space
Query phase failed org.elasticsearch.action.search.SearchPhaseExecutionException: All shards failed
Query phase failed java.net.SocketException: Broken pipe
Query phase failed org.elasticsearch.common.ParsingException: Failed to parse query
Query phase failed java.lang.ClassCastException: Cannot cast object to query type
Query phase failed java.lang.SecurityException: Access denied
Query phase failed org.elasticsearch.transport.RemoteTransportException: Remote node failure
Query phase failed java.lang.StackOverflowError: Recursive query call
Query phase failed org.elasticsearch.script.ScriptException: Script error
Error while executing bulk request java.lang.NullPointerException
Error while executing bulk request org.elasticsearch.ElasticsearchException: Bulk request failed
Error while executing bulk request java.net.SocketTimeoutException: Read timed out
Error while executing bulk request java.io.IOException: Connection reset by peer
Error while executing bulk request org.elasticsearch.action.bulk.BulkRequestBuilder$1.onFailure(BulkRequestBuilder.java:217)
Error while executing bulk request java.lang.IllegalArgumentException: Document contains at least one immense term in field="content" (whose UTF8 encoding is longer than the max length 32766)
Error while executing bulk request org.elasticsearch.cluster.block.ClusterBlockException: blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];
Error while executing bulk request org.elasticsearch.index.mapper.MapperParsingException: failed to parse [date]
Error while executing bulk request org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: rejected execution of org.elasticsearch.transport.TransportService$7@6c0f0a9f on EsThreadPoolExecutor[bulk, queue capacity = 200, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@5b9c4a8e[Running, pool size = 32, active threads = 32, queued tasks = 200, completed tasks = 123456]]
Error while executing bulk request java.lang.OutOfMemoryError: Java heap space
Error while executing bulk request org.elasticsearch.action.UnavailableShardsException: [index][0] primary shard is not active Timeout
Error while executing bulk request org.elasticsearch.index.engine.VersionConflictEngineException[[index][0] [type][id]: version conflict, current [123], provided [456]]
Error while executing bulk request org.elasticsearch.transport.RemoteTransportException[[node][ip_address][indices:data/write/bulk[s]]]; nested: IndexNotFoundException[no such index];
Error while executing bulk request org.elasticsearch.index.IndexNotFoundException: no such index
Error while executing bulk request java.lang.SecurityException: access denied ("java.net.SocketPermission" "localhost:9200" "connect,resolve")
Exception while closing AwsCredentialsProvider java.io.IOException
Exception while closing AwsCredentialsProvider java.lang.NullPointerException
Exception while closing AwsCredentialsProvider com.amazonaws.SdkClientException
Exception while closing AwsCredentialsProvider java.lang.IllegalStateException
Exception while closing AwsCredentialsProvider com.amazonaws.AmazonServiceException
Exception while closing AwsCredentialsProvider java.net.SocketTimeoutException
Exception while closing AwsCredentialsProvider java.lang.SecurityException
Exception while closing AwsCredentialsProvider com.amazonaws.auth.AWSCredentialsExpiredException
Exception while closing AwsCredentialsProvider java.util.concurrent.TimeoutException
Exception while closing AwsCredentialsProvider com.amazonaws.auth.AWS4Signer$AWS4SignerException
Exception while closing AwsCredentialsProvider java.lang.InterruptedException
Exception while closing AwsCredentialsProvider com.amazonaws.http.exception.HttpRequestTimeoutException
Exception while closing AwsCredentialsProvider java.net.UnknownHostException
Exception while closing AwsCredentialsProvider com.amazonaws.AmazonClientException
Exception while closing AwsCredentialsProvider java.lang.RuntimeException
Exception from http client java.net.SocketTimeoutException: Read timed out
Exception from http client org.apache.http.NoHttpResponseException: The target server failed to respond
Exception from http client javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure
Exception from http client java.net.ConnectException: Connection refused
Exception from http client java.io.IOException: Broken pipe
Exception from http client org.apache.http.client.ClientProtocolException: Unsupported scheme: ftp
Exception from http client java.net.UnknownHostException: www.example.com
Exception from http client java.lang.IllegalArgumentException: Invalid URI host: null
Exception from http client org.apache.http.conn.HttpHostConnectException: Connect to localhost:8080 [localhost/127.0.0.1] failed: Connection refused
Exception from http client javax.net.ssl.SSLPeerUnverifiedException: Hostname www.example.com not verified
Exception from http client org.apache.http.conn.ConnectTimeoutException: Connect to www.example.com timed out
Exception from http client java.net.MalformedURLException: no protocol: www.example.com
Exception from http client org.apache.http.client.HttpResponseException: HTTP/1.1 404 Not Found
Exception from http client org.apache.http.client.CircularRedirectException: Circular redirect to 'http://www.example.com/'
Exception from http client java.io.InterruptedIOException: thread interrupted
[0] [a1b2c3] snapshot to [test] [1] ...
[1] [d4e5f6] snapshot to [prod] [2] ...
[2] [g7h8i9] snapshot to [dev] [3] ...
[3] [j0k1l2] snapshot to [backup] [4] ...
[4] [m3n4o5] snapshot to [demo] [5] ...
[5] [p6q7r8] snapshot to [staging] [6] ...
[6] [s9t0u1] snapshot to [archive] [7] ...
[7] [v2w3x4] snapshot to [report] [8] ...
[8] [y5z6a7] snapshot to [config] [9] ...
[9] [b8c9d0] snapshot to [log] [10] ...
[10] [e1f2g3] snapshot to [temp] [11] ...
[11] [h4i5j6] snapshot to [cache] [12] ...
[12] [k7l8m9] snapshot to [data] [13] ...
[13] [n0o1p2] snapshot to [index] [14] ...
--> create random index products with 1000 records
--> create random index customers with 500 records
--> create random index orders with 2000 records
--> create random index reviews with 1500 records
--> create random index categories with 100 records
--> create random index books with 800 records
--> create random index movies with 600 records
--> create random index games with 400 records
--> create random index music with 700 records
--> create random index news with 1200 records
--> create random index blogs with 900 records
--> create random index tweets with 3000 records
--> create random index photos with 2500 records
--> create random index videos with 1800 records
--> create random index podcasts with 1100 records
try with createFile()
try with deleteFile()
try with copyFile()
try with moveFile()
try with renameFile()
try with readFile()
try with writeFile()
try with appendFile()
try with listFiles()
try with getFileSize()
try with getFileType()
try with getFileDate()
try with getFileOwner()
try with setFilePermission()
try with zipFile()
Local files = [a.txt, b.txt, c.txt] , Repo files = [a.txt, b.txt, c.txt]
Local files = [d.txt, e.txt, f.txt] , Repo files = [d.txt, e.txt]
Local files = [g.txt, h.txt] , Repo files = [g.txt, h.txt, i.txt]
Local files = [j.txt, k.txt, l.txt, m.txt] , Repo files = [j.txt, k.txt]
Local files = [n.txt, o.txt] , Repo files = [n.txt, o.txt]
Local files = [p.txt, q.txt, r.txt] , Repo files = [p.txt, q.txt, r.txt]
Local files = [s.txt, t.txt] , Repo files = [s.txt]
Local files = [u.txt, v.txt, w.txt] , Repo files = [u.txt, v.txt]
Local files = [x.txt, y.txt] , Repo files = [x.txt, y.txt, z.txt]
Local files = [a1.txt, b1.txt, c1.txt] , Repo files = [a1.txt]
Local files = [d1.txt] , Repo files = [d1.txt, e1.txt]
Local files = [f1.txt, g1.txt] , Repo files = [f1.txt]
Local files = [h1.txt, i1.txt] , Repo files = [h1.txt, i1.txt]
Local files = [j1.txt] , Repo files = []
Local files = [] , Repo files = [k1.txt]
total indexing heap bytes used [1.2 GB] vs index_buffer_size [10%], currently writing bytes [300 MB]
total indexing heap bytes used [2.5 GB] vs index_buffer_size [20%], currently writing bytes [500 MB]
total indexing heap bytes used [3.8 GB] vs index_buffer_size [15%], currently writing bytes [800 MB]
total indexing heap bytes used [4.1 GB] vs index_buffer_size [25%], currently writing bytes [1 GB]
total indexing heap bytes used [5.4 GB] vs index_buffer_size [30%], currently writing bytes [1.2 GB]
total indexing heap bytes used [6.7 GB] vs index_buffer_size [35%], currently writing bytes [1.5 GB]
total indexing heap bytes used [7.9 GB] vs index_buffer_size [40%], currently writing bytes [1.8 GB]
total indexing heap bytes used [9.2 GB] vs index_buffer_size [45%], currently writing bytes [2 GB]
total indexing heap bytes used [10.5 GB] vs index_buffer_size [50%], currently writing bytes [2.3 GB]
total indexing heap bytes used [11.8 GB] vs index_buffer_size [55%], currently writing bytes [2.5 GB]
total indexing heap bytes used [13 GB] vs index_buffer_size [60%], currently writing bytes [2.8 GB]
total indexing heap bytes used [14.3 GB] vs index_buffer_size [65%], currently writing bytes [3 GB]
total indexing heap bytes used [15.6 GB] vs index_buffer_size [70%], currently writing bytes [3.2 GB]
total indexing heap bytes used [16.9 GB] vs index_buffer_size [75%], currently writing bytes [3.5 GB]
total indexing heap bytes used [18.1 GB] vs index_buffer_size [80%], currently writing bytes [3.8 GB]
Rest tests for project [/home/user/my_project] will be copied to the test resources.
Rest tests for project [C:\Users\user\Documents\my_project] will be copied to the test resources.
Rest tests for project [/var/www/html/my_project] will be copied to the test resources.
Rest tests for project [D:\Projects\my_project] will be copied to the test resources.
Rest tests for project [/Users/user/Desktop/my_project] will be copied to the test resources.
Rest tests for project [E:\Work\my_project] will be copied to the test resources.
Rest tests for project [/opt/my_project] will be copied to the test resources.
Rest tests for project [F:\Data\my_project] will be copied to the test resources.
Rest tests for project [/mnt/my_project] will be copied to the test resources.
Rest tests for project [G:\Backup\my_project] will be copied to the test resources.
Rest tests for project [/tmp/my_project] will be copied to the test resources.
Rest tests for project [H:\Shared\my_project] will be copied to the test resources.
Rest tests for project [/media/user/my_project] will be copied to the test resources.
Rest tests for project [I:\Cloud\my_project] will be copied to the test resources.
Rest tests for project [/srv/my_project] will be copied to the test resources.
--> Deleting the repository= my-app
--> Deleting the repository= test-repo
--> Deleting the repository= hello-world
--> Deleting the repository= data-science
--> Deleting the repository= covid-19
--> Deleting the repository= music-player
--> Deleting the repository= chatbot
--> Deleting the repository= calculator
--> Deleting the repository= tic-tac-toe
--> Deleting the repository= portfolio
--> Deleting the repository= blog
--> Deleting the repository= weather-app
--> Deleting the repository= todo-list
--> Deleting the repository= snake-game
--> Deleting the repository= face-recognition
registering decommission metadata [decommissionAttributeMetadata{attributeId=1, attributeType=STRING, attributeValue='foo'}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=2, attributeType=INTEGER, attributeValue=42}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=3, attributeType=BOOLEAN, attributeValue=true}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=4, attributeType=FLOAT, attributeValue=3.14}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=5, attributeType=DATE, attributeValue='2021-10-20'}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=6, attributeType=ENUM, attributeValue='RED'}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=7, attributeType=ARRAY, attributeValue=[1, 2, 3]}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=8, attributeType=MAP, attributeValue={'key':'value'}}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=9, attributeType=OBJECT, attributeValue={name:'John', age:25}}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=10, attributeType=NULL, attributeValue=null}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=11, attributeType=BINARY, attributeValue='01010101'}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=12, attributeType=UUID, attributeValue='123e4567-e89b-12d3-a456-426614174000'}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=13, attributeType=CUSTOM, attributeValue='some custom value'}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=14, attributeType=MIXED, attributeValue=[1, 'foo', true]}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=15, attributeType=DYNAMIC, attributeValue={type:'STRING', value:'bar'}}] to execute action
submitting state update task to remove [node-1, node-2, node-3] nodes due to decommissioning
submitting state update task to remove [node-7, node-8] nodes due to decommissioning
submitting state update task to remove [node-4] nodes due to decommissioning
submitting state update task to remove [node-5, node-6, node-9, node-10] nodes due to decommissioning
submitting state update task to remove [node-11, node-12] nodes due to decommissioning
submitting state update task to remove [node-13, node-14, node-15] nodes due to decommissioning
submitting state update task to remove [node-16] nodes due to decommissioning
submitting state update task to remove [node-17, node-18, node-19] nodes due to decommissioning
submitting state update task to remove [node-20, node-21] nodes due to decommissioning
submitting state update task to remove [node-22] nodes due to decommissioning
submitting state update task to remove [node-23, node-24, node-25] nodes due to decommissioning
submitting state update task to remove [node-26, node-27] nodes due to decommissioning
submitting state update task to remove [node-28] nodes due to decommissioning
submitting state update task to remove [node-29, node-30, node-31] nodes due to decommissioning
submitting state update task to remove [node-32, node-33] nodes due to decommissioning
cancelling task [1001] and its descendants
cancelling task [2002] and its descendants
cancelling task [3003] and its descendants
cancelling task [4004] and its descendants
cancelling task [5005] and its descendants
cancelling task [6006] and its descendants
cancelling task [7007] and its descendants
cancelling task [8008] and its descendants
cancelling task [9009] and its descendants
cancelling task [1010] and its descendants
cancelling task [1111] and its descendants
cancelling task [1212] and its descendants
cancelling task [1313] and its descendants
cancelling task [1414] and its descendants
cancelling task [1515] and its descendants
Refreshing [index1]
Refreshing [index2]
Refreshing [index3]
Refreshing [index4]
Refreshing [index5]
Refreshing [index6]
Refreshing [index7]
Refreshing [index8]
Refreshing [index9]
Refreshing [index10]
Refreshing [index11]
Refreshing [index12]
Refreshing [index13]
Refreshing [index14]
Refreshing [index15]
--> node [123] has version [1.0]
--> node [456] has version [1.1]
--> node [789] has version [1.2]
--> node [101] has version [2.0]
--> node [112] has version [2.1]
--> node [131] has version [2.2]
--> node [415] has version [3.0]
--> node [161] has version [3.1]
--> node [718] has version [3.2]
--> node [192] has version [4.0]
--> node [202] has version [4.1]
--> node [232] has version [4.2]
--> node [526] has version [5.0]
--> node [262] has version [5.1]
--> node [929] has version [5.2]
stop throttling indexing: numMergesInFlight= 3 , maxNumMerges= 5
stop throttling indexing: numMergesInFlight= 2 , maxNumMerges= 4
stop throttling indexing: numMergesInFlight= 4 , maxNumMerges= 6
stop throttling indexing: numMergesInFlight= 1 , maxNumMerges= 3
stop throttling indexing: numMergesInFlight= 5 , maxNumMerges= 7
stop throttling indexing: numMergesInFlight= 6 , maxNumMerges= 8
stop throttling indexing: numMergesInFlight= 7 , maxNumMerges= 9
stop throttling indexing: numMergesInFlight= 8 , maxNumMerges= 10
stop throttling indexing: numMergesInFlight= 9 , maxNumMerges= 11
stop throttling indexing: numMergesInFlight= 10 , maxNumMerges= 12
stop throttling indexing: numMergesInFlight= 11 , maxNumMerges= 13
stop throttling indexing: numMergesInFlight= 12 , maxNumMerges= 14
stop throttling indexing: numMergesInFlight= 13 , maxNumMerges= 15
stop throttling indexing: numMergesInFlight= 14 , maxNumMerges= 16
stop throttling indexing: numMergesInFlight= 15 , maxNumMerges= 17
shard [0] - count 4567 , primary true
shard [1] - count 3421 , primary false
shard [2] - count 2890 , primary true
shard [3] - count 5123 , primary false
shard [4] - count 4678 , primary true
shard [5] - count 3987 , primary false
shard [6] - count 4231 , primary true
shard [7] - count 3765 , primary false
shard [8] - count 4982 , primary true
shard [9] - count 3214 , primary false
shard [10] - count 4679 , primary true
shard [11] - count 4123 , primary false
shard [12] - count 4890 , primary true
shard [13] - count 3789 , primary false
shard [14] - count 4532 , primary true
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
VERBOSE Checking node.roles setting
failed to rollback writer on close java.io.IOException: Stream closed
failed to rollback writer on close java.lang.NullPointerException: Writer is null
failed to rollback writer on close java.sql.SQLException: Connection is closed
failed to rollback writer on close java.lang.IllegalStateException: Writer is already closed
failed to rollback writer on close java.io.FileNotFoundException: File not found
failed to rollback writer on close java.nio.channels.ClosedChannelException: Channel is closed
failed to rollback writer on close java.lang.InterruptedException: Thread interrupted
failed to rollback writer on close java.util.concurrent.TimeoutException: Timeout exceeded
failed to rollback writer on close java.lang.OutOfMemoryError: Java heap space
failed to rollback writer on close java.net.SocketException: Socket is closed
failed to rollback writer on close org.apache.commons.io.IOExceptionWithCause: Cause: Stream closed
failed to rollback writer on close org.springframework.transaction.TransactionSystemException: Could not commit transaction
failed to rollback writer on close javax.persistence.PersistenceException: Transaction required
failed to rollback writer on close org.hibernate.TransactionException: Rollback failed
failed to rollback writer on close com.mongodb.MongoSocketException: Socket is closed
port mapping property: name = web-server
port mapping property: host = 192.168.1.100
port mapping property: name = database
port mapping property: host = 172.16.0.50
port mapping property: name = mail-server
port mapping property: host = 10.0.0.10
port mapping property: name = ftp-server
port mapping property: host = 192.168.1.101
port mapping property: name = ssh-server
port mapping property: host = 172.16.0.51
port mapping property: name = proxy-server
port mapping property: host = 10.0.0.11
port mapping property: name = dns-server
port mapping property: host = 192.168.1.102
port mapping property: name = vpn-server
port mapping property: host = 172.16.0.52
--> nodeWithoutPrimary: false
--> nodeWithoutPrimary: true
--> nodeWithoutPrimary: null
--> nodeWithoutPrimary: undefined
--> nodeWithoutPrimary: 0
--> nodeWithoutPrimary: 1
--> nodeWithoutPrimary: -1
--> nodeWithoutPrimary: "node1"
--> nodeWithoutPrimary: "node2"
--> nodeWithoutPrimary: "node3"
--> nodeWithoutPrimary: []
--> nodeWithoutPrimary: [0, 1, 2]
--> nodeWithoutPrimary: ["node1", "node2", "node3"]
--> nodeWithoutPrimary: {}
--> nodeWithoutPrimary: {"id": 1234, "name": "node1"}
successfully acquired shardlock for [shard-1]
successfully acquired shardlock for [shard-2]
successfully acquired shardlock for [shard-3]
successfully acquired shardlock for [shard-4]
successfully acquired shardlock for [shard-5]
successfully acquired shardlock for [shard-6]
successfully acquired shardlock for [shard-7]
successfully acquired shardlock for [shard-8]
successfully acquired shardlock for [shard-9]
successfully acquired shardlock for [shard-10]
successfully acquired shardlock for [shard-11]
successfully acquired shardlock for [shard-12]
successfully acquired shardlock for [shard-13]
successfully acquired shardlock for [shard-14]
successfully acquired shardlock for [shard-15]
--> creating [3] replicas for index [products]
--> creating [2] replicas for index [users]
--> creating [4] replicas for index [orders]
--> creating [1] replicas for index [reviews]
--> creating [5] replicas for index [inventory]
--> creating [2] replicas for index [categories]
--> creating [3] replicas for index [customers]
--> creating [4] replicas for index [sales]
--> creating [1] replicas for index [logs]
--> creating [5] replicas for index [settings]
--> creating [2] replicas for index [notifications]
--> creating [3] replicas for index [messages]
--> creating [4] replicas for index [analytics]
--> creating [1] replicas for index [reports]
--> creating [5] replicas for index [tasks]
check index failed during fetch seqNo java.lang.NullPointerException
check index failed during fetch seqNo java.io.IOException
check index failed during fetch seqNo java.lang.IndexOutOfBoundsException
check index failed during fetch seqNo java.lang.IllegalArgumentException
check index failed during fetch seqNo java.sql.SQLException
check index failed during fetch seqNo java.lang.ClassNotFoundException
check index failed during fetch seqNo java.net.SocketException
check index failed during fetch seqNo java.lang.NumberFormatException
check index failed during fetch seqNo java.util.ConcurrentModificationException
check index failed during fetch seqNo java.lang.OutOfMemoryError
check index failed during fetch seqNo java.lang.StackOverflowError
check index failed during fetch seqNo java.lang.ArithmeticException
check index failed during fetch seqNo java.lang.SecurityException
check index failed during fetch seqNo java.lang.UnsupportedOperationException
check index failed during fetch seqNo java.lang.NoSuchMethodError
--> search with user routing, should find one
--> search with date routing, should find one
--> search with location routing, should find one
--> search with keyword routing, should find one
--> search with category routing, should find one
--> search with price routing, should find one
--> search with rating routing, should find one
--> search with status routing, should find one
--> search with id routing, should find one
--> search with name routing, should find one
--> search with tag routing, should find one
--> search with color routing, should find one
--> search with size routing, should find one
--> search with type routing, should find one
--> search with author routing, should find one
Unable to detect content encoding java.io.IOException
Unable to detect content encoding org.apache.commons.compress.compressors.CompressorException
Unable to detect content encoding java.lang.IllegalArgumentException
Unable to detect content encoding java.nio.charset.UnsupportedCharsetException
Unable to detect content encoding org.apache.http.client.ClientProtocolException
Unable to detect content encoding javax.xml.stream.XMLStreamException
Unable to detect content encoding java.util.zip.ZipException
Unable to detect content encoding org.json.JSONException
Unable to detect content encoding java.net.MalformedURLException
Unable to detect content encoding java.io.EOFException
Unable to detect content encoding org.xml.sax.SAXException
Unable to detect content encoding java.io.FileNotFoundException
Unable to detect content encoding java.lang.NullPointerException
Unable to detect content encoding java.security.NoSuchAlgorithmException
Unable to detect content encoding javax.crypto.BadPaddingException
Scheduled retry with didRefresh= true
Scheduled retry with didRefresh= false
Scheduled retry with didRefresh= null
Scheduled retry with didRefresh= 1
Scheduled retry with didRefresh= 0
Scheduled retry with didRefresh= -1
Scheduled retry with didRefresh= "yes"
Scheduled retry with didRefresh= "no"
Scheduled retry with didRefresh= "maybe"
Scheduled retry with didRefresh= undefined
Scheduled retry with didRefresh= NaN
Scheduled retry with didRefresh= true && false
Scheduled retry with didRefresh= false || true
Scheduled retry with didRefresh= !true
Scheduled retry with didRefresh= !false
start primary shards for index [products]: 5
start primary shards for index [users]: 3
start primary shards for index [orders]: 4
start primary shards for index [reviews]: 2
start primary shards for index [inventory]: 6
start primary shards for index [sales]: 7
start primary shards for index [customers]: 8
start primary shards for index [categories]: 1
start primary shards for index [logs]: 9
start primary shards for index [settings]: 10
start primary shards for index [reports]: 11
start primary shards for index [analytics]: 12
start primary shards for index [notifications]: 13
start primary shards for index [messages]: 14
start primary shards for index [documents]: 15
Installing file: app-release.apk
Installing file: setup.exe
Installing file: image.iso
Installing file: data.zip
Installing file: report.pdf
Installing file: music.mp3
Installing file: video.mp4
Installing file: game.pkg
Installing file: document.docx
Installing file: presentation.pptx
Installing file: spreadsheet.xlsx
Installing file: wallpaper.jpg
Installing file: font.ttf
Installing file: script.py
Installing file: config.ini
Failed to call listener on global ordinals loading java.lang.NullPointerException
Failed to call listener on global ordinals loading java.io.IOException
Failed to call listener on global ordinals loading java.lang.OutOfMemoryError
Failed to call listener on global ordinals loading java.lang.IllegalArgumentException
Failed to call listener on global ordinals loading java.util.concurrent.TimeoutException
Failed to call listener on global ordinals loading java.lang.ClassNotFoundException
Failed to call listener on global ordinals loading java.lang.NoSuchMethodError
Failed to call listener on global ordinals loading java.lang.SecurityException
Failed to call listener on global ordinals loading java.net.SocketException
Failed to call listener on global ordinals loading java.sql.SQLException
Failed to call listener on global ordinals loading org.elasticsearch.ElasticsearchException
Failed to call listener on global ordinals loading org.apache.lucene.index.CorruptIndexException
Failed to call listener on global ordinals loading org.apache.lucene.store.LockObtainFailedException
Failed to call listener on global ordinals loading org.apache.lucene.search.BooleanQuery$TooManyClauses
Failed to call listener on global ordinals loading org.apache.lucene.index.IndexNotFoundException
setting index create block failed java.lang.NullPointerException
setting index create block failed java.io.IOException: No space left on device
setting index create block failed org.elasticsearch.cluster.block.ClusterBlockException: blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];
setting index create block failed java.lang.IllegalArgumentException: index name must not contain the following characters [\\, /, *, ?, \", <, >, |,  , ,]
setting index create block failed org.elasticsearch.index.IndexNotFoundException: no such index [test]
setting index create block failed org.elasticsearch.action.UnavailableShardsException: [test][0] primary shard is not active Timeout: [1m], request: [BulkShardRequest [[test][0]] containing [index {[test][_doc][1], source[n/a, actual length: [2.1kb], max length: 2kb]}]]
setting index create block failed org.elasticsearch.ElasticsearchException: failed to refresh store stats
setting index create block failed java.lang.OutOfMemoryError: Java heap space
setting index create block failed org.elasticsearch.indices.IndexClosedException: closed
setting index create block failed org.elasticsearch.transport.NodeDisconnectedException: [node-1][127.0.0.1:9300][indices:data/write/bulk[s]] disconnected
setting index create block failed org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [<http_request>] would be [1024788378/977.3mb], which is larger than the limit of [1020054732/972.7mb], real usage: [1024788378/977.3mb], new bytes reserved: [0/0b], usages [request=0/0b, fielddata=0/0b, in_flight_requests=0/0b, model_inference=0/0b, accounting=0/0b]
setting index create block failed org.elasticsearch.index.engine.VersionConflictEngineException: [test]: version conflict, required seqNo [10], primary term [1]. current document has seqNo [11] and primary term [1]
setting index create block failed org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$RetryOnPrimaryException: allocation id mismatch on primary
setting index create block failed org.elasticsearch.index.mapper.MapperParsingException: failed to parse field [date] of type [date] in document with id '1'. Preview of field's value: '2021-10-32'
setting index create block failed org.elasticsearch.index.shard.IndexShardRecoveryException: failed to recover from gateway
failed to build index metadata [request.index(books)]
failed to build index metadata [request.index(users)]
failed to build index metadata [request.index(products)]
failed to build index metadata [request.index(orders)]
failed to build index metadata [request.index(reviews)]
failed to build index metadata [request.index(categories)]
failed to build index metadata [request.index(tags)]
failed to build index metadata [request.index(comments)]
failed to build index metadata [request.index(posts)]
failed to build index metadata [request.index(articles)]
failed to build index metadata [request.index(images)]
failed to build index metadata [request.index(videos)]
failed to build index metadata [request.index(audios)]
failed to build index metadata [request.index(messages)]
failed to build index metadata [request.index(notifications)]
updated the decommission status to [active]
updated the decommission status to [inactive]
updated the decommission status to [pending]
updated the decommission status to [failed]
updated the decommission status to [completed]
updated the decommission status to [cancelled]
updated the decommission status to [paused]
updated the decommission status to [resumed]
updated the decommission status to [error]
updated the decommission status to [success]
updated the decommission status to [running]
updated the decommission status to [stopped]
updated the decommission status to [restarted]
updated the decommission status to [skipped]
updated the decommission status to [retrying]
--> Index 1000 documents on primary
--> Index 500 documents on primary
--> Index 2500 documents on primary
--> Index 150 documents on primary
--> Index 800 documents on primary
--> Index 1200 documents on primary
--> Index 300 documents on primary
--> Index 4000 documents on primary
--> Index 600 documents on primary
--> Index 2000 documents on primary
--> Index 700 documents on primary
--> Index 900 documents on primary
--> Index 3500 documents on primary
--> Index 4500 documents on primary
--> Index 3000 documents on primary
process did not terminate after 10 seconds, stopping it forcefully
process did not terminate after 5 minutes, stopping it forcefully
process did not terminate after 30 milliseconds, stopping it forcefully
process did not terminate after 1 hour, stopping it forcefully
process did not terminate after 15 seconds, stopping it forcefully
process did not terminate after 3 minutes, stopping it forcefully
process did not terminate after 100 milliseconds, stopping it forcefully
process did not terminate after 2 hours, stopping it forcefully
process did not terminate after 20 seconds, stopping it forcefully
process did not terminate after 10 minutes, stopping it forcefully
process did not terminate after 50 milliseconds, stopping it forcefully
process did not terminate after 4 hours, stopping it forcefully
process did not terminate after 25 seconds, stopping it forcefully
process did not terminate after 15 minutes, stopping it forcefully
[shard1] [snapshot-2021-10-20] no files to recover, all exist within the local store
[shard2] [snapshot-2021-10-19] no files to recover, all exist within the local store
[shard3] [snapshot-2021-10-18] no files to recover, all exist within the local store
[shard4] [snapshot-2021-10-17] no files to recover, all exist within the local store
[shard5] [snapshot-2021-10-16] no files to recover, all exist within the local store
[shard6] [snapshot-2021-10-15] no files to recover, all exist within the local store
[shard7] [snapshot-2021-10-14] no files to recover, all exist within the local store
[shard8] [snapshot-2021-10-13] no files to recover, all exist within the local store
[shard9] [snapshot-2021-10-12] no files to recover, all exist within the local store
[shard10] [snapshot-2021-10-11] no files to recover, all exist within the local store
[shard11] [snapshot-2021-10-10] no files to recover, all exist within the local store
[shard12] [snapshot-2021-10-09] no files to recover, all exist within the local store
[shard13] [snapshot-2021-10-08] no files to recover, all exist within the local store
[shard14] [snapshot-2021-10-07] no files to recover, all exist within the local store
[shard15] [snapshot-2021-10-06] no files to recover, all exist within the local store
snapshot translog for recovery; current size is [0]
snapshot translog for recovery; current size is [12]
snapshot translog for recovery; current size is [24]
snapshot translog for recovery; current size is [36]
snapshot translog for recovery; current size is [48]
snapshot translog for recovery; current size is [60]
snapshot translog for recovery; current size is [72]
snapshot translog for recovery; current size is [84]
snapshot translog for recovery; current size is [96]
snapshot translog for recovery; current size is [108]
snapshot translog for recovery; current size is [120]
snapshot translog for recovery; current size is [132]
snapshot translog for recovery; current size is [144]
snapshot translog for recovery; current size is [156]
snapshot translog for recovery; current size is [168]
num of docs in iter 10 0
num of docs in iter 15 1
num of docs in iter 12 2
num of docs in iter 9 3
num of docs in iter 11 4
num of docs in iter 13 5
num of docs in iter 14 6
num of docs in iter 8 7
num of docs in iter 16 8
num of docs in iter 10 9
num of docs in iter 12 10
num of docs in iter 9 11
num of docs in iter 14 12
num of docs in iter 13 13
num of docs in iter 11 14
delete repository [my_project]
delete repository [test_repo]
delete repository [hello_world]
delete repository [data_analysis]
delete repository [machine_learning]
delete repository [web_app]
delete repository [game_dev]
delete repository [backup_2021]
delete repository [final_version]
delete repository [demo_repo]
delete repository [new_feature]
delete repository [bug_fixes]
delete repository [docs_repo]
delete repository [config_repo]
delete repository [secret_repo]
Extra id [1001]
Extra id [2002]
Extra id [3003]
Extra id [4004]
Extra id [5005]
Extra id [6006]
Extra id [7007]
Extra id [8008]
Extra id [9009]
Extra id [1010]
Extra id [1111]
Extra id [1212]
Extra id [1313]
Extra id [1414]
Extra id [1515]
[shard-1] [snapshot-20211020] writing shard snapshot file
[shard-2] [snapshot-20211021] writing shard snapshot file
[shard-3] [snapshot-20211022] writing shard snapshot file
[shard-4] [snapshot-20211023] writing shard snapshot file
[shard-5] [snapshot-20211024] writing shard snapshot file
[shard-6] [snapshot-20211025] writing shard snapshot file
[shard-7] [snapshot-20211026] writing shard snapshot file
[shard-8] [snapshot-20211027] writing shard snapshot file
[shard-9] [snapshot-20211028] writing shard snapshot file
[shard-10] [snapshot-20211029] writing shard snapshot file
[shard-11] [snapshot-20211030] writing shard snapshot file
[shard-12] [snapshot-20211031] writing shard snapshot file
[shard-13] [snapshot-20211101] writing shard snapshot file
[shard-14] [snapshot-20211102] writing shard snapshot file
[shard-15] [snapshot-20211103] writing shard snapshot file
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.0.1:9300]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.0.2:9301]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.0.3:9302]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.1.1:9300]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.1.2:9301]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.1.3:9302]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.2.1:9300]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.2.2:9301]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.2.3:9302]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.3.1:9300]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.3.2:9301]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.3.3:9302]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.4.1:9300]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.4.2:9301]
Configuring remote cluster [cluster2RemoteClusterSeed=10.0.4.3:9302]
current node found. Ignoring webserver - 192.168.1.10
current node found. Ignoring database - 10.0.0.5
current node found. Ignoring loadbalancer - 172.16.0.2
current node found. Ignoring mailserver - 192.168.2.15
current node found. Ignoring backup - 10.0.1.7
current node found. Ignoring firewall - 172.16.1.1
current node found. Ignoring dns - 192.168.3.20
current node found. Ignoring proxy - 10.0.2.9
current node found. Ignoring ftp - 172.16.2.3
current node found. Ignoring vpn - 192.168.4.25
current node found. Ignoring ssh - 10.0.3.11
current node found. Ignoring ldap - 172.16.3.4
current node found. Ignoring ntp - 192.168.5.30
current node found. Ignoring dhcp - 10.0.4.13
current node found. Ignoring snmp - 172.16.4.5
starting segment upgrade upgradeOnlyAncientSegments= true
starting segment upgrade upgradeOnlyAncientSegments= false
starting segment upgrade upgradeOnlyAncientSegments= yes
starting segment upgrade upgradeOnlyAncientSegments= no
starting segment upgrade upgradeOnlyAncientSegments= 1
starting segment upgrade upgradeOnlyAncientSegments= 0
starting segment upgrade upgradeOnlyAncientSegments= on
starting segment upgrade upgradeOnlyAncientSegments= off
starting segment upgrade upgradeOnlyAncientSegments= enabled
starting segment upgrade upgradeOnlyAncientSegments= disabled
starting segment upgrade upgradeOnlyAncientSegments= Y
starting segment upgrade upgradeOnlyAncientSegments= N
starting segment upgrade upgradeOnlyAncientSegments= T
starting segment upgrade upgradeOnlyAncientSegments= F
starting segment upgrade upgradeOnlyAncientSegments= null
iteration [1] - failed shards: 0 (expected 0)
iteration [2] - failed shards: 1 (expected 0)
iteration [3] - failed shards: 2 (expected 0)
iteration [4] - failed shards: 0 (expected 0)
iteration [5] - failed shards: 3 (expected 0)
iteration [6] - failed shards: 1 (expected 0)
iteration [7] - failed shards: 4 (expected 0)
iteration [8] - failed shards: 2 (expected 0)
iteration [9] - failed shards: 0 (expected 0)
iteration [10] - failed shards: 5 (expected 0)
iteration [11] - failed shards: 3 (expected 0)
iteration [12] - failed shards: 1 (expected 0)
iteration [13] - failed shards: 6 (expected 0)
iteration [14] - failed shards: 4 (expected 0)
iteration [15] - failed shards: 2 (expected 0)
failed to invoke before index added to cluster callback java.lang.NullPointerException
failed to invoke before index added to cluster callback java.io.IOException
failed to invoke before index added to cluster callback java.lang.IllegalArgumentException
failed to invoke before index added to cluster callback java.lang.ClassNotFoundException
failed to invoke before index added to cluster callback java.lang.OutOfMemoryError
failed to invoke before index added to cluster callback java.lang.StackOverflowError
failed to invoke before index added to cluster callback java.lang.UnsupportedOperationException
failed to invoke before index added to cluster callback java.util.ConcurrentModificationException
failed to invoke before index added to cluster callback java.net.SocketTimeoutException
failed to invoke before index added to cluster callback java.sql.SQLException
failed to invoke before index added to cluster callback java.lang.SecurityException
failed to invoke before index added to cluster callback java.lang.NoSuchMethodError
failed to invoke before index added to cluster callback java.lang.NoSuchFieldError
failed to invoke before index added to cluster callback java.lang.AssertionError
failed to invoke before index added to cluster callback java.lang.RuntimeException
performing sequence numbers based recovery. starting at [100]
performing sequence numbers based recovery. starting at [345]
performing sequence numbers based recovery. starting at [789]
performing sequence numbers based recovery. starting at [1024]
performing sequence numbers based recovery. starting at [1500]
performing sequence numbers based recovery. starting at [2001]
performing sequence numbers based recovery. starting at [2500]
performing sequence numbers based recovery. starting at [3000]
performing sequence numbers based recovery. starting at [3500]
performing sequence numbers based recovery. starting at [4000]
performing sequence numbers based recovery. starting at [4500]
performing sequence numbers based recovery. starting at [5000]
performing sequence numbers based recovery. starting at [5500]
performing sequence numbers based recovery. starting at [6000]
performing sequence numbers based recovery. starting at [6500]
using explicit kms region [us-east-1]
using explicit kms region [eu-west-2]
using explicit kms region [ap-southeast-1]
using explicit kms region [ca-central-1]
using explicit kms region [sa-east-1]
using explicit kms region [eu-north-1]
using explicit kms region [us-west-2]
using explicit kms region [ap-northeast-2]
using explicit kms region [eu-central-1]
using explicit kms region [ap-south-1]
using explicit kms region [us-east-2]
using explicit kms region [ap-northeast-1]
using explicit kms region [af-south-1]
using explicit kms region [me-south-1]
using explicit kms region [eu-south-1]
--> using shard size [1024]
--> using shard size [2048]
--> using shard size [4096]
--> using shard size [8192]
--> using shard size [16384]
--> using shard size [32768]
--> using shard size [65536]
--> using shard size [131072]
--> using shard size [262144]
--> using shard size [524288]
--> using shard size [1048576]
--> using shard size [2097152]
--> using shard size [4194304]
--> using shard size [8388608]
--> using shard size [16777216]
[shard1] closing... (reason: connection timeout)
[shard5] closing... (reason: shard migration)
[shard3] closing... (reason: disk full)
[shard2] closing... (reason: manual shutdown)
[shard4] closing... (reason: network error)
[shard6] closing... (reason: memory leak)
[shard7] closing... (reason: corrupted data)
[shard8] closing... (reason: hardware failure)
[shard9] closing... (reason: power outage)
[shard10] closing... (reason: maintenance mode)
[shard11] closing... (reason: load balancing)
[shard12] closing... (reason: security breach)
[shard13] closing... (reason: replication lag)
[shard14] closing... (reason: version upgrade)
unexpected failure NullPointerException
unexpected failure IOException
unexpected failure OutOfMemoryError
unexpected failure ArithmeticException
unexpected failure FileNotFoundException
unexpected failure ArrayIndexOutOfBoundsException
unexpected failure ClassNotFoundException
unexpected failure NumberFormatException
unexpected failure SQLException
unexpected failure AssertionError
unexpected failure SocketException
unexpected failure MalformedURLException
unexpected failure InterruptedException
unexpected failure NoSuchMethodException
unexpected failure IllegalArgumentExcpetion
Searching for [test: one]
Searching for [test: two]
Searching for [test: three]
Searching for [test: four]
Searching for [test: five]
Searching for [test: six]
Searching for [test: seven]
Searching for [test: eight]
Searching for [test: nine]
Searching for [test: ten]
Searching for [test: eleven]
Searching for [test: twelve]
Searching for [test: thirteen]
Searching for [test: fourteen]
Searching for [test: fifteen]
Initializing shards: [index1][0], [index2][1], [index3][2]
Initializing shards: [index4][3], [index5][4], [index6][5]
Initializing shards: [index7][6], [index8][7], [index9][8]
Initializing shards: [index10][9], [index11][10], [index12][11]
Initializing shards: [index13][12], [index14][13], [index15][14]
Initializing shards: [index16][15], [index17][16], [index18][17]
Initializing shards: [index19][18], [index20][19], [index21][20]
Initializing shards: [index22][21], [index23][22], [index24][23]
Initializing shards: [index25][24], [index26][25], [index27][26]
Initializing shards: [index28][27], [index29][28], [index30][29]
Initializing shards: [index31][30], [index32][31], [index33][32]
Initializing shards: [index34][33], [index35][34], [index36][35]
Initializing shards: [index37][36], [index38][37], [index39][38]
Initializing shards: [index40][39], [index41][40], [index42][41]
Initializing shards: [index43][42],[ index44 ][43 ],[ index45 ][44 ]
controlTopDocs.scoreDocs[0].score= 0.95
controlTopDocs.scoreDocs[1].score= 0.91
controlTopDocs.scoreDocs[2].score= 0.87
controlTopDocs.scoreDocs[3].score= 0.84
controlTopDocs.scoreDocs[4].score= 0.81
controlTopDocs.scoreDocs[5].score= 0.78
controlTopDocs.scoreDocs[6].score= 0.75
controlTopDocs.scoreDocs[7].score= 0.72
controlTopDocs.scoreDocs[8].score= 0.69
controlTopDocs.scoreDocs[9].score= 0.66
controlTopDocs.scoreDocs[10].score= 0.63
controlTopDocs.scoreDocs[11].score= 0.6
controlTopDocs.scoreDocs[12].score= 0.57
controlTopDocs.scoreDocs[13].score= 0.54
controlTopDocs.scoreDocs[14].score= 0.51
--> unassigned: 5 , initializing: 3 , relocating: 2 , started: 10
--> unassigned: 0 , initializing: 1 , relocating: 0 , started: 19
--> unassigned: 4 , initializing: 4 , relocating: 1 , started: 11
--> unassigned: 2 , initializing: 2 , relocating: 3 , started: 13
--> unassigned: 1 , initializing: 5 , relocating: 2 , started: 12
--> unassigned: 3 , initializing: 3 , relocating: 4 , started: 10
--> unassigned: 6 , initializing: 2 , relocating: 1 , started: 11
--> unassigned: 7 , initializing: 1 , relocating: 0 , started: 12
--> unassigned: 8 , initializing: 0 , relocating: 0 , started: 12
--> unassigned: 9 , initializing: 0 , relocating: 1 , started: 10
--> unassigned: 10 , initializing: 0 , relocating: 0 , started: 10
0 reestablishing recovery from node-1
3 reestablishing recovery from node-4
1 reestablishing recovery from node-2
2 reestablishing recovery from node-3
4 reestablishing recovery from node-5
5 reestablishing recovery from node-6
6 reestablishing recovery from node-7
7 reestablishing recovery from node-8
8 reestablishing recovery from node-9
9 reestablishing recovery from node-10
10 reestablishing recovery from node-11
11 reestablishing recovery from node-12
12 reestablishing recovery from node-13
13 reestablishing recovery from node-14
14 reestablishing recovery from node-15
The specified location [/home/user/data] doesn't start with any repository paths specified by the path.repo setting: [/mnt/snapshots,/var/backups]
The specified location [C:\Users\user\Documents] doesn't start with any repository paths specified by the path.repo setting: [D:\Snapshots,E:\Backups]
The specified location [/tmp/test] doesn't start with any repository paths specified by the path.repo setting: [/opt/snapshots,/usr/local/backups]
The specified location [D:\Data\test] doesn't start with any repository paths specified by the path.repo setting: [C:\Snapshots,F:\Backups]
The specified location [/var/log/elasticsearch] doesn't start with any repository paths specified by the path.repo setting: [/home/snapshots,/data/backups]
The specified location [E:\Logstash\data] doesn't start with any repository paths specified by the path.repo setting: [F:\Snapshots,G:\Backups]
The specified location [/data/test] doesn't start with any repository paths specified by the path.repo setting: [/mnt/snapshots,/var/backups]
The specified location [F:\Elasticsearch\data] doesn't start with any repository paths specified by the path.repo setting: [G:\Snapshots,H:\Backups]
The specified location [/opt/logstash] doesn't start with any repository paths specified by the path.repo setting: [/home/snapshots,/data/backups]
The specified location [G:\Kibana\data] doesn't start with any repository paths specified by the path.repo setting: [H:\Snapshots,I:\Backups]
The specified location [/usr/local/kibana] doesn't start with any repository paths specified by the path.repo setting: [/opt/snapshots,/usr/local/backups]
The specified location [H:\Beats\data] doesn't start with any repository paths specified by the path.repo setting: [I:\Snapshots,J:\Backups]
The specified location [/etc/beats] doesn't start with any repository paths specified by the path.repo setting: [/mnt/snapshots,/var/backups]
The specified location [I:\APM\data] doesn't start with any repository paths specified by the path.repo setting: [J:\Snapshots,K:\Backups]
The specified location [/home/user/apm] doesn't start with any repository paths specified by the path.repo setting: [/home/snapshots,/data/backups]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/instances]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/global/images/family/ubuntu-1804-lts]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/operations/operation-1634794603-6e9f3a8c]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/global/networks/default]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/disks/disk-1]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/instanceGroups/instance-group-1]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/global/firewalls/firewall-1]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/instances/instance-1/getSerialPortOutput]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/instances/instance-2/getSerialPortOutput]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/instances/instance-3/getSerialPortOutput]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/instances/instance-4/getSerialPortOutput]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/instances/instance-5/getSerialPortOutput]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/machineTypes/n2-standard-4]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/machineTypes/n2-standard-8]
--> Simulate GCE API response for [https://www.googleapis.com/compute/v1/projects/my-project/zones/us-central1-a/machineTypes/n2-standard-16]
can't find replica source node because primary shard 0 is assigned to an unknown node.
can't find replica source node because primary shard 1 is assigned to an unknown node.
can't find replica source node because primary shard 2 is assigned to an unknown node.
can't find replica source node because primary shard 3 is assigned to an unknown node.
can't find replica source node because primary shard 4 is assigned to an unknown node.
can't find replica source node because primary shard 5 is assigned to an unknown node.
can't find replica source node because primary shard 6 is assigned to an unknown node.
can't find replica source node because primary shard 7 is assigned to an unknown node.
can't find replica source node because primary shard 8 is assigned to an unknown node.
can't find replica source node because primary shard 9 is assigned to an unknown node.
can't find replica source node because primary shard 10 is assigned to an unknown node.
can't find replica source node because primary shard 11 is assigned to an unknown node.
can't find replica source node because primary shard 12 is assigned to an unknown node.
can't find replica source node because primary shard 13 is assigned to an unknown node.
can't find replica source node because primary shard 14 is assigned to an unknown node.
--> creating index- 0 and ingest data
--> creating index- 1 and ingest data
--> creating index- 2 and ingest data
--> creating index- 3 and ingest data
--> creating index- 4 and ingest data
--> creating index- 5 and ingest data
--> creating index- 6 and ingest data
--> creating index- 7 and ingest data
--> creating index- 8 and ingest data
--> creating index- 9 and ingest data
--> creating index- 10 and ingest data
--> creating index- 11 and ingest data
--> creating index- 12 and ingest data
--> creating index- 13 and ingest data
--> creating index- 14 and ingest data
deleteBlob(profile.jpg)
deleteBlob(logo.png)
deleteBlob(data.csv)
deleteBlob(backup.zip)
deleteBlob(report.docx)
deleteBlob(video.mp4)
deleteBlob(invoice.pdf)
deleteBlob(archive.tar.gz)
deleteBlob(image.bmp)
deleteBlob(song.mp3)
deleteBlob(script.py)
deleteBlob(slide.pptx)
deleteBlob(chart.xlsx)
deleteBlob(thumbnail.gif)
deleteBlob(document.txt)
blobExists(image.jpg)
blobExists(video.mp4)
blobExists(document.pdf)
blobExists(archive.zip)
blobExists(audio.mp3)
blobExists(icon.png)
blobExists(script.js)
blobExists(style.css)
blobExists(data.csv)
blobExists(report.docx)
blobExists(presentation.pptx)
blobExists(chart.xlsx)
blobExists(diagram.svg)
blobExists(logo.gif)
blobExists(map.json)
start primary shards for index products
start primary shards for index customers
start primary shards for index orders
start primary shards for index reviews
start primary shards for index inventory
start primary shards for index sales
start primary shards for index categories
start primary shards for index users
start primary shards for index logs
start primary shards for index settings
start primary shards for index analytics
start primary shards for index reports
start primary shards for index alerts
start primary shards for index backups
start primary shards for index history
unexpected error while preparing shard for peer recovery, failing recovery java.lang.NullPointerException
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.transport.RemoteTransportException
unexpected error while preparing shard for peer recovery, failing recovery java.io.IOException
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.index.shard.IndexShardRecoveryException
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.indices.recovery.RecoveryFailedException
unexpected error while preparing shard for peer recovery, failing recovery java.lang.IllegalStateException
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.index.engine.EngineException
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.common.util.concurrent.EsRejectedExecutionException
unexpected error while preparing shard for peer recovery, failing recovery java.lang.OutOfMemoryError
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.action.UnavailableShardsException
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.index.translog.TranslogCorruptedException
unexpected error while preparing shard for peer recovery, failing recovery java.nio.file.FileSystemException
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.cluster.block.ClusterBlockException
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.index.IndexNotFoundException
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper
failing [cluster-join]: local node is no longer cluster-manager
failing [node-leave]: local node is no longer cluster-manager
failing [node-failover]: local node is no longer cluster-manager
failing [cluster-split]: local node is no longer cluster-manager
failing [node-restart]: local node is no longer cluster-manager
failing [cluster-rebalance]: local node is no longer cluster-manager
failing [node-upgrade]: local node is no longer cluster-manager
failing [cluster-shutdown]: local node is no longer cluster-manager
failing [node-maintenance]: local node is no longer cluster-manager
failing [cluster-resize]: local node is no longer cluster-manager
failing [node-replace]: local node is no longer cluster-manager
failing [cluster-backup]: local node is no longer cluster-manager
failing [node-repair]: local node is no longer cluster-manager
failing [cluster-restore]: local node is no longer cluster-manager
failing [node-reconfigure]: local node is no longer cluster-manager
element I don't know how to analyze element.getKind() yet.
element I don't know how to analyze element.getName() yet.
element I don't know how to analyze element.getType() yet.
element I don't know how to analyze element.getValue() yet.
element I don't know how to analyze element.getAttributes() yet.
element I don't know how to analyze element.getChildren() yet.
element I don't know how to analyze element.getParent() yet.
element I don't know how to analyze element.getSibling() yet.
element I don't know how to analyze element.getPosition() yet.
element I don't know how to analyze element.getSize() yet.
element I don't know how to analyze element.getColor() yet.
element I don't know how to analyze element.getStyle() yet.
element I don't know how to analyze element.getVisibility() yet.
element I don't know how to analyze element.getState() yet.
element I don't know how to analyze element.getAction() yet.
added [node1] to denylist
added [node7] to denylist
added [node3] to denylist
added [node9] to denylist
added [node5] to denylist
added [node2] to denylist
added [node8] to denylist
added [node4] to denylist
added [node6] to denylist
added [node10] to denylist
added [node12] to denylist
added [node11] to denylist
added [node14] to denylist
added [node13] to denylist
added [node15] to denylist
Multipart stream failed to close java.io.IOException: Stream closed
Multipart stream failed to close org.apache.commons.fileupload.MultipartStream$MalformedStreamException: Stream ended unexpectedly
Multipart stream failed to close java.net.SocketTimeoutException: Read timed out
Multipart stream failed to close java.lang.IllegalStateException: No multipart boundary was found
Multipart stream failed to close javax.servlet.ServletException: Could not parse multipart servlet request
Multipart stream failed to close org.springframework.web.multipart.MultipartException: Failed to parse multipart servlet request
Multipart stream failed to close java.io.EOFException: Unexpected end of ZLIB input stream
Multipart stream failed to close java.io.FileNotFoundException: No such file or directory
Multipart stream failed to close java.lang.OutOfMemoryError: Java heap space
Multipart stream failed to close java.lang.InterruptedException: Interrupted while waiting for data
Multipart stream failed to close org.apache.http.ConnectionClosedException: Premature end of Content-Length delimited message body
Multipart stream failed to close java.util.zip.ZipException: invalid stored block lengths
Multipart stream failed to close java.io.UTFDataFormatException: malformed input around byte 10
Multipart stream failed to close org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 1; Content is not allowed in prolog
Multipart stream failed to close java.lang.SecurityException: access denied ("java.io.FilePermission" "/tmp" "read")
processing [indexing]: took [1.2s] no change in cluster state
processing [refresh]: took [0.5s] no change in cluster state
processing [flush]: took [2.3s] no change in cluster state
processing [snapshot]: took [4.1s] no change in cluster state
processing [recovery]: took [3.7s] no change in cluster state
processing [merge]: took [2.9s] no change in cluster state
processing [optimize]: took [5.4s] no change in cluster state
processing [delete]: took [1.8s] no change in cluster state
processing [update]: took [2.1s] no change in cluster state
processing [bulk]: took [3.2s] no change in cluster state
processing [search]: took [0.9s] no change in cluster state
processing [query]: took [1.1s] no change in cluster state
processing [fetch]: took [0.7s] no change in cluster state
processing [scroll]: took [1.4s] no change in cluster state
processing [suggest]: took [0.6s] no change in cluster state
Flushing [index1]
Flushing [index2]
Flushing [index3]
Flushing [index4]
Flushing [index5]
Flushing [index6]
Flushing [index7]
Flushing [index8]
Flushing [index9]
Flushing [index10]
Flushing [index11]
Flushing [index12]
Flushing [index13]
Flushing [index14]
Flushing [index15]
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob java.lang.NullPointerException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob org.elasticsearch.action.FailedNodeException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob java.net.SocketTimeoutException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob org.elasticsearch.cluster.block.ClusterBlockException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob java.io.IOException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob org.elasticsearch.ElasticsearchException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob java.lang.IllegalArgumentException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob org.elasticsearch.transport.RemoteTransportException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob java.lang.OutOfMemoryError
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob org.elasticsearch.action.UnavailableShardsException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob java.lang.SecurityException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob org.elasticsearch.index.IndexNotFoundException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob java.lang.ClassCastException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob org.elasticsearch.common.breaker.CircuitBreakingException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob java.lang.UnsupportedOperationException
[index1, index2, index3] indices closed, but the operation timed out while waiting for enough shards to be started.
[index4, index5] indices closed, but the operation timed out while waiting for enough shards to be started.
[index6] indices closed, but the operation timed out while waiting for enough shards to be started.
[index7, index8, index9, index10] indices closed, but the operation timed out while waiting for enough shards to be started.
[index11, index12] indices closed, but the operation timed out while waiting for enough shards to be started.
[index13, index14, index15] indices closed, but the operation timed out while waiting for enough shards to be started.
[index16] indices closed, but the operation timed out while waiting for enough shards to be started.
[index17, index18, index19] indices closed, but the operation timed out while waiting for enough shards to be started.
[index20, index21] indices closed, but the operation timed out while waiting for enough shards to be started.
[index22] indices closed, but the operation timed out while waiting for enough shards to be started.
[index23, index24, index25] indices closed, but the operation timed out while waiting for enough shards to be started.
[index26, index27] indices closed, but the operation timed out while waiting for enough shards to be started.
[index28] indices closed, but the operation timed out while waiting for enough shards to be started.
[index29, index30, index31] indices closed, but the operation timed out while waiting for enough shards to be started.
[index32, index33] indices closed, but the operation timed out while waiting for enough shards to be started.
--> creating 5 snapshots
--> creating 12 snapshots
--> creating 3 snapshots
--> creating 8 snapshots
--> creating 10 snapshots
--> creating 6 snapshots
--> creating 9 snapshots
--> creating 4 snapshots
--> creating 7 snapshots
--> creating 11 snapshots
--> creating 2 snapshots
--> creating 1 snapshots
--> creating 13 snapshots
--> creating 14 snapshots
--> creating 15 snapshots
0 starting recovery from node-1
0 starting recovery from node-1
5 starting recovery from node-3
2 starting recovery from node-2
7 starting recovery from node-4
3 starting recovery from node-1
1 starting recovery from node-3
4 starting recovery from node-2
6 starting recovery from node-4
8 starting recovery from node-1
9 starting recovery from node-3
10 starting recovery from node-2
11 starting recovery from node-4
12 starting recovery from node-1
13 starting recovery from node-3
Loading plugin [Calculator]...
Loading plugin [Calendar]...
Loading plugin [Weather]...
Loading plugin [Music]...
Loading plugin [Camera]...
Loading plugin [Maps]...
Loading plugin [News]...
Loading plugin [Email]...
Loading plugin [Contacts]...
Loading plugin [Games]...
Loading plugin [Translator]...
Loading plugin [Browser]...
Loading plugin [Clock]...
Loading plugin [Gallery]...
Loading plugin [Notes]...
node: [1] least available path has less than 0 total bytes of disk [0], skipping
node: [2] least available path has less than 0 total bytes of disk [0], skipping
node: [3] least available path has less than 0 total bytes of disk [0], skipping
node: [4] least available path has less than 0 total bytes of disk [0], skipping
node: [5] least available path has less than 0 total bytes of disk [0], skipping
node: [6] least available path has less than 0 total bytes of disk [0], skipping
node: [7] least available path has less than 0 total bytes of disk [0], skipping
node: [8] least available path has less than 0 total bytes of disk [0], skipping
node: [9] least available path has less than 0 total bytes of disk [0], skipping
node: [10] least available path has less than 0 total bytes of disk [0], skipping
node: [11] least available path has less than 0 total bytes of disk [1], skipping
node: [12] least available path has less than 0 total bytes of disk [2], skipping
node: [13] least available path has less than 0 total bytes of disk [3], skipping
node: [14] least available path has less than 0 total bytes of disk [4], skipping
node: [15] least available path has less than 0 total bytes of disk [5], skipping
iteration [1] - returned documents: 10 (expected 10)
iteration [2] - returned documents: 9 (expected 10)
iteration [3] - returned documents: 8 (expected 10)
iteration [4] - returned documents: 7 (expected 10)
iteration [5] - returned documents: 6 (expected 10)
iteration [6] - returned documents: 5 (expected 10)
iteration [7] - returned documents: 4 (expected 10)
iteration [8] - returned documents: 3 (expected 10)
iteration [9] - returned documents: 2 (expected 10)
iteration [10] - returned documents: 1 (expected 10)
iteration [11] - returned documents: 0 (expected 10)
iteration [12] - returned documents: 0 (expected 0)
iteration [13] - returned documents: 0 (expected 0)
iteration [14] - returned documents: 0 (expected 0)
delaying recovery of [index-1][0] as source shard is not marked yet as relocating to [node-2]
delaying recovery of [index-2][1] as source shard is not marked yet as relocating to [node-3]
delaying recovery of [index-3][2] as source shard is not marked yet as relocating to [node-4]
delaying recovery of [index-4][3] as source shard is not marked yet as relocating to [node-5]
delaying recovery of [index-5][4] as source shard is not marked yet as relocating to [node-6]
delaying recovery of [index-6][5] as source shard is not marked yet as relocating to [node-7]
delaying recovery of [index-7][6] as source shard is not marked yet as relocating to [node-8]
delaying recovery of [index-8][7] as source shard is not marked yet as relocating to [node-9]
delaying recovery of [index-9][8] as source shard is not marked yet as relocating to [node-10]
delaying recovery of [index-10][9] as source shard is not marked yet as relocating to [node-11]
delaying recovery of [index-11][10] as source shard is not marked yet as relocating to [node-12]
delaying recovery of [index-12][11] as source shard is not marked yet as relocating to [node-13]
delaying recovery of [index-13][12] as source shard is not marked yet as relocating to [node-14]
delaying recovery of [index-14][13] as source shard is not marked yet as relocating to [node-15]
delaying recovery of [index-15][14] as source shard is not marked yet as relocating to [node-16]
expiring unused [lease 1]
expiring unused [lease 12]
expiring unused [lease 7]
expiring unused [lease 3]
expiring unused [lease 9]
expiring unused [lease 4]
expiring unused [lease 10]
expiring unused [lease 2]
expiring unused [lease 8]
expiring unused [lease 6]
expiring unused [lease 11]
expiring unused [lease 5]
expiring unused [lease 13]
expiring unused [lease 14]
expiring unused [lease 15]
---- Unexpected exit code (expected 0 , got 1 ) for script: backup.sh
---- Unexpected exit code (expected 2 , got 3 ) for script: install.py
---- Unexpected exit code (expected 0 , got 127 ) for script: update.jar
---- Unexpected exit code (expected 1 , got 0 ) for script: test.rb
---- Unexpected exit code (expected 3 , got 2 ) for script: uninstall.pl
---- Unexpected exit code (expected 0 , got 255 ) for script: scan.exe
---- Unexpected exit code (expected 2 , got 1 ) for script: deploy.sh
---- Unexpected exit code (expected 1 , got 4 ) for script: check.py
---- Unexpected exit code (expected 0 , got -1 ) for script: clean.jar
---- Unexpected exit code (expected 3 , got 0 ) for script: run.rb
---- Unexpected exit code (expected 1 , got 2 ) for script: verify.pl
---- Unexpected exit code (expected 2 , got -2 ) for script: restore.exe
---- Unexpected exit code (expected 0 , got 5 ) for script: backup.sh
---- Unexpected exit code (expected 1 , got -3 ) for script: install.py
---- Unexpected exit code (expected 2 , got 0 ) for script: update.jar
Logged in as user Alice
Logged in as user Bob
Logged in as user Charlie
Logged in as user David
Logged in as user Eve
Logged in as user Frank
Logged in as user Grace
Logged in as user Harry
Logged in as user Irene
Logged in as user Jack
Logged in as user Kate
Logged in as user Leo
Logged in as user Mary
Logged in as user Nick
Logged in as user Olivia
--> START relocate the shard from nodes[10.0.0.1] to nodes[10.0.0.2]
--> START relocate the shard from nodes[10.0.0.3] to nodes[10.0.0.4]
--> START relocate the shard from nodes[10.0.0.5] to nodes[10.0.0.6]
--> START relocate the shard from nodes[10.0.0.7] to nodes[10.0.0.8]
--> START relocate the shard from nodes[10.0.0.9] to nodes[10.0.0.10]
--> START relocate the shard from nodes[10.1.1.1] to nodes[10.1.1.2]
--> START relocate the shard from nodes[10.1.1.3] to nodes[10.1.1.4]
--> START relocate the shard from nodes[10.1.1.5] to nodes[10.1.1.6]
--> START relocate the shard from nodes[10.1.1.7] to nodes[10.1.1.8]
--> START relocate the shard from nodes[10.1.1.9] to nodes[10.1.1.10]
--> START relocate the shard from nodes[192.168.0.1] to nodes[192,168,0,2]
--> START relocate the shard from nodes[192,168,0,3] to nodes[192,168,0,4]
--> START relocate the shard from nodes[192,168,0,5] to nodes[192,168,0,6]
--> START relocate the shard from nodes[192,168,0,7] to nodes[192,168,0,8]
--> START relocate the shard from nodes[192,168,0,9] to nodes[192,168,0,10]
Failed to close ReaderManager java.io.IOException: Stream closed
Failed to close ReaderManager java.lang.NullPointerException: ReaderManager is null
Failed to close ReaderManager java.lang.IllegalStateException: ReaderManager is already closed
Failed to close ReaderManager java.net.SocketException: Connection reset
Failed to close ReaderManager java.lang.InterruptedException: Thread interrupted
Failed to close ReaderManager java.util.concurrent.TimeoutException: Timeout waiting for response
Failed to close ReaderManager org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss
Failed to close ReaderManager org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block
Failed to close ReaderManager org.apache.hadoop.ipc.RemoteException: Server is not running
Failed to close ReaderManager org.apache.spark.SparkException: Job aborted due to stage failure
Failed to close ReaderManager com.amazonaws.AmazonClientException: Unable to execute HTTP request
Failed to close ReaderManager com.google.cloud.storage.StorageException: Service unavailable
Failed to close ReaderManager javax.net.ssl.SSLHandshakeException: No appropriate protocol
Failed to close ReaderManager java.security.AccessControlException: Access denied
Failed to close ReaderManager java.lang.OutOfMemoryError: Java heap space
JSON schema : [/home/user/schema1.json]
JSON schema : [C:\Users\user\schema2.json]
JSON schema : [/var/lib/schema3.json]
JSON schema : [D:\schema4.json]
JSON schema : [/opt/schema5.json]
JSON schema : [E:\Users\user\schema6.json]
JSON schema : [/tmp/schema7.json]
JSON schema : [F:\schema8.json]
JSON schema : [/etc/schema9.json]
JSON schema : [G:\Users\user\schema10.json]
JSON schema : [/usr/local/schema11.json]
JSON schema : [H:\schema12.json]
JSON schema : [/root/schema13.json]
JSON schema : [I:\Users\user\schema14.json]
JSON schema : [/mnt/schema15.json]
Failed to load repository data generation [12] because a concurrent operation moved the current generation to [13] java.io.FileNotFoundException
Failed to load repository data generation [7] because a concurrent operation moved the current generation to [8] java.lang.IllegalStateException
Failed to load repository data generation [4] because a concurrent operation moved the current generation to [5] java.nio.file.NoSuchFileException
Failed to load repository data generation [9] because a concurrent operation moved the current generation to [10] java.util.ConcurrentModificationException
Failed to load repository data generation [3] because a concurrent operation moved the current generation to [4] java.lang.InterruptedException
Failed to load repository data generation [11] because a concurrent operation moved the current generation to [12] java.io.IOException
Failed to load repository data generation [6] because a concurrent operation moved the current generation to [7] java.lang.NullPointerException
Failed to load repository data generation [10] because a concurrent operation moved the current generation to [11] java.lang.IllegalArgumentException
Failed to load repository data generation [8] because a concurrent operation moved the current generation to [9] java.nio.file.AccessDeniedException
Failed to load repository data generation [5] because a concurrent operation moved the current generation to [6] java.lang.RuntimeException
Failed to load repository data generation [14] because a concurrent operation moved the current generation to [15] java.io.EOFException
Failed to load repository data generation [13] because a concurrent operation moved the current generation to [14] java.nio.file.FileSystemException
Failed to load repository data generation [15] because a concurrent operation moved the current generation to [16] java.lang.SecurityException
Failed to load repository data generation [16] because a concurrent operation moved the current generation to [17] java.io.SyncFailedException
Failed to load repository data generation [17] because a concurrent operation moved the current generation to [18] java.lang.OutOfMemoryError
using bucket [s3://my-data], base_path [/home/user], chunk_size [1024], compress [true]
using bucket [gs://my-project], base_path [/var/log], chunk_size [4096], compress [false]
using bucket [hdfs://my-cluster], base_path [/data/input], chunk_size [2048], compress [true]
using bucket [s3://your-data], base_path [/home/admin], chunk_size [512], compress [false]
using bucket [gs://your-project], base_path [/var/tmp], chunk_size [8192], compress [true]
using bucket [hdfs://your-cluster], base_path [/data/output], chunk_size [4096], compress [false]
using bucket [s3://our-data], base_path [/home/shared], chunk_size [2048], compress [true]
using bucket [gs://our-project], base_path [/var/cache], chunk_size [1024], compress [false]
using bucket [hdfs://our-cluster], base_path [/data/intermediate], chunk_size [512], compress [true]
using bucket [s3://test-data], base_path [/home/tester], chunk_size [8192], compress [false]
using bucket [gs://test-project], base_path [/var/debug], chunk_size [4096], compress [true]
using bucket [hdfs://test-cluster], base_path [/data/test], chunk_size [2048], compress [false]
using bucket [s3://prod-data], base_path [/home/manager], chunk_size [1024], compress [true]
using bucket [gs://prod-project], base_path [/var/backup], chunk_size [512], compress [false]
using bucket [hdfs://prod-cluster], base_path [/data/prod], chunk_size [8192], compress [true]
recovery [phase2]: took [3.5s]
recovery [phase2]: took [4.1s]
recovery [phase2]: took [2.8s]
recovery [phase2]: took [5.2s]
recovery [phase2]: took [3.9s]
recovery [phase2]: took [4.7s]
recovery [phase2]: took [3.1s]
recovery [phase2]: took [4.3s]
recovery [phase2]: took [3.6s]
recovery [phase2]: took [5.0s]
recovery [phase2]: took [3.3s]
recovery [phase2]: took [4.5s]
recovery [phase2]: took [3.7s]
recovery [phase2]: took [4.9s]
recovery [phase2]: took [3.4s]
percentile_75: 0.67
percentile_75: 0.54
percentile_75: 0.72
percentile_75: 0.61
percentile_75: 0.78
percentile_75: 0.69
percentile_75: 0.58
percentile_75: 0.74
percentile_75: 0.64
percentile_75: 0.81
percentile_75: 0.66
percentile_75: 0.56
percentile_75: 0.73
percentile_75: 0.62
percentile_75: 0.79
failing shard on node [node-1]
failing shard on node [node-7]
failing shard on node [node-3]
failing shard on node [node-5]
failing shard on node [node-9]
failing shard on node [node-2]
failing shard on node [node-8]
failing shard on node [node-4]
failing shard on node [node-6]
failing shard on node [node-10]
failing shard on node [node-11]
failing shard on node [node-13]
failing shard on node [node-15]
failing shard on node [node-12]
failing shard on node [node-14]
Rest tests for project [src/main/java/com/example/demo] will be copied to the test resources from the published jar (version: [1.0.0]).
Rest tests for project [src/test/java/com/example/test] will be copied to the test resources from the published jar (version: [1.1.0]).
Rest tests for project [src/main/resources/application.properties] will be copied to the test resources from the published jar (version: [1.0.1]).
Rest tests for project [src/test/resources/test.properties] will be copied to the test resources from the published jar (version: [1.1.1]).
Rest tests for project [src/main/java/com/example/service] will be copied to the test resources from the published jar (version: [1.0.2]).
Rest tests for project [src/test/java/com/example/serviceTest] will be copied to the test resources from the published jar (version: [1.1.2]).
Rest tests for project [src/main/java/com/example/controller] will be copied to the test resources from the published jar (version: [1.0.3]).
Rest tests for project [src/test/java/com/example/controllerTest] will be copied to the test resources from the published jar (version: [1.1.3]).
Rest tests for project [src/main/java/com/example/model] will be copied to the test resources from the published jar (version: [1.0.4]).
Rest tests for project [src/test/java/com/example/modelTest] will be copied to the test resources from the published jar (version: [1.1.4]).
Rest tests for project [src/main/java/com/example/repository] will be copied to the test resources from the published jar (version: [1.0.5]).
Rest tests for project [src/test/java/com/example/repositoryTest] will be copied to the test resources from the published jar (version: [1.1.5]).
Rest tests for project [src/main/java/com/example/config] will be copied to the test resources from the published jar (version: [1.0.6]).
Rest tests for project [src/test/java/com/example/configTest] will be copied to the test resources from the published jar (version: [1.1.6]).
Rest tests for project [src/main/java/com/example/exception] will be copied to the test resources from the published jar (version: [1.0.7]).
attempting to update current decommission status [ACTIVE] with expected status [DELETED]
attempting to update current decommission status [DELETED] with expected status [ACTIVE]
attempting to update current decommission status [PENDING] with expected status [DELETED]
attempting to update current decommission status [ACTIVE] with expected status [PENDING]
attempting to update current decommission status [PENDING] with expected status [ACTIVE]
attempting to update current decommission status [DELETED] with expected status [PENDING]
attempting to update current decommission status [ERROR] with expected status [ACTIVE]
attempting to update current decommission status [ACTIVE] with expected status [ERROR]
attempting to update current decommission status [ERROR] with expected status [DELETED]
attempting to update current decommission status [DELETED] with expected status [ERROR]
attempting to update current decommission status [ERROR] with expected status [PENDING]
attempting to update current decommission status [PENDING] with expected status [ERROR]
attempting to update current decommission status [UNKNOWN] with expected status [ACTIVE]
attempting to update current decommission status [ACTIVE] with expected status [UNKNOWN]
attempting to update current decommission status [UNKNOWN] with expected status [DELETED]
indexed [10] docs
indexed [25] docs
indexed [0] docs
indexed [100] docs
indexed [7] docs
indexed [50] docs
indexed [12] docs
indexed [33] docs
indexed [1] docs
indexed [64] docs
indexed [16] docs
indexed [42] docs
indexed [9] docs
indexed [28] docs
indexed [76] docs
Failed to close test suite output stream java.io.IOException: Stream closed
Failed to close test suite output stream java.net.SocketException: Connection reset
Failed to close test suite output stream java.lang.NullPointerException: null
Failed to close test suite output stream java.io.FileNotFoundException: No such file or directory
Failed to close test suite output stream java.util.zip.ZipException: Invalid zip file format
Failed to close test suite output stream java.lang.OutOfMemoryError: Java heap space
Failed to close test suite output stream java.nio.charset.MalformedInputException: Input length = 1
Failed to close test suite output stream org.xml.sax.SAXParseException: Premature end of file
Failed to close test suite output stream javax.xml.stream.XMLStreamException: ParseError at [row,col]:[1,1]
Failed to close test suite output stream org.apache.commons.compress.archivers.ArchiveException: No Archiver found for the stream signature
Failed to close test suite output stream java.lang.IllegalStateException: Stream has already been operated upon or closed
Failed to close test suite output stream java.io.EOFException: End of input at line 1 column 1 path $
Failed to close test suite output stream java.io.InterruptedIOException: thread interrupted
Failed to close test suite output stream java.util.concurrent.TimeoutException: Timeout waiting for task
Failed to close test suite output stream org.json.JSONException: A JSONArray text must start with '[' at 1 [character 2 line 1]
Retrying [3] times : [https://example.com/api/users]
Retrying [1] times : [https://example.com/api/posts]
Retrying [2] times : [https://example.com/api/comments]
Retrying [4] times : [https://example.com/api/albums]
Retrying [5] times : [https://example.com/api/todos]
Retrying [2] times : [https://example.com/api/photos]
Retrying [3] times : [https://example.com/api/geo]
Retrying [1] times : [https://example.com/api/auth]
Retrying [4] times : [https://example.com/api/profile]
Retrying [5] times : [https://example.com/api/settings]
Retrying [2] times : [https://example.com/api/notifications]
Retrying [3] times : [https://example.com/api/messages]
Retrying [1] times : [https://example.com/api/friends]
Retrying [4] times : [https://example.com/api/groups]
Retrying [5] times : [https://example.com/api/events]
token [a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6] will expire in [3600] s
token [z9y8x7w6v5u4t3s2r1q0p9o8n7m6l5k4] will expire in [1800] s
token [b3c4d5e6f7g8h9i0j1k2l3m4n5o6p7q8] will expire in [7200] s
token [y8x7w6v5u4t3s2r1q0p9o8n7m6l5k4j3] will expire in [2700] s
token [c4d5e6f7g8h9i0j1k2l3m4n5o6p7q8r9] will expire in [5400] s
token [x7w6v5u4t3s2r1q0p9o8n7m6l5k4j3i2] will expire in [900] s
token [d5e6f7g8h9i0j1k2l3m4n5o6p7q8r9s0] will expire in [4500] s
token [w6v5u4t3s2r1q0p9o8n7m6l5k4j3i2h1] will expire in [1200] s
token [e6f7g8h9i0j1k2l3m4n5o6p7q8r9s0t1] will expire in [6300] s
token [v5u4t3s2r1q0p9o8n7m6l5k4j3i2h1g0] will expire in [1500] s
token [f7g8h9i0j1k2l3m4n5o6p7q8r9s0t1u2] will expire in [8100] s
token [u4t3s2r1q0p9o8n7m6l5k4j3i2h1g0f9] will expire in [2100] s
token [g8h9i0j1k2l3m4n5o6p7q8r9s0t1u2v3] will expire in [9900] s
token [t3s2r1q0p9o8n7m6l5k4j3i2h1g0f9e8] will expire in [3000] s
token [h9i0j1k2l3m4n5o6p7q8r9s0t1u2v3w4] will expire in [11700] s
session id [a3f5b1] is gone
session id [c9d7e2] is gone
session id [b4e6c3] is gone
session id [d8f9a4] is gone
session id [e7a8b5] is gone
session id [f6b9c6] is gone
session id [g5c8d7] is gone
session id [h4d7e8] is gone
session id [i3e6f9] is gone
session id [j2f5g8] is gone
session id [k1g4h7] is gone
session id [l0h3i6] is gone
session id [m9i2j5] is gone
session id [n8j1k4] is gone
session id [o7k0l3] is gone
Failed to call listener on field data cache unloading java.lang.NullPointerException
Failed to call listener on field data cache unloading java.io.IOException: Stream closed
Failed to call listener on field data cache unloading java.lang.IllegalStateException: Cache is already unloaded
Failed to call listener on field data cache unloading java.lang.OutOfMemoryError: Java heap space
Failed to call listener on field data cache unloading java.util.ConcurrentModificationException
Failed to call listener on field data cache unloading java.lang.ClassCastException: Cannot cast java.lang.String to java.lang.Integer
Failed to call listener on field data cache unloading java.lang.SecurityException: Permission denied
Failed to call listener on field data cache unloading java.net.SocketTimeoutException: Read timed out
Failed to call listener on field data cache unloading java.lang.NoSuchMethodError: No such method found
Failed to call listener on field data cache unloading java.lang.StackOverflowError
Failed to call listener on field data cache unloading java.lang.UnsupportedOperationException: Operation not supported
Failed to call listener on field data cache unloading java.lang.ArithmeticException: Division by zero
Failed to call listener on field data cache unloading java.lang.ArrayIndexOutOfBoundsException: Index 10 out of bounds for length 10
Failed to call listener on field data cache unloading java.lang.NumberFormatException: For input string: "abc"
Failed to call listener on field data cache unloading java.sql.SQLException: Connection closed
--> [1] done. tested [10] snapshots
--> [2] done. tested [15] snapshots
--> [3] done. tested [12] snapshots
--> [4] done. tested [8] snapshots
--> [5] done. tested [9] snapshots
--> [6] done. tested [11] snapshots
--> [7] done. tested [13] snapshots
--> [8] done. tested [14] snapshots
--> [9] done. tested [7] snapshots
--> [10] done. tested [6] snapshots
--> [11] done. tested [5] snapshots
--> [12] done. tested [4] snapshots
--> [13] done. tested [3] snapshots
--> [14] done. tested [2] snapshots
--> [15] done. tested [1] snapshots
Holes: [0, 0, 0, 0, 0]
Holes: [1, 2, 3, 4, 5]
Holes: [2, 4, 6, 8, 10]
Holes: [3, 6, 9, 12, 15]
Holes: [4, 8, 12, 16, 20]
Holes: [5, 10, 15, 20, 25]
Holes: [6, 12, 18, 24, 30]
Holes: [7, 14, 21, 28, 35]
Holes: [8, 16, 24, 32, 40]
Holes: [9, 18, 27, 36, 45]
Holes: [10, 20, 30, 40, 50]
Holes: [11, 22, 33, 44, 55]
Holes: [12, 24, 36, 48, 60]
Holes: [13, 26, 39, 52, 65]
Holes: [14, 28, 42, 56 ,70]
Exception during periodic request cache cleanup: java.lang.NullPointerException
Exception during periodic request cache cleanup: java.io.IOException
Exception during periodic request cache cleanup: java.lang.OutOfMemoryError
Exception during periodic request cache cleanup: java.lang.IllegalArgumentException
Exception during periodic request cache cleanup: java.net.SocketTimeoutException
Exception during periodic request cache cleanup: java.sql.SQLException
Exception during periodic request cache cleanup: java.lang.ClassNotFoundException
Exception during periodic request cache cleanup: java.lang.SecurityException
Exception during periodic request cache cleanup: java.util.ConcurrentModificationException
Exception during periodic request cache cleanup: org.springframework.beans.factory.BeanCreationException
Exception during periodic request cache cleanup: javax.xml.parsers.ParserConfigurationException
Exception during periodic request cache cleanup: org.xml.sax.SAXException
Exception during periodic request cache cleanup: javax.naming.NamingException
Exception during periodic request cache cleanup: javax.crypto.BadPaddingException
Exception during periodic request cache cleanup: javax.net.ssl.SSLHandshakeException
failed to apply settings java.lang.NullPointerException
failed to apply settings java.io.FileNotFoundException: config.json
failed to apply settings org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource'
failed to apply settings java.net.SocketTimeoutException: Read timed out
failed to apply settings java.lang.IllegalArgumentException: Invalid port number
failed to apply settings javax.naming.AuthenticationException: [LDAP: error code 49 - Invalid Credentials]
failed to apply settings java.sql.SQLException: Access denied for user 'root'@'localhost'
failed to apply settings org.hibernate.HibernateException: Could not parse configuration: hibernate.cfg.xml
failed to apply settings java.lang.OutOfMemoryError: Java heap space
failed to apply settings java.lang.SecurityException: Permission denied
failed to apply settings java.lang.ClassNotFoundException: com.example.MyClass
failed to apply settings org.apache.commons.configuration.ConfigurationException: Cannot locate configuration source example.properties
failed to apply settings java.lang.UnsupportedOperationException: Not implemented
failed to apply settings org.json.JSONException: A JSONObject text must begin with '{' at 1 [character 2 line 1]
failed to apply settings java.lang.NoClassDefFoundError: Could not initialize class com.example.MyClass
Slice count using max target slice supplier [0]
Slice count using max target slice supplier [12]
Slice count using max target slice supplier [3]
Slice count using max target slice supplier [8]
Slice count using max target slice supplier [5]
Slice count using max target slice supplier [10]
Slice count using max target slice supplier [1]
Slice count using max target slice supplier [7]
Slice count using max target slice supplier [4]
Slice count using max target slice supplier [9]
Slice count using max target slice supplier [6]
Slice count using max target slice supplier [11]
Slice count using max target slice supplier [2]
Slice count using max target slice supplier [13]
Slice count using max target slice supplier [14]
--> DONE relocate the shard from node-1 to node-2
--> DONE relocate the shard from node-3 to node-4
--> DONE relocate the shard from node-5 to node-6
--> DONE relocate the shard from node-7 to node-8
--> DONE relocate the shard from node-9 to node-10
--> DONE relocate the shard from node-11 to node-12
--> DONE relocate the shard from node-13 to node-14
--> DONE relocate the shard from node-15 to node-16
--> DONE relocate the shard from node-17 to node-18
--> DONE relocate the shard from node-19 to node-20
--> DONE relocate the shard from node-21 to node-22
--> DONE relocate the shard from node-23 to node-24
--> DONE relocate the shard from node-25 to node-26
--> DONE relocate the shard from node-27 to node-28
--> DONE relocate the shard from node-29 to node-30
failed to list dangling indices java.lang.NullPointerException
failed to list dangling indices org.elasticsearch.cluster.block.ClusterBlockException
failed to list dangling indices java.io.IOException
failed to list dangling indices org.elasticsearch.action.support.broadcast.BroadcastShardOperationFailedException
failed to list dangling indices java.lang.IllegalStateException
failed to list dangling indices org.elasticsearch.ElasticsearchException
failed to list dangling indices java.lang.IllegalArgumentException
failed to list dangling indices org.elasticsearch.index.IndexNotFoundException
failed to list dangling indices java.lang.SecurityException
failed to list dangling indices org.elasticsearch.transport.RemoteTransportException
failed to list dangling indices java.lang.OutOfMemoryError
failed to list dangling indices org.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException
failed to list dangling indices java.net.SocketTimeoutException
failed to list dangling indices org.elasticsearch.index.engine.EngineClosedException
failed to list dangling indices java.lang.ClassNotFoundException
primary shard 0 is unassigned, ignoring
primary shard 1 is unassigned, ignoring
primary shard 2 is unassigned, ignoring
primary shard 3 is unassigned, ignoring
primary shard 4 is unassigned, ignoring
primary shard 5 is unassigned, ignoring
primary shard 6 is unassigned, ignoring
primary shard 7 is unassigned, ignoring
primary shard 8 is unassigned, ignoring
primary shard 9 is unassigned, ignoring
primary shard 10 is unassigned, ignoring
primary shard 11 is unassigned, ignoring
primary shard 12 is unassigned, ignoring
primary shard 13 is unassigned, ignoring
primary shard 14 is unassigned, ignoring
Failure while waiting for process to exist java.lang.NullPointerException
Failure while waiting for process to exist java.io.IOException
Failure while waiting for process to exist java.lang.InterruptedException
Failure while waiting for process to exist java.util.concurrent.TimeoutException
Failure while waiting for process to exist java.lang.IllegalStateException
Failure while waiting for process to exist java.lang.SecurityException
Failure while waiting for process to exist java.lang.ClassNotFoundException
Failure while waiting for process to exist java.lang.NoSuchMethodException
Failure while waiting for process to exist java.lang.IllegalArgumentException
Failure while waiting for process to exist java.lang.OutOfMemoryError
Failure while waiting for process to exist java.lang.StackOverflowError
Failure while waiting for process to exist java.lang.UnsupportedOperationException
Failure while waiting for process to exist java.net.SocketException
Failure while waiting for process to exist java.sql.SQLException
Failure while waiting for process to exist java.lang.RuntimeException
Error while deleting unreferenced file java.io.FileNotFoundException: File does not exist
Error while deleting unreferenced file java.nio.file.AccessDeniedException: Permission denied
Error while deleting unreferenced file java.lang.NullPointerException: File is null
Error while deleting unreferenced file java.io.IOException: Stream closed
Error while deleting unreferenced file java.lang.SecurityException: Operation not allowed
Error while deleting unreferenced file java.nio.file.NoSuchFileException: File not found
Error while deleting unreferenced file java.lang.IllegalArgumentException: Invalid file name
Error while deleting unreferenced file java.io.InterruptedIOException: Thread interrupted
Error while deleting unreferenced file java.nio.file.FileSystemException: File system error
Error while deleting unreferenced file java.lang.OutOfMemoryError: Heap space exhausted
Error while deleting unreferenced file java.io.SyncFailedException: Sync failed
Error while deleting unreferenced file java.nio.file.FileAlreadyExistsException: File already exists
Error while deleting unreferenced file java.lang.UnsupportedOperationException: Unsupported operation
Error while deleting unreferenced file java.io.EOFException: End of file reached
Error while deleting unreferenced file java.nio.file.InvalidPathException: Path is invalid
failed to read latest segment infos on flush java.io.FileNotFoundException: /var/log/elasticsearch/index_1/_0.cfs (No such file or directory)
failed to read latest segment infos on flush java.nio.file.AccessDeniedException: /var/log/elasticsearch/index_2/_1.cfs
failed to read latest segment infos on flush org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=1f3b6c4 actual=4d6a7b2 (resource=BufferedChecksumIndexInput(MMapIndexInput(path="/var/log/elasticsearch/index_3/_2.cfs")))
failed to read latest segment infos on flush java.io.IOException: Input/output error
failed to read latest segment infos on flush org.apache.lucene.store.LockObtainFailedException: Lock held by this virtual machine: /var/log/elasticsearch/index_4/write.lock
failed to read latest segment infos on flush java.lang.OutOfMemoryError: Java heap space
failed to read latest segment infos on flush org.apache.lucene.index.IndexNotFoundException: no segments* file found in MMapDirectory@/var/log/elasticsearch/index_5 lockFactory=org.apache.lucene.store.NativeFSLockFactory@6f3b5d16
failed to read latest segment infos on flush java.lang.IllegalStateException: index writer is closed
failed to read latest segment infos on flush org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: rejected execution of org.elasticsearch.index.engine.InternalEngine$Flush@7a8b9c6a on EsThreadPoolExecutor[name = elasticsearch/write, queue capacity = 200, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@5e8c9f36[Running, pool size = 8, active threads = 8, queued tasks = 200, completed tasks = 123456]]
failed to read latest segment infos on flush java.lang.InterruptedException: Thread interrupted
failed to read latest segment infos on flush java.nio.file.NoSuchFileException: /var/log/elasticsearch/index_6/_3.si
failed to read latest segment infos on flush org.apache.lucene.index.MergePolicy$MergeException: java.io.EOFException: read past EOF: MMapIndexInput(path="/var/log/elasticsearch/index_7/_4.cfs")
failed to read latest segment infos on flush java.lang.AssertionError: numDocs=10000 but saw 9999 deletes
failed to read latest segment infos on flush org.apache.lucene.index.IndexFormatTooOldException: Format version is not supported (resource BufferedChecksumIndexInput(MMapIndexInput(path="/var/log/elasticsearch/index_8/_5.cfs"))): -11 (needs to be between -9 and -1). This version of Lucene only supports indexes created with release 6.0 and later.
failed to read latest segment infos on flush org.apache.lucene.index.IndexFormatTooNewException: Format version is not supported (resource BufferedChecksumIndexInput(MMapIndexInput(path="/var/log/elasticsearch/index_9/_6.cfs"))): 10 (needs to be between -9 and -1). This version of Lucene only supports indexes created with release 6.0 and later.
will try to reestablish recovery with id [a7b3] in [5 seconds] (reason [connection lost])
will try to reestablish recovery with id [f4d9] in [10 minutes] (reason [server error])
will try to reestablish recovery with id [c2e6] in [30 seconds] (reason [timeout])
will try to reestablish recovery with id [b8f1] in [1 minute] (reason [network failure])
will try to reestablish recovery with id [d9c4] in [15 seconds] (reason [invalid request])
will try to reestablish recovery with id [e3a7] in [2 minutes] (reason [internal error])
will try to reestablish recovery with id [g6b2] in [20 seconds] (reason [resource unavailable])
will try to reestablish recovery with id [h1e5] in [3 minutes] (reason [authentication failed])
will try to reestablish recovery with id [i4f8] in [25 seconds] (reason [permission denied])
will try to reestablish recovery with id [j7c3] in [4 minutes] (reason [quota exceeded])
will try to reestablish recovery with id [k2d6] in [35 seconds] (reason [conflict detected])
will try to reestablish recovery with id [l5a1] in [5 minutes] (reason [data corrupted])
will try to reestablish recovery with id [m8e4] in [40 seconds] (reason [unsupported operation])
will try to reestablish recovery with id [n3b7] in [6 minutes] (reason [service unavailable])
will try to reestablish recovery with id [o6f2] in [45 seconds] (reason [unknown error])
error while reading response for trace purposes java.io.IOException: Connection reset by peer
error while reading response for trace purposes java.lang.NullPointerException: null value in header
error while reading response for trace purposes java.net.SocketTimeoutException: Read timed out
error while reading response for trace purposes org.apache.http.client.HttpResponseException: Bad Request
error while reading response for trace purposes javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake
error while reading response for trace purposes java.lang.IllegalArgumentException: Invalid character in URI
error while reading response for trace purposes org.json.JSONException: A JSONObject text must begin with '{' at 1 [character 2 line 1]
error while reading response for trace purposes java.io.EOFException: End of input at line 1 column 1 path $
error while reading response for trace purposes java.net.URISyntaxException: Illegal character in query at index 23
error while reading response for trace purposes java.net.MalformedURLException: no protocol
error while reading response for trace purposes org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 1; Content is not allowed in prolog.
error while reading response for trace purposes java.net.UnknownHostException: api.example.com
error while reading response for trace purposes javax.xml.bind.UnmarshalException - with linked exception:
error while reading response for trace purposes java.lang.OutOfMemoryError: Java heap space
error while reading response for trace purposes java.lang.StackOverflowError
All md files [README.md]
All md files [LICENSE.md]
All md files [CONTRIBUTING.md]
All md files [CHANGELOG.md]
All md files [SUMMARY.md]
All md files [INTRODUCTION.md]
All md files [FAQ.md]
All md files [CODE_OF_CONDUCT.md]
All md files [INSTALLATION.md]
All md files [USAGE.md]
All md files [CONFIGURATION.md]
All md files [TESTING.md]
All md files [DOCUMENTATION.md]
All md files [DEPLOYMENT.md]
All md files [REPORT.md]
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
processing [summary]: ignoring, cluster-manager service not started
local tasks [{"id":1,"state":"RUNNING","start_time":"2023-10-26T03:58:12.345Z","node":{"id":"node-1","name":"Node 1","host":"192.168.0.1","port":8080}}]
local tasks [{"id":2,"state":"FINISHED","start_time":"2023-10-26T03:57:45.678Z","end_time":"2023-10-26T03:58:23.901Z","node":{"id":"node-2","name":"Node 2","host":"192.168.0.2","port":8080}}]
local tasks [{"id":3,"state":"FAILED","start_time":"2023-10-26T03:56:34.567Z","end_time":"2023-10-26T03:57:12.789Z","failure_reason":"NullPointerException","node":{"id":"node-3","name":"Node 3","host":"192.168.0.3","port":8080}}]
local tasks [{"id":4,"state":"CANCELLED","start_time":"2023-10-26T03:55:23.456Z","end_time":"2023-10-26T03:56:01.678Z","cancel_reason":"User request","node":{"id":"node-4","name":"Node 4","host":"192.168.0.4","port":8080}}]
local tasks [{"id":5,"state":"RUNNING","start_time":"2023-10-26T03:54:12.345Z","node":{"id":"node-5","name":"Node 5","host":"192.168.0.5","port":8080}}]
local tasks [{"id":6,"state":"FINISHED","start_time":"2023-10-26T03:53:45.678Z","end_time":"2023-10-26T03:54:23.901Z","node":{"id":"node-6","name":"Node 6","host":"192.168.0.6","port":8080}}]
local tasks [{"id":7,"state":"FAILED","start_time":"2023-10-26T03:52:34.567Z","end_time":"2023-10-26T03:53:12.789Z","failure_reason":"OutOfMemoryError","node":{"id":"node-7","name":"Node 7","host":"192.168.0.7","port":8080}}]
local tasks [{"id":8,"state":"CANCELLED","start_time":"2023-10-26T03:51:23.456Z","end_time":"2023-10-26T03:52:01.678Z","cancel_reason":"TimeoutException","node":{"id":"node-8","name":"Node 8","host":"192.168.0.8","port":8080}}]
local tasks [{"id":9,"state":"RUNNING","start_time":"2023-10-26T03:50:12.345Z","node":{"id":"node-9","name":"Node 9","host":"192.168.0.9","port":8080}}]
local tasks [{"id":10,"state":"FINISHED","start_time":"2023-10-26T03:49:45.678Z", "end_time": "2023-10-26T03:50:23.901Z", "node":{"id": "node-10", "name": "Node 10", "host": "192.168.0.10", "port": 8080}}]
local tasks [{"id":11,"state": "FAILED", "start_time": "2023-10-26T03:48:34,567Z", "end_time": "2023-10-26T03:49:12,789Z", "failure_reason": "IOException", "node":{"id": "node-11", "name": "Node 11", "host": "192,168,0,11", "port": 8080}}]
local tasks [{"id":12,"state": "CANCELLED", "start_time": "2023-10-26T03:47:23,456Z", "end_time": "2023-10-26T03:48:01,678Z", "cancel_reason": "InterruptedException", "node":{"id": "node-12", "name": "Node 12", "host": "192,168,0,12", "port": 8080}}]
local tasks [{"id":13,"state": "RUNNING", "start_time": "2023-10-26T03:46:12,345Z", "node":{"id": "node-13", "name": "Node 13", "host": "192,168,0,13", "port": 8080}}]
local tasks [{"id":14,"state": "FINISHED", "start_time": "2023-10-26T03:45:45,678Z", "end_time": "2023-10-26T03:46:23,901Z", "node":{"id": "node-14", "name": "Node 14", "host": "192,168,0,14", "port": 8080}}]
local tasks [{"id":15,"state": "FAILED", "start_time": "2023-10-26T03:44:34,567Z", "end_time": "2023-10-26T03:45:12,789Z", "failure_reason": "IllegalArgumentException", "node":{"id": "node-15", "name": "Node 15", "host": "192,168,0,15", "port": 8080}}]
Sending off 5 operations
Sending off 12 operations
Sending off 8 operations
Sending off 3 operations
Sending off 10 operations
Sending off 7 operations
Sending off 6 operations
Sending off 9 operations
Sending off 4 operations
Sending off 11 operations
Sending off 2 operations
Sending off 13 operations
Sending off 14 operations
index_1 deleting index
index_2 deleting index
index_3 deleting index
index_4 deleting index
index_5 deleting index
index_6 deleting index
index_7 deleting index
index_8 deleting index
index_9 deleting index
index_10 deleting index
index_11 deleting index
index_12 deleting index
index_13 deleting index
index_14 deleting index
index_15 deleting index
[0] [snapshot_20211022_120733] failed to delete file [segments_6] during snapshot cleanup
[1] [snapshot_20211022_120733] failed to delete file [write.lock] during snapshot cleanup
[2] [snapshot_20211022_120733] failed to delete file [_0.cfe] during snapshot cleanup
[3] [snapshot_20211022_120733] failed to delete file [_0.si] during snapshot cleanup
[4] [snapshot_20211022_120733] failed to delete file [_0.cfs] during snapshot cleanup
[5] [snapshot_20211022_120733] failed to delete file [_0_Lucene80_0.dvd] during snapshot cleanup
[6] [snapshot_20211022_120733] failed to delete file [_0_Lucene80_0.dvm] during snapshot cleanup
[7] [snapshot_20211022_120733] failed to delete file [_1.cfe] during snapshot cleanup
[8] [snapshot_20211022_120733] failed to delete file [_1.si] during snapshot cleanup
[9] [snapshot_20211022_120733] failed to delete file [_1.cfs] during snapshot cleanup
[10] [snapshot_20211022_120733] failed to delete file [_1_Lucene80_0.dvd] during snapshot cleanup
[11] [snapshot_20211022_120733] failed to delete file [_1_Lucene80_0.dvm] during snapshot cleanup
[12] [snapshot_20211022_120733] failed to delete file [_2.cfe] during snapshot cleanup
[13] [snapshot_20211022_120733] failed to delete file [_2.si] during snapshot cleanup
[14] [snapshot_20211022_120733] failed to delete file [_2.cfs] during snapshot cleanup
testRelocationWhileIndexingRandom(numRelocations= 3 , numberOfReplicas= 2 , numberOfNodes= 5 )
testRelocationWhileIndexingRandom(numRelocations= 1 , numberOfReplicas= 4 , numberOfNodes= 6 )
testRelocationWhileIndexingRandom(numRelocations= 2 , numberOfReplicas= 3 , numberOfNodes= 7 )
testRelocationWhileIndexingRandom(numRelocations= 4 , numberOfReplicas= 1 , numberOfNodes= 8 )
testRelocationWhileIndexingRandom(numRelocations= 5 , numberOfReplicas= 2 , numberOfNodes= 9 )
testRelocationWhileIndexingRandom(numRelocations= 6 , numberOfReplicas= 3 , numberOfNodes= 10 )
testRelocationWhileIndexingRandom(numRelocations= 7 , numberOfReplicas= 4 , numberOfNodes= 11 )
testRelocationWhileIndexingRandom(numRelocations= 8 , numberOfReplicas= 5 , numberOfNodes= 12 )
testRelocationWhileIndexingRandom(numRelocations= 9 , numberOfReplicas= 6 , numberOfNodes= 13 )
testRelocationWhileIndexingRandom(numRelocations= 10 , numberOfReplicas= 7 , numberOfNodes= 14 )
testRelocationWhileIndexingRandom(numRelocations= 11 , numberOfReplicas= 8 , numberOfNodes= 15 )
testRelocationWhileIndexingRandom(numRelocations= 12 , numberOfReplicas= 9 , numberOfNodes= 16 )
testRelocationWhileIndexingRandom(numRelocations= 13 , numberOfReplicas= 10 , numberOfNodes= 17 )
testRelocationWhileIndexingRandom(numRelocations= 14 , numberOfReplicas= 11 , numberOfNodes= 18 )
testRelocationWhileIndexingRandom(numRelocations= 15 , numberOfReplicas= 12 , numberOfNodes= 19 )
failed to invoke after index removed callback java.lang.NullPointerException
failed to invoke after index removed callback java.io.IOException: Stream closed
failed to invoke after index removed callback java.lang.IllegalStateException: Index not found
failed to invoke after index removed callback java.lang.ClassCastException: Cannot cast Foo to Bar
failed to invoke after index removed callback java.util.ConcurrentModificationException
failed to invoke after index removed callback java.lang.OutOfMemoryError: Java heap space
failed to invoke after index removed callback java.lang.StackOverflowError
failed to invoke after index removed callback java.lang.ArrayIndexOutOfBoundsException: -1
failed to invoke after index removed callback java.lang.NumberFormatException: For input string: "abc"
failed to invoke after index removed callback java.lang.ArithmeticException: / by zero
failed to invoke after index removed callback java.net.SocketTimeoutException: Read timed out
failed to invoke after index removed callback java.sql.SQLException: No suitable driver found
failed to invoke after index removed callback java.lang.SecurityException: Access denied
failed to invoke after index removed callback java.lang.UnsupportedOperationException: Not implemented
failed to invoke after index removed callback java.lang.NoSuchMethodError: No such method foo()
Error while closing Opentelemetry java.lang.NullPointerException
Error while closing Opentelemetry java.io.IOException
Error while closing Opentelemetry java.lang.IllegalStateException
Error while closing Opentelemetry java.lang.ClassNotFoundException
Error while closing Opentelemetry java.lang.NoSuchMethodError
Error while closing Opentelemetry java.net.SocketException
Error while closing Opentelemetry java.lang.OutOfMemoryError
Error while closing Opentelemetry java.lang.StackOverflowError
Error while closing Opentelemetry java.util.ConcurrentModificationException
Error while closing Opentelemetry java.lang.UnsupportedOperationException
Error while closing Opentelemetry java.lang.SecurityException
Error while closing Opentelemetry java.lang.IllegalArgumentException
Error while closing Opentelemetry java.lang.NumberFormatException
Error while closing Opentelemetry java.util.NoSuchElementException
Error while closing Opentelemetry java.time.DateTimeException
using max_chunk_size[8192], max_header_size[4096], max_initial_line_length[1024], max_content_length[1048576], pipelining_max_events[100]
using max_chunk_size[16384], max_header_size[8192], max_initial_line_length[2048], max_content_length[2097152], pipelining_max_events[200]
using max_chunk_size[32768], max_header_size[16384], max_initial_line_length[4096], max_content_length[4194304], pipelining_max_events[400]
using max_chunk_size[65536], max_header_size[32768], max_initial_line_length[8192], max_content_length[8388608], pipelining_max_events[800]
using max_chunk_size[131072], max_header_size[65536], max_initial_line_length[16384], max_content_length[16777216], pipelining_max_events[1600]
using max_chunk_size[262144], max_header_size[131072], max_initial_line_length[32768], max_content_length[33554432], pipelining_max_events[3200]
using max_chunk_size[524288], max_header_size[262144], max_initial_line_length[65536], max_content_length[67108864], pipelining_max_events[6400]
using max_chunk_size[1048576], max_header_size[524288], max_initial_line_length[131072], max_content_length[134217728], pipelining_max_events[12800]
using max_chunk_size[2097152], max_header_size[1048576], max_initial_line_length[262144], max_content_length[268435456], pipelining_max_events[25600]
using max_chunk_size[4194304], max_header_size[2097152], max_initial_line_length[524288], max_content_length[536870912], pipelining_max_events[51200]
using max_chunk_size[8388608], max_header_size[4194304], max_initial_line_length[1048576], max_content_length[1073741824], pipelining_max_events[102400]
Failed to update shard information for ClusterInfoUpdateJob within 5s timeout
Failed to update shard information for ClusterInfoUpdateJob within 10ms timeout
Failed to update shard information for ClusterInfoUpdateJob within 1m timeout
Failed to update shard information for ClusterInfoUpdateJob within 500ms timeout
Failed to update shard information for ClusterInfoUpdateJob within 30s timeout
Failed to update shard information for ClusterInfoUpdateJob within 100ms timeout
Failed to update shard information for ClusterInfoUpdateJob within 2m timeout
Failed to update shard information for ClusterInfoUpdateJob within 15s timeout
Failed to update shard information for ClusterInfoUpdateJob within 20ms timeout
Failed to update shard information for ClusterInfoUpdateJob within 3m timeout
Failed to update shard information for ClusterInfoUpdateJob within 1s timeout
Failed to update shard information for ClusterInfoUpdateJob within 50ms timeout
Failed to update shard information for ClusterInfoUpdateJob within 4m timeout
Failed to update shard information for ClusterInfoUpdateJob within 25s timeout
Failed to update shard information for ClusterInfoUpdateJob within 40ms timeout
context [main]: compiling script, type: [function], lang: [Python], options: [debug]
context [test]: compiling script, type: [class], lang: [Java], options: [verbose]
context [user]: compiling script, type: [module], lang: [Ruby], options: [optimize]
context [admin]: compiling script, type: [script], lang: [Bash], options: [run]
context [web]: compiling script, type: [template], lang: [HTML], options: [render]
context [db]: compiling script, type: [query], lang: [SQL], options: [execute]
context [app]: compiling script, type: [widget], lang: [JavaScript], options: [update]
context [game]: compiling script, type: [sprite], lang: [C++], options: [animate]
context [ml]: compiling script, type: [model], lang: [R], options: [train]
context [api]: compiling script, type: [endpoint], lang: [PHP], options: [validate]
context [gui]: compiling script, type: [window], lang: [C#], options: [design]
context [bot]: compiling script, type: [dialogue], lang: [Lisp], options: [interact]
context [log]: compiling script, type: [report], lang: [XML], options: [save]
context [doc]: compiling script, type: [document], lang: [Markdown], options: [format]
context [test2]: compiling script, type: [test case], lang: [Perl], options: [test]
--> using settings
--> using settings.xml
--> using settings.json
--> using settings.ini
--> using settings.properties
--> using settings.yaml
--> using settings.conf
--> using settings.env
--> using settings.cfg
--> using settings.py
--> using settings.php
--> using settings.rb
--> using settings.js
--> using settings.dart
--> using settings.ts
Successfully aborted snapshot [runningSnapshot_1]
Successfully aborted snapshot [runningSnapshot_2]
Successfully aborted snapshot [runningSnapshot_3]
Successfully aborted snapshot [runningSnapshot_4]
Successfully aborted snapshot [runningSnapshot_5]
Successfully aborted snapshot [runningSnapshot_6]
Successfully aborted snapshot [runningSnapshot_7]
Successfully aborted snapshot [runningSnapshot_8]
Successfully aborted snapshot [runningSnapshot_9]
Successfully aborted snapshot [runningSnapshot_10]
Successfully aborted snapshot [runningSnapshot_11]
Successfully aborted snapshot [runningSnapshot_12]
Successfully aborted snapshot [runningSnapshot_13]
Successfully aborted snapshot [runningSnapshot_14]
Successfully aborted snapshot [runningSnapshot_15]
Repository [my_repo] updating index.latest with generation [12]
Repository [test_repo] updating index.latest with generation [5]
Repository [backup_repo] updating index.latest with generation [8]
Repository [demo_repo] updating index.latest with generation [10]
Repository [data_repo] updating index.latest with generation [7]
Repository [config_repo] updating index.latest with generation [9]
Repository [docs_repo] updating index.latest with generation [6]
Repository [code_repo] updating index.latest with generation [11]
Repository [logs_repo] updating index.latest with generation [4]
Repository [media_repo] updating index.latest with generation [3]
Repository [user_repo] updating index.latest with generation [13]
Repository [admin_repo] updating index.latest with generation [14]
Repository [temp_repo] updating index.latest with generation [2]
Repository [main_repo] updating index.latest with generation [15]
Repository [archive_repo] updating index.latest with generation [1]
found global metadata with last-accepted term [3]
found global metadata with last-accepted term [5]
found global metadata with last-accepted term [1]
found global metadata with last-accepted term [4]
found global metadata with last-accepted term [2]
found global metadata with last-accepted term [6]
found global metadata with last-accepted term [7]
found global metadata with last-accepted term [8]
found global metadata with last-accepted term [9]
found global metadata with last-accepted term [10]
found global metadata with last-accepted term [11]
found global metadata with last-accepted term [12]
found global metadata with last-accepted term [13]
found global metadata with last-accepted term [14]
found global metadata with last-accepted term [15]
Your repository metadata blob for repository [my-app] is larger than 5MB. Consider moving to a fresh repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable repository behavior going forward.
Your repository metadata blob for repository [test-repo] is larger than 5MB. Consider moving to a fresh repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable repository behavior going forward.
Your repository metadata blob for repository [backup] is larger than 5MB. Consider moving to a fresh repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable repository behavior going forward.
Your repository metadata blob for repository [demo] is larger than 5MB. Consider moving to a fresh repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable repository behavior going forward.
Your repository metadata blob for repository [project-x] is larger than 5MB. Consider moving to a fresh repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable repository behavior going forward.
Your repository metadata blob for repository [data-analysis] is larger than 5MB. Consider moving to a fresh repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable repository behavior going forward.
Your repository metadata blob for repository [web-dev] is larger than 5MB. Consider moving to a fresh repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable repository behavior going forward.
Your repository metadata blob for repository [machine-learning] is larger than 5MB. Consider moving to a fresh repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable repository behavior going forward.
Your repository metadata blob for repository [blog] is larger than 5MB. Consider moving to a fresh repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable repository behavior going forward.
Your repository metadata blob for repository [portfolio] is larger than 5MB. Consider moving to a fresh repository for new snapshots or deleting unneeded snapshots from your repository to ensure stable repository behavior going forward.
0 local file count [1]
1 local file count [2]
2 local file count [3]
3 local file count [4]
4 local file count [5]
5 local file count [6]
6 local file count [7]
7 local file count [8]
8 local file count [9]
9 local file count [10]
10 local file count [11]
11 local file count [12]
12 local file count [13]
13 local file count [14]
14 local file count [15]
checking abstract runnable exception for runner1
checking abstract runnable exception for runner2
checking abstract runnable exception for runner3
checking abstract runnable exception for runner4
checking abstract runnable exception for runner5
checking abstract runnable exception for runner6
checking abstract runnable exception for runner7
checking abstract runnable exception for runner8
checking abstract runnable exception for runner9
checking abstract runnable exception for runner10
checking abstract runnable exception for runner11
checking abstract runnable exception for runner12
checking abstract runnable exception for runner13
checking abstract runnable exception for runner14
checking abstract runnable exception for runner15
can't find replica source node because primary shard 0 is not active.
can't find replica source node because primary shard 1 is not active.
can't find replica source node because primary shard 2 is not active.
can't find replica source node because primary shard 3 is not active.
can't find replica source node because primary shard 4 is not active.
can't find replica source node because primary shard 5 is not active.
can't find replica source node because primary shard 6 is not active.
can't find replica source node because primary shard 7 is not active.
can't find replica source node because primary shard 8 is not active.
can't find replica source node because primary shard 9 is not active.
can't find replica source node because primary shard 10 is not active.
can't find replica source node because primary shard 11 is not active.
can't find replica source node because primary shard 12 is not active.
can't find replica source node because primary shard 13 is not active.
can't find replica source node because primary shard 14 is not active.
C:\Users\Alice\Documents shard folder empty, recovering all files
D:\Backup shard folder empty, recovering all files
E:\Music shard folder empty, recovering all files
F:\Games shard folder empty, recovering all files
G:\Photos shard folder empty, recovering all files
H:\Videos shard folder empty, recovering all files
I:\Downloads shard folder empty, recovering all files
J:\Projects shard folder empty, recovering all files
K:\Work shard folder empty, recovering all files
L:\School shard folder empty, recovering all files
M:\Software shard folder empty, recovering all files
N:\Books shard folder empty, recovering all files
O:\Podcasts shard folder empty, recovering all files
P:\Movies shard folder empty, recovering all files
Q:\Comics shard folder empty, recovering all files
Slice count using lucene default [3]
Slice count using lucene default [5]
Slice count using lucene default [1]
Slice count using lucene default [4]
Slice count using lucene default [2]
Slice count using lucene default [6]
Slice count using lucene default [7]
Slice count using lucene default [8]
Slice count using lucene default [9]
Slice count using lucene default [10]
Slice count using lucene default [11]
Slice count using lucene default [12]
Slice count using lucene default [13]
Slice count using lucene default [14]
Slice count using lucene default [15]
Rest specs for project [/home/userA/my_project] will be copied to the test resources.
Rest specs for project [C:\Users\userB\Documents\projectX] will be copied to the test resources.
Rest specs for project [/var/www/html/projectY] will be copied to the test resources.
Rest specs for project [D:\Projects\userC\projectZ] will be copied to the test resources.
Rest specs for project [/Users/userD/Desktop/my_project] will be copied to the test resources.
Rest specs for project [E:\userE\Documents\Projects\projectW] will be copied to the test resources.
Rest specs for project [/home/userF/Projects/projectV] will be copied to the test resources.
Rest specs for project [C:\userG\Desktop\projectU] will be copied to the test resources.
Rest specs for project [/var/www/userH/projectT] will be copied to the test resources.
Rest specs for project [F:\Projects\userI\projectS] will be copied to the test resources.
Rest specs for project [/Users/userJ/Documents/my_project] will be copied to the test resources.
Rest specs for project [G:\userK\Documents\Projects\projectR] will be copied to the test resources.
Rest specs for project [/home/userL/Projects/projectQ] will be copied to the test resources.
Rest specs for project [H:\userM\Desktop\projectP] will be copied to the test resources.
Rest specs for project [/var/www/userN/projectO] will be copied to the test resources.
Trial run 1 / 10
Trial run 2 / 10
Trial run 3 / 10
Trial run 4 / 10
Trial run 5 / 10
Trial run 6 / 10
Trial run 7 / 10
Trial run 8 / 10
Trial run 9 / 10
Trial run 10 / 10
Trial run 11 / 15
Trial run 12 / 15
Trial run 13 / 15
Trial run 14 / 15
Trial run 15 / 15
triggered dangling indices update for index [products]
triggered dangling indices update for index [users]
triggered dangling indices update for index [orders]
triggered dangling indices update for index [reviews]
triggered dangling indices update for index [inventory]
triggered dangling indices update for index [sales]
triggered dangling indices update for index [customers]
triggered dangling indices update for index [categories]
triggered dangling indices update for index [logs]
triggered dangling indices update for index [settings]
triggered dangling indices update for index [analytics]
triggered dangling indices update for index [notifications]
triggered dangling indices update for index [messages]
triggered dangling indices update for index [reports]
triggered dangling indices update for index [tasks]
Failed to create input stream java.io.FileNotFoundException: File not found
Failed to create input stream java.net.SocketTimeoutException: Read timed out
Failed to create input stream java.lang.NullPointerException: Null object reference
Failed to create input stream java.io.IOException: Stream closed
Failed to create input stream java.net.MalformedURLException: Invalid URL
Failed to create input stream java.security.AccessControlException: Access denied
Failed to create input stream java.util.zip.ZipException: Zip file format error
Failed to create input stream javax.xml.stream.XMLStreamException: Parse error
Failed to create input stream org.apache.commons.compress.archivers.ArchiveException: Unsupported archive format
Failed to create input stream com.fasterxml.jackson.core.JsonParseException: Unrecognized token
Failed to create input stream org.xml.sax.SAXException: Invalid XML document
Failed to create input stream java.io.EOFException: End of file reached
Failed to create input stream java.nio.charset.MalformedInputException: Input length = 1
Failed to create input stream javax.crypto.BadPaddingException: Given final block not properly padded
Failed to create input stream org.apache.poi.EncryptedDocumentException: Unable to process encrypted document
closing repository [git][my-project]
closing repository [svn][test-repo]
closing repository [hg][demo-app]
closing repository [git][hello-world]
closing repository [svn][docs]
closing repository [hg][blog-site]
closing repository [git][machine-learning]
closing repository [svn][web-design]
closing repository [hg][game-dev]
closing repository [git][data-analysis]
closing repository [svn][music-player]
closing repository [hg][chat-bot]
closing repository [git][e-commerce]
closing repository [svn][calculator]
closing repository [hg][weather-app]
index [test] has been blocked before closing and is now deleted, ignoring
index [user] has been blocked before closing and is now deleted, ignoring
index [product] has been blocked before closing and is now deleted, ignoring
index [order] has been blocked before closing and is now deleted, ignoring
index [blog] has been blocked before closing and is now deleted, ignoring
index [news] has been blocked before closing and is now deleted, ignoring
index [comment] has been blocked before closing and is now deleted, ignoring
index [photo] has been blocked before closing and is now deleted, ignoring
index [video] has been blocked before closing and is now deleted, ignoring
index [music] has been blocked before closing and is now deleted, ignoring
index [book] has been blocked before closing and is now deleted, ignoring
index [movie] has been blocked before closing and is now deleted, ignoring
index [game] has been blocked before closing and is now deleted, ignoring
index [forum] has been blocked before closing and is now deleted, ignoring
index [review] has been blocked before closing and is now deleted, ignoring
failed to construct failure response exception
failed to construct failure response error
failed to construct failure response timeout
failed to construct failure response null
failed to construct failure response invalid
failed to construct failure response format
failed to construct failure response overflow
failed to construct failure response out of memory
failed to construct failure response not found
failed to construct failure response access denied
failed to construct failure response connection refused
failed to construct failure response parse
failed to construct failure response type mismatch
failed to construct failure response unsupported
Determined repository's generation from its contents to [5] but current generation is at least [7]
Determined repository's generation from its contents to [3] but current generation is at least [4]
Determined repository's generation from its contents to [8] but current generation is at least [10]
Determined repository's generation from its contents to [6] but current generation is at least [9]
Determined repository's generation from its contents to [4] but current generation is at least [6]
Determined repository's generation from its contents to [7] but current generation is at least [8]
Determined repository's generation from its contents to [9] but current generation is at least [11]
Determined repository's generation from its contents to [10] but current generation is at least [12]
Determined repository's generation from its contents to [2] but current generation is at least [3]
Determined repository's generation from its contents to [1] but current generation is at least [2]
Determined repository's generation from its contents to [11] but current generation is at least [13]
Determined repository's generation from its contents to [12] but current generation is at least [14]
Determined repository's generation from its contents to [13] but current generation is at least [15]
Determined repository's generation from its contents to [14] but current generation is at least [16]
Determined repository's generation from its contents to [15] but current generation is at least [17]
EST from 2023-03-12T01:59:59-05:00 to 2023-03-12T03:00:00-04:00
PST from 2023-11-05T01:59:59-07:00 to 2023-11-05T01:00:00-08:00
GMT from 2023-10-29T01:59:59+00:00 to 2023-10-29T01:00:00+00:00
CST from 2023-04-02T02:59:59+08:00 to 2023-04-02T02:00:00+09:00
AEST from 2023-04-01T15:59:59+10:00 to 2023-04-01T15:00:00+11:00
IST from 2023-10-15T23:59:59+05:30 to 2023-10-16T00:30:00+06:30
NZDT from 2023-04-01T13:59:59+13:00 to 2023-04-01T14:00:00+12:00
HST from 2023-11-05T05:59:59-10:00 to 2023-11-05T06:00:00-10:00
CET from 2023-03-26T01:59:59+01:00 to 2023-03-26T03:00:00+02:00
EAT from 2023-06-21T23:59.59+03.00 to 2023.06.22.01.30.30+04.30
MST from 2023.11.05.06.59.59.-07.00 to 2023.11.05.07.30.30.-06.30
SAST from 2023.09.03.01.59.59.+02.00 to 2023.09.03.02.30.+02.30
BRT from 2023.02.19.01.59.59.-03.00 to 2023.02.19.03.+03
NPT from 2023.04.14.23.44.+05.45 to 2023.04.15.+06.+06
Swap relocation performed for shard [node-1{p}{s}->node-2{p}{s}]
Swap relocation performed for shard [node-3{r}{s}->node-4{r}{s}]
Swap relocation performed for shard [node-5{p}{a}->node-6{p}{a}]
Swap relocation performed for shard [node-7{r}{a}->node-8{r}{a}]
Swap relocation performed for shard [node-9{p}{s}->node-10{r}{s}]
Swap relocation performed for shard [node-11{r}{s}->node-12{p}{s}]
Swap relocation performed for shard [node-13{p}{a}->node-14{r}{a}]
Swap relocation performed for shard [node-15{r}{a}->node-16{p}{a}]
Swap relocation performed for shard [node-17{p}{s}->node-18{p}{a}]
Swap relocation performed for shard [node-19{r}{s}->node-20{r}{a}]
Swap relocation performed for shard [node-21{p}{a}->node-22{p}{s}]
Swap relocation performed for shard [node-23{r}{a}->node-24{r}{s}]
Swap relocation performed for shard [node-25{p}{s}->node-26{r}{a}]
Swap relocation performed for shard [node-27{r}{s}->node-28{p}{a}]
Swap relocation performed for shard [node-29{p}{a}->node-30{p}{a}]
Using non-concurrent aggregation processor over segments for request with context id 7a8b9c
Using non-concurrent aggregation processor over segments for request with context id 3f4g5h
Using non-concurrent aggregation processor over segments for request with context id 9k0l1m
Using non-concurrent aggregation processor over segments for request with context id 6n7o8p
Using non-concurrent aggregation processor over segments for request with context id 4q5r6s
Using non-concurrent aggregation processor over segments for request with context id 2t3u4v
Using non-concurrent aggregation processor over segments for request with context id 0w1x2y
Using non-concurrent aggregation processor over segments for request with context id 5z6a7b
Using non-concurrent aggregation processor over segments for request with context id 3c4d5e
Using non-concurrent aggregation processor over segments for request with context id 1f2g3h
Using non-concurrent aggregation processor over segments for request with context id 8i9j0k
Using non-concurrent aggregation processor over segments for request with context id 6l7m8n
Using non-concurrent aggregation processor over segments for request with context id 4o5p6q
Using non-concurrent aggregation processor over segments for request with context id 2r3s4t
Using non-concurrent aggregation processor over segments for request with context id 0u1v2w
verification of shards before blocking 1 failed [timeout]
verification of shards before blocking 5 failed [checksum mismatch]
verification of shards before blocking 3 failed [connection error]
verification of shards before blocking 7 failed [permission denied]
verification of shards before blocking 2 failed [out of memory]
verification of shards before blocking 4 failed [invalid shard]
verification of shards before blocking 6 failed [corrupted data]
verification of shards before blocking 8 failed [disk full]
verification of shards before blocking 9 failed [unknown error]
verification of shards before blocking 10 failed [server busy]
verification of shards before blocking 11 failed [network failure]
verification of shards before blocking 12 failed [shard not found]
verification of shards before blocking 13 failed [operation aborted]
verification of shards before blocking 14 failed [shard locked]
verification of shards before blocking 15 failed [internal error]
top warming has been interrupted by a NullPointerException
top warming has been interrupted due to a timeout error
top warming has been interrupted because of a low battery level
top warming has been interrupted by a user request
top warming has been interrupted as a result of a power outage
top warming has been interrupted by an unexpected shutdown
top warming has been interrupted for maintenance purposes
top warming has been interrupted by a network failure
top warming has been interrupted by a security breach
top warming has been interrupted due to insufficient memory
top warming has been interrupted by a hardware malfunction
top warming has been interrupted by a software update
top warming has been interrupted by a system crash
top warming has been interrupted due to overheating
top warming has been interrupted by an external interference
can not access [image.jpg] in container {photos}: java.io.FileNotFoundException
can not access [report.docx] in container {documents}: java.net.SocketTimeoutException
can not access [video.mp4] in container {media}: java.lang.OutOfMemoryError
can not access [data.csv] in container {analytics}: java.nio.file.AccessDeniedException
can not access [index.html] in container {web}: java.net.UnknownHostException
can not access [song.mp3] in container {music}: java.io.IOException
can not access [invoice.pdf] in container {finance}: java.security.NoSuchAlgorithmException
can not access [logo.png] in container {design}: java.lang.IllegalArgumentException
can not access [game.exe] in container {fun}: java.lang.SecurityException
can not access [resume.txt] in container {personal}: java.io.EOFException
can not access [map.json] in container {location}: java.util.zip.ZipException
can not access [calendar.ics] in container {schedule}: java.text.ParseException
can not access [recipe.doc] in container {food}: java.lang.NullPointerException
can not access [contact.vcf] in container {contacts}: java.net.MalformedURLException
can not access [book.epub] in container {reading}: java.io.UnsupportedEncodingException
apply cluster state with version 1
apply cluster state with version 2
apply cluster state with version 3
apply cluster state with version 4
apply cluster state with version 5
apply cluster state with version 6
apply cluster state with version 7
apply cluster state with version 8
apply cluster state with version 9
apply cluster state with version 10
apply cluster state with version 11
apply cluster state with version 12
apply cluster state with version 13
apply cluster state with version 14
apply cluster state with version 15
will process 1
will process 2
will process 3
will process 4
will process 5
will process 6
will process 7
will process 8
will process 9
will process 10
will process 11
will process 12
will process 13
will process 14
will process 15
--> candidate on 1.0 node; shard routing: [index][0], node[1], [P], s[STARTED], a[id=123]
--> candidate on 2.1 node; shard routing: [index][1], node[2], [P], s[STARTED], a[id=456]
--> candidate on 3.2 node; shard routing: [index][2], node[3], [P], s[STARTED], a[id=789]
--> candidate on 4.3 node; shard routing: [index][3], node[4], [P], s[STARTED], a[id=101]
--> candidate on 5.4 node; shard routing: [index][4], node[5], [P], s[STARTED], a[id=112]
--> candidate on 6.5 node; shard routing: [index][5], node[6], [P], s[STARTED], a[id=131]
--> candidate on 7.6 node; shard routing: [index][6], node[7], [P], s[STARTED], a[id=415]
--> candidate on 8.7 node; shard routing: [index][7], node[8], [P], s[STARTED], a[id=161]
--> candidate on 9.8 node; shard routing: [index][8], node[9], [P], s[STARTED], a[id=718]
--> candidate on 10.9 node; shard routing: [index][9], node[10], [P], s[STARTED], a[id=191]
--> candidate on 11.10 node; shard routing: [index][10], node[11], [P], s[STARTED], a[id=202]
--> candidate on 12.11 node; shard routing: [index][11], node[12], [P], s[STARTED], a[id=212]
--> candidate on 13.12 node; shard routing: [index][12], node[13], [P], s[STARTED], a[id=232]
--> candidate on 14.13 node; shard routing: [index][13], node[14], [P], s[STARTED], a[id=252]
--> candidate on 15.14 node; shard routing: [index][14], node[15], [P], s[STARTED], a[id=272]
performing file-based recovery followed by history replay starting at [123456]
performing file-based recovery followed by history replay starting at [789012]
performing file-based recovery followed by history replay starting at [345678]
performing file-based recovery followed by history replay starting at [901234]
performing file-based recovery followed by history replay starting at [567890]
performing file-based recovery followed by history replay starting at [234567]
performing file-based recovery followed by history replay starting at [890123]
performing file-based recovery followed by history replay starting at [678901]
performing file-based recovery followed by history replay starting at [456789]
performing file-based recovery followed by history replay starting at [123789]
performing file-based recovery followed by history replay starting at [987654]
performing file-based recovery followed by history replay starting at [654321]
performing file-based recovery followed by history replay starting at [321987]
performing file-based recovery followed by history replay starting at [987321]
performing file-based recovery followed by history replay starting at [321654]
stop throttling indexing for shard [0]
stop throttling indexing for shard [1]
stop throttling indexing for shard [2]
stop throttling indexing for shard [3]
stop throttling indexing for shard [4]
stop throttling indexing for shard [5]
stop throttling indexing for shard [6]
stop throttling indexing for shard [7]
stop throttling indexing for shard [8]
stop throttling indexing for shard [9]
stop throttling indexing for shard [10]
stop throttling indexing for shard [11]
stop throttling indexing for shard [12]
stop throttling indexing for shard [13]
stop throttling indexing for shard [14]
unable to publish secure settings hashes java.lang.NullPointerException
unable to publish secure settings hashes java.io.IOException: Connection refused
unable to publish secure settings hashes java.security.NoSuchAlgorithmException: SHA-256 not supported
unable to publish secure settings hashes java.lang.IllegalArgumentException: Invalid hash format
unable to publish secure settings hashes java.util.concurrent.TimeoutException: Publish operation timed out
unable to publish secure settings hashes javax.crypto.BadPaddingException: Decryption error
unable to publish secure settings hashes org.json.JSONException: Malformed JSON data
unable to publish secure settings hashes java.net.SocketException: Broken pipe
unable to publish secure settings hashes java.lang.OutOfMemoryError: Java heap space
unable to publish secure settings hashes java.lang.SecurityException: Permission denied
unable to publish secure settings hashes java.lang.ClassNotFoundException: com.example.HashPublisher
unable to publish secure settings hashes java.lang.UnsupportedOperationException: Not implemented
unable to publish secure settings hashes java.lang.AssertionError: Hash mismatch
unable to publish secure settings hashes java.net.UnknownHostException: www.example.com
unable to publish secure settings hashes java.lang.InterruptedException: Thread interrupted
--> stopping node [A1]
--> stopping node [B3]
--> stopping node [C5]
--> stopping node [D7]
--> stopping node [E9]
--> stopping node [F2]
--> stopping node [G4]
--> stopping node [H6]
--> stopping node [I8]
--> stopping node [J0]
--> stopping node [K1]
--> stopping node [L3]
--> stopping node [M5]
--> stopping node [N7]
--> stopping node [O9]
resending full cluster state to node 192.168.1.1 reason Connection reset by peer
resending full cluster state to node 10.0.0.5 reason Cluster state update failed
resending full cluster state to node 172.16.0.3 reason TimeoutException: No response from node
resending full cluster state to node 192.168.1.2 reason NodeNotConnectedException: Node is not connected
resending full cluster state to node 10.0.0.6 reason ClusterStateApplierException: Failed to apply cluster state
resending full cluster state to node 172.16.0.4 reason IOException: Broken pipe
resending full cluster state to node 192.168.1.3 reason IllegalStateException: Cluster state is too large
resending full cluster state to node 10.0.0.7 reason NodeClosedException: Node is closed
resending full cluster state to node 172.16.0.5 reason ClusterBlockException: Cluster is blocked
resending full cluster state to node 192.168.1.4 reason MasterNotDiscoveredException: Master node not found
resending full cluster state to node 10.0.0.8 reason IllegalArgumentException: Invalid cluster state version
resending full cluster state to node 172.16.0.6 reason ElasticsearchException: Unknown error
resending full cluster state to node 192.168.1.5 reason OutOfMemoryError: Java heap space
resending full cluster state to node 10.0.0.9 reason InterruptedException: Thread interrupted
resending full cluster state to node 172.16.0.7 reason SecurityException: Access denied
UserTest is a test because it matches the naming convention
CalculatorTest is a test because it matches the naming convention
StringUtilsTest is a test because it matches the naming convention
DatabaseTest is a test because it matches the naming convention
ArrayUtilsTest is a test because it matches the naming convention
FileTest is a test because it matches the naming convention
MathTest is a test because it matches the naming convention
DateUtilsTest is a test because it matches the naming convention
NetworkTest is a test because it matches the naming convention
JsonParserTest is a test because it matches the naming convention
XmlParserTest is a test because it matches the naming convention
RegexTest is a test because it matches the naming convention
EncryptionTest is a test because it matches the naming convention
CompressionTest is a test because it matches the naming convention
LoggerTest is a test because it matches the naming convention
comparing this routing to other routing
comparing this routing to other routing methods
comparing this routing algorithm to other routing algorithms
comparing this routing protocol to other routing protocols
comparing this routing strategy to other routing strategies
comparing this routing scheme to other routing schemes
comparing this routing technique to other routing techniques
comparing this routing system to other routing systems
comparing this routing model to other routing models
comparing this routing function to other routing functions
comparing this routing process to other routing processes
comparing this routing solution to other routing solutions
comparing this routing option to other routing options
comparing this routing rule to other routing rules
comparing this routing feature to other routing features
INFO failed on parsing mappings on index creation [users] java.lang.IllegalArgumentException
DEBUG failed on parsing mappings on index creation [products] org.elasticsearch.index.mapper.MapperParsingException
INFO failed on parsing mappings on index creation [orders] java.io.IOException
DEBUG failed on parsing mappings on index creation [reviews] org.elasticsearch.common.xcontent.XContentParseException
INFO failed on parsing mappings on index creation [blogs] java.lang.NullPointerException
DEBUG failed on parsing mappings on index creation [posts] org.elasticsearch.index.mapper.MapperException
INFO failed on parsing mappings on index creation [comments] java.lang.ClassCastException
DEBUG failed on parsing mappings on index creation [tags] org.elasticsearch.common.compress.NotXContentException
INFO failed on parsing mappings on index creation [categories] java.lang.UnsupportedOperationException
DEBUG failed on parsing mappings on index creation [authors] org.elasticsearch.index.mapper.StrictDynamicMappingException
INFO failed on parsing mappings on index creation [books] java.lang.IllegalStateException
DEBUG failed on parsing mappings on index creation [movies] org.elasticsearch.index.mapper.MergeMappingException
INFO failed on parsing mappings on index creation [songs] java.lang.ArrayIndexOutOfBoundsException
DEBUG failed on parsing mappings on index creation [albums] org.elasticsearch.common.ParsingException
INFO failed on parsing mappings on index creation [artists] java.lang.NumberFormatException
--> failing primary shard a second time, should select: startedReplica [node-1]
--> failing primary shard a second time, should select: startedReplica [node-3]
--> failing primary shard a second time, should select: startedReplica [node-5]
--> failing primary shard a second time, should select: startedReplica [node-2]
--> failing primary shard a second time, should select: startedReplica [node-4]
--> failing primary shard a second time, should select: startedReplica [node-6]
--> failing primary shard a second time, should select: startedReplica [node-7]
--> failing primary shard a second time, should select: startedReplica [node-8]
--> failing primary shard a second time, should select: startedReplica [node-9]
--> failing primary shard a second time, should select: startedReplica [node-10]
--> failing primary shard a second time, should select: startedReplica [node-11]
--> failing primary shard a second time, should select: startedReplica [node-12]
--> failing primary shard a second time, should select: startedReplica [node-13]
--> failing primary shard a second time, should select: startedReplica [node-14]
--> failing primary shard a second time, should select: startedReplica [node-15]
Failed to clean up old shard generation blobs java.io.IOException: No space left on device
Failed to clean up old shard generation blobs java.lang.NullPointerException: Blob reference is null
Failed to clean up old shard generation blobs java.nio.file.AccessDeniedException: Permission denied for /tmp/shard-blobs
Failed to clean up old shard generation blobs java.util.concurrent.TimeoutException: Operation timed out after 10 seconds
Failed to clean up old shard generation blobs java.lang.IllegalStateException: Blob store is closed
Failed to clean up old shard generation blobs java.net.SocketException: Connection reset by peer
Failed to clean up old shard generation blobs java.lang.OutOfMemoryError: Java heap space
Failed to clean up old shard generation blobs org.elasticsearch.ElasticsearchException: Shard not found
Failed to clean up old shard generation blobs java.io.FileNotFoundException: /tmp/shard-blobs/1234.blob (No such file or directory)
Failed to clean up old shard generation blobs java.lang.InterruptedException: Thread interrupted while waiting for lock
Failed to clean up old shard generation blobs org.apache.http.HttpException: Bad request
Failed to clean up old shard generation blobs java.security.PrivilegedActionException: Access denied for user 'admin'
Failed to clean up old shard generation blobs java.net.UnknownHostException: Blob store host not resolved
Failed to clean up old shard generation blobs javax.net.ssl.SSLHandshakeException: Certificate verification failed
Failed to clean up old shard generation blobs org.json.JSONException: Invalid JSON format
took [15 ms], which is over [10 ms], to [update] for [user profile]
took [25 ms], which is over [20 ms], to [query] for [product list]
took [12 ms], which is over [10 ms], to [delete] for [expired session]
took [18 ms], which is over [15 ms], to [insert] for [new order]
took [22 ms], which is over [20 ms], to [fetch] for [customer review]
took [14 ms], which is over [10 ms], to [save] for [settings]
took [28 ms], which is over [25 ms], to [search] for [keyword]
took [16 ms], which is over [15 ms], to [send] for [email notification]
took [24 ms], which is over [20 ms], to [load] for [dashboard]
took [11 ms], which is over [10 ms], to [check] for [availability]
took [19 ms], which is over [15 ms], to [generate] for [report]
took [26 ms], which is over [20 ms], to [validate] for [payment]
took [13 ms], which is over [10 ms], to [sync] for [data]
took [17 ms], which is over [15 ms], to [download] for [file]
processing [cluster update task: add template [.slm-history-ilm-policy], cause [api]]: ignoring, cluster applier service not started
processing [cluster update task: update settings for index [test]]: ignoring, cluster applier service not started
processing [cluster update task: create index [.kibana_1], cause [auto(bulk api)]]: ignoring, cluster applier service not started
processing [cluster update task: delete indices [[.monitoring-es-7-2023.10.27]]]: ignoring, cluster applier service not started
processing [cluster update task: apply cluster state (from master [master {node-1}{aBcDeFgHiJkLmNoPqRsTuVwXyZ} committed version [123]])]: ignoring, cluster applier service not started
processing [cluster update task: create index [.security-7], cause [api]]: ignoring, cluster applier service not started
processing [cluster update task: create component template [.watch-history-13]], cause [api]]: ignoring, cluster applier service not started
processing [cluster update task: put mapping [_doc], indices [[.kibana-event-log-7.16.0-000001]]]: ignoring, cluster applier service not started
processing [cluster update task: create index [.kibana-event-log-7.16.0-000002], cause [rollover_index]]: ignoring, cluster applier service not started
processing [cluster update task: put pipeline [_enrich_pipeline_policy-leader-cluster]], cause [api]]: ignoring, cluster applier service not started
processing [cluster update task: create index [.async-search], cause [api]]: ignoring, cluster applier service not started
processing [cluster update task: create index template [.deprecation-indexing-template], cause [api]]: ignoring, cluster applier service not started
processing [cluster update task: create index [.deprecation-indexing-mappings], cause [api]]: ignoring, cluster applier service not started
processing [cluster update task: create index [.transform-notifications-000002], cause [rollover_index]]: ignoring, cluster applier service not started
processing [cluster update task: put mapping [_doc], indices [[.transform-notifications-000002]]]: ignoring, cluster applier service not started
-> Rolling back 0x7f8c3a4b
-> Rolling back 0x9a2d4c6e
-> Rolling back 0x6b3e5a7d
-> Rolling back 0x4c5d6e8f
-> Rolling back 0x8f9a2b3c
-> Rolling back 0x7d6b4e5a
-> Rolling back 0x5e7c8a9b
-> Rolling back 0x3b5c7d9e
-> Rolling back 0x2a4d6f8c
-> Rolling back 0x1c3e5b7a
-> Rolling back 0x0d2f4a6b
-> Rolling back 0xfe1d3c5a
-> Rolling back 0xed2c4b6d
-> Rolling back 0xdc3b5a7e
-> Rolling back 0xcb4a6d8f
clearing all bitsets because [memory limit exceeded]
clearing all bitsets because [cache is full]
clearing all bitsets because [reset requested by user]
clearing all bitsets because [error occurred in processing]
clearing all bitsets because [system shutdown initiated]
clearing all bitsets because [configuration changed]
clearing all bitsets because [data corrupted]
clearing all bitsets because [test mode enabled]
clearing all bitsets because [performance optimization]
clearing all bitsets because [maintenance scheduled]
clearing all bitsets because [security breach detected]
clearing all bitsets because [new version available]
clearing all bitsets because [backup completed]
clearing all bitsets because [time interval reached]
clearing all bitsets because [debugging mode activated]
Using values= [0.25, 0.5, 0.75, 1.0]
Using values= [0.1, 0.2, 0.3, 0.4, 0.5]
Using values= [0.01, 0.02, 0.03, 0.04]
Using values= [0.9, 0.8, 0.7, 0.6]
Using values= [0.05, 0.1, 0.15, 0.2, 0.25]
Using values= [1.0, 0.9, 0.8, 0.7, 0.6]
Using values= [0.2, 0.4, 0.6, 0.8]
Using values= [0.3, 0.6, 0.9]
Using values= [1.0, 1.5, 2.0]
Using values= [2.5, 3.5, 4.5]
Using values= [10.0, 20.0, 30.0]
Using values= [100.0, 200.0, 300.0]
Using values= [50.5, 51.5, 52.5]
Using values= [99.9, 99.8, 99.7]
Using values= [25.4, 26.4, 27.4]
heap usage not dominated by search requests [ 0.65 / 0.8 ]
heap usage not dominated by search requests [ 0.75 / 0.9 ]
heap usage not dominated by search requests [ 0.7 / 0.85 ]
heap usage not dominated by search requests [ 0.6 / 0.8 ]
heap usage not dominated by search requests [ 0.8 / 0.95 ]
heap usage not dominated by search requests [ 0.55 / 0.75 ]
heap usage not dominated by search requests [ 0.68 / 0.9 ]
heap usage not dominated by search requests [ 0.72 / 0.88 ]
heap usage not dominated by search requests [ 0.63 / 0.83 ]
heap usage not dominated by search requests [ 0.77 / 0.92 ]
heap usage not dominated by search requests [ 0.58 / 0.78 ]
heap usage not dominated by search requests [ 0.66 / 0.86 ]
heap usage not dominated by search requests [ 0.74 / 0.91 ]
heap usage not dominated by search requests [ 0.62 / 0.82 ]
heap usage not dominated by search requests [ 0.76 / 0.93 ]
0 no shard lock for pending delete
1 no shard lock for pending delete
2 no shard lock for pending delete
3 no shard lock for pending delete
4 no shard lock for pending delete
5 no shard lock for pending delete
6 no shard lock for pending delete
7 no shard lock for pending delete
8 no shard lock for pending delete
9 no shard lock for pending delete
10 no shard lock for pending delete
11 no shard lock for pending delete
12 no shard lock for pending delete
13 no shard lock for pending delete
14 no shard lock for pending delete
using explicit ec2 endpoint [ec2.us-east-1.amazonaws.com]
using explicit ec2 endpoint [ec2.ap-southeast-2.amazonaws.com]
using explicit ec2 endpoint [ec2.eu-west-1.amazonaws.com]
using explicit ec2 endpoint [ec2.sa-east-1.amazonaws.com]
using explicit ec2 endpoint [ec2.ca-central-1.amazonaws.com]
using explicit ec2 endpoint [ec2.cn-north-1.amazonaws.com.cn]
using explicit ec2 endpoint [ec2.us-gov-west-1.amazonaws.com]
using explicit ec2 endpoint [ec2.us-gov-east-1.amazonaws.com]
using explicit ec2 endpoint [ec2.af-south-1.amazonaws.com]
using explicit ec2 endpoint [ec2.eu-south-1.amazonaws.com]
using explicit ec2 endpoint [ec2.me-south-1.amazonaws.com]
using explicit ec2 endpoint [ec2.ap-northeast-3.amazonaws.com]
using explicit ec2 endpoint [ec2.ap-east-1.amazonaws.com]
using explicit ec2 endpoint [ec2.eu-north-1.amazonaws.com]
using explicit ec2 endpoint [ec2.ap-northeast-1.amazonaws.com]
iteration [1] - successful shards: 5 (expected 5)
iteration [2] - successful shards: 4 (expected 5)
iteration [3] - successful shards: 5 (expected 5)
iteration [4] - successful shards: 3 (expected 5)
iteration [5] - successful shards: 5 (expected 5)
iteration [6] - successful shards: 4 (expected 5)
iteration [7] - successful shards: 2 (expected 5)
iteration [8] - successful shards: 5 (expected 5)
iteration [9] - successful shards: 3 (expected 5)
iteration [10] - successful shards: 4 (expected 5)
iteration [11] - successful shards: 1 (expected 5)
iteration [12] - successful shards: 5 (expected 5)
iteration [13] - successful shards: 4 (expected 5)
iteration [14] - successful shards: 2 (expected 5)
Overwriting password to: 123456
Overwriting password to: qwerty
Overwriting password to: password
Overwriting password to: abcdef
Overwriting password to: iloveyou
Overwriting password to: 654321
Overwriting password to: asdfgh
Overwriting password to: letmein
Overwriting password to: zxcvbn
Overwriting password to: trustno1
Overwriting password to: dragon
Overwriting password to: monkey
Overwriting password to: shadow
Overwriting password to: master
Overwriting password to: sunshine
failed to send failure response due to timeout
failed to send failure response connection refused
failed to send failure response with code 500
failed to send failure response invalid request
failed to send failure response no such method
failed to send failure response out of memory
failed to send failure response with code 404
failed to send failure response internal server error
failed to send failure response due to network error
failed to send failure response with code 403
failed to send failure response bad gateway
failed to send failure response due to socket error
failed to send failure response with code 400
failed to send failure response service unavailable
updated weighted routing weights [0.3, 0.4, 0.3] in metadata
updated weighted routing weights [0.5, 0.2, 0.3] in metadata
updated weighted routing weights [0.25, 0.25, 0.5] in metadata
updated weighted routing weights [0.4, 0.4, 0.2] in metadata
updated weighted routing weights [0.1, 0.6, 0.3] in metadata
updated weighted routing weights [0.2, 0.5, 0.3] in metadata
updated weighted routing weights [0.6, 0.2, 0.2] in metadata
updated weighted routing weights [0.3, 0.3, 0.4] in metadata
updated weighted routing weights [0.4, 0.2, 0.4] in metadata
updated weighted routing weights [0.2, 0.4, 0.4] in metadata
updated weighted routing weights [0.5, 0.3, 0.2] in metadata
updated weighted routing weights [0.2, 0.3, 0.5] in metadata
updated weighted routing weights [0.3, 0.5, 0.2] in metadata
updated weighted routing weights [0.4, 0.3, 0.3] in metadata
updated weighted routing weights [0.1, 0.4, 0.5] in metadata
localcheckpoint 0 , global 0
localcheckpoint 1 , global 1
localcheckpoint 2 , global 2
localcheckpoint 3 , global 3
localcheckpoint 4 , global 4
localcheckpoint 5 , global 5
localcheckpoint 6 , global 6
localcheckpoint 7 , global 7
localcheckpoint 8 , global 8
localcheckpoint 9 , global 9
localcheckpoint 10 , global 10
localcheckpoint 11 , global 11
localcheckpoint 12 , global 12
localcheckpoint 13 , global 13
localcheckpoint 14 , global 14
failed to close resource java.io.IOException
failed to close resource java.sql.SQLException
failed to close resource java.net.SocketException
failed to close resource java.lang.NullPointerException
failed to close resource java.nio.channels.ClosedChannelException
failed to close resource javax.naming.NamingException
failed to close resource org.apache.commons.dbcp.SQLNestedException
failed to close resource org.xml.sax.SAXException
failed to close resource javax.xml.parsers.ParserConfigurationException
failed to close resource java.util.zip.ZipException
failed to close resource java.security.NoSuchAlgorithmException
failed to close resource javax.crypto.BadPaddingException
failed to close resource javax.net.ssl.SSLException
failed to close resource java.lang.ClassNotFoundException
failed to close resource java.lang.IllegalStateException
Keys to add: 5
Keys to add: 12
Keys to add: 0
Keys to add: 3
Keys to add: 9
Keys to add: 7
Keys to add: 4
Keys to add: 10
Keys to add: 2
Keys to add: 8
Keys to add: 6
Keys to add: 1
Keys to add: 11
Keys to add: 13
Keys to add: 14
topDocs.scoreDocs.length= 10
topDocs.scoreDocs.length= 5
topDocs.scoreDocs.length= 12
topDocs.scoreDocs.length= 8
topDocs.scoreDocs.length= 7
topDocs.scoreDocs.length= 9
topDocs.scoreDocs.length= 11
topDocs.scoreDocs.length= 6
topDocs.scoreDocs.length= 4
topDocs.scoreDocs.length= 13
topDocs.scoreDocs.length= 14
topDocs.scoreDocs.length= 3
topDocs.scoreDocs.length= 15
topDocs.scoreDocs.length= 2
topDocs.scoreDocs.length= 1
updating repository [my-app]
updating repository [data-science]
updating repository [web-design]
updating repository [machine-learning]
updating repository [game-dev]
updating repository [crypto-currency]
updating repository [music-production]
updating repository [travel-blog]
updating repository [e-commerce]
updating repository [health-care]
updating repository [education]
updating repository [social-media]
updating repository [news-aggregator]
updating repository [weather-forecast]
updating repository [personal-finance]
Failure occurred while dumping connection for decommission nodes - java.lang.NullPointerException
Failure occurred while dumping connection for decommission nodes - java.io.IOException: Connection reset by peer
Failure occurred while dumping connection for decommission nodes - org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException
Failure occurred while dumping connection for decommission nodes - java.net.SocketTimeoutException: Read timed out
Failure occurred while dumping connection for decommission nodes - java.lang.IllegalStateException: Connection pool shut down
Failure occurred while dumping connection for decommission nodes - org.apache.hadoop.ipc.RemoteException: File does not exist
Failure occurred while dumping connection for decommission nodes - java.lang.OutOfMemoryError: Java heap space
Failure occurred while dumping connection for decommission nodes - java.lang.InterruptedException
Failure occurred while dumping connection for decommission nodes - org.apache.hadoop.security.AccessControlException: Permission denied
Failure occurred while dumping connection for decommission nodes - java.io.EOFException
Failure occurred while dumping connection for decommission nodes - org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException
Failure occurred while dumping connection for decommission nodes - java.net.ConnectException: Connection refused
Failure occurred while dumping connection for decommission nodes - java.lang.ClassNotFoundException
Failure occurred while dumping connection for decommission nodes - org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException
Failure occurred while dumping connection for decommission nodes - java.io.FileNotFoundException
[0] preparing shard for peer recovery
[1] preparing shard for peer recovery
[2] preparing shard for peer recovery
[3] preparing shard for peer recovery
[4] preparing shard for peer recovery
[5] preparing shard for peer recovery
[6] preparing shard for peer recovery
[7] preparing shard for peer recovery
[8] preparing shard for peer recovery
[9] preparing shard for peer recovery
[10] preparing shard for peer recovery
[11] preparing shard for peer recovery
[12] preparing shard for peer recovery
[13] preparing shard for peer recovery
[14] preparing shard for peer recovery
request [ GET www.example.com /index.html ] returned [HTTP/1.1 200 OK]
request [ POST www.bing.com /search ] returned [HTTP/1.1 302 Found]
request [ PUT www.github.com /repo/file.txt ] returned [HTTP/1.1 403 Forbidden]
request [ DELETE www.amazon.com /cart/item/123 ] returned [HTTP/1.1 204 No Content]
request [ PATCH www.facebook.com /profile/picture ] returned [HTTP/1.1 400 Bad Request]
request [ HEAD www.wikipedia.org /wiki/Bing ] returned [HTTP/1.1 200 OK]
request [ OPTIONS www.google.com /mail ] returned [HTTP/1.1 405 Method Not Allowed]
request [ TRACE www.twitter.com /status/456 ] returned [HTTP/1.1 501 Not Implemented]
request [ CONNECT www.netflix.com /watch/789 ] returned [HTTP/1.1 200 OK]
request [ GET www.instagram.com /p/abc ] returned [HTTP/1.1 404 Not Found]
request [ POST www.reddit.com /r/bing/comments ] returned [HTTP/1.1 201 Created]
request [ PUT www.spotify.com /playlist/song/def ] returned [HTTP/1.1 409 Conflict]
request [ DELETE www.youtube.com /channel/video/ghi ] returned [HTTP/1.1 401 Unauthorized]
request [ PATCH www.medium.com /story/edit/jkl ] returned [HTTP/1.1 500 Internal Server Error]
request [ HEAD www.quora.com /question/answer/mno ] returned [HTTP/1.1 304 Not Modified]
Failed to close translog java.io.IOException: Input/output error
Failed to close translog java.nio.channels.ClosedChannelException: null
Failed to close translog org.elasticsearch.index.translog.TranslogCorruptedException: translog corruption while reading from stream
Failed to close translog java.lang.IllegalStateException: Translog is already closed
Failed to close translog java.lang.OutOfMemoryError: Java heap space
Failed to close translog org.elasticsearch.index.engine.EngineClosedException: CurrentState[CLOSED] Closed
Failed to close translog java.nio.file.AccessDeniedException: /var/lib/elasticsearch/nodes/0/indices/7f9e8c6a-9a8b-4f0d-9b5c-3f0c1d0e9c5a/0/translog/translog-1.ckp
Failed to close translog org.apache.lucene.store.AlreadyClosedException: this IndexWriter is closed
Failed to close translog java.lang.InterruptedException: sleep interrupted
Failed to close translog org.elasticsearch.index.shard.ShardNotFoundException: no such shard
Failed to close translog java.net.SocketTimeoutException: Read timed out
Failed to close translog org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper: remote_transport_exception
Failed to close translog java.lang.NullPointerException: null
Failed to close translog org.elasticsearch.index.translog.TranslogException: failed to sync translog
Failed to close translog java.util.concurrent.ExecutionException: org.elasticsearch.action.UnavailableShardsException
partSize: 1024 , lastPartSize: 512 , partCount: 10
partSize: 2048 , lastPartSize: 1024 , partCount: 5
partSize: 4096 , lastPartSize: 2048 , partCount: 3
partSize: 8192 , lastPartSize: 4096 , partCount: 2
partSize: 16384 , lastPartSize: 8192 , partCount: 1
partSize: 512 , lastPartSize: 256 , partCount: 20
partSize: 256 , lastPartSize: 128 , partCount: 40
partSize: 128 , lastPartSize: 64 , partCount: 80
partSize: 64 , lastPartSize: 32 , partCount: 160
partSize: 32 , lastPartSize: 16 , partCount: 320
partSize: 1000 , lastPartSize: 500 , partCount: 9
partSize: 2000 , lastPartSize: 1000 , partCount: 4
partSize: 3000 , lastPartSize: 1500 , partCount: 3
partSize: 4000 , lastPartSize: 2000 , partCount: 2
partSize: 5000 , lastPartSize: 2500 , partCount: 1
failing primary shards 1,2,3 for index [products]
failing primary shards 4,5 for index [customers]
failing primary shards 6,7,8,9 for index [orders]
failing primary shards 10 for index [reviews]
failing primary shards 11,12,13 for index [inventory]
failing primary shards 14,15 for index [sales]
failing primary shards 16,17,18,19,20 for index [analytics]
failing primary shards 21,22 for index [logs]
failing primary shards 23,24,25 for index [users]
failing primary shards 26,27 for index [settings]
failing primary shards 28,29,30 for index [reports]
failing primary shards 31 for index [alerts]
failing primary shards 32,33 for index [notifications]
failing primary shards 34,35,36 for index [messages]
failing primary shards 37,38,39,40 for index [tasks]
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-pub ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-core ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-dashboards ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-security ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-alerting ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-sql ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-knn ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-anomaly-detection ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-notebooks ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-reports-scheduler ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-index-management ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-job-scheduler ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-performance-analyzer-rca ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-trace-analytics-dashboards-plugin  ' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no ' opensearch-trace-analytics-data-prepper-plugin  ' publication is defined.
using transport addresses [10.0.0.1, 10.0.0.2, 10.0.0.3]
using transport addresses [192.168.1.100, 192.168.1.101, 192.168.1.102]
using transport addresses [172.16.0.4, 172.16.0.5, 172.16.0.6]
using transport addresses [10.1.1.1, 10.1.1.2, 10.1.1.3]
using transport addresses [192.168.2.200, 192.168.2.201, 192.168.2.202]
using transport addresses [172.17.0.7, 172.17.0.8, 172.17.0.9]
using transport addresses [10.2.2.2, 10.2.2.3, 10.2.2.4]
searching for [apple]
searching for [red]
searching for [dog]
searching for [book]
searching for [pizza]
searching for [flower]
searching for [car]
searching for [movie]
searching for [music]
searching for [weather]
searching for [news]
searching for [game]
searching for [math]
searching for [art]
searching for [science]
resumable upload is composed of 10 total chunks (9 chunks of length 100 MB and last chunk of length 50 MB)
resumable upload is composed of 5 total chunks (4 chunks of length 200 MB and last chunk of length 150 MB)
resumable upload is composed of 8 total chunks (7 chunks of length 120 MB and last chunk of length 80 MB)
resumable upload is composed of 12 total chunks (11 chunks of length 90 MB and last chunk of length 40 MB)
resumable upload is composed of 6 total chunks (5 chunks of length 180 MB and last chunk of length 100 MB)
resumable upload is composed of 9 total chunks (8 chunks of length 110 MB and last chunk of length 70 MB)
resumable upload is composed of 7 total chunks (6 chunks of length 140 MB and last chunk of length 60 MB)
resumable upload is composed of 11 total chunks (10 chunks of length 95 MB and last chunk of length 45 MB)
resumable upload is composed of 4 total chunks (3 chunks of length 220 MB and last chunk of length 170 MB)
resumable upload is composed of 13 total chunks (12 chunks of length 85 MB and last chunk of length 35 MB)
resumable upload is composed of 15 total chunks (14 chunks of length 75 MB and last chunk of length 25 MB)
resumable upload is composed of 3 total chunks (2 chunks of length 240 MB and last chunk of length 190 MB)
resumable upload is composed of 14 total chunks (13 chunks of length 80 MB and last chunk of length 30 MB)
resumable upload is composed of 16 total chunks (15 chunks of length 70 MB and last chunk of length 20 MB)
adding listener 1
adding listener 2
adding listener 3
adding listener 4
adding listener 5
adding listener 6
adding listener 7
adding listener 8
adding listener 9
adding listener 10
adding listener 11
adding listener 12
adding listener 13
adding listener 14
adding listener 15
warmed global ordinals for [title], took [0.5ms]
warmed global ordinals for [content], took [1.2ms]
warmed global ordinals for [author], took [0.8ms]
warmed global ordinals for [date], took [0.6ms]
warmed global ordinals for [category], took [1.5ms]
warmed global ordinals for [tags], took [1.1ms]
warmed global ordinals for [rating], took [0.9ms]
warmed global ordinals for [comments], took [1.4ms]
warmed global ordinals for [views], took [0.7ms]
warmed global ordinals for [likes], took [1.3ms]
warmed global ordinals for [shares], took [0.4ms]
warmed global ordinals for [status], took [1.6ms]
warmed global ordinals for [type], took [0.3ms]
warmed global ordinals for [source], took [1.7ms]
warmed global ordinals for [language], took [0.2ms]
Building initial routing table with 10 indices
Building initial routing table with 25 indices
Building initial routing table with 5 indices
Building initial routing table with 12 indices
Building initial routing table with 8 indices
Building initial routing table with 20 indices
Building initial routing table with 15 indices
Building initial routing table with 18 indices
Building initial routing table with 6 indices
Building initial routing table with 9 indices
Building initial routing table with 7 indices
Building initial routing table with 11 indices
Building initial routing table with 14 indices
Building initial routing table with 16 indices
Building initial routing table with 13 indices
reroute after snapshot shard size update failed java.lang.IllegalArgumentException
reroute after snapshot shard size update failed java.io.IOException
reroute after snapshot shard size update failed java.lang.NullPointerException
reroute after snapshot shard size update failed java.lang.OutOfMemoryError
reroute after snapshot shard size update failed java.net.SocketTimeoutException
reroute after snapshot shard size update failed java.util.ConcurrentModificationException
reroute after snapshot shard size update failed java.lang.ClassNotFoundException
reroute after snapshot shard size update failed java.lang.NoSuchMethodError
reroute after snapshot shard size update failed java.lang.SecurityException
reroute after snapshot shard size update failed java.lang.UnsupportedOperationException
reroute after snapshot shard size update failed java.sql.SQLException
reroute after snapshot shard size update failed java.lang.NumberFormatException
reroute after snapshot shard size update failed java.lang.ArrayIndexOutOfBoundsException
reroute after snapshot shard size update failed java.util.NoSuchElementException
reroute after snapshot shard size update failed java.lang.StackOverflowError
Corrupting file data.txt -- flipping at position 1024 from 0x0a to 0x0b
Corrupting file image.jpg -- flipping at position 2048 from 0xff to 0x00
Corrupting file report.docx -- flipping at position 4096 from 0x1c to 0x1d
Corrupting file music.mp3 -- flipping at position 8192 from 0x55 to 0x56
Corrupting file video.mp4 -- flipping at position 16384 from 0xaa to 0xab
Corrupting file backup.zip -- flipping at position 32768 from 0xf0 to 0xf1
Corrupting file code.java -- flipping at position 65536 from 0x05 to 0x06
Corrupting file log.txt -- flipping at position 131072 from 0xfa to 0xfb
Corrupting file game.exe -- flipping at position 262144 from 0x3f to 0x40
Corrupting file config.ini -- flipping at position 524288 from 0xc4 to 0xc5
Corrupting file readme.md -- flipping at position 1048576 from 0x9a to 0x9b
Corrupting file test.csv -- flipping at position 2097152 from 0x6e to 0x6f
Corrupting file email.eml -- flipping at position 4194304 from 0xd2 to 0xd3
Corrupting file book.pdf -- flipping at position 8388608 from 0x7c to 0x7d
Corrupting file wallpaper.bmp -- flipping at position 16777216 from 0xe8 to 0xe9
expected ConnectTransportException but got NullPointerException
expected ConnectTransportException but got TimeoutException
expected ConnectTransportException but got IOException
expected ConnectTransportException but got SecurityException
expected ConnectTransportException but got IllegalArgumentException
expected ConnectTransportException but got IllegalStateException
expected ConnectTransportException but got SocketException
expected ConnectTransportException but got UnknownHostException
expected ConnectTransportException but got ClassNotFoundException
expected ConnectTransportException but got NoSuchMethodException
expected ConnectTransportException but got OutOfMemoryError
expected ConnectTransportException but got AssertionError
expected ConnectTransportException but got RuntimeException
expected ConnectTransportException but got InterruptedException
expected ConnectTransportException but got IndexOutOfBoundsException
removed unassigned node 5678
removed unassigned node 4321
removed unassigned node 9876
removed unassigned node 2468
removed unassigned node 1357
removed unassigned node 8642
removed unassigned node 9513
removed unassigned node 7294
removed unassigned node 1836
removed unassigned node 4725
removed unassigned node 6190
removed unassigned node 3048
removed unassigned node 7561
removed unassigned node 9487
removed unassigned node 1629
unexpected exception while stopping nio group java.lang.NullPointerException
unexpected exception while stopping nio group java.io.IOException
unexpected exception while stopping nio group java.lang.IllegalStateException
unexpected exception while stopping nio group java.lang.InterruptedException
unexpected exception while stopping nio group java.net.SocketException
unexpected exception while stopping nio group java.lang.ClassNotFoundException
unexpected exception while stopping nio group java.lang.NoSuchMethodError
unexpected exception while stopping nio group java.lang.OutOfMemoryError
unexpected exception while stopping nio group java.lang.StackOverflowError
unexpected exception while stopping nio group java.lang.UnsupportedOperationException
unexpected exception while stopping nio group java.util.ConcurrentModificationException
unexpected exception while stopping nio group java.util.NoSuchElementException
unexpected exception while stopping nio group java.util.regex.PatternSyntaxException
unexpected exception while stopping nio group java.security.AccessControlException
unexpected exception while stopping nio group javax.net.ssl.SSLException
Interrupted while waiting for opensearch process java.io.IOException: Connection reset by peer
Interrupted while waiting for opensearch process java.lang.InterruptedException: sleep interrupted
Interrupted while waiting for opensearch process java.util.concurrent.TimeoutException: Timeout waiting for task
Interrupted while waiting for opensearch process org.opensearch.OpenSearchException: Cluster block exception
Interrupted while waiting for opensearch process org.opensearch.OpenSearchTimeoutException: Request timed out
Interrupted while waiting for opensearch process org.opensearch.action.search.SearchPhaseExecutionException: all shards failed
Interrupted while waiting for opensearch process org.opensearch.client.transport.NoNodeAvailableException: None of the configured nodes are available
Interrupted while waiting for opensearch process org.opensearch.index.engine.VersionConflictEngineException: version conflict, current version [1] is different than the one provided [2]
Interrupted while waiting for opensearch process org.opensearch.index.IndexNotFoundException: no such index [test]
Interrupted while waiting for opensearch process org.opensearch.index.shard.ShardNotFoundException: no such shard
Interrupted while waiting for opensearch process org.opensearch.indices.IndexClosedException: closed
Interrupted while waiting for opensearch process org.opensearch.rest.RestStatusException: Bad Request
Interrupted while waiting for opensearch process org.opensearch.script.ScriptException: runtime error
Interrupted while waiting for opensearch process org.opensearch.transport.NodeDisconnectedException: [node1][127.0.0.1:9300][indices:data/read/search] disconnected
Interrupted while waiting for opensearch process java.lang.OutOfMemoryError: Java heap space
[metadata.name()] Found stale root level blobs blobsToLog . Cleaning them up
[user_data] Found stale root level blobs 3 . Cleaning them up
[config] Found stale root level blobs 5 . Cleaning them up
[cache] Found stale root level blobs 2 . Cleaning them up
[logs] Found stale root level blobs 4 . Cleaning them up
[images] Found stale root level blobs 6 . Cleaning them up
[videos] Found stale root level blobs 7 . Cleaning them up
[audio] Found stale root level blobs 1 . Cleaning them up
[documents] Found stale root level blobs 8 . Cleaning them up
[backup] Found stale root level blobs 9 . Cleaning them up
[temp] Found stale root level blobs 10 . Cleaning them up
[downloads] Found stale root level blobs 11 . Cleaning them up
[uploads] Found stale root level blobs 12 . Cleaning them up
[system] Found stale root level blobs 13 . Cleaning them up
[network] Found stale root level blobs 14 . Cleaning them up
[security] Found stale root level blobs 15 . Cleaning them up
unable to gather network information java.net.SocketTimeoutException
unable to gather network information java.net.UnknownHostException
unable to gather network information java.io.IOException
unable to gather network information java.net.ConnectException
unable to gather network information java.net.MalformedURLException
unable to gather network information javax.net.ssl.SSLHandshakeException
unable to gather network information java.net.NoRouteToHostException
unable to gather network information java.net.BindException
unable to gather network information java.net.ProtocolException
unable to gather network information javax.net.ssl.SSLException
unable to gather network information java.net.SocketException
unable to gather network information java.lang.SecurityException
unable to gather network information javax.naming.NamingException
unable to gather network information org.apache.http.conn.HttpHostConnectException
unable to gather network information org.apache.http.client.ClientProtocolException
will retry recovery with id [a3b5c7] in [5 minutes] (reason [network error])
will retry recovery with id [f8d2e4] in [10 seconds] (reason [timeout])
will retry recovery with id [c9e1f6] in [30 minutes] (reason [server busy])
will retry recovery with id [b4d6f8] in [1 hour] (reason [disk full])
will retry recovery with id [e7a2c5] in [15 minutes] (reason [permission denied])
will retry recovery with id [d3c4e6] in [2 minutes] (reason [connection reset])
will retry recovery with id [g6f1d4] in [3 seconds] (reason [invalid request])
will retry recovery with id [h5e3g7] in [45 minutes] (reason [service unavailable])
will retry recovery with id [j4g6h8] in [20 minutes] (reason [internal error])
will retry recovery with id [i3h5j7] in [10 minutes] (reason [quota exceeded])
will retry recovery with id [k2j4i6] in [1 minute] (reason [authentication failed])
will retry recovery with id [l1k3j5] in [4 minutes] (reason [conflict])
will retry recovery with id [m3l2k4] in [12 minutes] (reason [not found])
will retry recovery with id [n2m4l3] in [25 minutes] (reason [bad gateway])
will retry recovery with id [o1n3m2] in [50 minutes] (reason [unsupported operation])
--> Created index= user_info
--> Created index= product_catalog
--> Created index= order_history
--> Created index= customer_review
--> Created index= inventory_status
--> Created index= sales_report
--> Created index= employee_record
--> Created index= event_log
--> Created index= email_list
--> Created index= transaction_detail
--> Created index= web_page
--> Created index= news_article
--> Created index= social_media_post
--> Created index= image_file
--> Created index= video_file
shard [1] is using [1.2 GB] heap, writing [0.5 GB] heap
shard [2] is using [1.5 GB] heap, writing [0.7 GB] heap
shard [3] is using [1.8 GB] heap, writing [0.9 GB] heap
shard [4] is using [2.1 GB] heap, writing [1.1 GB] heap
shard [5] is using [2.4 GB] heap, writing [1.3 GB] heap
shard [6] is using [2.7 GB] heap, writing [1.5 GB] heap
shard [7] is using [3.0 GB] heap, writing [1.7 GB] heap
shard [8] is using [3.3 GB] heap, writing [1.9 GB] heap
shard [9] is using [3.6 GB] heap, writing [2.1 GB] heap
shard [10] is using [3.9 GB] heap, writing [2.3 GB] heap
shard [11] is using [4.2 GB] heap, writing [2.5 GB] heap
shard [12] is using [4.5 GB] heap, writing [2.7 GB] heap
shard [13] is using [4.8 GB] heap, writing [2.9 GB] heap
shard [14] is using [5.1 GB] heap, writing [3.1 GB] heap
shard [15] is using [5.4 GB] heap, writing [3.3 GB] heap
successfully removed all decommissioned nodes [node-1, node-2, node-3] from the cluster
successfully removed all decommissioned nodes [node-4, node-5] from the cluster
successfully removed all decommissioned nodes [node-6] from the cluster
successfully removed all decommissioned nodes [node-7, node-8, node-9, node-10] from the cluster
successfully removed all decommissioned nodes [node-11, node-12, node-13] from the cluster
successfully removed all decommissioned nodes [node-14, node-15, node-16] from the cluster
successfully removed all decommissioned nodes [node-17] from the cluster
successfully removed all decommissioned nodes [node-18, node-19] from the cluster
successfully removed all decommissioned nodes [node-20, node-21, node-22, node-23] from the cluster
successfully removed all decommissioned nodes [node-24] from the cluster
successfully removed all decommissioned nodes [node-25, node-26] from the cluster
successfully removed all decommissioned nodes [node-27, node-28, node-29] from the cluster
successfully removed all decommissioned nodes [node-30] from the cluster
successfully removed all decommissioned nodes [node-31, node-32, node-33] from the cluster
successfully removed all decommissioned nodes [node-34, node-35] from the cluster
comparing instance tags [name:webserver, region:us-east-1] with tags filter [region:us-east-1].
comparing instance tags [name:database, region:us-west-2] with tags filter [name:*].
comparing instance tags [name:appserver, region:eu-central-1] with tags filter [region:*].
comparing instance tags [name:test, region:ap-southeast-1] with tags filter [name:test, region:*].
comparing instance tags [name:prod, region:sa-east-1] with tags filter [name:prod, region:sa-east-1].
comparing instance tags [name:dev, region:ca-central-1] with tags filter [name:dev, region:*].
comparing instance tags [name:webserver, region:us-east-2] with tags filter [region:*].
comparing instance tags [name:database, region:us-west-1] with tags filter [region:*].
comparing instance tags [name:appserver, region:eu-west-1] with tags filter [region:*].
comparing instance tags [name:test, region:ap-northeast-1] with tags filter [name:test, region:*].
comparing instance tags [name:prod, region:af-south-1] with tags filter [name:*].
comparing instance tags [name:dev, region:eu-north-1] with tags filter [region:*].
comparing instance tags [name:webserver, region:*] with tags filter [region:*].
comparing instance tags [name:database, region:*] with tags filter [region:*].
Found service principal. Converted original principal name [user1@domain.com] to server principal [user1@server.com]
Found service principal. Converted original principal name [admin@domain.com] to server principal [admin@server.com]
Found service principal. Converted original principal name [guest@domain.com] to server principal [guest@server.com]
Found service principal. Converted original principal name [user2@domain.com] to server principal [user2@server.com]
Found service principal. Converted original principal name [user3@domain.com] to server principal [user3@server.com]
Found service principal. Converted original principal name [user4@domain.com] to server principal [user4@server.com]
Found service principal. Converted original principal name [user5@domain.com] to server principal [user5@server.com]
Found service principal. Converted original principal name [user6@domain.com] to server principal [user6@server.com]
Found service principal. Converted original principal name [user7@domain.com] to server principal [user7@server.com]
Found service principal. Converted original principal name [user8@domain.com] to server principal [user8@server.com]
Found service principal. Converted original principal name [user9@domain.com] to server principal [user9@server.com]
Found service principal. Converted original principal name [user10@domain.com] to server principal [user10@server.com]
Found service principal. Converted original principal name [user11@domain.com] to server principal [user11@server.com]
Found service principal. Converted original principal name [user12@domain.com] to server principal [user12@server.com]
Found service principal. Converted original principal name [user13@domain.com] to server principal [user13@server.com]
recoveryTarget.shardId() collecting local files for [node-1]
recoveryTarget.sourceNode() collecting local files for [shard-2]
recoveryTarget.shardId() collecting local files for [node-3]
recoveryTarget.sourceNode() collecting local files for [shard-4]
recoveryTarget.shardId() collecting local files for [node-5]
recoveryTarget.sourceNode() collecting local files for [shard-6]
recoveryTarget.shardId() collecting local files for [node-7]
recoveryTarget.sourceNode() collecting local files for [shard-8]
recoveryTarget.shardId() collecting local files for [node-9]
recoveryTarget.sourceNode() collecting local files for [shard-10]
recoveryTarget.shardId() collecting local files for [node-11]
recoveryTarget.sourceNode() collecting local files for [shard-12]
recoveryTarget.shardId() collecting local files for [node-13]
recoveryTarget.sourceNode() collecting local files for [shard-14]
recoveryTarget.shardId() collecting local files for [node-15]
Add routing /home
Add routing /login
Add routing /products
Add routing /cart
Add routing /checkout
Add routing /profile
Add routing /orders
Add routing /reviews
Add routing /contact
Add routing /about
Add routing /blog
Add routing /search
Add routing /faq
Add routing /terms
Add routing /privacy
schedule pending delete retry after 500 ms
schedule pending delete retry after 1000 ms
schedule pending delete retry after 1500 ms
schedule pending delete retry after 2000 ms
schedule pending delete retry after 2500 ms
schedule pending delete retry after 3000 ms
schedule pending delete retry after 3500 ms
schedule pending delete retry after 4000 ms
schedule pending delete retry after 4500 ms
schedule pending delete retry after 5000 ms
schedule pending delete retry after 5500 ms
schedule pending delete retry after 6000 ms
schedule pending delete retry after 6500 ms
schedule pending delete retry after 7000 ms
schedule pending delete retry after 7500 ms
An authentication header was detected but the token type was not supported Bearer
An authentication header was detected but the token type was not supported Basic
An authentication header was detected but the token type was not supported Digest
An authentication header was detected but the token type was not supported OAuth
An authentication header was detected but the token type was not supported JWT
An authentication header was detected but the token type was not supported SAML
An authentication header was detected but the token type was not supported NTLM
An authentication header was detected but the token type was not supported Kerberos
An authentication header was detected but the token type was not supported API Key
An authentication header was detected but the token type was not supported HMAC
An authentication header was detected but the token type was not supported AWS Signature
An authentication header was detected but the token type was not supported Azure AD
An authentication header was detected but the token type was not supported OpenID Connect
An authentication header was detected but the token type was not supported Firebase
An authentication header was detected but the token type was not supported Custom
using [node] query cache with size [1000] max filter count [50]
using [node] query cache with size [500] max filter count [25]
using [node] query cache with size [2000] max filter count [100]
using [node] query cache with size [1500] max filter count [75]
using [node] query cache with size [2500] max filter count [125]
using [node] query cache with size [3000] max filter count [150]
using [node] query cache with size [3500] max filter count [175]
using [node] query cache with size [4000] max filter count [200]
using [node] query cache with size [4500] max filter count [225]
using [node] query cache with size [5000] max filter count [250]
using [node] query cache with size [5500] max filter count [275]
using [node] query cache with size [6000] max filter count [300]
using [node] query cache with size [6500] max filter count [325]
using [node] query cache with size [7000] max filter count [350]
using [node] query cache with size [7500] max filter count [375]
failed to send bad request response java.lang.NullPointerException
failed to send bad request response java.io.IOException: Broken pipe
failed to send bad request response java.net.SocketTimeoutException: Read timed out
failed to send bad request response javax.servlet.ServletException: Invalid request format
failed to send bad request response org.springframework.web.client.HttpClientErrorException: 400 Bad Request
failed to send bad request response java.lang.IllegalArgumentException: Invalid parameter value
failed to send bad request response java.net.MalformedURLException: No protocol specified
failed to send bad request response org.apache.http.ProtocolException: Unsupported transfer encoding
failed to send bad request response com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'foo'
failed to send bad request response org.xml.sax.SAXException: Invalid XML document
failed to send bad request response java.lang.OutOfMemoryError: Java heap space
failed to send bad request response java.lang.SecurityException: Access denied
failed to send bad request response javax.net.ssl.SSLHandshakeException: Certificate expired
failed to send bad request response org.hibernate.exception.ConstraintViolationException: Could not execute statement
failed to send bad request response java.util.concurrent.TimeoutException: Future timed out
removed [node-1] from denylist
removed [node-23] from denylist
removed [node-7] from denylist
removed [node-12] from denylist
removed [node-4] from denylist
removed [node-19] from denylist
removed [node-9] from denylist
removed [node-16] from denylist
removed [node-3] from denylist
removed [node-21] from denylist
removed [node-8] from denylist
removed [node-14] from denylist
removed [node-5] from denylist
removed [node-18] from denylist
removed [node-10] from denylist
index [0] is a hidden index
index [1] is a hidden index
index [2] is a hidden index
index [3] is a hidden index
index [4] is a hidden index
index [5] is a hidden index
index [6] is a hidden index
index [7] is a hidden index
index [8] is a hidden index
index [9] is a hidden index
index [10] is a hidden index
index [11] is a hidden index
index [12] is a hidden index
index [13] is a hidden index
index [14] is a hidden index
[shard1] [snapshot-20211021] Aborted on the file [data.csv], exiting
[shard2] [snapshot-20211020] Aborted on the file [config.json], exiting
[shard3] [snapshot-20211019] Aborted on the file [index.html], exiting
[shard4] [snapshot-20211018] Aborted on the file [logo.png], exiting
[shard5] [snapshot-20211017] Aborted on the file [report.docx], exiting
[shard6] [snapshot-20211016] Aborted on the file [users.db], exiting
[shard7] [snapshot-20211015] Aborted on the file [script.py], exiting
[shard8] [snapshot-20211014] Aborted on the file [style.css], exiting
[shard9] [snapshot-20211013] Aborted on the file [readme.md], exiting
[shard10] [snapshot-20211012] Aborted on the file [video.mp4], exiting
[shard11] [snapshot-20211011] Aborted on the file [audio.mp3], exiting
[shard12] [snapshot-20211010] Aborted on the file [image.jpg], exiting
[shard13] [snapshot-20211009] Aborted on the file [text.txt], exiting
[shard14] [snapshot-20211008] Aborted on the file [code.java], exiting
[shard15] [snapshot-20211007] Aborted on the file [graph.xlsx], exiting
unexpected exception while closing http channels Exception",
unexpected exception while closing http channels NullPointerException",
unexpected exception while closing http channels IOException",
unexpected exception while closing http channels TimeoutException",
unexpected exception while closing http channels IndexOutOfBoundsException",
unexpected exception while closing http channels IllegalStateException",
unexpected exception while closing http channels NetworkException",
unexpected exception while closing http channels SecurityException",
unexpected exception while closing http channels ConnectionRefusedException",
unexpected exception while closing http channels ResourceNotFoundException",
unexpected exception while closing http channels ClassNotFoundException",
unexpected exception while closing http channels UnknownHostException",
unexpected exception while closing http channels OutOfMemoryError",
unexpected exception while closing http channels StackOverflowError",
unexpected exception while closing http channels ArithmeticException"
could not lock IndexWriter java.io.IOException: No space left on device
could not lock IndexWriter org.apache.lucene.store.LockObtainFailedException: Lock obtain timed out
could not lock IndexWriter java.lang.IllegalStateException: IndexWriter is closed
could not lock IndexWriter java.nio.file.AccessDeniedException: Permission denied
could not lock IndexWriter org.apache.lucene.index.CorruptIndexException: checksum failed
could not lock IndexWriter java.lang.InterruptedException: Thread interrupted
could not lock IndexWriter java.net.SocketTimeoutException: Read timed out
could not lock IndexWriter org.apache.lucene.store.AlreadyClosedException: this Directory is closed
could not lock IndexWriter java.lang.OutOfMemoryError: Java heap space
could not lock IndexWriter java.nio.file.NoSuchFileException: File not found
could not lock IndexWriter org.apache.lucene.index.IndexNotFoundException: no segments* file found
could not lock IndexWriter java.io.FileNotFoundException: The system cannot find the file specified
could not lock IndexWriter org.apache.lucene.store.LockReleaseFailedException: Cannot forcefully unlock a NativeFSLock which is held by another indexer component
could not lock IndexWriter java.lang.IllegalArgumentException: Directory of index is already locked
could not lock IndexWriter org.apache.lucene.index.MergePolicy$MergeException: Merge failed
primary resolved to node 1
primary resolved to node 2
primary resolved to node 3
primary resolved to node 4
primary resolved to node 5
primary resolved to node 6
primary resolved to node 7
primary resolved to node 8
primary resolved to node 9
primary resolved to node 10
primary resolved to node 11
primary resolved to node 12
primary resolved to node 13
primary resolved to node 14
primary resolved to node 15
stats for node-1, primary [true]: [maxSeqNo=100, localCheckpoint=99, globalCheckpoint=99]
stats for node-2, primary [false]: [maxSeqNo=100, localCheckpoint=98, globalCheckpoint=97]
stats for node-3, primary [false]: [maxSeqNo=101, localCheckpoint=100, globalCheckpoint=99]
stats for node-4, primary [true]: [maxSeqNo=102, localCheckpoint=101, globalCheckpoint=101]
stats for node-5, primary [false]: [maxSeqNo=103, localCheckpoint=102, globalCheckpoint=101]
stats for node-6, primary [true]: [maxSeqNo=104, localCheckpoint=103, globalCheckpoint=103]
stats for node-7, primary [false]: [maxSeqNo=105, localCheckpoint=104, globalCheckpoint=103]
stats for node-8, primary [false]: [maxSeqNo=106, localCheckpoint=105, globalCheckpoint=104]
stats for node-9, primary [true]: [maxSeqNo=107, localCheckpoint=106, globalCheckpoint=106]
stats for node-10, primary [false]: [maxSeqNo=108, localCheckpoint=107, globalCheckpoint=106]
stats for node-11, primary [false]: [maxSeqNo=109, localCheckpoint=108, globalCheckpoint=107]
stats for node-12, primary [true]: [maxSeqNo=110, localCheckpoint=109, globalCheckpoint=109]
stats for node-13, primary [false]: [maxSeqNo=111, localCheckpoint=110, globalCheckpoint=109]
stats for node-14, primary [false]: [maxSeqNo=112, localCheckpoint=111, globalCheckpoint=110]
stats for node-15, primary [true]: [maxSeqNo=113, localCheckpoint=112, globalCheckpoint=112]
--> created snapshot-20211023 in [my-repo]
--> created backup-20210930 in [test-repo]
--> created image-20210815 in [prod-repo]
--> created restore-20210701 in [archive-repo]
--> created snapshot-20210630 in [dev-repo]
--> created backup-20210531 in [my-repo]
--> created image-20210430 in [test-repo]
--> created restore-20210331 in [prod-repo]
--> created snapshot-20210228 in [archive-repo]
--> created backup-20210131 in [dev-repo]
--> created image-20201231 in [my-repo]
--> created restore-20201130 in [test-repo]
--> created snapshot-20201031 in [prod-repo]
--> created backup-20200930 in [archive-repo]
--> created image-20200831 in [dev-repo]
Dumping jstack of opensearch processb (123) that failed to start
Dumping jstack of opensearch processb (456) that failed to start
Dumping jstack of opensearch processb (789) that failed to start
Dumping jstack of opensearch processb (1011) that failed to start
Dumping jstack of opensearch processb (1213) that failed to start
Dumping jstack of opensearch processb (1415) that failed to start
Dumping jstack of opensearch processb (1617) that failed to start
Dumping jstack of opensearch processb (1819) that failed to start
Dumping jstack of opensearch processb (2021) that failed to start
Dumping jstack of opensearch processb (2223) that failed to start
Dumping jstack of opensearch processb (2425) that failed to start
Dumping jstack of opensearch processb (2627) that failed to start
Dumping jstack of opensearch processb (2829) that failed to start
Dumping jstack of opensearch processb (3031) that failed to start
Dumping jstack of opensearch processb (3233) that failed to start
--> deleting snapshot [daily_backup] from repo [main] from non cluster-manager client
--> deleting snapshot [test_01] from repo [dev] from non cluster-manager client
--> deleting snapshot [weekly_report] from repo [analytics] from non cluster-manager client
--> deleting snapshot [user_data] from repo [security] from non cluster-manager client
--> deleting snapshot [config] from repo [settings] from non cluster-manager client
--> deleting snapshot [product_catalog] from repo [sales] from non cluster-manager client
--> deleting snapshot [logs_2021_10_23] from repo [monitoring] from non cluster-manager client
--> deleting snapshot [demo] from repo [marketing] from non cluster-manager client
--> deleting snapshot [archive_2020] from repo [backup] from non cluster-manager client
--> deleting snapshot [project_x] from repo [research] from non cluster-manager client
--> deleting snapshot [profile_pics] from repo [social_media] from non cluster-manager client
--> deleting snapshot [invoices] from repo [accounting] from non cluster-manager client
--> deleting snapshot [videos] from repo [media] from non cluster-manager client
--> deleting snapshot [emails] from repo [communication] from non cluster-manager client
--> deleting snapshot [documents] from repo [storage] from non cluster-manager client
--> creating full snapshot [backup_20211023] to repo [main] from non cluster-manager client
--> creating full snapshot [restore_20211024] to repo [backup] from non cluster-manager client
--> creating full snapshot [test_20211025] to repo [dev] from non cluster-manager client
--> creating full snapshot [prod_20211026] to repo [release] from non cluster-manager client
--> creating full snapshot [demo_20211027] to repo [staging] from non cluster-manager client
--> creating full snapshot [archive_20211028] to repo [history] from non cluster-manager client
--> creating full snapshot [config_20211029] to repo [settings] from non cluster-manager client
--> creating full snapshot [logs_20211030] to repo [monitoring] from non cluster-manager client
--> creating full snapshot [data_20211031] to repo [storage] from non cluster-manager client
--> creating full snapshot [report_20211101] to repo [analytics] from non cluster-manager client
--> creating full snapshot [user_20211102] to repo [profile] from non cluster-manager client
--> creating full snapshot [session_20211103] to repo [auth] from non cluster-manager client
--> creating full snapshot [media_20211104] to repo [content] from non cluster-manager client
--> creating full snapshot [code_20211105] to repo [source] from non cluster-manager client
--> creating full snapshot [patch_20211106] to repo [update] from non cluster-manager client
--> corrupting [index-3] in [/home/user/repo1]
--> corrupting [index-7] in [/var/lib/repo2]
--> corrupting [index-12] in [/opt/data/repo3]
--> corrupting [index-5] in [/tmp/repo4]
--> corrupting [index-9] in [/etc/repo5]
--> corrupting [index-2] in [/root/repo6]
--> corrupting [index-8] in [/usr/local/repo7]
--> corrupting [index-4] in [/mnt/repo8]
--> corrupting [index-10] in [/media/repo9]
--> corrupting [index-6] in [/srv/repo10]
--> corrupting [index-1] in [/dev/repo11]
--> corrupting [index-11] in [/proc/repo12]
--> corrupting [index-13] in [/sys/repo13]
--> corrupting [index-15] in [/run/repo14]
--> corrupting [index-14] in [/boot/repo15]
--> creating full snapshot [daily_backup] to repo [main_repo] from cluster-manager client
--> creating full snapshot [weekly_report] to repo [analytics_repo] from cluster-manager client
--> creating full snapshot [user_data] to repo [security_repo] from cluster-manager client
--> creating full snapshot [system_state] to repo [backup_repo] from cluster-manager client
--> creating full snapshot [product_catalog] to repo [sales_repo] from cluster-manager client
--> creating full snapshot [test_results] to repo [qa_repo] from cluster-manager client
--> creating full snapshot [logs_archive] to repo [logs_repo] from cluster-manager client
--> creating full snapshot [config_files] to repo [config_repo] from cluster-manager client
--> creating full snapshot [media_content] to repo [media_repo] from cluster-manager client
--> creating full snapshot [email_history] to repo [email_repo] from cluster-manager client
--> creating full snapshot [customer_feedback] to repo [support_repo] from cluster-manager client
--> creating full snapshot [inventory_status] to repo [inventory_repo] from cluster-manager client
--> creating full snapshot [project_plan] to repo [project_repo] from cluster-manager client
--> creating full snapshot [code_review] to repo [code_repo] from cluster-manager client
--> creating full snapshot [performance_metrics] to repo [monitoring_repo] from cluster-manager client
---- Unexpected exit code (expected 0, got 1) for script: backup.sh
---- Unexpected exit code (expected 2, got 0) for script: install.py
---- Unexpected exit code (expected 1, got 3) for script: update.bat
---- Unexpected exit code (expected 0, got 127) for script: test.pl
---- Unexpected exit code (expected 3, got 2) for script: clean.rb
---- Unexpected exit code (expected 0, got -1) for script: run.sh
---- Unexpected exit code (expected 2, got 4) for script: uninstall.py
---- Unexpected exit code (expected 1, got 0) for script: restore.bat
---- Unexpected exit code (expected 0, got 255) for script: check.pl
---- Unexpected exit code (expected 3, got 1) for script: scan.rb
---- Unexpected exit code (expected 0, got -2) for script: compile.sh
---- Unexpected exit code (expected 2, got -1) for script: deploy.py
---- Unexpected exit code (expected 1, got -3) for script: reboot.bat
---- Unexpected exit code (expected 0, got -127) for script: debug.pl
---- Unexpected exit code (expected 3, got -2) for script: optimize.rb
Loading Docker image: /home/ubuntu/docker/ubuntu-18.04.tar.gz
Loading Docker image: /var/lib/docker/images/centos-7.9.2009-x86_64.tar.xz
Loading Docker image: /opt/dockerfiles/alpine-3.14.2-amd64.tar
Loading Docker image: /tmp/docker-build/nginx-1.21.3-alpine.tar.gz
Loading Docker image: /usr/local/docker/images/python-3.9.7-slim-buster.tar
Loading Docker image: /mnt/docker-storage/images/mongo-5.0.3-linux-x64.tar.xz
Loading Docker image: /root/docker/images/node-16.10.0-buster-slim.tar.gz
Loading Docker image: /data/docker/images/postgres-13.4-alpine.tar
Loading Docker image: /etc/docker/images/redis-6.2.5-alpine.tar.gz
Loading Docker image: /srv/docker/images/ruby-3.0.2-slim-buster.tar
Loading Docker image: /media/docker/images/java-11-openjdk-slim-buster.tar.gz
Loading Docker image: /run/docker/images/golang-1.17.1-alpine3.14.tar
Loading Docker image: /dev/docker/images/mysql-8.0.26-linux-glibc2.12-x86_64.tar.xz
Loading Docker image: /boot/docker/images/haproxy-2.4.7-alpine.tar.gz
Loading Docker image: /lib/docker/images/tomcat-10.0.12-jdk11-openjdk-slim-buster.tar
--> creating repository at C:\Users\Alice\Documents\my_project
--> creating repository at /home/bob/repos/test_repo
--> creating repository at D:\work\java\demo_repo
--> creating repository at /var/lib/git/repo1
--> creating repository at E:\backup\repos\old_repo
--> creating repository at /Users/charlie/Desktop/new_repo
--> creating repository at C:\Program Files\Git\repo2
--> creating repository at /opt/git/repo3
--> creating repository at F:\data\repos\repo4
--> creating repository at /tmp/git/repo5
--> creating repository at G:\shared\repos\repo6
--> creating repository at /mnt/c/Users/Dave/repos/repo7
--> creating repository at H:\git\repos\repo8
--> creating repository at /root/git/repo9
-->  truncating shard index file [shard-000001.dat]
-->  truncating shard index file [shard-000002.dat]
-->  truncating shard index file [shard-000003.dat]
-->  truncating shard index file [shard-000004.dat]
-->  truncating shard index file [shard-000005.dat]
-->  truncating shard index file [shard-000006.dat]
-->  truncating shard index file [shard-000007.dat]
-->  truncating shard index file [shard-000008.dat]
-->  truncating shard index file [shard-000009.dat]
-->  truncating shard index file [shard-000010.dat]
-->  truncating shard index file [shard-000011.dat]
-->  truncating shard index file [shard-000012.dat]
-->  truncating shard index file [shard-000013.dat]
-->  truncating shard index file [shard-000014.dat]
-->  truncating shard index file [shard-000015.dat]
-->  verifying snapshot state for [snapshot1]
-->  verifying snapshot state for [snapshot2]
-->  verifying snapshot state for [snapshot3]
-->  verifying snapshot state for [snapshot4]
-->  verifying snapshot state for [snapshot5]
-->  verifying snapshot state for [snapshot6]
-->  verifying snapshot state for [snapshot7]
-->  verifying snapshot state for [snapshot8]
-->  verifying snapshot state for [snapshot9]
-->  verifying snapshot state for [snapshot10]
-->  verifying snapshot state for [snapshot11]
-->  verifying snapshot state for [snapshot12]
-->  verifying snapshot state for [snapshot13]
-->  verifying snapshot state for [snapshot14]
-->  verifying snapshot state for [snapshot15]
Copying file from container with: backup.sh
Copying file from container with: install.py
Copying file from container with: config.ini
Copying file from container with: data.csv
Copying file from container with: index.html
Copying file from container with: main.java
Copying file from container with: test.rb
Copying file from container with: style.css
Copying file from container with: report.pdf
Copying file from container with: logo.png
Copying file from container with: readme.md
Copying file from container with: app.js
Copying file from container with: game.exe
Copying file from container with: music.mp3
Copying file from container with: video.mp4
changing max_merge_at_once from [10] to [15] because segments_per_tier [12] has to be higher or equal to it
changing max_merge_at_once from [8] to [10] because segments_per_tier [10] has to be higher or equal to it
changing max_merge_at_once from [12] to [16] because segments_per_tier [18] has to be higher or equal to it
changing max_merge_at_once from [6] to [8] because segments_per_tier [9] has to be higher or equal to it
changing max_merge_at_once from [9] to [12] because segments_per_tier [14] has to be higher or equal to it
changing max_merge_at_once from [7] to [9] because segments_per_tier [11] has to be higher or equal to it
changing max_merge_at_once from [11] to [14] because segments_per_tier [16] has to be higher or equal to it
changing max_merge_at_once from [5] to [7] because segments_per_tier [8] has to be higher or equal to it
changing max_merge_at_once from [13] to [17] because segments_per_tier [20] has to be higher or equal to it
changing max_merge_at_once from [4] to [6] because segments_per_tier [7] has to be higher or equal to it
changing max_merge_at_once from [14] to [18] because segments_per_tier [22] has to be higher or equal to it
changing max_merge_at_once from [3] to [5] because segments_per_tier [6] has to be higher or equal to it
changing max_merge_at_once from [15] to [19] because segments_per_tier [24] has to be higher or equal to it
changing max_merge_at_once from [2] to [4] because segments_per_tier [5] has to be higher or equal to it
changing max_merge_at_once from [16] to [20] because segments_per_tier [26] has to be higher or equal to it
--> deleting index [users]
--> deleting index [products]
--> deleting index [orders]
--> deleting index [reviews]
--> deleting index [categories]
--> deleting index [tags]
--> deleting index [posts]
--> deleting index [comments]
--> deleting index [events]
--> deleting index [books]
--> deleting index [authors]
--> deleting index [movies]
--> deleting index [genres]
--> deleting index [ratings]
-->  restoring snapshot [snapshot1]
-->  restoring snapshot [snapshot2]
-->  restoring snapshot [snapshot3]
-->  restoring snapshot [snapshot4]
-->  restoring snapshot [snapshot5]
-->  restoring snapshot [snapshot6]
-->  restoring snapshot [snapshot7]
-->  restoring snapshot [snapshot8]
-->  restoring snapshot [snapshot9]
-->  restoring snapshot [snapshot10]
-->  restoring snapshot [snapshot11]
-->  restoring snapshot [snapshot12]
-->  restoring snapshot [snapshot13]
-->  restoring snapshot [snapshot14]
-->  restoring snapshot [snapshot15]
-->  creating snapshot [snapshot2-20211023-212500]
-->  creating snapshot [snapshot2-20211023-212600]
-->  creating snapshot [snapshot2-20211023-212700]
-->  creating snapshot [snapshot2-20211023-212800]
-->  creating snapshot [snapshot2-20211023-212900]
-->  creating snapshot [snapshot2-20211023-213000]
-->  creating snapshot [snapshot2-20211023-213100]
-->  creating snapshot [snapshot2-20211023-213200]
-->  creating snapshot [snapshot2-20211023-213300]
-->  creating snapshot [snapshot2-20211023-213400]
-->  creating snapshot [snapshot2-20211023-213500]
-->  creating snapshot [snapshot2-20211023-213600]
-->  creating snapshot [snapshot2-20211023-213700]
-->  creating snapshot [snapshot2-20211023-213800]
-->  creating snapshot [snapshot2-20211023-213900]
Checking permissions and ownership of [/home/user/documents]
Checking permissions and ownership of [/var/log/syslog]
Checking permissions and ownership of [/etc/passwd]
Checking permissions and ownership of [/usr/bin/python3]
Checking permissions and ownership of [/dev/sda1]
Checking permissions and ownership of [/tmp/file.txt]
Checking permissions and ownership of [/opt/java/bin/java]
Checking permissions and ownership of [/root/.bashrc]
Checking permissions and ownership of [/media/cdrom0]
Checking permissions and ownership of [/proc/uptime]
Checking permissions and ownership of [/lib/modules/5.4.0-91-generic/kernel/drivers]
Checking permissions and ownership of [/boot/grub/grub.cfg]
Checking permissions and ownership of [/srv/http/index.html]
Checking permissions and ownership of [/mnt/backup.tar.gz]
Checking permissions and ownership of [/run/user/1000/gvfs]
Index restore is not supported for non-existent index. Skipping: products
Index restore is not supported for non-existent index. Skipping: users
Index restore is not supported for non-existent index. Skipping: orders
Index restore is not supported for non-existent index. Skipping: reviews
Index restore is not supported for non-existent index. Skipping: inventory
Index restore is not supported for non-existent index. Skipping: categories
Index restore is not supported for non-existent index. Skipping: transactions
Index restore is not supported for non-existent index. Skipping: customers
Index restore is not supported for non-existent index. Skipping: ratings
Index restore is not supported for non-existent index. Skipping: comments
Index restore is not supported for non-existent index. Skipping: posts
Index restore is not supported for non-existent index. Skipping: tags
Index restore is not supported for non-existent index. Skipping: articles
Index restore is not supported for non-existent index. Skipping: authors
Index restore is not supported for non-existent index. Skipping: books
adding listener threadNum=1
adding listener threadNum=5
adding listener threadNum=10
adding listener threadNum=15
adding listener threadNum=20
adding listener threadNum=25
adding listener threadNum=30
adding listener threadNum=35
adding listener threadNum=40
adding listener threadNum=45
adding listener threadNum=50
adding listener threadNum=55
adding listener threadNum=60
adding listener threadNum=65
adding listener threadNum=70
executing initial scroll against all indices
executing initial scroll against [index1, index2, index3]
executing initial scroll against index4
executing initial scroll against [index5, index6]
executing initial scroll against []
executing initial scroll against [index7]
executing initial scroll against [index8, index9, index10, index11]
executing initial scroll against all indices
executing initial scroll against [index12, index13]
executing initial scroll against index14
executing initial scroll against [index15]
executing initial scroll against [index16, index17, index18]
executing initial scroll against all indices
executing initial scroll against index19
executing initial scroll against [index20, index21, index22]
=== Contents of `index.html` (/home/user/Desktop/index.html) ===
=== Contents of `config.ini` (/etc/config.ini) ===
=== Contents of `report.pdf` (/mnt/usb/report.pdf) ===
=== Contents of `data.csv` (/var/log/data.csv) ===
=== Contents of `script.py` (/usr/local/bin/script.py) ===
=== Contents of `image.jpg` (/tmp/image.jpg) ===
=== Contents of `README.md` (/opt/project/README.md) ===
=== Contents of `main.cpp` (/home/user/Documents/main.cpp) ===
=== Contents of `style.css` (/var/www/html/style.css) ===
=== Contents of `database.db` (/root/database.db) ===
=== Contents of `music.mp3` (/media/user/music.mp3) ===
=== Contents of `notes.txt` (/home/user/notes.txt) ===
=== Contents of `logo.png` (/srv/logo.png) ===
=== Contents of `backup.zip` (/backup.zip) ===
=== Contents of `video.mp4` (/home/user/Videos/video.mp4) ===
[task1]: rethrottling to [5] requests per second
[task2]: rethrottling to [10] requests per second
[task3]: rethrottling to [7] requests per second
[task4]: rethrottling to [8] requests per second
[task5]: rethrottling to [6] requests per second
[task6]: rethrottling to [9] requests per second
[task7]: rethrottling to [4] requests per second
[task8]: rethrottling to [3] requests per second
[task9]: rethrottling to [2] requests per second
[task10]: rethrottling to [1] requests per second
[task11]: rethrottling to [12] requests per second
[task12]: rethrottling to [11] requests per second
[task13]: rethrottling to [15] requests per second
[task14]: rethrottling to [13] requests per second
[task15]: rethrottling to [14] requests per second
--> executor: Spark
--> executor: Hadoop
--> executor: SQL
--> executor: Python
--> executor: Java
--> executor: C++
--> executor: Ruby
--> executor: Bash
--> executor: R
--> executor: Scala
--> executor: MATLAB
--> executor: Perl
--> executor: JavaScript
--> executor: PHP
--> executor: C#
=== End of contents of `config.txt`===
=== End of contents of `log.txt`===
=== End of contents of `index.html`===
=== End of contents of `data.csv`===
=== End of contents of `script.py`===
=== End of contents of `report.docx`===
=== End of contents of `image.jpg`===
=== End of contents of `video.mp4`===
=== End of contents of `audio.mp3`===
=== End of contents of `archive.zip`===
=== End of contents of `database.db`===
=== End of contents of `certificate.pem`===
=== End of contents of `readme.md`===
=== End of contents of `license.txt`===
=== End of contents of `settings.json`===
[task1]: skipping rescheduling because there is no scheduled task
[task2]: skipping rescheduling because there is no scheduled task
[task3]: skipping rescheduling because there is no scheduled task
[task4]: skipping rescheduling because there is no scheduled task
[task5]: skipping rescheduling because there is no scheduled task
[task6]: skipping rescheduling because there is no scheduled task
[task7]: skipping rescheduling because there is no scheduled task
[task8]: skipping rescheduling because there is no scheduled task
[task9]: skipping rescheduling because there is no scheduled task
[task10]: skipping rescheduling because there is no scheduled task
[task11]: skipping rescheduling because there is no scheduled task
[task12]: skipping rescheduling because there is no scheduled task
[task13]: skipping rescheduling because there is no scheduled task
[task14]: skipping rescheduling because there is no scheduled task
[task15]: skipping rescheduling because there is no scheduled task
[node1] cluster-manager is [node1]
[node2] cluster-manager is [node1]
[node3] cluster-manager is [node1]
[node4] cluster-manager is [node4]
[node5] cluster-manager is [node4]
[node6] cluster-manager is [node4]
[node7] cluster-manager is [node7]
[node8] cluster-manager is [node7]
[node9] cluster-manager is [node7]
[node10] cluster-manager is [node10]
[node11] cluster-manager is [node10]
[node12] cluster-manager is [node10]
[node13] cluster-manager is [node13]
[node14] cluster-manager is [node13]
[node15] cluster-manager is [node13]
[task_001]: skipping rescheduling because we couldn't cancel the task
[task_042]: skipping rescheduling because we couldn't cancel the task
[task_123]: skipping rescheduling because we couldn't cancel the task
[task_007]: skipping rescheduling because we couldn't cancel the task
[task_056]: skipping rescheduling because we couldn't cancel the task
[task_098]: skipping rescheduling because we couldn't cancel the task
[task_034]: skipping rescheduling because we couldn't cancel the task
[task_089]: skipping rescheduling because we couldn't cancel the task
[task_015]: skipping rescheduling because we couldn't cancel the task
[task_067]: skipping rescheduling because we couldn't cancel the task
[task_028]: skipping rescheduling because we couldn't cancel the task
[task_076]: skipping rescheduling because we couldn't cancel the task
[task_045]: skipping rescheduling because we couldn't cancel the task
[task_012]: skipping rescheduling because we couldn't cancel the task
[task_099]: skipping rescheduling because we couldn't cancel the task
[123]: rescheduling for [5 seconds] in the future
[123]: rescheduling for [5 seconds] in the future
[456]: rescheduling for [10 minutes] in the future
[789]: rescheduling for [1 hour] in the future
[1011]: rescheduling for [3 days] in the future
[1213]: rescheduling for [15 minutes] in the future
[1415]: rescheduling for [30 seconds] in the future
[1617]: rescheduling for [2 hours] in the future
[1819]: rescheduling for [1 day] in the future
[2021]: rescheduling for [4 hours] in the future
[2223]: rescheduling for [6 seconds] in the future
[2425]: rescheduling for [12 minutes] in the future
[2627]: rescheduling for [2 days] in the future
[2829]: rescheduling for [20 minutes] in the future
[3031]: rescheduling for [40 seconds] in the future
[3233]: rescheduling for [3 hours] in the future
failed to resolve host [google.com]java.net.UnknownHostException
failed to resolve host [localhost]java.net.UnknownHostException
failed to resolve host [bing.com]java.net.UnknownHostException
failed to resolve host [example.com]java.net.UnknownHostException
failed to resolve host [facebook.com]java.net.UnknownHostException
failed to resolve host [amazon.com]java.net.UnknownHostException
failed to resolve host [reddit.com]java.net.UnknownHostException
failed to resolve host [twitter.com]java.net.UnknownHostException
failed to resolve host [youtube.com]java.net.UnknownHostException
failed to resolve host [wikipedia.org]java.net.UnknownHostException
failed to resolve host [github.com]java.net.UnknownHostException
failed to resolve host [stackoverflow.com]java.net.UnknownHostException
failed to resolve host [netflix.com]java.net.UnknownHostException
failed to resolve host [instagram.com]java.net.UnknownHostException
failed to resolve host [linkedin.com]java.net.UnknownHostException
--> execution was blocked on node [node-1], shutting it down
--> execution was blocked on node [node-5], shutting it down
--> execution was blocked on node [node-3], shutting it down
--> execution was blocked on node [node-7], shutting it down
--> execution was blocked on node [node-2], shutting it down
--> execution was blocked on node [node-4], shutting it down
--> execution was blocked on node [node-6], shutting it down
--> execution was blocked on node [node-8], shutting it down
--> execution was blocked on node [node-9], shutting it down
--> execution was blocked on node [node-10], shutting it down
--> execution was blocked on node [node-11], shutting it down
--> execution was blocked on node [node-12], shutting it down
--> execution was blocked on node [node-13], shutting it down
--> execution was blocked on node [node-14], shutting it down
--> execution was blocked on node [node-15], shutting it down
--> stopping node [blockedNode-1]
--> stopping node [blockedNode-5]
--> stopping node [blockedNode-9]
--> stopping node [blockedNode-12]
--> stopping node [blockedNode-16]
--> stopping node [blockedNode-20]
--> stopping node [blockedNode-23]
--> stopping node [blockedNode-27]
--> stopping node [blockedNode-30]
--> stopping node [blockedNode-34]
--> stopping node [blockedNode-37]
--> stopping node [blockedNode-41]
--> stopping node [blockedNode-44]
--> stopping node [blockedNode-48]
--> stopping node [blockedNode-51]
Created RemoteSegmentTransferTracker for shardId=0
Created RemoteSegmentTransferTracker for shardId=1
Created RemoteSegmentTransferTracker for shardId=2
Created RemoteSegmentTransferTracker for shardId=3
Created RemoteSegmentTransferTracker for shardId=4
Created RemoteSegmentTransferTracker for shardId=5
Created RemoteSegmentTransferTracker for shardId=6
Created RemoteSegmentTransferTracker for shardId=7
Created RemoteSegmentTransferTracker for shardId=8
Created RemoteSegmentTransferTracker for shardId=9
Created RemoteSegmentTransferTracker for shardId=10
Created RemoteSegmentTransferTracker for shardId=11
Created RemoteSegmentTransferTracker for shardId=12
Created RemoteSegmentTransferTracker for shardId=13
Created RemoteSegmentTransferTracker for shardId=14
--> Case SINGLE
--> Case MULTI
--> Case HYBRID
--> Case NONE
--> Case CUSTOM
--> Case LOCAL
--> Case REMOTE
--> Case SHARED
--> Case DEDICATED
--> Case BALANCED
--> Case RANDOM
--> Case OPTIMAL
--> Case DEFAULT
--> Case MANUAL
--> Case AUTO
--> Cluster manager cm1
--> Cluster manager cm2
--> Cluster manager cm3
--> Cluster manager cm4
--> Cluster manager cm5
--> Cluster manager cm6
--> Cluster manager cm7
--> Cluster manager cm8
--> Cluster manager cm9
--> Cluster manager cm10
--> Cluster manager cm11
--> Cluster manager cm12
--> Cluster manager cm13
--> Cluster manager cm14
--> Cluster manager cm15
Created RemoteTranslogTransferTracker for shardId=0
Created RemoteTranslogTransferTracker for shardId=1
Created RemoteTranslogTransferTracker for shardId=2
Created RemoteTranslogTransferTracker for shardId=3
Created RemoteTranslogTransferTracker for shardId=4
Created RemoteTranslogTransferTracker for shardId=5
Created RemoteTranslogTransferTracker for shardId=6
Created RemoteTranslogTransferTracker for shardId=7
Created RemoteTranslogTransferTracker for shardId=8
Created RemoteTranslogTransferTracker for shardId=9
Created RemoteTranslogTransferTracker for shardId=10
Created RemoteTranslogTransferTracker for shardId=11
Created RemoteTranslogTransferTracker for shardId=12
Created RemoteTranslogTransferTracker for shardId=13
Created RemoteTranslogTransferTracker for shardId=14
timed out after [10s] resolving host [www.google.com]
timed out after [5s] resolving host [www.facebook.com]
timed out after [15s] resolving host [www.amazon.com]
timed out after [8s] resolving host [www.wikipedia.org]
timed out after [12s] resolving host [www.netflix.com]
timed out after [7s] resolving host [www.twitter.com]
timed out after [9s] resolving host [www.youtube.com]
timed out after [6s] resolving host [www.instagram.com]
timed out after [11s] resolving host [www.microsoft.com]
timed out after [13s] resolving host [www.apple.com]
timed out after [14s] resolving host [www.bbc.com]
timed out after [4s] resolving host [www.cnn.com]
timed out after [16s] resolving host [www.reddit.com]
timed out after [3s] resolving host [www.spotify.com]
--> execution was blocked on node [node-1], aborting snapshot
--> execution was blocked on node [node-5], aborting snapshot
--> execution was blocked on node [node-3], aborting snapshot
--> execution was blocked on node [node-7], aborting snapshot
--> execution was blocked on node [node-2], aborting snapshot
--> execution was blocked on node [node-4], aborting snapshot
--> execution was blocked on node [node-6], aborting snapshot
--> execution was blocked on node [node-8], aborting snapshot
--> execution was blocked on node [node-9], aborting snapshot
--> execution was blocked on node [node-10], aborting snapshot
--> execution was blocked on node [node-11], aborting snapshot
--> execution was blocked on node [node-12], aborting snapshot
--> execution was blocked on node [node-13], aborting snapshot
--> execution was blocked on node [node-14], aborting snapshot
--> execution was blocked on node [node-15], aborting snapshot
Deleted RemoteSegmentTransferTracker for shardId=0
Deleted RemoteSegmentTransferTracker for shardId=1
Deleted RemoteSegmentTransferTracker for shardId=2
Deleted RemoteSegmentTransferTracker for shardId=3
Deleted RemoteSegmentTransferTracker for shardId=4
Deleted RemoteSegmentTransferTracker for shardId=5
Deleted RemoteSegmentTransferTracker for shardId=6
Deleted RemoteSegmentTransferTracker for shardId=7
Deleted RemoteSegmentTransferTracker for shardId=8
Deleted RemoteSegmentTransferTracker for shardId=9
Deleted RemoteSegmentTransferTracker for shardId=10
Deleted RemoteSegmentTransferTracker for shardId=11
Deleted RemoteSegmentTransferTracker for shardId=12
Deleted RemoteSegmentTransferTracker for shardId=13
Deleted RemoteSegmentTransferTracker for shardId=14
Deleted RemoteTranslogTransferTracker for shardId=0
Deleted RemoteTranslogTransferTracker for shardId=1
Deleted RemoteTranslogTransferTracker for shardId=2
Deleted RemoteTranslogTransferTracker for shardId=3
Deleted RemoteTranslogTransferTracker for shardId=4
Deleted RemoteTranslogTransferTracker for shardId=5
Deleted RemoteTranslogTransferTracker for shardId=6
Deleted RemoteTranslogTransferTracker for shardId=7
Deleted RemoteTranslogTransferTracker for shardId=8
Deleted RemoteTranslogTransferTracker for shardId=9
Deleted RemoteTranslogTransferTracker for shardId=10
Deleted RemoteTranslogTransferTracker for shardId=11
Deleted RemoteTranslogTransferTracker for shardId=12
Deleted RemoteTranslogTransferTracker for shardId=13
Deleted RemoteTranslogTransferTracker for shardId=14
lucene state metadata: {term=1, version=2, id=3}
lucene state metadata: {term=2, version=4, id=6}
lucene state metadata: {term=3, version=5, id=9}
lucene state metadata: {term=4, version=6, id=12}
lucene state metadata: {term=5, version=7, id=15}
lucene state metadata: {term=6, version=8, id=18}
lucene state metadata: {term=7, version=9, id=21}
lucene state metadata: {term=8, version=10, id=24}
lucene state metadata: {term=9, version=11, id=27}
lucene state metadata: {term=10, version=12, id=30}
lucene state metadata: {term=11, version=13, id=33}
lucene state metadata: {term=12, version=14, id=36}
lucene state metadata: {term=13, version=15, id=39}
lucene state metadata: {term=14, version=16, id=42}
lucene state metadata: {term=15, version=17, id=45}
Rejecting write requests for shard, stale shards [12%] shards: [2, 5, 7]
Rejecting write requests for shard, stale shards [25%] shards: [1, 3, 4, 6]
Rejecting write requests for shard, stale shards [8%] shards: [9]
Rejecting write requests for shard, stale shards [15%] shards: [2, 4, 8]
Rejecting write requests for shard, stale shards [18%] shards: [1, 5, 7]
Rejecting write requests for shard, stale shards [22%] shards: [3, 6, 9]
Rejecting write requests for shard, stale shards [10%] shards: [4, 8]
Rejecting write requests for shard, stale shards [13%] shards: [1, 2, 6]
Rejecting write requests for shard, stale shards [20%] shards: [3, 5, 7, 9]
Rejecting write requests for shard, stale shards [17%] shards: [2, 4, 6, 8]
Rejecting write requests for shard, stale shards [11%] shards: [1, 7]
Rejecting write requests for shard, stale shards [14%] shards: [3, 4, 9]
Rejecting write requests for shard, stale shards [16%] shards: [5, 6]
Rejecting write requests for shard, stale shards [19%] shards: [1, 2, 3]
Rejecting write requests for shard, stale shards [21%] shards: [7, 8]
Corrupting file data.txt -- flipping at position 1024 from 0x0a to 0x0b
Corrupting file image.jpg -- flipping at position 2048 from 0xff to 0x00
Corrupting file report.docx -- flipping at position 4096 from 0x1c to 0x1d
Corrupting file music.mp3 -- flipping at position 8192 from 0x7f to 0x80
Corrupting file video.mp4 -- flipping at position 16384 from 0x3e to 0x3f
Corrupting file backup.zip -- flipping at position 32768 from 0xf8 to 0xf9
Corrupting file code.java -- flipping at position 65536 from 0x2a to 0x2b
Corrupting file game.exe -- flipping at position 131072 from 0xd4 to 0xd5
Corrupting file email.eml -- flipping at position 262144 from 0x6c to 0x6d
Corrupting file config.ini -- flipping at position 524288 from 0xb2 to 0xb3
Corrupting file log.txt -- flipping at position 1048576 from 0x5a to 0x5b
Corrupting file photo.png -- flipping at position 2097152 from 0xe6 to 0xe7
Corrupting file script.py -- flipping at position 4194304 from 0x4e to 0x4f
Corrupting file book.pdf -- flipping at position 8388608 from 0xc8 to 0xc9
--> excluding index [0] from node [node-1]
--> excluding index [1] from node [node-2]
--> excluding index [2] from node [node-3]
--> excluding index [3] from node [node-4]
--> excluding index [4] from node [node-5]
--> excluding index [5] from node [node-6]
--> excluding index [6] from node [node-7]
--> excluding index [7] from node [node-8]
--> excluding index [8] from node [node-9]
--> excluding index [9] from node [node-10]
--> excluding index [10] from node [node-11]
--> excluding index [11] from node [node-12]
--> excluding index [12] from node [node-13]
--> excluding index [13] from node [node-14]
--> excluding index [14] from node [node-15]
expiring unused lease
expiring unused lease for tenant 5678
expiring unused lease in zone us-east-1
expiring unused lease with id 9a87b6c5
expiring unused lease after 30 days
expiring unused lease for resource type EC2
expiring unused lease with tag ProjectX
expiring unused lease for user alice@example.com
expiring unused lease with status ACTIVE
expiring unused lease for group devops
expiring unused lease in region eu-west-2
expiring unused lease with expiration date 2023-10-31
expiring unused lease for service S3
expiring unused lease with size 10 GB
Blocking on the document 5f8a7b3c4d6e8b002a4c8e7d
Blocking on the document 5f8a7b3c4d6e8b002a4c8e7e
Blocking on the document 5f8a7b3c4d6e8b002a4c8e7f
Blocking on the document 5f8a7b3c4d6e8b002a4c8e80
Blocking on the document 5f8a7b3c4d6e8b002a4c8e81
Blocking on the document 5f8a7b3c4d6e8b002a4c8e82
Blocking on the document 5f8a7b3c4d6e8b002a4c8e83
Blocking on the document 5f8a7b3c4d6e8b002a4c8e84
Blocking on the document 5f8a7b3c4d6e8b002a4c8e85
Blocking on the document 5f8a7b3c4d6e8b002a4c8e86
Blocking on the document 5f8a7b3c4d6e8b002a4c8e87
Blocking on the document 5f8a7b3c4d6e8b002a4c8e88
Blocking on the document 5f8a7b3c4d6e8b002a4c8e89
Blocking on the document 5f8a7b3c4d6e8b002a4c8e90
Blocking on the document 5f8a7b3c4d6e8b002a4c8e91
Connecting to uri: https://www.bing.com
Connecting to uri: http://localhost:8080
Connecting to uri: ftp://example.com
Connecting to uri: https://api.github.com
Connecting to uri: ws://chat.example.com
Connecting to uri: https://www.google.com/search?q=bing
Connecting to uri: https://en.wikipedia.org/wiki/URI
Connecting to uri: mailto:user@example.com
Connecting to uri: tel:+1-555-1234
Connecting to uri: file:///C:/Users/Bing/Desktop/log.txt
Connecting to uri: data:text/plain,Hello%20Bing
Connecting to uri: urn:isbn:978-0-123456-47-2
Connecting to uri: ssh://user@host:22
Connecting to uri: sftp://user@host/path/to/file
Connecting to uri: ldap://[2001:db8::7]/c=GB?objectClass?one
localcheckpoint 0, global 1
localcheckpoint 1, global 2
localcheckpoint 2, global 3
localcheckpoint 3, global 4
localcheckpoint 4, global 5
localcheckpoint 5, global 6
localcheckpoint 6, global 7
localcheckpoint 7, global 8
localcheckpoint 8, global 9
localcheckpoint 9, global 10
localcheckpoint 10, global 11
localcheckpoint 11, global 12
localcheckpoint 12, global 13
localcheckpoint 13, global 14
localcheckpoint 14, global 15
Fetching resource at https://api.example.com/users
Fetching resource at http://localhost:3000/posts
Fetching resource at ftp://files.example.net/images
Fetching resource at https://www.example.org/data.json
Fetching resource at http://192.168.1.100:8080/index.html
Fetching resource at https://api.example.com/products?category=books
Fetching resource at http://localhost:3000/comments?post_id=42
Fetching resource at ftp://files.example.net/videos/movie.mp4
Fetching resource at https://www.example.org/data.xml
Fetching resource at http://192.168.1.100:8080/about.html
Fetching resource at https://api.example.com/users/123
Fetching resource at http://localhost:3000/posts/456
Fetching resource at ftp://files.example.net/images/logo.png
Fetching resource at https://www.example.org/data.csv
Fetching resource at http://192.168.1.100:8080/contact.html
expiring retention leases [3] from current retention leases [12]
expiring retention leases [5] from current retention leases [15]
expiring retention leases [2] from current retention leases [8]
expiring retention leases [4] from current retention leases [10]
expiring retention leases [6] from current retention leases [18]
expiring retention leases [1] from current retention leases [7]
expiring retention leases [7] from current retention leases [20]
expiring retention leases [8] from current retention leases [16]
expiring retention leases [9] from current retention leases [19]
expiring retention leases [10] from current retention leases [22]
expiring retention leases [11] from current retention leases [25]
expiring retention leases [12] from current retention leases [28]
expiring retention leases [13] from current retention leases [31]
expiring retention leases [14] from current retention leases [34]
expiring retention leases [15] from current retention leases [37]
adding new retention lease [primary/0] to current retention leases [primary/0,replica/1,replica/2]
adding new retention lease [replica/3] to current retention leases [primary/0,replica/1,replica/2]
adding new retention lease [primary/1] to current retention leases [primary/1,replica/4,replica/5]
adding new retention lease [replica/6] to current retention leases [primary/1,replica/4,replica/5]
adding new retention lease [primary/2] to current retention leases [primary/2,replica/7,replica/8]
adding new retention lease [replica/9] to current retention leases [primary/2,replica/7,replica/8]
adding new retention lease [primary/3] to current retention leases [primary/3,replica/10,replica/11]
adding new retention lease [replica/12] to current retention leases [primary/3,replica/10,replica/11]
adding new retention lease [primary/4] to current retention leases [primary/4,replica/13,replica/14]
adding new retention lease [replica/15] to current retention leases [primary/4,replica/13,replica/14]
adding new retention lease [primary/5] to current retention leases [primary/5,replica/16,replica/17]
adding new retention lease [replica/18] to current retention leases [primary/5,replica/16,replica/17]
adding new retention lease [primary/6] to current retention leases [primary/6,replica/19,replica/20]
adding new retention lease [replica/21] to current retention leases [primary/6,replica/19,replica/20]
adding new retention lease [primary/7] to current retention leases [primary/7,replica/22,replica/23]
removing retention lease [primary] from current retention leases [primary,replica]
removing retention lease [replica] from current retention leases [primary,replica]
removing retention lease [snapshot] from current retention leases [primary,snapshot]
removing retention lease [peer_recovery] from current retention leases [primary,peer_recovery]
removing retention lease [primary] from current retention leases [primary,snapshot,peer_recovery]
removing retention lease [replica] from current retention leases [primary,replica,snapshot,peer_recovery]
removing retention lease [snapshot] from current retention leases [primary,replica,snapshot,peer_recovery]
removing retention lease [peer_recovery] from current retention leases [primary,replica,snapshot,peer_recovery]
removing retention lease [test] from current retention leases [test]
removing retention lease [test1] from current retention leases [test1,test2,test3]
removing retention lease [test2] from current retention leases [test1,test2,test3]
removing retention lease [test3] from current retention leases [test1,test2,test3]
removing retention lease [foo] from current retention leases [foo,bar,baz]
removing retention lease [bar] from current retention leases [foo,bar,baz]
removing retention lease [baz] from current retention leases [foo,bar,baz]
--> got seqID: 1001
--> got seqID: 2002
--> got seqID: 3003
--> got seqID: 4004
--> got seqID: 5005
--> got seqID: 6006
--> got seqID: 7007
--> got seqID: 8008
--> got seqID: 9009
--> got seqID: 1010
--> got seqID: 1111
--> got seqID: 1212
--> got seqID: 1313
--> got seqID: 1414
--> got seqID: 1515
skipping persisting retention leases [0], already persisted
skipping persisting retention leases [1], already persisted
skipping persisting retention leases [2], already persisted
skipping persisting retention leases [3], already persisted
skipping persisting retention leases [4], already persisted
skipping persisting retention leases [5], already persisted
skipping persisting retention leases [6], already persisted
skipping persisting retention leases [7], already persisted
skipping persisting retention leases [8], already persisted
skipping persisting retention leases [9], already persisted
skipping persisting retention leases [10], already persisted
skipping persisting retention leases [11], already persisted
skipping persisting retention leases [12], already persisted
skipping persisting retention leases [13], already persisted
skipping persisting retention leases [14], already persisted
top: 10 bottom: 20
top: 15 bottom: 25
top: 12 bottom: 18
top: 8 bottom: 16
top: 9 bottom: 21
top: 11 bottom: 19
top: 13 bottom: 23
top: 14 bottom: 24
top: 7 bottom: 17
top: 6 bottom: 22
top: 16 bottom: 26
top: 5 bottom: 15
top: 4 bottom: 14
top: 3 bottom: 13
top: 2 bottom: 12
updated global checkpoint from [0] to [1] due to [flush]
updated global checkpoint from [2] to [3] due to [sync]
updated global checkpoint from [4] to [5] due to [merge]
updated global checkpoint from [6] to [7] due to [recovery]
updated global checkpoint from [8] to [9] due to [rollover]
updated global checkpoint from [10] to [11] due to [retention lease]
updated global checkpoint from [12] to [13] due to [translog deletion]
updated global checkpoint from [14] to [15] due to [snapshot restore]
updated global checkpoint from [16] to [17] due to [force merge]
updated global checkpoint from [18] to [19] due to [replication]
updated global checkpoint from [20] to [21] due to [shard relocation]
updated global checkpoint from [22] to [23] due to [split]
updated global checkpoint from [24] to [25] due to [clone]
updated global checkpoint from [26] to [27] due to [close]
updated global checkpoint from [28] to [29] due to [delete]
updated local knowledge for [1] on the primary of the global checkpoint from [0] to [10]
updated local knowledge for [2] on the primary of the global checkpoint from [5] to [15]
updated local knowledge for [3] on the primary of the global checkpoint from [10] to [20]
updated local knowledge for [4] on the primary of the global checkpoint from [15] to [25]
updated local knowledge for [5] on the primary of the global checkpoint from [20] to [30]
updated local knowledge for [6] on the primary of the global checkpoint from [25] to [35]
updated local knowledge for [7] on the primary of the global checkpoint from [30] to [40]
updated local knowledge for [8] on the primary of the global checkpoint from [35] to [45]
updated local knowledge for [9] on the primary of the global checkpoint from [40] to [50]
updated local knowledge for [10] on the primary of the global checkpoint from [45] to [55]
updated local knowledge for [11] on the primary of the global checkpoint from [50] to [60]
updated local knowledge for [12] on the primary of the global checkpoint from [55] to [65]
updated local knowledge for [13] on the primary of the global checkpoint from [60] to [70]
updated local knowledge for [14] on the primary of the global checkpoint from [65] to [75]
updated local knowledge for [15] on the primary of the global checkpoint from [70] to [80]
Ignoring the checkpoint update for allocation ID 5a3f9c as its not being tracked by primary
Ignoring the checkpoint update for allocation ID 7b2d6e as its not being tracked by primary
Ignoring the checkpoint update for allocation ID 9c1e4a as its not being tracked by primary
Ignoring the checkpoint update for allocation ID 3d4f6b as its not being tracked by primary
Ignoring the checkpoint update for allocation ID 6e5a8c as its not being tracked by primary
Ignoring the checkpoint update for allocation ID 8f7c9d as its not being tracked by primary
Ignoring the checkpoint update for allocation ID 4a6b8e as its not being tracked by primary
Ignoring the checkpoint update for allocation ID 2b3d5f as its not being tracked by primary
Ignoring the checkpoint update for allocation ID 1c2e4g as its not being tracked by primary
Ignoring the checkpoint update for allocation ID 0d1f3h as its not being tracked by primary
Ignoring the checkpoint update for allocation ID a0b1c2 as its not being tracked by primary
Ignoring the checkpoint update for allocation ID c2d3e4 as its not being tracked by primary
Ignoring the checkpoint update for allocation ID e4f5g6 as its not being tracked by primary
Ignoring the checkpoint update for allocation ID g6h7i8 as its not being tracked by primary
Ignoring the checkpoint update for allocation ID i8j9k0 as its not being tracked by primary
--> stopping data node dataNode1
--> stopping data node dataNode2
--> stopping data node dataNode3
--> stopping data node dataNode4
--> stopping data node dataNode5
--> stopping data node dataNode6
--> stopping data node dataNode7
--> stopping data node dataNode8
--> stopping data node dataNode9
--> stopping data node dataNode10
--> stopping data node dataNode11
--> stopping data node dataNode12
--> stopping data node dataNode13
--> stopping data node dataNode14
--> stopping data node dataNode15
--> stopping cluster-manager node 1
--> stopping cluster-manager node 2
--> stopping cluster-manager node 3
--> stopping cluster-manager node 4
--> stopping cluster-manager node 5
--> stopping cluster-manager node 6
--> stopping cluster-manager node 7
--> stopping cluster-manager node 8
--> stopping cluster-manager node 9
--> stopping cluster-manager node 10
--> stopping cluster-manager node 11
--> stopping cluster-manager node 12
--> stopping cluster-manager node 13
--> stopping cluster-manager node 14
--> stopping cluster-manager node 15
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-0]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-1]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-2]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-3]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-4]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-5]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-6]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-7]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-8]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-9]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-10]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-11]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-12]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-13]
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [lease-14]
skipped updating local checkpoint of [123] from [456] to [789], current checkpoint is higher
skipped updating local checkpoint of [234] from [567] to [890], current checkpoint is higher
skipped updating local checkpoint of [345] from [678] to [901], current checkpoint is higher
skipped updating local checkpoint of [456] from [789] to [123], current checkpoint is higher
skipped updating local checkpoint of [567] from [890] to [234], current checkpoint is higher
skipped updating local checkpoint of [678] from [901] to [345], current checkpoint is higher
skipped updating local checkpoint of [789] from [123] to [456], current checkpoint is higher
skipped updating local checkpoint of [890] from [234] to [567], current checkpoint is higher
skipped updating local checkpoint of [901] from [345] to [678], current checkpoint is higher
skipped updating local checkpoint of [012] from [456] to [789], current checkpoint is higher
skipped updating local checkpoint of [111] from [222] to [333], current checkpoint is higher
skipped updating local checkpoint of [222] from [333] to [444], current checkpoint is higher
skipped updating local checkpoint of [333] from [444] to [555], current checkpoint is higher
skipped updating local checkpoint of [444] from [555] to [666], current checkpoint is higher
skipped updating local checkpoint of [555] from [666] to [777], current checkpoint is higher
number of shards, total: [12], primaries: [4]
number of shards, total: [8], primaries: [2]
number of shards, total: [16], primaries: [6]
number of shards, total: [10], primaries: [3]
number of shards, total: [14], primaries: [5]
number of shards, total: [9], primaries: [3]
number of shards, total: [11], primaries: [4]
number of shards, total: [7], primaries: [2]
number of shards, total: [15], primaries: [6]
number of shards, total: [13], primaries: [5]
number of shards, total: [6], primaries: [2]
number of shards, total: [18], primaries: [7]
number of shards, total: [17], primaries: [7]
number of shards, total: [19], primaries: [8]
number of shards, total: [20], primaries: [8]
updated global checkpoint to [123456789]
updated global checkpoint to [987654321]
updated global checkpoint to [456789123]
updated global checkpoint to [789123456]
updated global checkpoint to [321456789]
updated global checkpoint to [654321987]
updated global checkpoint to [147258369]
updated global checkpoint to [963852741]
updated global checkpoint to [258369147]
updated global checkpoint to [741963852]
updated global checkpoint to [159357246]
updated global checkpoint to [246753951]
updated global checkpoint to [357159468]
updated global checkpoint to [468951357]
updated global checkpoint to [951357468]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[test][0], node[0], [P], s[STARTED], a[id=0]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[index][1], node[1], [R], s[INITIALIZING], a[id=1]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[logs][2], node[2], [P], s[RELOCATING], a[id=2]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[data][3], node[3], [R], s[UNASSIGNED], a[id=3]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[docs][4], node[4], [P], s[STARTED], a[id=4]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[users][5], node[5], [R], s[INITIALIZING], a[id=5]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[posts][6], node[6], [P], s[RELOCATING], a[id=6]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[comments][7], node[7], [R], s[UNASSIGNED], a[id=7]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[likes][8], node[8], [P], s[STARTED], a[id=8]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[shares][9], node[9], [R], s[INITIALIZING], a[id=9]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[media][10], node[10], [P], s[RELOCATING], a[id=10]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[messages][11], node[11], [R], s[UNASSIGNED], a[id=11]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[notifications][12], node[12], [P], s[STARTED], a[id=12]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[settings][13], node[13], [R], s[INITIALIZING], a[id=13]]]
createMissingPeerRecoveryRetentionLeases: adding missing lease for [shardId[[profile][14], node[14], [P], s[RELOCATING], a[id=14]]]
main event node 1
main event node 2
main event node 3
main event node 4
main event node 5
main event node 6
main event node 7
main event node 8
main event node 9
main event node 10
main event node 11
main event node 12
main event node 13
main event node 14
main event node 15
--> indexing 100 docs into products
--> indexing 500 docs into customers
--> indexing 250 docs into orders
--> indexing 50 docs into reviews
--> indexing 300 docs into inventory
--> indexing 75 docs into categories
--> indexing 400 docs into sales
--> indexing 150 docs into employees
--> indexing 200 docs into suppliers
--> indexing 125 docs into coupons
--> indexing 350 docs into transactions
--> indexing 175 docs into promotions
--> indexing 225 docs into feedback
--> indexing 275 docs into analytics
--> indexing 425 docs into reports
--> adding retention lease with id 7a8b9c to [index-1][0]
--> adding retention lease with id 3f4g5h to [index-2][1]
--> adding retention lease with id 9k0l1m to [index-3][2]
--> adding retention lease with id 6n7o8p to [index-4][3]
--> adding retention lease with id 4q5r6s to [index-5][4]
--> adding retention lease with id 2t3u4v to [index-6][5]
--> adding retention lease with id 0w1x2y to [index-7][6]
--> adding retention lease with id 8z9a0b to [index-8][7]
--> adding retention lease with id 5c6d7e to [index-9][8]
--> adding retention lease with id 3f4g5h to [index-10][9]
--> adding retention lease with id 1i2j3k to [index-11][10]
--> adding retention lease with id 9l0m1n to [index-12][11]
--> adding retention lease with id 7o8p9q to [index-13][12]
--> adding retention lease with id 5r6s7t to [index-14][13]
--> adding retention lease with id 3u4v5w to [index-15][14]
[s] events 3
[s] events 5
[s] events 7
[s] events 9
[s] events 11
[s] events 13
[s] events 15
[s] events 17
[s] events 19
[s] events 21
[s] events 23
[s] events 25
[s] events 27
[s] events 29
[s] events 31
[s][*] events 0
[s][*] events 1
[s][*] events 2
[s][*] events 3
[s][*] events 4
[s][*] events 5
[s][*] events 6
[s][*] events 7
[s][*] events 8
[s][*] events 9
[s][*] events 10
[s][*] events 11
[s][*] events 12
[s][*] events 13
[s][*] events 14
nodes with the index [0]
nodes with the index [1]
nodes with the index [2]
nodes with the index [3]
nodes with the index [4]
nodes with the index [5]
nodes with the index [6]
nodes with the index [7]
nodes with the index [8]
nodes with the index [9]
nodes with the index [10]
nodes with the index [11]
nodes with the index [12]
nodes with the index [13]
nodes with the index [14]
error notifying global checkpoint listener of timeout: java.lang.InterruptedException
error notifying global checkpoint listener of timeout: java.io.IOException
error notifying global checkpoint listener of timeout: java.util.concurrent.TimeoutException
error notifying global checkpoint listener of timeout: java.lang.NullPointerException
error notifying global checkpoint listener of timeout: org.elasticsearch.ElasticsearchException
error notifying global checkpoint listener of timeout: org.elasticsearch.cluster.coordination.FailedToCommitClusterStateException
error notifying global checkpoint listener of timeout: org.elasticsearch.action.UnavailableShardsException
error notifying global checkpoint listener of timeout: org.elasticsearch.index.engine.EngineClosedException
error notifying global checkpoint listener of timeout: org.elasticsearch.index.shard.IndexShardClosedException
error notifying global checkpoint listener of timeout: org.elasticsearch.index.shard.ShardNotFoundException
error notifying global checkpoint listener of timeout: org.elasticsearch.index.translog.TranslogCorruptedException
error notifying global checkpoint listener of timeout: org.elasticsearch.indices.recovery.RecoveryFailedException
error notifying global checkpoint listener of timeout: org.elasticsearch.rest.RestStatusException
error notifying global checkpoint listener of timeout: org.elasticsearch.transport.NodeDisconnectedException
error notifying global checkpoint listener of timeout: org.elasticsearch.transport.ReceiveTimeoutTransportException
Blocking [backup] starting
Blocking [update] starting
Blocking [sync] starting
Blocking [scan] starting
Blocking [delete] starting
Blocking [restore] starting
Blocking [copy] starting
Blocking [move] starting
Blocking [encrypt] starting
Blocking [decrypt] starting
Blocking [compress] starting
Blocking [decompress] starting
Blocking [upload] starting
Blocking [download] starting
Blocking [install] starting
[t1] completed [seqNo: 100]
[t2] completed [seqNo: 101]
[t3] completed [seqNo: 102]
[t4] completed [seqNo: 103]
[t5] completed [seqNo: 104]
[t6] completed [seqNo: 105]
[t7] completed [seqNo: 106]
[t8] completed [seqNo: 107]
[t9] completed [seqNo: 108]
[t10] completed [seqNo: 109]
[t11] completed [seqNo: 110]
[t12] completed [seqNo: 111]
[t13] completed [seqNo: 112]
[t14] completed [seqNo: 113]
[t15] completed [seqNo: 114]
--> restore index products from snapshot
--> restore index customers from snapshot
--> restore index orders from snapshot
--> restore index reviews from snapshot
--> restore index categories from snapshot
--> restore index users from snapshot
--> restore index posts from snapshot
--> restore index comments from snapshot
--> restore index books from snapshot
--> restore index movies from snapshot
--> restore index songs from snapshot
--> restore index articles from snapshot
--> restore index events from snapshot
--> restore index contacts from snapshot
--> restore index invoices from snapshot
active: true, initializing: false
active: false, initializing: true
active: true, initializing: true
active: false, initializing: false
active: 1, initializing: 0
active: 0, initializing: 1
active: 1, initializing: 1
active: 0, initializing: 0
active: yes, initializing: no
active: no, initializing: yes
active: yes, initializing: yes
active: no, initializing: no
active: on, initializing: off
active: off, initializing: on
active: on, initializing: on
- [a1], local checkpoint [0], [source]
- [a2], local checkpoint [1], [sink]
- [a3], local checkpoint [2], [transform]
- [a4], local checkpoint [3], [source]
- [a5], local checkpoint [4], [sink]
- [a6], local checkpoint [5], [transform]
- [a7], local checkpoint [6], [source]
- [a8], local checkpoint [7], [sink]
- [a9], local checkpoint [8], [transform]
- [a10], local checkpoint [9], [source]
- [a11], local checkpoint [10], [sink]
- [a12], local checkpoint [11], [transform]
- [a13], local checkpoint [12], [source]
- [a14], local checkpoint [13], [sink]
- [a15], local checkpoint [14], [transform]
primary-replica resync completed with 456 operations
primary-replica resync completed with 789 operations
primary-replica resync completed with 123 operations
primary-replica resync completed with 987 operations
primary-replica resync completed with 654 operations
primary-replica resync completed with 321 operations
primary-replica resync completed with 432 operations
primary-replica resync completed with 876 operations
primary-replica resync completed with 543 operations
primary-replica resync completed with 210 operations
primary-replica resync completed with 345 operations
primary-replica resync completed with 678 operations
primary-replica resync completed with 901 operations
primary-replica resync completed with 234 operations
primary-replica resync completed with 567 operations
Total ops: 4567, global checkpoint: 123
Total ops: 2345, global checkpoint: 456
Total ops: 6789, global checkpoint: 789
Total ops: 8910, global checkpoint: 1011
Total ops: 5432, global checkpoint: 1213
Total ops: 1098, global checkpoint: 1415
Total ops: 7654, global checkpoint: 1617
Total ops: 3210, global checkpoint: 1819
Total ops: 9876, global checkpoint: 2021
Total ops: 4321, global checkpoint: 2223
Total ops: 8765, global checkpoint: 2425
Total ops: 2109, global checkpoint: 2627
Total ops: 6543, global checkpoint: 2829
Total ops: 0987, global checkpoint: 3031
Total ops: 3456, global checkpoint: 3233
--> creating index-1 and ingest data
--> creating index-2 and ingest data
--> creating index-3 and ingest data
--> creating index-4 and ingest data
--> creating index-5 and ingest data
--> creating index-6 and ingest data
--> creating index-7 and ingest data
--> creating index-8 and ingest data
--> creating index-9 and ingest data
--> creating index-10 and ingest data
--> creating index-11 and ingest data
--> creating index-12 and ingest data
--> creating index-13 and ingest data
--> creating index-14 and ingest data
--> creating index-15 and ingest data
--> creating snapshot: backup-2021-10-23
--> creating snapshot: user-profile-123
--> creating snapshot: system-state-001
--> creating snapshot: project-final
--> creating snapshot: test-case-456
--> creating snapshot: restore-point-789
--> creating snapshot: database-dump
--> creating snapshot: game-save-007
--> creating snapshot: photo-album-2020
--> creating snapshot: video-edit-101
--> creating snapshot: document-revision-3
--> creating snapshot: music-library
--> creating snapshot: email-archive
--> creating snapshot: settings-config
--> creating snapshot: app-data-xyz
--> primary store after force merge [__segments_1, _0.cfe, _0.cfs, _0.si, write.lock]
--> primary store after force merge [__segments_2, _1.cfe, _1.cfs, _1.si, write.lock]
--> primary store after force merge [__segments_3, _2.cfe, _2.cfs, _2.si, write.lock]
--> primary store after force merge [__segments_4, _3.cfe, _3.cfs, _3.si, write.lock]
--> primary store after force merge [__segments_5, _4.cfe, _4.cfs, _4.si, write.lock]
--> primary store after force merge [__segments_6, _5.cfe, _5.cfs, _5.si, write.lock]
--> primary store after force merge [__segments_7, _6.cfe, _6.cfs, _6.si, write.lock]
--> primary store after force merge [__segments_8, _7.cfe, _7.cfs, _7.si, write.lock]
--> primary store after force merge [__segments_9, _8.cfe, _8.cfs, _8.si, write.lock]
--> primary store after force merge [__segments_10, _9.cfe, _9.cfs, _9.si, write.lock]
--> primary store after force merge [__segments_11, _10.cfe, _10.cfs, _10.si, write.lock]
--> primary store after force merge [__segments_12, _11.cfe, _11.cfs, _11.si, write.lock]
--> primary store after force merge [__segments_13, _12.cfe, _12.cfs, _12.si, write.lock]
--> primary store after force merge [__segments_14, _13.cfe, _13.cfs, _13.si, write.lock]
--> primary store after force merge [__segments_15,_14.cfe,_14.cfs,_14.si,_write.lock]
merge node 1
merge node 2
merge node 3
merge node 4
merge node 5
merge node 6
merge node 7
merge node 8
merge node 9
merge node 10
merge node 11
merge node 12
merge node 13
merge node 14
merge node 15
upgraded segments for shard1 from version 2.3.4 to version 2.4.0
upgraded segments for shard5 from version 2.3.5 to version 2.4.1
upgraded segments for shard3 from version 2.3.6 to version 2.4.2
upgraded segments for shard7 from version 2.3.7 to version 2.4.3
upgraded segments for shard9 from version 2.3.8 to version 2.4.4
upgraded segments for shard11 from version 2.3.9 to version 2.4.5
upgraded segments for shard13 from version 2.3.10 to version 2.4.6
upgraded segments for shard15 from version 2.3.11 to version 2.4.7
upgraded segments for shard17 from version 2.3.12 to version 2.4.8
upgraded segments for shard19 from version 2.3.13 to version 2.4.9
upgraded segments for shard21 from version 2.3.14 to version 2.5.0
upgraded segments for shard23 from version 2.3.15 to version 2.5.1
upgraded segments for shard25 from version 2.3.16 to version 2.5.2
upgraded segments for shard27 from version 2.3.17 to version 2.5.3
upgraded segments for shard29 from version 2.3.18 to version 2.5.
--> primary store after final flush [".lock", "segments_1", "_0.cfe", "_0.cfs", "_0.si"]
--> primary store after final flush [".lock", "segments_2", "_1.cfe", "_1.cfs", "_1.si"]
--> primary store after final flush [".lock", "segments_3", "_2.cfe", "_2.cfs", "_2.si"]
--> primary store after final flush [".lock", "segments_4", "_3.cfe", "_3.cfs", "_3.si"]
--> primary store after final flush [".lock", "segments_5", "_4.cfe", "_4.cfs", "_4.si"]
--> primary store after final flush [".lock", "segments_6", "_5.cfe", "_5.cfs", "_5.si"]
--> primary store after final flush [".lock", "segments_7", "_6.cfe", "_6.cfs", "_6.si"]
--> primary store after final flush [".lock", "segments_8", "_7.cfe", "_7.cfs", "_7.si"]
--> primary store after final flush [".lock", "segments_9", "_8.cfe", "_8.cfs", "_8.si"]
--> primary store after final flush [".lock", "segments_a", "_9.cfe", "_9.cfs", "_9.si"]
--> primary store after final flush [".lock", "segments_b", "_a.cfe", "_a.cfs", "_a.si"]
--> primary store after final flush [".lock", "segments_c", "_b.cfe", "_b.cfs", "_b.si"]
--> primary store after final flush [".lock", "segments_d", "_c.cfe", "_c.cfs", "_c.si"]
--> primary store after final flush [".lock", "segments_e", "_d.cfe", "_d.cfs", "_d.si"]
--> primary store after final flush [".lock","segments_f","_e.cfe","_e.cfs","_e.si"]
use routing true use mixed routing false use nested true
use routing false use mixed routing true use nested false
use routing true use mixed routing true use nested false
use routing false use mixed routing false use nested true
use routing true use mixed routing false use nested false
use routing false use mixed routing true use nested true
use routing false use mixed routing false use nested false
use routing true use mixed routing true use nested true
use routing true use mixed routing null use nested null
use routing null use mixed routing null use nested null
use routing null use mixed routing true use nested false
use routing null use mixed routing false use nested true
use routing false use mixed routing null use nested null
use routing null use mixed routing true use nested true
use routing true use mixed routing null use nested false
skip local recovery as failed to find the safe commit. Error: index corrupted
skip local recovery as failed to find the safe commit. Error: no segments file found
skip local recovery as failed to find the safe commit. Error: file not found exception
skip local recovery as failed to find the safe commit. Error: checksum mismatch
skip local recovery as failed to find the safe commit. Error: out of memory error
skip local recovery as failed to find the safe commit. Error: access denied exception
skip local recovery as failed to find the safe commit. Error: invalid shard state
skip local recovery as failed to find the safe commit. Error: shard already exists exception
skip local recovery as failed to find the safe commit. Error: index out of bounds exception
skip local recovery as failed to find the safe commit. Error: illegal argument exception
skip local recovery as failed to find the safe commit. Error: null pointer exception
skip local recovery as failed to find the safe commit. Error: concurrent modification exception
skip local recovery as failed to find the safe commit. Error: io exception
skip local recovery as failed to find the safe commit. Error: timeout exception
skip local recovery as failed to find the safe commit. Error: interrupted exception
--> failing shard [1] on node [node-1]
--> failing shard [2] on node [node-2]
--> failing shard [3] on node [node-3]
--> failing shard [4] on node [node-4]
--> failing shard [5] on node [node-5]
--> failing shard [6] on node [node-6]
--> failing shard [7] on node [node-7]
--> failing shard [8] on node [node-8]
--> failing shard [9] on node [node-9]
--> failing shard [10] on node [node-10]
--> failing shard [11] on node [node-11]
--> failing shard [12] on node [node-12]
--> failing shard [13] on node [node-13]
--> failing shard [14] on node [node-14]
--> failing shard [15] on node [node-15]
--> Restarting replica 0
--> Restarting replica 1
--> Restarting replica 2
--> Restarting replica 3
--> Restarting replica 4
--> Restarting replica 5
--> Restarting replica 6
--> Restarting replica 7
--> Restarting replica 8
--> Restarting replica 9
--> Restarting replica 10
--> Restarting replica 11
--> Restarting replica 12
--> Restarting replica 13
--> Restarting replica 14
--> failed shard [2] on node [node-1]
--> failed shard [5] on node [node-3]
--> failed shard [7] on node [node-2]
--> failed shard [4] on node [node-4]
--> failed shard [1] on node [node-5]
--> failed shard [3] on node [node-6]
--> failed shard [6] on node [node-7]
--> failed shard [8] on node [node-8]
--> failed shard [9] on node [node-9]
--> failed shard [10] on node [node-10]
--> failed shard [11] on node [node-11]
--> failed shard [12] on node [node-12]
--> failed shard [13] on node [node-13]
--> failed shard [14] on node [node-14]
--> failed shard [15] on node [node-15]
skip local recovery as the safe commit is up to date; safe commit [0] global checkpoint [0]
skip local recovery as the safe commit is up to date; safe commit [1] global checkpoint [1]
skip local recovery as the safe commit is up to date; safe commit [2] global checkpoint [2]
skip local recovery as the safe commit is up to date; safe commit [3] global checkpoint [3]
skip local recovery as the safe commit is up to date; safe commit [4] global checkpoint [4]
skip local recovery as the safe commit is up to date; safe commit [5] global checkpoint [5]
skip local recovery as the safe commit is up to date; safe commit [6] global checkpoint [6]
skip local recovery as the safe commit is up to date; safe commit [7] global checkpoint [7]
skip local recovery as the safe commit is up to date; safe commit [8] global checkpoint [8]
skip local recovery as the safe commit is up to date; safe commit [9] global checkpoint [9]
skip local recovery as the safe commit is up to date; safe commit [10] global checkpoint [10]
skip local recovery as the safe commit is up to date; safe commit [11] global checkpoint [11]
skip local recovery as the safe commit is up to date; safe commit [12] global checkpoint [12]
skip local recovery as the safe commit is up to date; safe commit [13] global checkpoint [13]
skip local recovery as the safe commit is up to date; safe commit [14] global checkpoint [14]
--> Recover newReplica 0
--> Recover newReplica 1
--> Recover newReplica 2
--> Recover newReplica 3
--> Recover newReplica 4
--> Recover newReplica 5
--> Recover newReplica 6
--> Recover newReplica 7
--> Recover newReplica 8
--> Recover newReplica 9
--> Recover newReplica 10
--> Recover newReplica 11
--> Recover newReplica 12
--> Recover newReplica 13
--> Recover newReplica 14
--> fail to index id=1001
--> fail to index id=3456
--> fail to index id=7890
--> fail to index id=1234
--> fail to index id=5678
--> fail to index id=9012
--> fail to index id=2345
--> fail to index id=6789
--> fail to index id=0123
--> fail to index id=4567
--> fail to index id=8901
--> fail to index id=3210
--> fail to index id=6543
--> fail to index id=9876
--> fail to index id=4321
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=1, generation=2, userData={translog_uuid=3a9f6b4c-0f9c-4f5a-8d7e-3e8b0d6c0a9f, translog_generation=1, max_seq_no=0, min_seq_no=0, global_checkpoint=-1}}] global checkpoint [-1]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=3, generation=5, userData={translog_uuid=7c8f2d3b-4e2c-4d9b-b6d4-1f7b7d8c7a6d, translog_generation=4, max_seq_no=12, min_seq_no=10, global_checkpoint=11}}] global checkpoint [11]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=2, generation=7, userData={translog_uuid=b9f4a6e9-8a7c-42c6-a5f9-2f8d7e9b9b7f, translog_generation=6, max_seq_no=17, min_seq_no=13, global_checkpoint=16}}] global checkpoint [16]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=4, generation=10, userData={translog_uuid=f2c7d8e3-9b6c-48c7-b8f9-3e8d7e9b9b7f, translog_generation=9, max_seq_no=25, min_seq_no=18, global_checkpoint=24}}] global checkpoint [24]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=5, generation=13, userData={translog_uuid=c3d8e2f4-8b7c-49c6-a6f9-4f8d7e9b9b7f, translog_generation=12, max_seq_no=34, min_seq_no=26, global_checkpoint=33}}] global checkpoint [33]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=6, generation=16, userData={translog_uuid=d4e9f3c5-9c8d-4ad7-b7fa-5f9d7e9b9b7f, translog_generation=15, max_seq_no=45, min_seq_no=35, global_checkpoint=44}}] global checkpoint [44]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=7, generation=19, userData={translog_uuid=e5faa4d6-ad9e-4be8-c8fb-6fad7e9b9b7f, translog_generation=18, max_seq_no=58, min_seq_no=46, global_checkpoint=57}}] global checkpoint [57]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=8, generation=22, userData={translog_uuid=f6abb5e7-beaf-5cf9-d9fc-7fae7e9b9b7f, translog_generation=21, max_seq_no=73, min_seq_no=59, global_checkpoint=72}}] global checkpoint [72]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=9, generation=25, userData={translog_uuid=g7bcc6f8-cfb0-6dg0-eafd-8fbe7e9b9b7f, translog_generation=24, max_seq_no=90, min_seq_no=74, global_checkpoint=89}}] global checkpoint [89]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=10, generation=28, userData={translog_uuid=h8cdd7g9-dgc1-7eh1-fage-9gcf7e9b9b7f, translog_generation=27, max_seq_no=109, min_seq_no=91, global_checkpoint=108}}] global checkpoint [108]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=11, generation=31, userData={translog_uuid=i9dee8h0-egd2-8fi2-gahf-ahdg7e9b9b7f, translog_generation=30, max_seq_no=130, min_seq_no=110, global_checkpoint=129}}] global checkpoint [129]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=12, generation=34, userData={translog_uuid=j0eff9i1-fhe3-9gj3-haig-bieh7e9b9b7f, translog_generation=33, max_seq_no=153, min_seq_no=131, global_checkpoint=152}}] global checkpoint [152]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=13, generation=37, userData={translog_uuid=k1fgg0j2-gif4-0hk4-iajh-cifj7e9b9b7f, translog_generation=36, max_seq_no=178, min_seq_no=154, global_checkpoint=177}}] global checkpoint [177]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=14, generation=40, userData={translog_uuid=l2ghh1k3-hjg5-1il5-jaki-djgk7e9b9b7f, translog_generation=39, max_seq_no=205, min_seq_no=179, global_checkpoint=204}}] global checkpoint [204]
skip local recovery as the index was closed or not allowed to write; safe commit [CommitPoint{segmentCount=15, generation=43, userData={translog_uuid=m3hii2l4-ikg6-2jm6-kalj-ekgl7e9b9b7f, translog_generation=42, max_seq_no=234, min_seq_no=206, global_checkpoint=233}}] global checkpoint [233]
--> truncating file1.txt, prev: 1024 bytes, now: 512 bytes
--> truncating file2.jpg, prev: 2.3 MB, now: 1.5 MB
--> truncating file3.pdf, prev: 345 KB, now: 200 KB
--> truncating file4.docx, prev: 1.2 MB, now: 800 KB
--> truncating file5.mp3, prev: 4.5 MB, now: 3 MB
--> truncating file6.zip, prev: 10 MB, now: 5 MB
--> truncating file7.csv, prev: 512 KB, now: 256 KB
--> truncating file8.png, prev: 1.8 MB, now: 1.2 MB
--> truncating file9.mp4, prev: 20 MB, now: 15 MB
--> truncating file10.html, prev: 256 bytes, now: 128 bytes
--> truncating file11.py, prev: 512 bytes, now: 256 bytes
--> truncating file12.exe, prev: 5 MB, now: 3 MB
--> truncating file13.xls, prev: 768 KB, now: 512 KB
--> truncating file14.pptx, prev: 2.5 MB, now: 2 MB
--> truncating file15.log, prev: 1 MB, now: 500 KB
check index failed during fetch seqNo: java.lang.NullPointerException
check index failed during fetch seqNo: java.io.IOException: Stream closed
check index failed during fetch seqNo: java.lang.IndexOutOfBoundsException: Index 5 out of bounds for length 4
check index failed during fetch seqNo: java.sql.SQLException: Column 'seqNo' not found
check index failed during fetch seqNo: java.lang.IllegalArgumentException: Invalid sequence number -1
check index failed during fetch seqNo: java.util.concurrent.TimeoutException: Timeout waiting for seqNo
check index failed during fetch seqNo: java.lang.NumberFormatException: For input string "abc"
check index failed during fetch seqNo: java.net.SocketException: Connection reset
check index failed during fetch seqNo: java.lang.OutOfMemoryError: Java heap space
check index failed during fetch seqNo: java.lang.ClassCastException: class java.lang.String cannot be cast to class java.lang.Integer
check index failed during fetch seqNo: org.apache.lucene.index.CorruptIndexException: checksum failed (hardware problem?) : expected=1f3b967 actual=2d4c869 (resource=BufferedChecksumIndexInput(MMapIndexInput(path="/var/data/index/segments_1")))
check index failed during fetch seqNo: org.elasticsearch.ElasticsearchException: Failed to execute phase [query], all shards failed
check index failed during fetch seqNo: org.springframework.dao.DataIntegrityViolationException: could not execute statement; SQL [n/a]; constraint [seq_no_pk]; nested exception is org.hibernate.exception.ConstraintViolationException
check index failed during fetch seqNo: com.mongodb.MongoWriteException: E11000 duplicate key error collection: test.seqNos index: _id_ dup key
check index failed during fetch seqNo: redis.clients.jedis.exceptions.JedisDataException: ERR value is not an integer or out of range
unexpected error while closing view, after failure: java.lang.NullPointerException
unexpected error while closing view, after failure: java.io.IOException
unexpected error while closing view, after failure: java.lang.IllegalStateException
unexpected error while closing view, after failure: java.lang.ClassNotFoundException
unexpected error while closing view, after failure: java.lang.OutOfMemoryError
unexpected error while closing view, after failure: java.lang.StackOverflowError
unexpected error while closing view, after failure: java.lang.NoSuchMethodError
unexpected error while closing view, after failure: java.lang.SecurityException
unexpected error while closing view, after failure: java.lang.UnsupportedOperationException
unexpected error while closing view, after failure: java.lang.ArithmeticException
unexpected error while closing view, after failure: java.lang.NumberFormatException
unexpected error while closing view, after failure: java.lang.ArrayIndexOutOfBoundsException
unexpected error while closing view, after failure: java.lang.StringIndexOutOfBoundsException
unexpected error while closing view, after failure: java.util.ConcurrentModificationException
unexpected error while closing view, after failure: java.util.NoSuchElementException
--> [Thread-1] done. wrote [1000] ops.
--> [Thread-2] done. wrote [950] ops.
--> [Thread-3] done. wrote [1025] ops.
--> [Thread-4] done. wrote [975] ops.
--> [Thread-5] done. wrote [1050] ops.
--> [Thread-6] done. wrote [900] ops.
--> [Thread-7] done. wrote [1100] ops.
--> [Thread-8] done. wrote [925] ops.
--> [Thread-9] done. wrote [1075] ops.
--> [Thread-10] done. wrote [950] ops.
--> [Thread-11] done. wrote [1125] ops.
--> [Thread-12] done. wrote [875] ops.
--> [Thread-13] done. wrote [1150] ops.
--> [Thread-14] done. wrote [900] ops.
--> [Thread-15] done. wrote [1075] ops.
--> [Thread-1] min gen after acquiring lock [3]
--> [Thread-5] min gen after acquiring lock [2]
--> [Thread-3] min gen after acquiring lock [4]
--> [Thread-2] min gen after acquiring lock [1]
--> [Thread-4] min gen after acquiring lock [5]
--> [Thread-6] min gen after acquiring lock [6]
--> [Thread-8] min gen after acquiring lock [7]
--> [Thread-7] min gen after acquiring lock [8]
--> [Thread-9] min gen after acquiring lock [9]
--> [Thread-10] min gen after acquiring lock [10]
--> [Thread-11] min gen after acquiring lock [11]
--> [Thread-12] min gen after acquiring lock [12]
--> [Thread-13] min gen after acquiring lock [13]
--> [Thread-14] min gen after acquiring lock [14]
--> [Thread-15] min gen after acquiring lock [15]
--> [Thread-1] done. tested [10] snapshots
--> [Thread-2] done. tested [12] snapshots
--> [Thread-3] done. tested [11] snapshots
--> [Thread-4] done. tested [9] snapshots
--> [Thread-5] done. tested [13] snapshots
--> [Thread-6] done. tested [8] snapshots
--> [Thread-7] done. tested [14] snapshots
--> [Thread-8] done. tested [7] snapshots
--> [Thread-9] done. tested [15] snapshots
--> [Thread-10] done. tested [6] snapshots
--> [Thread-11] done. tested [16] snapshots
--> [Thread-12] done. tested [5] snapshots
--> [Thread-13] done. tested [17] snapshots
--> [Thread-14] done. tested [4] snapshots
--> [Thread-15] done. tested [18] snapshots
turn off the translog retention for the replication group [0] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [1] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [2] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [3] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [4] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [5] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [6] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [7] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [8] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [9] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [10] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [11] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [12] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [13] as it starts using retention leases exclusively in peer recoveries
turn off the translog retention for the replication group [14] as it starts using retention leases exclusively in peer recoveries
Translog exception: java.lang.IllegalStateException: translog is already closed
Translog exception: java.io.IOException: failed to read [id:1, file:/var/log/translog-1.tlog]
Translog exception: org.elasticsearch.index.translog.TranslogCorruptedException: translog corruption while reading from stream
Translog exception: java.lang.OutOfMemoryError: Java heap space
Translog exception: org.elasticsearch.index.engine.EngineException: failed to create new translog file
Translog exception: java.nio.file.AccessDeniedException: /var/log/translog-2.tlog
Translog exception: org.elasticsearch.index.translog.TranslogException: failed to sync translog
Translog exception: java.lang.InterruptedException: interrupted while waiting for translog sync
Translog exception: java.nio.file.NoSuchFileException: /var/log/translog-3.tlog
Translog exception: org.elasticsearch.index.translog.TranslogSnapshot$CorruptedTranslogException: corrupted translog entry source
Translog exception: java.lang.IllegalArgumentException: translog id mismatch, expected 4, got 5
Translog exception: java.io.EOFException: reached end of stream with 8 bytes left to read
Translog exception: org.elasticsearch.index.translog.TranslogTruncationException: translog was truncated while it was being read
Translog exception: java.nio.file.FileSystemException: /var/log/translog-4.tlog -> /var/log/translog-5.tlog: Operation not permitted
Translog exception: org.elasticsearch.index.translog.TranslogGeneration$MissingTranslogFileException: no translog file found for generation 6
All data files tlogFiles_2023_10_25_08_48_42.log
All data files tlogFiles_2023_10_24_23_15_19.log
All data files tlogFiles_2023_10_24_15_32_07.log
All data files tlogFiles_2023_10_24_07_49_54.log
All data files tlogFiles_2023_10_23_20_06_41.log
All data files tlogFiles_2023_10_23_12_23_29.log
All data files tlogFiles_2023_10_23_04_40_16.log
All data files tlogFiles_2023_10_22_16_57_04.log
All data files tlogFiles_2023_10_22_09_13_51.log
All data files tlogFiles_2023_10_21_21_30_38.log
All data files tlogFiles_backup.zip
All data files tlogFiles_archive.tar.gz
All data files tlogFiles_error.txt
All data files tlogFiles_summary.csv
All data files tlogFiles_config.ini
--> corruptRandomTranslogFile: translogDir [/var/log/elasticsearch], minUsedTranslogGen [3]
--> corruptRandomTranslogFile: translogDir [/home/user/data/translog], minUsedTranslogGen [5]
--> corruptRandomTranslogFile: translogDir [/opt/elasticsearch/translog], minUsedTranslogGen [2]
--> corruptRandomTranslogFile: translogDir [/tmp/translog], minUsedTranslogGen [4]
--> corruptRandomTranslogFile: translogDir [/mnt/translog], minUsedTranslogGen [6]
--> corruptRandomTranslogFile: translogDir [/usr/local/elasticsearch/data/translog], minUsedTranslogGen [7]
--> corruptRandomTranslogFile: translogDir [/data/translog], minUsedTranslogGen [8]
--> corruptRandomTranslogFile: translogDir [/elasticsearch/translog], minUsedTranslogGen [9]
--> corruptRandomTranslogFile: translogDir [/var/lib/elasticsearch/translog], minUsedTranslogGen [10]
--> corruptRandomTranslogFile: translogDir [/root/translog], minUsedTranslogGen [11]
--> corruptRandomTranslogFile: translogDir [/srv/elasticsearch/translog], minUsedTranslogGen [12]
--> corruptRandomTranslogFile: translogDir [/media/translog], minUsedTranslogGen [13]
--> corruptRandomTranslogFile: translogDir [/etc/elasticsearch/translog], minUsedTranslogGen [14]
--> corruptRandomTranslogFile: translogDir [/dev/translog], minUsedTranslogGen [15]
--> corruptRandomTranslogFile: translogDir [/run/translog], minUsedTranslogGen [16]
corruptFile: deleting file C:\Users\John\Documents\report.docx
corruptFile: deleting file /home/mary/Pictures/wedding.jpg
corruptFile: deleting file D:\Games\Minecraft\worlds\survival.dat
corruptFile: deleting file /var/log/syslog
corruptFile: deleting file E:\Music\Beatles\Hey_Jude.mp3
corruptFile: deleting file /tmp/cache/abc123.zip
corruptFile: deleting file C:\Windows\System32\drivers\etc\hosts
corruptFile: deleting file /usr/bin/python3
corruptFile: deleting file F:\Videos\Movies\Inception.mkv
corruptFile: deleting file /etc/passwd
corruptFile: deleting file G:\Backup\2023-10-25.bak
corruptFile: deleting file /opt/java/jdk-11/bin/java
corruptFile: deleting file H:\Books\Harry_Potter_and_the_Philosopher's_Stone.pdf
corruptFile: deleting file /root/.ssh/id_rsa
corruptFile: deleting file I:\Software\Photoshop\setup.exe
corruptFile: truncating file data.txt from length 1024 to length 512
corruptFile: truncating file image.jpg from length 2048 to length 1024
corruptFile: truncating file report.docx from length 4096 to length 2048
corruptFile: truncating file music.mp3 from length 8192 to length 4096
corruptFile: truncating file video.mp4 from length 16384 to length 8192
corruptFile: truncating file backup.zip from length 32768 to length 16384
corruptFile: truncating file game.exe from length 65536 to length 32768
corruptFile: truncating file config.ini from length 128 to length 64
corruptFile: truncating file log.txt from length 256 to length 128
corruptFile: truncating file email.eml from length 512 to length 256
corruptFile: truncating file resume.pdf from length 1024 to length 512
corruptFile: truncating file code.py from length 2048 to length 1024
corruptFile: truncating file presentation.pptx from length 4096 to length 2048
corruptFile: truncating file book.epub from length 8192 to length 4096
corruptFile: truncating file database.db from length 16384 to length 8192
0 skip writing shard state, has been written before
1 skip writing shard state, has been written before
2 skip writing shard state, has been written before
3 skip writing shard state, has been written before
4 skip writing shard state, has been written before
5 skip writing shard state, has been written before
6 skip writing shard state, has been written before
7 skip writing shard state, has been written before
8 skip writing shard state, has been written before
9 skip writing shard state, has been written before
10 skip writing shard state, has been written before
11 skip writing shard state, has been written before
12 skip writing shard state, has been written before
13 skip writing shard state, has been written before
14 skip writing shard state, has been written before
--> using initial block settings {height: 100, width: 200, color: blue}
--> using initial block settings {height: 50, width: 100, color: red}
--> using initial block settings {height: 80, width: 160, color: green}
--> using initial block settings {height: 120, width: 240, color: yellow}
--> using initial block settings {height: 40, width: 80, color: purple}
--> using initial block settings {height: 60, width: 120, color: orange}
--> using initial block settings {height: 90, width: 180, color: pink}
--> using initial block settings {height: 70, width: 140, color: brown}
--> using initial block settings {height: 110, width: 220, color: black}
--> using initial block settings {height: 30, width: 60, color: white}
--> using initial block settings {height: 130, width: 260, color: gray}
--> using initial block settings {height: 20, width: 40, color: cyan}
--> using initial block settings {height: 140, width: 280, color: magenta}
--> using initial block settings {height: 10, width: 20, color: lime}
--> using initial block settings {height: 150, width: 300, color: navy}
corruptFile: corrupting file data.txt at position 1024 turning 0x4f into 0x2a
corruptFile: corrupting file image.jpg at position 4096 turning 0xff into 0x00
corruptFile: corrupting file report.docx at position 512 turning 0x1a into 0x3c
corruptFile: corrupting file music.mp3 at position 8192 turning 0xb7 into 0x5e
corruptFile: corrupting file video.mp4 at position 16384 turning 0x6d into 0xf1
corruptFile: corrupting file backup.zip at position 2048 turning 0x9c into 0x47
corruptFile: corrupting file code.java at position 256 turning 0x7e into 0x11
corruptFile: corrupting file game.exe at position 32768 turning 0xd2 into 0x88
corruptFile: corrupting file email.eml at position 128 turning 0x2f into 0x76
corruptFile: corrupting file book.pdf at position 65536 turning 0xe9 into 0x33
corruptFile: corrupting file logo.png at position 5120 turning 0xc4 into 0x09
corruptFile: corrupting file resume.doc at position 10240 turning 0x5a into 0xbd
corruptFile: corrupting file song.wav at position 24576 turning 0x8e into 0x62
corruptFile: corrupting file movie.mkv at position 49152 turning 0xf7 into 0x4c
corruptFile: corrupting file archive.rar at position 40960 turning 0xa3 into 0xd8
[shard1] writing shard state, reason [primary term transition]
[shard2] writing shard state, reason [started]
[shard3] writing shard state, reason [replica recovery]
[shard4] writing shard state, reason [allocation id changed]
[shard5] writing shard state, reason [routing changed]
[shard6] writing shard state, reason [failed]
[shard7] writing shard state, reason [relocated]
[shard8] writing shard state, reason [restore started]
[shard9] writing shard state, reason [restore completed]
[shard10] writing shard state, reason [snapshot started]
[shard11] writing shard state, reason [snapshot completed]
[shard12] writing shard state, reason [closed]
[shard13] writing shard state, reason [opened]
[shard14] writing shard state, reason [deleted]
[shard15] writing shard state, reason [force merged]
Downloaded segments here: [1, 2, 3, 4, 5]
Downloaded segments here: [6, 7, 8, 9, 10]
Downloaded segments here: [11, 12, 13, 14, 15]
Downloaded segments here: [16, 17, 18, 19, 20]
Downloaded segments here: [21, 22, 23, 24, 25]
Downloaded segments here: [26, 27, 28, 29, 30]
Downloaded segments here: [31, 32, 33, 34, 35]
Downloaded segments here: [36, 37, 38, 39, 40]
Downloaded segments here: [41, 42, 43, 44, 45]
Downloaded segments here: [46, 47, 48, 49, 50]
Downloaded segments here: [51, 52, 53, 54]
Downloaded segments here: [55, 56]
Downloaded segments here: [57]
Downloaded segments here: []
Downloaded segments here: [58]
Skipped download for segments here: [1, 2, 3, 4, 5]
Skipped download for segments here: [10, 11, 12, 13, 14]
Skipped download for segments here: [6, 7, 8, 9]
Skipped download for segments here: [15, 16, 17, 18]
Skipped download for segments here: [19, 20, 21]
Skipped download for segments here: [22, 23, 24, 25]
Skipped download for segments here: [26, 27]
Skipped download for segments here: [28, 29, 30]
Skipped download for segments here: [31, 32, 33]
Skipped download for segments here: [34, 35]
Skipped download for segments here: [36, 37, 38]
Skipped download for segments here: [39, 40]
Skipped download for segments here: [41, 42]
Skipped download for segments here: [43, 44]
Skipped download for segments here: [45]
--> starting asynchronous flush for indices [a, b, c]
--> starting asynchronous flush for indices [x, y, z]
--> starting asynchronous flush for indices [foo, bar, baz]
--> starting asynchronous flush for indices [1, 2, 3]
--> starting asynchronous flush for indices [red, green, blue]
--> starting asynchronous flush for indices [apple, banana, orange]
--> starting asynchronous flush for indices [cat, dog, bird]
--> starting asynchronous flush for indices [alpha, beta, gamma]
--> starting asynchronous flush for indices [hello, world, test]
--> starting asynchronous flush for indices [user1, user2, user3]
--> starting asynchronous flush for indices [index1, index2, index3]
--> starting asynchronous flush for indices [book, movie, song]
--> starting asynchronous flush for indices [java, python, c#]
--> starting asynchronous flush for indices [true, false, null]
--> starting asynchronous flush for indices [pi, e, phi]
File index.html does not exist in local FS, downloading from remote store
File logo.png does not exist in local FS, downloading from remote store
File data.csv does not exist in local FS, downloading from remote store
File report.pdf does not exist in local FS, downloading from remote store
File script.js does not exist in local FS, downloading from remote store
File style.css does not exist in local FS, downloading from remote store
File video.mp4 does not exist in local FS, downloading from remote store
File audio.mp3 does not exist in local FS, downloading from remote store
File image.jpg does not exist in local FS, downloading from remote store
File document.docx does not exist in local FS, downloading from remote store
File presentation.pptx does not exist in local FS, downloading from remote store
File spreadsheet.xlsx does not exist in local FS, downloading from remote store
File archive.zip does not exist in local FS, downloading from remote store
File config.ini does not exist in local FS, downloading from remote store
File readme.txt does not exist in local FS, downloading from remote store
Checksum mismatch between local and remote segment file: data_2023_10_25.csv, will override local file
Checksum mismatch between local and remote segment file: config.ini, will override local file
Checksum mismatch between local and remote segment file: image.jpg, will override local file
Checksum mismatch between local and remote segment file: report.docx, will override local file
Checksum mismatch between local and remote segment file: video.mp4, will override local file
Checksum mismatch between local and remote segment file: backup.zip, will override local file
Checksum mismatch between local and remote segment file: index.html, will override local file
Checksum mismatch between local and remote segment file: log.txt, will override local file
Checksum mismatch between local and remote segment file: music.mp3, will override local file
Checksum mismatch between local and remote segment file: script.py, will override local file
Checksum mismatch between local and remote segment file: database.db, will override local file
Checksum mismatch between local and remote segment file: game.exe, will override local file
Checksum mismatch between local and remote segment file: presentation.pptx, will override local file
Checksum mismatch between local and remote segment file: book.pdf, will override local file
Checksum mismatch between local and remote segment file: wallpaper.png, will override local file
--> Added and started replica [replica1.routingEntry(0x1234)]
--> Added and started replica [replica1.routingEntry(0x4321)]
--> Added and started replica [replica1.routingEntry(0x5678)]
--> Added and started replica [replica1.routingEntry(0x8765)]
--> Added and started replica [replica1.routingEntry(0x9abc)]
--> Added and started replica [replica1.routingEntry(0xcba9)]
--> Added and started replica [replica1.routingEntry(0xdef0)]
--> Added and started replica [replica1.routingEntry(0x0fed)]
--> Added and started replica [replica1.routingEntry(0x1357)]
--> Added and started replica [replica1.routingEntry(0x7531)]
--> Added and started replica [replica1.routingEntry(0x2468)]
--> Added and started replica [replica1.routingEntry(0x8642)]
--> Added and started replica [replica1.routingEntry(0x3a5b)]
--> Added and started replica [replica1.routingEntry(0xb5a3)]
--> Added and started replica [replica1.routingEntry(0x4c6d)]
shard1 resync completed (total sent: 345, skipped: 12)
shard2 resync completed (total sent: 456, skipped: 23)
shard3 resync completed (total sent: 567, skipped: 34)
shard4 resync completed (total sent: 678, skipped: 45)
shard5 resync completed (total sent: 789, skipped: 56)
shard6 resync completed (total sent: 890, skipped: 67)
shard7 resync completed (total sent: 901, skipped: 78)
shard8 resync completed (total sent: 123, skipped: 9)
shard9 resync completed (total sent: 234, skipped: 10)
shard10 resync completed (total sent: 432, skipped: 21)
shard11 resync completed (total sent: 543, skipped: 32)
shard12 resync completed (total sent: 654, skipped: 43)
shard13 resync completed (total sent: 765, skipped: 54)
shard14 resync completed (total sent: 876, skipped: 65)
shard1 sending batch of [100][1.2mb] (total sent: 1000, skipped: 0)
shard2 sending batch of [50][600kb] (total sent: 500, skipped: 10)
shard3 sending batch of [75][900kb] (total sent: 750, skipped: 5)
shard4 sending batch of [25][300kb] (total sent: 250, skipped: 15)
shard5 sending batch of [80][960kb] (total sent: 800, skipped: 2)
shard6 sending batch of [40][480kb] (total sent: 400, skipped: 8)
shard7 sending batch of [60][720kb] (total sent: 600, skipped: 4)
shard8 sending batch of [30][360kb] (total sent: 300, skipped: 12)
shard9 sending batch of [90][1.08mb] (total sent: 900, skipped: 1)
shard10 sending batch of [20][240kb] (total sent: 200, skipped: 16)
shard11 sending batch of [70][840kb] (total sent: 700, skipped: 3)
shard12 sending batch of [45][540kb] (total sent: 450, skipped: 9)
shard13 sending batch of [55][660kb] (total sent: 550, skipped: 7)
shard14 sending batch of [35][420kb] (total sent: 350, skipped: 11)
--> execution was blocked on node [node-1], moving shards away from this node
--> execution was blocked on node [node-5], moving shards away from this node
--> execution was blocked on node [node-3], moving shards away from this node
--> execution was blocked on node [node-7], moving shards away from this node
--> execution was blocked on node [node-2], moving shards away from this node
--> execution was blocked on node [node-4], moving shards away from this node
--> execution was blocked on node [node-6], moving shards away from this node
--> execution was blocked on node [node-8], moving shards away from this node
--> execution was blocked on node [node-9], moving shards away from this node
--> execution was blocked on node [node-10], moving shards away from this node
--> execution was blocked on node [node-11], moving shards away from this node
--> execution was blocked on node [node-12], moving shards away from this node
--> execution was blocked on node [node-13], moving shards away from this node
--> execution was blocked on node [node-14], moving shards away from this node
--> execution was blocked on node [node-15], moving shards away from this node
Exception in runAfterRefreshExactlyOnce() method: java.lang.NullPointerException
Exception in runAfterRefreshExactlyOnce() method: java.io.IOException
Exception in runAfterRefreshExactlyOnce() method: java.lang.IllegalArgumentException
Exception in runAfterRefreshExactlyOnce() method: java.util.ConcurrentModificationException
Exception in runAfterRefreshExactlyOnce() method: java.lang.ClassNotFoundException
Exception in runAfterRefreshExactlyOnce() method: java.lang.OutOfMemoryError
Exception in runAfterRefreshExactlyOnce() method: java.lang.StackOverflowError
Exception in runAfterRefreshExactlyOnce() method: java.lang.ArithmeticException
Exception in runAfterRefreshExactlyOnce() method: java.lang.IndexOutOfBoundsException
Exception in runAfterRefreshExactlyOnce() method: java.lang.SecurityException
Exception in runAfterRefreshExactlyOnce() method: java.sql.SQLException
Exception in runAfterRefreshExactlyOnce() method: java.net.SocketException
Exception in runAfterRefreshExactlyOnce() method: java.lang.UnsupportedOperationException
Exception in runAfterRefreshExactlyOnce() method: java.time.DateTimeException
Exception in runAfterRefreshExactlyOnce() method: java.lang.NoSuchMethodError
--> execution was blocked on node [node-1], trying to delete repository
--> execution was blocked on node [node-5], trying to delete repository
--> execution was blocked on node [node-3], trying to delete repository
--> execution was blocked on node [node-7], trying to delete repository
--> execution was blocked on node [node-2], trying to delete repository
--> execution was blocked on node [node-4], trying to delete repository
--> execution was blocked on node [node-6], trying to delete repository
--> execution was blocked on node [node-8], trying to delete repository
--> execution was blocked on node [node-9], trying to delete repository
--> execution was blocked on node [node-10], trying to delete repository
--> execution was blocked on node [node-11], trying to delete repository
--> execution was blocked on node [node-12], trying to delete repository
--> execution was blocked on node [node-13], trying to delete repository
--> execution was blocked on node [node-14], trying to delete repository
--> execution was blocked on node [node-15], trying to delete repository
Exception while reading SegmentInfosSnapshot: java.io.FileNotFoundException: No such file or directory
Exception while reading SegmentInfosSnapshot: java.lang.NullPointerException: SegmentInfosSnapshot is null
Exception while reading SegmentInfosSnapshot: java.io.IOException: Stream closed unexpectedly
Exception while reading SegmentInfosSnapshot: java.lang.IllegalArgumentException: Invalid SegmentInfosSnapshot format
Exception while reading SegmentInfosSnapshot: java.lang.OutOfMemoryError: Java heap space
Exception while reading SegmentInfosSnapshot: java.lang.SecurityException: Access denied to SegmentInfosSnapshot
Exception while reading SegmentInfosSnapshot: java.util.ConcurrentModificationException: SegmentInfosSnapshot was modified by another thread
Exception while reading SegmentInfosSnapshot: java.lang.ClassNotFoundException: SegmentInfosSnapshot class not found
Exception while reading SegmentInfosSnapshot: java.lang.UnsupportedOperationException: SegmentInfosSnapshot is read-only
Exception while reading SegmentInfosSnapshot: java.nio.file.NoSuchFileException: SegmentInfosSnapshot file does not exist
Exception while reading SegmentInfosSnapshot: java.lang.IndexOutOfBoundsException: Index out of range for SegmentInfosSnapshot
Exception while reading SegmentInfosSnapshot: java.nio.file.FileSystemException: File system error occurred while reading SegmentInfosSnapshot
Exception while reading SegmentInfosSnapshot: java.lang.NumberFormatException: Invalid number in SegmentInfosSnapshot
Exception while reading SegmentInfosSnapshot: java.util.zip.ZipException: Corrupted or invalid zip file for SegmentInfosSnapshot
Exception while reading SegmentInfosSnapshot: java.net.SocketTimeoutException: Timeout while reading SegmentInfosSnapshot from remote server
--> execution was blocked on node [node-1], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-5], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-3], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-7], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-2], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-4], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-6], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-8], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-9], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-10], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-11], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-12], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-13], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-14], checking snapshot status with specified repository and snapshot
--> execution was blocked on node [node-15], checking snapshot status with specified repository and snapshot
Exception while reading checksum of local segment file: data_2023_10_25.csv, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: report_2023_10_24.pdf, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: image_2023_10_23.jpg, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: video_2023_10_22.mp4, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: audio_2023_10_21.wav, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: config_2023_10_20.ini, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: log_2023_10_19.txt, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: backup_2023_10_18.zip, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: code_2023_10_17.py, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: document_2023_10_16.docx, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: presentation_2023_10_15.pptx, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: spreadsheet_2023_10_14.xlsx, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: music_2023_10_13.mp3, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: game_2023_10_12.exe, ignoring the exception and re-uploading the file
Exception while reading checksum of local segment file: model_2023_10_11.h5, ignoring the exception and re-uploading the file
--> getting user alias for index foobar
--> getting admin alias for index foobar
--> getting test alias for index foobar
--> getting backup alias for index foobar
--> getting default alias for index foobar
--> getting prod alias for index foobar
--> getting dev alias for index foobar
--> getting foo alias for index foobar
--> getting bar alias for index foobar
--> getting baz alias for index foobar
--> getting qux alias for index foobar
--> getting quux alias for index foobar
--> getting corge alias for index foobar
--> getting grault alias for index foobar
--> getting garply alias for index foobar
Checking static index user
Checking static index product
Checking static index order
Checking static index category
Checking static index review
Checking static index cart
Checking static index payment
Checking static index shipment
Checking static index inventory
Checking static index coupon
Checking static index wishlist
Checking static index customer
Checking static index feedback
Checking static index promotion
Checking static index sales
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now set allocateTest1 to true and reroute we should see the [test1] index initializing
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
now start initializing shards and expect exactly one rebalance from node1 to node 2 since index [test] is all on node1
missing id [a3b5c7] on shard [node-1]
missing id [f9d2e4] on shard [node-2]
missing id [c6a8b4] on shard [node-3]
missing id [e7d5c3] on shard [node-4]
missing id [b4a6c8] on shard [node-5]
missing id [d3e5f7] on shard [node-6]
missing id [a9c4e6] on shard [node-7]
missing id [f8d6b5] on shard [node-8]
missing id [c7a5b9] on shard [node-9]
missing id [e6d4a8] on shard [node-10]
missing id [b8c6d7] on shard [node-11]
missing id [d7e8f6] on shard [node-12]
missing id [a6b7c9] on shard [node-13]
missing id [f7d9e5] on shard [node-14]
missing id [c8a7b6] on shard [node-15]
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now, start 1 more node, check that rebalancing will not happen since we have shard sync going on
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
now set hasFetches to true and reroute we should now see exactly one relocating shard
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
start two nodes and fully start the shards
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
now, start 8 more nodes, and check that no rebalancing/relocation have happened
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
start the replica shards, rebalancing should start, but, only 3 should be rebalancing
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 3 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, 2 more should relocate now
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
finalize this session relocation, no more relocation
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> adding 2 nodes on same rack and do rerouting
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> verifying all is allocated
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> fail node with primary
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> adding additional node
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> moving primary shard to node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on node3 being initialized by killing node3
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> adding nodes and starting shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting primary shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Starting replica shards
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Performing a reroute
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Disabling cluster_concurrent_recoveries and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> Bumping cluster_concurrent_recoveries up and re-routing
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> calling fake getClusterInfo
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> adding node3
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing decider settings
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> changing settings again
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> adding node4
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> apply INITIALIZING shards
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> adding node1 and node2 node
--> nodeWithPrimary: node1
--> nodeWithPrimary: node2
--> nodeWithPrimary: node3
--> nodeWithPrimary: node4
--> nodeWithPrimary: node5
--> nodeWithPrimary: node6
--> nodeWithPrimary: node7
--> nodeWithPrimary: node8
--> nodeWithPrimary: node9
--> nodeWithPrimary: node10
--> nodeWithPrimary: master
--> nodeWithPrimary: backup
--> nodeWithPrimary: replica
--> nodeWithPrimary: leader
--> nodeWithPrimary: follower
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> trying to wait
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> adding node5
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> final cluster state:
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> adding node1
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> start the shards
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> adding one cluster-manager node, one data node
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> simulating snapshot shards size retrieval failure
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> shard is always allocated when its size could not be retrieved
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> simulating snapshot shards size retrieval success
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> shard allocation depends on its size
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> starting [node1] ...
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> flush so we have an actual index
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> relocate the shard from node1 to node2
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
--> verifying count again...
warmed bitset for [age > 30], took [3.2 nanoseconds]
warmed bitset for [name = "Alice"], took [4.5 nanoseconds]
warmed bitset for [gender = "male"], took [2.9 nanoseconds]
warmed bitset for [salary < 50000], took [3.7 nanoseconds]
warmed bitset for [city = "New York"], took [5.1 nanoseconds]
warmed bitset for [occupation = "teacher"], took [4.2 nanoseconds]
warmed bitset for [hobby = "reading"], took [3.4 nanoseconds]
warmed bitset for [status = "married"], took [4.8 nanoseconds]
warmed bitset for [education = "master"], took [3.6 nanoseconds]
warmed bitset for [language = "English"], took [5.3 nanoseconds]
warmed bitset for [country = "USA"], took [4.1 nanoseconds]
warmed bitset for [pet = "dog"], took [3.9 nanoseconds]
warmed bitset for [height > 170], took [4.6 nanoseconds]
warmed bitset for [weight < 80], took [3.1 nanoseconds]
warmed bitset for [color = "red"], took [5.4 nanoseconds]
--> unassigned: 5, initializing: 3, relocating: 2, started: 10
--> unassigned: 0, initializing: 4, relocating: 1, started: 15
--> unassigned: 7, initializing: 2, relocating: 0, started: 11
--> unassigned: 1, initializing: 6, relocating: 3, started: 10
--> unassigned: 4, initializing: 5, relocating: 2, started: 9
--> unassigned: 3, initializing: 4, relocating: 1, started: 12
--> unassigned: 6, initializing: 3, relocating: 0, started: 11
--> unassigned: 2, initializing: 5, relocating: 2, started: 11
--> unassigned: 0, initializing: 3, relocating: 3, started: 14
--> unassigned: 8, initializing: 1, relocating: 1, started: 10
--> unassigned: 4, initializing: 4, relocating: 0, started: 12
--> unassigned: 1, initializing: 7, relocating: 2, started: 10
--> unassigned: 3, initializing: 6, relocating: 1, started: 10
--> unassigned: 5, initializing: 4, relocating: 1, started: 10
Using no query cache
Using no query cache
Using no query cache
Using no query cache
Using no query cache
Using no query cache
Using no query cache
Using no query cache
Using no query cache
Using no query cache
Using no query cache
Using no query cache
Using no query cache
Using no query cache
Using no query cache
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes and do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> adding two nodes do rerouting
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> verify only enabled index has been routed
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding one nodes and do rerouting
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> adding nodes
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> do the reroute
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
--> assert cluster health
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Adding two nodes and performing rerouting
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the primary shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start the replica shards
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
Start another node and perform rerouting
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
find the replica shard that gets relocated
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
make sure all the primary shards are active
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Adding one node and performing rerouting
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Start the primary shard
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
Add another one node and reroute
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
start 4 nodes
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
remove 2 nodes where primaries are allocated, reroute
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> adding random nodes
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> creating some indices
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting shards
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
--> starting replicas a random number of times
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
starting gce discovery plugin...
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
Register _gce_, _gce:xxx network names
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> starting relocations...
--> verifying version for shardRouting [0]
--> verifying version for shardRouting [1]
--> verifying version for shardRouting [2]
--> verifying version for shardRouting [3]
--> verifying version for shardRouting [4]
--> verifying version for shardRouting [5]
--> verifying version for shardRouting [6]
--> verifying version for shardRouting [7]
--> verifying version for shardRouting [8]
--> verifying version for shardRouting [9]
--> verifying version for shardRouting [10]
--> verifying version for shardRouting [11]
--> verifying version for shardRouting [12]
--> verifying version for shardRouting [13]
--> verifying version for shardRouting [14]
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node3 being initialized
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
--> fail primary shard recovering instance on node1 being relocated
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (primaries)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
Start the shards (backups)
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
fail the primary shard, will have no place to be rerouted to (single node), so stays unassigned
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
Adding single node and performing rerouting
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
fail the first shard, will have no place to be rerouted to (single node), so stays unassigned
--> flushing
--> flushing
--> flushing
--> flushing
--> flushing
--> flushing
--> flushing
--> flushing
--> flushing
--> flushing
--> flushing
--> flushing
--> flushing
--> flushing
--> flushing
failed to invoke on store created: NullPointerException
failed to invoke on store created: TimeoutException
failed to invoke on store created: IOException
failed to invoke on store created: SecurityException
failed to invoke on store created: IllegalArgumentException
failed to invoke on store created: OutOfMemoryError
failed to invoke on store created: AssertionError
failed to invoke on store created: ClassNotFoundException
failed to invoke on store created: NoSuchMethodError
failed to invoke on store created: StackOverflowError
failed to invoke on store created: SQLException
failed to invoke on store created: NetworkException
failed to invoke on store created: DataFormatException
failed to invoke on store created: NumberFormatException
failed to invoke on store created: IndexOutOfBoundsException
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> done relocations
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> waiting for indexing threads to stop ...
--> searching the index
--> searching the index
--> searching the index
--> searching the index
--> searching the index
--> searching the index
--> searching the index
--> searching the index
--> searching the index
--> searching the index
--> searching the index
--> searching the index
--> searching the index
--> searching the index
--> searching the index
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
fail the first shard, will start INITIALIZING on the second node
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Adding third node and reroute
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
Fail the shards on node 3
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
unzipping all tika sample files
--> failing primary shard a second time, should select: [node-1, node-2]
--> failing primary shard a second time, should select: [node-3, node-4]
--> failing primary shard a second time, should select: [node-5, node-6]
--> failing primary shard a second time, should select: [node-7, node-8]
--> failing primary shard a second time, should select: [node-9, node-10]
--> failing primary shard a second time, should select: [node-11, node-12]
--> failing primary shard a second time, should select: [node-13, node-14]
--> failing primary shard a second time, should select: [node-15, node-16]
--> failing primary shard a second time, should select: [node-17, node-18]
--> failing primary shard a second time, should select: [node-19, node-20]
--> failing primary shard a second time, should select: [node-21, node-22]
--> failing primary shard a second time, should select: [node-23, node-24]
--> failing primary shard a second time, should select: [node-25, node-26]
--> failing primary shard a second time, should select: [node-27, node-28]
--> failing primary shard a second time, should select: [node-29, node-30]
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> rerouting
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> make sure shards are only allocated on tag1 with value1 and value2
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> switch between value2 and value4, shards should be relocating
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> finish relocation
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> adding two nodes and performing rerouting
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> start the shards (only primaries)
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> make sure all shards are started
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> disable allocation for node1 and reroute
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> move shards from node1 to node2
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> check that concurrent recoveries only allows 1 shard to move
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
--> move second shard from node1 to node2
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Adding three node and performing rerouting
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Another round of rebalancing
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Reroute, nothing should change
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Start the more shards
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Add another node and perform rerouting, nothing will happen since primary not started
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Start the backup shard
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
Add new index 3 shards 1 replica
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
creating an index with 1 shard, 2 replicas
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
adding three nodes and performing rerouting
start replica shards
start replica shards
start replica shards
start replica shards
start replica shards
start replica shards
start replica shards
start replica shards
start replica shards
start replica shards
start replica shards
start replica shards
start replica shards
start replica shards
start replica shards
remove a node
remove a node
remove a node
remove a node
remove a node
remove a node
remove a node
remove a node
remove a node
remove a node
remove a node
remove a node
remove a node
remove a node
remove a node
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
remove all remaining nodes
fail primary shard
fail primary shard
fail primary shard
fail primary shard
fail primary shard
fail primary shard
fail primary shard
fail primary shard
fail primary shard
fail primary shard
fail primary shard
fail primary shard
fail primary shard
fail primary shard
fail primary shard
remove replica node
remove replica node
remove replica node
remove replica node
remove replica node
remove replica node
remove replica node
remove replica node
remove replica node
remove replica node
remove replica node
remove replica node
remove replica node
remove replica node
remove replica node
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
fail replica (for which there is no shard routing in the CS anymore)
add back node
add back node
add back node
add back node
add back node
add back node
add back node
add back node
add back node
add back node
add back node
add back node
add back node
add back node
add back node
remove the node
remove the node
remove the node
remove the node
remove the node
remove the node
remove the node
remove the node
remove the node
remove the node
remove the node
remove the node
remove the node
remove the node
remove the node
remove primary node
remove primary node
remove primary node
remove primary node
remove primary node
remove primary node
remove primary node
remove primary node
remove primary node
remove primary node
remove primary node
remove primary node
remove primary node
remove primary node
remove primary node
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
decrease number of replicas to 0
add back node 1
add back node 1
add back node 1
add back node 1
add back node 1
add back node 1
add back node 1
add back node 1
add back node 1
add back node 1
add back node 1
add back node 1
add back node 1
add back node 1
add back node 1
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
creating an index with 1 shard, 1 replica
start replica shard
start replica shard
start replica shard
start replica shard
start replica shard
start replica shard
start replica shard
start replica shard
start replica shard
start replica shard
start replica shard
start replica shard
start replica shard
start replica shard
start replica shard
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
Building initial routing table for 'testNewUnassignedPrimaryAllocationOnOverload'
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> adding five nodes on same zone and do rerouting
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
--> Remove nodes from zone holding primaries
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
add another index with 20 shards
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
no limits should be applied on newly created primaries
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testNoAllocationLimitsOnOverloadForDisabledLoadFactor'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
Building initial routing table for 'testExistingPrimariesAllocationOnOverload'
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
limits should be applied on newly create primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> Remove node4 from zone holding primaries
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> change the overload load factor to zero and verify if unassigned primaries on disk get assigned despite overload
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
--> Add back node4 and ensure existing primaries are assigned
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsShardAllocationOnOverload'
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node1 from zone
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
--> Remove node2 when the limit of overload is reached
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
add another index with 60 shards
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
change settings to allow unassigned primaries
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
add another index with 5 shards
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverload'
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> replica will not start because we have only one zone value
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add five new node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> add another five node in new zone and reroute
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
--> Remove three node from zone3 holding primary and replicas
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
Building initial routing table for 'testThreeZoneOneReplicaLimitsShardAllocationOnOverload'
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> starting [node_0] ...
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
--> Remove three node from zone3
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsShardAllocationOnOverloadAcrossZones'
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> adding three nodes on same zone and do rerouting
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> add three new node with a new rack and reroute
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
--> Remove two nodes from zones
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneTwoReplicaLimitsReplicaAllocationOnOverload'
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> adding three nodes on same rack and do rerouting
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> replicas are initializing
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
--> all shards are started
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
Building initial routing table for 'testSingleZoneOneReplicaLimitsReplicaAllocationOnOverload'
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> 2 replicas are initializing
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
--> replicas are started
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
Building initial routing table for 'testThreeZoneTwoReplicaLimitsUnderFullZoneFailure'
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
--> Remove complete zone3 holding primary and replicas
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
Building initial routing table for 'testThreeZoneOneReplicaWithSkewFactorZeroAllShardsAssignedAfterRecovery'
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
--> Removing three nodes from zone3
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
add another index with 30 primary 1 replica
Error while deleting unreferenced file java.io.FileNotFoundException: /tmp/file1.txt (No such file or directory)
Error while deleting unreferenced file java.lang.SecurityException: Permission denied: /home/user/file2.pdf
Error while deleting unreferenced file java.nio.file.FileSystemException: /mnt/usb/file3.jpg: Device or resource busy
Error while deleting unreferenced file java.lang.NullPointerException: File name is null
Error while deleting unreferenced file java.io.IOException: Input/output error: /var/log/file4.log
Error while deleting unreferenced file java.lang.IllegalArgumentException: Invalid file name: /etc/file5.*
Error while deleting unreferenced file java.nio.file.NoSuchFileException: /opt/file6.bin
Error while deleting unreferenced file java.nio.file.AccessDeniedException: /root/file7.docx
Error while deleting unreferenced file java.lang.OutOfMemoryError: Unable to allocate memory for file buffer
Error while deleting unreferenced file java.nio.file.DirectoryNotEmptyException: /usr/local/file8
Error while deleting unreferenced file java.lang.UnsupportedOperationException: File system is read-only
Error while deleting unreferenced file java.net.URISyntaxException: Illegal character in path: /www/file9.html
Error while deleting unreferenced file java.nio.file.InvalidPathException: Path contains invalid characters: /lib/file10??.dll
Error while deleting unreferenced file java.util.zip.ZipException: Zip file is corrupted: /backup/file11.zip
Error while deleting unreferenced file java.lang.ClassCastException: Cannot cast File to String
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
--> verifying all searches return the same number of docs
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquire writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushAndClose now acquired writeLock
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
flushing shard on close - this might take some time to sync files to disk
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
engine already closed - skipping flushAndClose
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close now acquiring writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
close acquired writeLock
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
created new InternalEngine
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
acquired flush lock immediately
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
waiting for in-flight flush to finish
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
acquired flush lock after blocking
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
starting commit for flush; commitTranslog=true
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
finished commit for flush
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> stopping replica assignment
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> wait for all replica shards to be removed, on all nodes
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
--> verifying no temporary recoveries are left
red nodes: [A, B, C]
red nodes: [D, E, F, G]
red nodes: [H, I]
red nodes: [J, K, L, M, N]
red nodes: [O, P, Q]
red nodes: [R, S, T, U]
red nodes: [V, W]
red nodes: [X, Y, Z]
red nodes: [A1, B1, C1]
red nodes: [D1, E1, F1, G1]
red nodes: [H1, I1]
red nodes: [J1, K1, L1, M1, N1]
red nodes: [O1, P1, Q1]
red nodes: [R1, S1, T1, U1]
red nodes: [V1, W1]
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
--> moving index to new nodes
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
adding two nodes and performing rerouting till all are allocated
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
remove one of the nodes and apply filter to move everything from another node
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
finished segment upgrade
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
start flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
finish flush for snapshot
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
--> waiting for relocation to complete
start node back up
start node back up
start node back up
start node back up
start node back up
start node back up
start node back up
start node back up
start node back up
start node back up
start node back up
start node back up
start node back up
start node back up
start node back up
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create an allocation with 1 initial recoveries
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
create several indices with no replicas, and wait till all are allocated
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
increasing the number of replicas to 1, and perform a reroute (to get the replicas allocation going)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
2 replicas should be initializing now for the existing indices (we throttle to 1)
create a new index
create a new index
create a new index
create a new index
create a new index
create a new index
create a new index
create a new index
create a new index
create a new index
create a new index
create a new index
create a new index
create a new index
create a new index
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
reroute, verify that primaries for the new index primary shards are allocated
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the primary shard (on node1)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Start the backup shard (on node2)
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
Adding third node and reroute and kill first node
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, replica will start recovering form primary
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
start another node, make sure the primary is not relocated
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> index 100 docs while relocating
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> bumping replicas to 1
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is yellow with no initializing shards
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
--> Cluster is green
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Application Default Credentials" are not supported out of the box. Additional file system permissions have to be granted to the plugin.
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
Fill up nodes such that every shard can be allocated
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
now say YES to everything
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
rollback indexWriter done
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
start the replica shards, rebalancing should start
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, other half of relocation should happen
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
complete relocation, that's it!
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Start all the primary shards
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, assign
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the primaries
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
Reroute, start the replicas
kill one node
kill one node
kill one node
kill one node
kill one node
kill one node
kill one node
kill one node
kill one node
kill one node
kill one node
kill one node
kill one node
kill one node
kill one node
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 1
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
Start Recovering shards round 2
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> adding two nodes with the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> start all primary shards, no replica will be started since its on the same host
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
--> add another node, with a different host, replicas will be allocating
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure its still not allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Do another reroute, make sure shards are now allocated
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
Adding one node and reroute
reroute after setting
reroute after setting
reroute after setting
reroute after setting
reroute after setting
reroute after setting
reroute after setting
reroute after setting
reroute after setting
reroute after setting
reroute after setting
reroute after setting
reroute after setting
reroute after setting
reroute after setting
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Rerouting again, nothing should change
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Marking the shard as started
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Starting another node and making sure nothing changed
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Killing node1 where the shard is, checking the shard is unassigned
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Bring node1 back, and see it's assinged
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start another node, make sure that things remain the same (shard is in node2 and initializing)
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Start the shard on node 1
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Adding one node and rerouting
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Marking the shard as failed
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Starting 3 nodes and rerouting
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Start two more nodes, things should remain the same
Using file-system [hdfs://localhost:9000] for URI [hdfs://localhost:9000], path [/user/hadoop/input.txt]
Using file-system [s3a://mybucket] for URI [s3a://mybucket], path [/data/2023/10/23/file.csv]
Using file-system [file:///] for URI [file:///], path [/home/user/Desktop/image.png]
Using file-system [ftp://user:password@host:port] for URI [ftp://user:password@host:port], path [/pub/example.zip]
Using file-system [gs://my-project] for URI [gs://my-project], path [/logs/2023/10/23/log.txt]
Using file-system [hdfs://namenode1:8020] for URI [hdfs://namenode1:8020], path [/user/hive/warehouse/table.parquet]
Using file-system [s3n://mybucket] for URI [s3n://mybucket], path [/images/2023/10/23/photo.jpg]
Using file-system [file:///] for URI [file:///], path [/tmp/output.txt]
Using file-system [webhdfs://namenode2:50070] for URI [webhdfs://namenode2:50070], path [/user/spark/application.log]
Using file-system [adl://myaccount.azuredatalakestore.net] for URI [adl://myaccount.azuredatalakestore.net], path [/folder/file.json]
Using file-system [wasb://container@storageaccount.blob.core.windows.net] for URI [wasb://container@storageaccount.blob.core.windows.net], path [/documents/2023/10/23/report.docx]
Using file-system [hdfs://cluster1] for URI [hdfs://cluster1], path [/user/flink/checkpoints]
Using file-system [sftp://user@host:path] for URI [sftp://user@host:path], path [/var/log/syslog]
Using file-system [swift://container.sahara] for URI [swift://container.sahara], path [/notebooks/2023/10/23/notebook.ipynb]
Using file-system [abfs://container@account.dfs.core.windows.net] for URI [abfs://container@account.dfs.core.windows.net], path [/videos/2023/10/23/movie.mp4]
Using kerberos principal [hdfs@EXAMPLE.COM] and keytab located at [/etc/hadoop/conf/hdfs.keytab]
Using kerberos principal [hive@EXAMPLE.COM] and keytab located at [/etc/hive/conf/hive.keytab]
Using kerberos principal [spark@EXAMPLE.COM] and keytab located at [/usr/local/spark/conf/spark.keytab]
Using kerberos principal [yarn@EXAMPLE.COM] and keytab located at [/etc/yarn/conf/yarn.keytab]
Using kerberos principal [zookeeper@EXAMPLE.COM] and keytab located at [/etc/zookeeper/conf/zookeeper.keytab]
Using kerberos principal [kafka@EXAMPLE.COM] and keytab located at [/etc/kafka/conf/kafka.keytab]
Using kerberos principal [flink@EXAMPLE.COM] and keytab located at [/opt/flink/conf/flink.keytab]
Using kerberos principal [hbase@EXAMPLE.COM] and keytab located at [/etc/hbase/conf/hbase.keytab]
Using kerberos principal [kudu@EXAMPLE.COM] and keytab located at [/etc/kudu/conf/kudu.keytab]
Using kerberos principal [impala@EXAMPLE.COM] and keytab located at [/etc/impala/conf/impala.keytab]
Using kerberos principal [hue@EXAMPLE.COM] and keytab located at [/var/lib/hue/hue.keytab]
Using kerberos principal [oozie@EXAMPLE.COM] and keytab located at [/var/lib/oozie/oozie.keytab]
Using kerberos principal [sqoop@EXAMPLE.COM] and keytab located at [/var/lib/sqoop/sqoop.keytab]
Using kerberos principal [nifi@EXAMPLE.COM] and keytab located at [/opt/nifi/conf/nifi.keytab]
Using kerberos principal [admin@EXAMPLE.COM] and keytab located at [/home/admin/admin.keytab]
committing writer with commit data [id: 4567, size: 12 KB, timestamp: 1623423432]
committing writer with commit data [id: 7890, size: 8 KB, timestamp: 1623423435]
committing writer with commit data [id: 1234, size: 10 KB, timestamp: 1623423438]
committing writer with commit data [id: 4321, size: 15 KB, timestamp: 1623423441]
committing writer with commit data [id: 8765, size: 9 KB, timestamp: 1623423444]
committing writer with commit data [id: 5678, size: 11 KB, timestamp: 1623423447]
committing writer with commit data [id: 9012, size: 13 KB, timestamp: 1623423450]
committing writer with commit data [id: 3456, size: 14 KB, timestamp: 1623423453]
committing writer with commit data [id: 7891, size: 7 KB, timestamp: 1623423456]
committing writer with commit data [id: 2345, size: 16 KB, timestamp: 1623423459]
committing writer with commit data [id: 6789, size: 6 KB, timestamp: 1623423462]
committing writer with commit data [id: 0123, size: 17 KB, timestamp: 1623423465]
committing writer with commit data [id: 4568, size: 18 KB, timestamp: 1623423468]
committing writer with commit data [id: 8901, size: 5 KB, timestamp: 1623423471]
committing writer with commit data [id: 1235, size: 19 KB, timestamp: 1623423474]
Found service principal. Converted original principal name [alice@domain.com] to server principal [alice@server.com]
Found service principal. Converted original principal name [bob@domain.com] to server principal [bob@server.com]
Found service principal. Converted original principal name [charlie@domain.com] to server principal [charlie@server.com]
Found service principal. Converted original principal name [david@domain.com] to server principal [david@server.com]
Found service principal. Converted original principal name [eve@domain.com] to server principal [eve@server.com]
Found service principal. Converted original principal name [frank@domain.com] to server principal [frank@server.com]
Found service principal. Converted original principal name [grace@domain.com] to server principal [grace@server.com]
Found service principal. Converted original principal name [harry@domain.com] to server principal [harry@server.com]
Found service principal. Converted original principal name [irene@domain.com] to server principal [irene@server.com]
Found service principal. Converted original principal name [jack@domain.com] to server principal [jack@server.com]
Found service principal. Converted original principal name [kate@domain.com] to server principal [kate@server.com]
Found service principal. Converted original principal name [leo@domain.com] to server principal [leo@server.com]
Found service principal. Converted original principal name [mary@domain.com] to server principal [mary@server.com]
Found service principal. Converted original principal name [nick@domain.com] to server principal [nick@server.com]
Found service principal. Converted original principal name [olivia@domain.com] to server principal [olivia@server.com]
Swapping active namenodes: [nn1] to standby and [nn2] to active
Swapping active namenodes: [nn3] to standby and [nn4] to active
Swapping active namenodes: [nn5] to standby and [nn6] to active
Swapping active namenodes: [nn7] to standby and [nn8] to active
Swapping active namenodes: [nn9] to standby and [nn10] to active
Swapping active namenodes: [nn11] to standby and [nn12] to active
Swapping active namenodes: [nn13] to standby and [nn14] to active
Swapping active namenodes: [nn15] to standby and [nn16] to active
Swapping active namenodes: [nn17] to standby and [nn18] to active
Swapping active namenodes: [nn19] to standby and [nn20] to active
Swapping active namenodes: [nn21] to standby and [nn22] to active
Swapping active namenodes: [nn23] to standby and [nn24] to active
Swapping active namenodes: [nn25] to standby and [nn26] to active
Swapping active namenodes: [nn27] to standby and [nn28] to active
Swapping active namenodes: [nn29] to standby and [nn30] to active
merge [segments_1] starting..., merging [3] segments, [1000] docs, [10 MB] size, into [15 MB] estimated_size
merge [segments_2] starting..., merging [5] segments, [2000] docs, [20 MB] size, into [25 MB] estimated_size
merge [segments_3] starting..., merging [4] segments, [1500] docs, [15 MB] size, into [18 MB] estimated_size
merge [segments_4] starting..., merging [6] segments, [2500] docs, [25 MB] size, into [30 MB] estimated_size
merge [segments_5] starting..., merging [2] segments, [500] docs, [5 MB] size, into [7 MB] estimated_size
merge [segments_6] starting..., merging [7] segments, [3000] docs, [30 MB] size, into [35 MB] estimated_size
merge [segments_7] starting..., merging [8] segments, [3500] docs, [35 MB] size, into [40 MB] estimated_size
merge [segments_8] starting..., merging [9] segments, [4000] docs, [40 MB] size, into [45 MB] estimated_size
merge [segments_9] starting..., merging [10] segments, [4500] docs, [45 MB] size, into [50 MB] estimated_size
merge [segments_10] starting..., merging [11] segments, [5000] docs, [50 MB] size, into [55 MB] estimated_size
merge [segments_11] starting..., merging [12] segments, [5500] docs, [55 MB] size, into [60 MB] estimated_size
merge [segments_12] starting..., merging [13] segments, [6000] docs, [60 MB] size, into [65 MB] estimated_size
using endpoint [https://api.example.com] and region [us-east-1]
using endpoint [http://localhost:8080] and region [local]
using endpoint [https://service.example.net] and region [eu-west-2]
using endpoint [http://192.168.0.1:3000] and region [custom]
using endpoint [https://api.example.org] and region [ap-southeast-1]
using endpoint [http://example.com:8000] and region [us-west-2]
using endpoint [https://service.example.io] and region [eu-central-1]
using endpoint [http://127.0.0.1:5000] and region [local]
using endpoint [https://api.example.co.uk] and region [eu-west-1]
using endpoint [http://10.0.0.1:4000] and region [custom]
using endpoint [https://service.example.com.au] and region [ap-southeast-2]
using endpoint [http://example.net:9000] and region [us-east-2]
using endpoint [https://api.example.in] and region [ap-south-1]
using endpoint [http://localhost:7000] and region [local]
using endpoint [https://service.example.ca] and region [ca-central-1]
start primary shards for index products
start primary shards for index customers
start primary shards for index orders
start primary shards for index reviews
start primary shards for index inventory
start primary shards for index sales
start primary shards for index categories
start primary shards for index users
start primary shards for index blogs
start primary shards for index news
start primary shards for index events
start primary shards for index books
start primary shards for index movies
start primary shards for index music
start primary shards for index games
global-ordinals [title][123456] took [0.5ms]
global-ordinals [content][789012] took [1.2ms]
global-ordinals [author][345678] took [0.8ms]
global-ordinals [date][901234] took [0.6ms]
global-ordinals [category][567890] took [1.0ms]
global-ordinals [tag][210987] took [1.4ms]
global-ordinals [rating][654321] took [0.9ms]
global-ordinals [comment][987654] took [1.3ms]
global-ordinals [view][432109] took [0.7ms]
global-ordinals [like][876543] took [1.1ms]
global-ordinals [share][109876] took [0.4ms]
global-ordinals [status][765432] took [1.5ms]
global-ordinals [type][098765] took [0.3ms]
global-ordinals [source][654098] took [1.6ms]
global-ordinals [language][543210] took [0.2ms]
Local files = [file1.txt, file2.txt, file3.txt], Repo files = [file1.txt, file2.txt, file4.txt]
Local files = [file5.txt, file6.txt], Repo files = [file5.txt, file7.txt, file8.txt]
Local files = [file9.txt, file10.txt, file11.txt], Repo files = [file9.txt, file10.txt, file11.txt]
Local files = [file12.txt, file13.txt], Repo files = [file12.txt, file14.txt]
Local files = [file15.txt], Repo files = [file15.txt, file16.txt]
Local files = [file17.txt, file18.txt, file19.txt], Repo files = [file17.txt, file18.txt]
Local files = [file20.txt, file21.txt], Repo files = [file20.txt, file21.txt, file22.txt]
Local files = [file23.txt, file24.txt], Repo files = [file23.txt]
Local files = [file25.txt, file26.txt], Repo files = [file25.txt, file26.txt]
Local files = [], Repo files = [file27.txt, file28.txt]
Local files = [file29.txt], Repo files = []
Local files = [file30.txt], Repo files = [file30.txt]
Local files = [file31.txt, file32.txt], Repo files = [file31.txt]
Local files = [], Repo files = []
Local files = [file33.txt], Repo files = [file33.txt]
Keys in 'before' map: [name, age, gender]
Keys in 'before' map: [id, status, date]
Keys in 'before' map: [title, author, price]
Keys in 'before' map: [city, country, population]
Keys in 'before' map: [type, color, size]
Keys in 'before' map: [email, password, role]
Keys in 'before' map: [product, quantity, cost]
Keys in 'before' map: [student, grade, score]
Keys in 'before' map: [account, balance, transaction]
Keys in 'before' map: [car, model, year]
Keys in 'before' map: [animal, species, habitat]
Keys in 'before' map: [movie, genre, rating]
Keys in 'before' map: [food, calories, nutrition]
Keys in 'before' map: [book, category, review]
Keys in 'before' map: [song, artist, album]
Repository [test] closed during cool-down period
Repository [main] closed during cool-down period
Repository [dev] closed during cool-down period
Repository [backup] closed during cool-down period
Repository [docs] closed during cool-down period
Repository [config] closed during cool-down period
Repository [data] closed during cool-down period
Repository [logs] closed during cool-down period
Repository [images] closed during cool-down period
Repository [videos] closed during cool-down period
Repository [audio] closed during cool-down period
Repository [models] closed during cool-down period
Repository [scripts] closed during cool-down period
Repository [utils] closed during cool-down period
Repository [demo] closed during cool-down period
Failed to abort stream before closing: Connection reset by peer
Failed to abort stream before closing: Socket timeout exception
Failed to abort stream before closing: Null pointer exception
Failed to abort stream before closing: Stream closed unexpectedly
Failed to abort stream before closing: Out of memory error
Failed to abort stream before closing: Interrupted IO exception
Failed to abort stream before closing: Illegal state exception
Failed to abort stream before closing: File not found exception
Failed to abort stream before closing: Access denied exception
Failed to abort stream before closing: Unsupported operation exception
Failed to abort stream before closing: Class not found exception
Failed to abort stream before closing: No such element exception
Failed to abort stream before closing: Array index out of bounds exception
Failed to abort stream before closing: Number format exception
Failed to abort stream before closing: Invalid argument exception
--> waiting for block to kick in on clusterManagerNode-1
--> waiting for block to kick in on clusterManagerNode-5
--> waiting for block to kick in on clusterManagerNode-9
--> waiting for block to kick in on clusterManagerNode-12
--> waiting for block to kick in on clusterManagerNode-3
--> waiting for block to kick in on clusterManagerNode-7
--> waiting for block to kick in on clusterManagerNode-10
--> waiting for block to kick in on clusterManagerNode-14
--> waiting for block to kick in on clusterManagerNode-2
--> waiting for block to kick in on clusterManagerNode-6
--> waiting for block to kick in on clusterManagerNode-8
--> waiting for block to kick in on clusterManagerNode-11
--> waiting for block to kick in on clusterManagerNode-13
--> waiting for block to kick in on clusterManagerNode-4
--> waiting for block to kick in on clusterManagerNode-15
Keys to remove: [a, b, c]
Keys to remove: [x, y, z]
Keys to remove: [foo, bar, baz]
Keys to remove: [1, 2, 3]
Keys to remove: [red, green, blue]
Keys to remove: [apple, banana, orange]
Keys to remove: [cat, dog, mouse]
Keys to remove: [name, age, gender]
Keys to remove: [true, false, null]
Keys to remove: [hello, world, bye]
Keys to remove: [pi, e, phi]
Keys to remove: [A, B, C]
Keys to remove: [i, j, k]
Keys to remove: [star, moon, sun]
Keys to remove: [one, two, three]
0 failed to load shard path, trying to remove leftover
1 failed to load shard path, trying to remove leftover
2 failed to load shard path, trying to remove leftover
3 failed to load shard path, trying to remove leftover
4 failed to load shard path, trying to remove leftover
5 failed to load shard path, trying to remove leftover
6 failed to load shard path, trying to remove leftover
7 failed to load shard path, trying to remove leftover
8 failed to load shard path, trying to remove leftover
9 failed to load shard path, trying to remove leftover
10 failed to load shard path, trying to remove leftover
11 failed to load shard path, trying to remove leftover
12 failed to load shard path, trying to remove leftover
13 failed to load shard path, trying to remove leftover
14 failed to load shard path, trying to remove leftover
--> creating repository my_project at /home/user/my_project
--> creating repository test_repo at /tmp/test_repo
--> creating repository hello_world at /opt/hello_world
--> creating repository data_analysis at /data/data_analysis
--> creating repository blog at /var/www/blog
--> creating repository music_app at /usr/local/music_app
--> creating repository game_dev at /home/user/Documents/game_dev
--> creating repository machine_learning at /data/machine_learning
--> creating repository web_scraping at /home/user/web_scraping
--> creating repository chatbot at /opt/chatbot
--> creating repository portfolio at /var/www/portfolio
--> creating repository calculator at /usr/local/calculator
--> creating repository todo_list at /home/user/todo_list
--> creating repository image_processing at /data/image_processing
--> creating repository password_manager at /opt/password_manager
-->  create snapshot myRepo:backup1
-->  create snapshot testRepo:snapshot20211023
-->  create snapshot dataRepo:weeklyReport
-->  create snapshot demoRepo:version1.0
-->  create snapshot mainRepo:restorePoint
-->  create snapshot projectRepo:finalDraft
-->  create snapshot musicRepo:playlist1
-->  create snapshot photoRepo:album2
-->  create snapshot gameRepo:saveState3
-->  create snapshot blogRepo:post4
-->  create snapshot videoRepo:clip5
-->  create snapshot bookRepo:chapter6
-->  create snapshot codeRepo:bugFix7
-->  create snapshot artRepo:drawing8
-->  create snapshot workRepo:invoice9
Keys to add: 5
Keys to add: 12
Keys to add: 0
Keys to add: 8
Keys to add: 3
Keys to add: 10
Keys to add: 1
Keys to add: 7
Keys to add: 4
Keys to add: 9
Keys to add: 6
Keys to add: 11
Keys to add: 2
Keys to add: 13
Keys to add: 14
--> routed search on index [products] visited [5] shards for routing [category=electronics] and got hits [23]
--> routed search on index [users] visited [3] shards for routing [name=alice] and got hits [1]
--> routed search on index [orders] visited [4] shards for routing [status=pending] and got hits [12]
--> routed search on index [blogs] visited [6] shards for routing [tag=travel] and got hits [34]
--> routed search on index [books] visited [2] shards for routing [author=john] and got hits [7]
--> routed search on index [movies] visited [8] shards for routing [genre=comedy] and got hits [56]
--> routed search on index [products] visited [5] shards for routing [category=clothing] and got hits [45]
--> routed search on index [users] visited [3] shards for routing [name=bob] and got hits [0]
--> routed search on index [orders] visited [4] shards for routing [status=completed] and got hits [67]
--> routed search on index [blogs] visited [6] shards for routing [tag=food] and got hits [29]
--> routed search on index [books] visited [2] shards for routing [author=mary] and got hits [9]
--> routed search on index [movies] visited [8] shards for routing [genre=horror] and got hits [32]
--> routed search on index [products] visited [5] shards for routing [category=books] and got hits [18]
--> routed search on index [users] visited [3] shards for routing [name=charlie] and got hits [2]
--> indexing with id [1], and routing [user_123]
--> indexing with id [1], and routing [product_456]
--> indexing with id [1], and routing [order_789]
--> indexing with id [1], and routing [null]
--> indexing with id [1], and routing [category_abc]
--> indexing with id [1], and routing [review_def]
--> indexing with id [1], and routing [cart_ghi]
--> indexing with id [1], and routing [payment_jkl]
--> indexing with id [1], and routing [shipment_mno]
--> indexing with id [1], and routing [feedback_pqr]
--> indexing with id [1], and routing [coupon_stu]
--> indexing with id [1], and routing [wishlist_vwx]
--> indexing with id [1], and routing [profile_yz]
--> indexing with id [1], and routing [history_01]
--> indexing with id [1], and routing [recommendation_23]
[shard-0] closed (reason: shutdown)
[shard-1] closed (reason: timeout)
[shard-2] closed (reason: error)
[shard-3] closed (reason: restart)
[shard-4] closed (reason: maintenance)
[shard-5] closed (reason: overload)
[shard-6] closed (reason: crash)
[shard-7] closed (reason: upgrade)
[shard-8] closed (reason: network failure)
[shard-9] closed (reason: disk full)
[shard-10] closed (reason: corrupted data)
[shard-11] closed (reason: security breach)
[shard-12] closed (reason: power outage)
[shard-13] closed (reason: hardware failure)
--> indexing with id [user_123], and routing [email]
--> indexing with id [post_456], and routing [blog]
--> indexing with id [order_789], and routing [store]
--> indexing with id [comment_101], and routing [forum]
--> indexing with id [product_202], and routing [catalog]
--> indexing with id [event_303], and routing [calendar]
--> indexing with id [task_404], and routing [todo]
--> indexing with id [photo_505], and routing [gallery]
--> indexing with id [video_606], and routing [stream]
--> indexing with id [message_707], and routing [chat]
--> indexing with id [review_808], and routing [rating]
--> indexing with id [profile_909], and routing [social]
--> indexing with id [article_010], and routing [news]
--> indexing with id [song_111], and routing [music]
--> indexing with id [game_212], and routing [play]
[0] store not initialized prior to closing shard, nothing to close
[1] store not initialized prior to closing shard, nothing to close
[2] store not initialized prior to closing shard, nothing to close
[3] store not initialized prior to closing shard, nothing to close
[4] store not initialized prior to closing shard, nothing to close
[5] store not initialized prior to closing shard, nothing to close
[6] store not initialized prior to closing shard, nothing to close
[7] store not initialized prior to closing shard, nothing to close
[8] store not initialized prior to closing shard, nothing to close
[9] store not initialized prior to closing shard, nothing to close
[10] store not initialized prior to closing shard, nothing to close
[11] store not initialized prior to closing shard, nothing to close
[12] store not initialized prior to closing shard, nothing to close
[13] store not initialized prior to closing shard, nothing to close
[14] store not initialized prior to closing shard, nothing to close
--> search with 1234, 5678 indexRoutings , should find two1
--> search with 4321, 8765 indexRoutings , should find two1
--> search with 5678, 1234 indexRoutings , should find two1
--> search with 8765, 4321 indexRoutings , should find two1
--> search with 1357, 2468 indexRoutings , should find two1
--> search with 2468, 1357 indexRoutings , should find two1
--> search with 9753, 8642 indexRoutings , should find two1
--> search with 8642, 9753 indexRoutings , should find two1
--> search with 1598, 3579 indexRoutings , should find two1
--> search with 3579, 1598 indexRoutings , should find two1
--> search with 9512, 7531 indexRoutings , should find two1
--> search with 7531, 9512 indexRoutings , should find two1
--> search with 8526, 7413 indexRoutings , should find two1
--> search with 7413, 8526 indexRoutings , should find two1
--> search with 9632, 1478 indexRoutings , should find two1
--> indexing with id [2], and routing [null]
--> indexing with id [2], and routing [user_1]
--> indexing with id [2], and routing [product_5]
--> indexing with id [2], and routing [order_23]
--> indexing with id [2], and routing [category_7]
--> indexing with id [2], and routing [location_9]
--> indexing with id [2], and routing [date_2023-10-23]
--> indexing with id [2], and routing [status_active]
--> indexing with id [2], and routing [type_image]
--> indexing with id [2], and routing [tag_funny]
--> indexing with id [2], and routing [rating_4.5]
--> indexing with id [2], and routing [price_19.99]
--> indexing with id [2], and routing [color_red]
--> indexing with id [2], and routing [size_large]
--> indexing with id [2], and routing [brand_nike]
using preference dark mode
using preference metric system
using preference auto-save
using preference voice control
using preference notifications
using preference cloud sync
using preference night shift
using preference keyboard shortcuts
using preference accessibility
using preference language: English
using preference font size: 12pt
using preference theme: blue
using preference sound effects: on
using preference location services: off
using preference privacy: high
running iteration for id 5678, preference high
running iteration for id 4321, preference low
running iteration for id 9876, preference medium
running iteration for id 2468, preference high
running iteration for id 1357, preference low
running iteration for id 8642, preference medium
running iteration for id 9513, preference high
running iteration for id 7284, preference low
running iteration for id 6149, preference medium
running iteration for id 3927, preference high
running iteration for id 4856, preference low
running iteration for id 1763, preference medium
running iteration for id 8295, preference high
running iteration for id 5432, preference low
running iteration for id 7981, preference medium
checking error for runner 1
checking error for runner 2
checking error for runner 3
checking error for runner 4
checking error for runner 5
checking error for runner 6
checking error for runner 7
checking error for runner 8
checking error for runner 9
checking error for runner 10
checking error for runner 11
checking error for runner 12
checking error for runner 13
checking error for runner 14
checking error for runner 15
--> Testing out preference=dark
--> Testing out preference=light
--> Testing out preference=blue
--> Testing out preference=red
--> Testing out preference=green
--> Testing out preference=yellow
--> Testing out preference=purple
--> Testing out preference=orange
--> Testing out preference=pink
--> Testing out preference=black
--> Testing out preference=white
--> Testing out preference=gray
--> Testing out preference=brown
--> Testing out preference=gold
--> Testing out preference=silver
Explanation for [title] / [123] / ["The Lord of the Rings"] : [The document matched the query term in the title field with a high score]
Explanation for [author] / [456] / ["J.K. Rowling"] : [The document matched the query term in the author field with a moderate score]
Explanation for [content] / [789] / ["Once upon a time, there was a little girl who lived in a village near the forest."] : [The document matched the query term in the content field with a low score]
Explanation for [date] / [1011] / ["2021-10-23"] : [The document matched the query term in the date field with an exact match]
Explanation for [rating] / [1213] / ["4.5"] : [The document matched the query term in the rating field with a range query]
Explanation for [genre] / [1415] / ["Fantasy"] : [The document matched the query term in the genre field with a term query]
Explanation for [price] / [1617] / ["$19.99"] : [The document matched the query term in the price field with a numeric query]
Explanation for [publisher] / [1819] / ["Penguin Books"] : [The document matched the query term in the publisher field with a phrase query]
Explanation for [language] / [2021] / ["English"] : [The document matched the query term in the language field with a boolean query]
Explanation for [summary] / [2223] / ["A classic tale of adventure and friendship"] : [The document matched the query term in the summary field with a fuzzy query]
Explanation for [isbn] / [2425] / ["978-0-141-32037-9"] : [The document matched the query term in the isbn field with a wildcard query]
Explanation for [review] / [2627] / ["I loved this book! It was so engaging and well-written."] : [The document matched the query term in the review field with a proximity query]
Explanation for [keywords] / [2829] / ["magic, wizard, school"] : [The document matched the query term in the keywords field with a multi-term query]
Explanation for [format] / [3031] / ["Paperback"] : [The document matched the query term in the format field with a constant score query]
checking direct exception for runner_1
checking direct exception for runner_2
checking direct exception for runner_3
checking direct exception for runner_4
checking direct exception for runner_5
checking direct exception for runner_6
checking direct exception for runner_7
checking direct exception for runner_8
checking direct exception for runner_9
checking direct exception for runner_10
checking direct exception for runner_11
checking direct exception for runner_12
checking direct exception for runner_13
checking direct exception for runner_14
checking direct exception for runner_15
All shards failed with NullPointerException
All shards failed with TimeoutException
All shards failed with OutOfMemoryError
All shards failed with IOException
All shards failed with ElasticsearchException
All shards failed with IndexNotFoundException
All shards failed with IllegalArgumentException
All shards failed with SecurityException
All shards failed with ClusterBlockException
All shards failed with QueryShardException
All shards failed with ScriptException
All shards failed with ShardNotFoundException
All shards failed with SnapshotException
All shards failed with VersionConflictEngineException
All shards failed with CircuitBreakingException
Executing scroll with id 5f4a8c7b
Executing scroll with id 9e3d6f2a
Executing scroll with id 1b7c9d4e
Executing scroll with id 6a5e3f1c
Executing scroll with id 8d4c7a9b
Executing scroll with id 3f2e6d8a
Executing scroll with id 7c9b4e1d
Executing scroll with id 4e1d7c9b
Executing scroll with id 2a9f5e3c
Executing scroll with id 5e3c2a9f
Executing scroll with id 0d8a6f4e
Executing scroll with id 6f4e0d8a
Executing scroll with id 1c7b9e3d
Executing scroll with id 9e3d1c7b
Executing scroll with id 2f8c5a4b
d2: d2Builder-1.0.0
d2: d2Builder-2.3.4
d2: d2Builder-3.1.5
d2: d2Builder-4.4.4
d2: d2Builder-5.0.1
d2: d2Builder-6.6.6
d2: d2Builder-7.7.7
d2: d2Builder-8.8.8
d2: d2Builder-9.9.9
d2: d2Builder-10.10.10
d2: d2Builder-11.11.11
d2: d2Builder-12.12.12
d2: d2Builder-13.13.13
d2: d2Builder-14.14.14
d2: d2Builder-15.15.15
d1: (0, 0, 0)
d1: (1, 2, 3)
d1: (4, 5, 6)
d1: (7, 8, 9)
d1: (10, 11, 12)
d1: (13, 14, 15)
d1: (16, 17, 18)
d1: (19, 20, 21)
d1: (22, 23, 24)
d1: (25, 26, 27)
d1: (28, 29, 30)
d1: (31, 32, 33)
d1: (34, 35, 36)
d1: (37, 38, 39)
d1: (40, 41, 42)
--> blocking all data nodes for repository [backup]
--> blocking all data nodes for repository [test]
--> blocking all data nodes for repository [default]
--> blocking all data nodes for repository [logs]
--> blocking all data nodes for repository [images]
--> blocking all data nodes for repository [docs]
--> blocking all data nodes for repository [videos]
--> blocking all data nodes for repository [music]
--> blocking all data nodes for repository [data]
--> blocking all data nodes for repository [config]
--> blocking all data nodes for repository [cache]
--> blocking all data nodes for repository [temp]
--> blocking all data nodes for repository [users]
--> blocking all data nodes for repository [projects]
--> blocking all data nodes for repository [reports]
--> unblocking repository [my-app]
--> unblocking repository [data-analysis]
--> unblocking repository [web-design]
--> unblocking repository [machine-learning]
--> unblocking repository [game-dev]
--> unblocking repository [security-tools]
--> unblocking repository [blog-posts]
--> unblocking repository [math-problems]
--> unblocking repository [music-player]
--> unblocking repository [photo-editor]
--> unblocking repository [chat-bot]
--> unblocking repository [weather-app]
--> unblocking repository [crypto-currency]
--> unblocking repository [travel-guide]
--> unblocking repository [todo-list]
--> Shutting down initial primary node [node-1]
--> Shutting down initial primary node [node-7]
--> Shutting down initial primary node [node-12]
--> Shutting down initial primary node [node-3]
--> Shutting down initial primary node [node-9]
--> Shutting down initial primary node [node-4]
--> Shutting down initial primary node [node-10]
--> Shutting down initial primary node [node-2]
--> Shutting down initial primary node [node-8]
--> Shutting down initial primary node [node-11]
--> Shutting down initial primary node [node-5]
--> Shutting down initial primary node [node-6]
--> Shutting down initial primary node [node-13]
--> Shutting down initial primary node [node-14]
--> Shutting down initial primary node [node-15]
cluster discovered: [node1, node2, node3]
cluster discovered: [node4, node5, node6, node7]
cluster discovered: [node8, node9]
cluster discovered: [node10, node11, node12, node13]
cluster discovered: [node14, node15, node16]
cluster discovered: [node17, node18, node19, node20]
cluster discovered: [node21, node22]
cluster discovered: [node23, node24, node25, node26, node27]
cluster discovered: [node28, node29, node30]
cluster discovered: [node31, node32, node33]
cluster discovered: [node34, node35]
cluster discovered: [node36, node37, node38, node39]
cluster discovered: [node40, node41]
cluster discovered: [node42, node43, node44]
--> Shutting down new primary node [node-1]
--> Shutting down new primary node [node-5]
--> Shutting down new primary node [node-9]
--> Shutting down new primary node [node-12]
--> Shutting down new primary node [node-15]
--> Shutting down new primary node [node-18]
--> Shutting down new primary node [node-21]
--> Shutting down new primary node [node-24]
--> Shutting down new primary node [node-27]
--> Shutting down new primary node [node-30]
--> Shutting down new primary node [node-33]
--> Shutting down new primary node [node-36]
--> Shutting down new primary node [node-39]
--> Shutting down new primary node [node-42]
--> Shutting down new primary node [node-45]
cluster discovered: [node1, node2, node3]
cluster discovered: [node4, node5, node6, node7]
cluster discovered: [node8]
cluster discovered: [node9, node10, node11]
cluster discovered: [node12, node13]
cluster discovered: [node14, node15, node16, node17, node18]
cluster discovered: [node19, node20]
cluster discovered: [node21, node22, node23, node24]
cluster discovered: [node25, node26, node27]
cluster discovered: [node28, node29, node30]
cluster discovered: [node31, node32, node33, node34]
cluster discovered: [node35, node36]
cluster discovered: [node37, node38, node39]
cluster discovered: [node40, node41, node42]
cluster discovered: [node43]
moving primary to new node by excluding node1
moving primary to new node by excluding node5
moving primary to new node by excluding node3
moving primary to new node by excluding node7
moving primary to new node by excluding node2
moving primary to new node by excluding node9
moving primary to new node by excluding node4
moving primary to new node by excluding node6
moving primary to new node by excluding node8
moving primary to new node by excluding node10
moving primary to new node by excluding node12
moving primary to new node by excluding node11
moving primary to new node by excluding node14
moving primary to new node by excluding node13
moving primary to new node by excluding node15
--> restoring snapshot 2021-10-23 22:53:27
--> restoring snapshot 2021-10-22 18:45:12
--> restoring snapshot 2021-10-21 23:59:59
--> restoring snapshot 2021-10-20 12:34:56
--> restoring snapshot 2021-10-19 08:15:43
--> restoring snapshot 2021-10-18 16:27:39
--> restoring snapshot 2021-10-17 09:48:51
--> restoring snapshot 2021-10-16 14:36:24
--> restoring snapshot 2021-10-15 19:25:18
--> restoring snapshot 2021-10-14 11:11:11
--> restoring snapshot 2021-10-13 13:13:13
--> restoring snapshot 2021-10-12 15:15:15
--> restoring snapshot 2021-10-11 17:17:17
--> restoring snapshot 2021-10-10 21:21:21
Terminal.Verbosity.SILENT Silent output
Terminal.Verbosity.SILENT Silent output
Terminal.Verbosity.SILENT Silent output
Terminal.Verbosity.SILENT Silent output
Terminal.Verbosity.SILENT Silent output
Terminal.Verbosity.SILENT Silent output
Terminal.Verbosity.SILENT Silent output
Terminal.Verbosity.SILENT Silent output
Terminal.Verbosity.SILENT Silent output
Terminal.Verbosity.SILENT Silent output
Starting request
Starting request
Starting request
Starting request
Starting request
Starting request
Starting request
Starting request
Starting request
Starting request
Starting request
Starting request
Starting request
Starting request
Starting request
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
--> closing connections from source node to target node
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
Waiting for bulk rejections
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
--> closing connections from target node to source node
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
Waiting for the request to finish
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
--> starting recovery from blue to red
Some extra help
Some extra help
Some extra help
Some extra help
Some extra help
Some extra help
Some extra help
Some extra help
Some extra help
Some extra help
Some extra help
Some extra help
Some extra help
Some extra help
Some extra help
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newCurrentTermQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
resetting newStateQueued
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
Remote repository is not yet registered
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
--> adding two new healthy nodes
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
setting auto-shrink reconfiguration to true
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
-->  creating repository
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> changing health of newly added nodes to unhealthy
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> indexing some data
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> clearing rules to allow recovery to proceed
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> snapshot
--> delete index
--> delete index
--> delete index
--> delete index
--> delete index
--> delete index
--> delete index
--> delete index
--> delete index
--> delete index
--> delete index
--> delete index
--> delete index
--> delete index
--> delete index
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> create read-only URL repository
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> restore index after deletion
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> list available shapshots
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
--> delete snapshot
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
not recovering from gateway, no cluster-manager elected yet
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> starting replica recovery from blue to red
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> list available shapshot again, no snapshots should be returned
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
--> starting primary relocation recovery from blue to red
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
performing state recovery...
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
setting auto-shrink reconfiguration to false
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> remove replicas
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> index more documents
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
--> adding three new healthy nodes
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
cluster is already recovered
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> add replicas again
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 only
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> starting a node on ipv4 and ipv6
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
--> waiting for the cluster to declare itself stable
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
successful state recovery, importing cluster state...
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> checking if boundAddress matching publishAddress has same port
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> publishing another value
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Closing the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Opening the index
--> Close index
--> Close index
--> Close index
--> Close index
--> Close index
--> Close index
--> Close index
--> Close index
--> Close index
--> Close index
--> Close index
--> Close index
--> Close index
--> Close index
--> Close index
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> waiting for allocation to have shards assigned
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Collect all scroll query hits
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Create scroll query
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> Waiting for file copy
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> disconnecting all nodes
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
--> relocate the shard
validation successful
validation successful
validation successful
validation successful
validation successful
validation successful
validation successful
validation successful
validation successful
validation successful
validation successful
validation successful
validation successful
validation successful
validation successful
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
Verify older primary is still refreshing replica nodes
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> flush to have segments on disk
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> index more docs so there are ops in the transaction log
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> relocate the shard from primary to replica
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> creating first checker
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> verifying count
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> relocate the shard from primary to newPrimary
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> flush so we have some segment files on disk
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> running remaining tasks
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> index more docs so we have something in the translog
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> creating second checker
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
--> start empty node to add replica shard
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
Using basic session credentials
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
--> starting [Primary Node] ...
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
Using basic key/secret credentials
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
--> creating test index ...
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
Using either environment variables, system properties or instance profile credentials
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
--> index 10 docs
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
Generating new data key pair
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start primary node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start first replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
--> start second replica node
Creating index test
Creating index test
Creating index test
Creating index test
Creating index test
Creating index test
Creating index test
Creating index test
Creating index test
Creating index test
Creating index test
Creating index test
Creating index test
Creating index test
Creating index test
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
Increasing the number of replicas from 1 to 2
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
starting another node to new replicas will be allocated to it
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
Decreasing number of replicas from 2 to 0
[_global] state written
[_global] state written
[_global] state written
[_global] state written
[_global] state written
[_global] state written
[_global] state written
[_global] state written
[_global] state written
[_global] state written
[_global] state written
[_global] state written
[_global] state written
[_global] state written
[_global] state written
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> creating index test with auto expand replicas
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
--> running cluster health
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
got global metadata, now reading index metadata
--> start first node
--> start first node
--> start first node
--> start first node
--> start first node
--> start first node
--> start first node
--> start first node
--> start first node
--> start first node
--> start first node
--> start first node
--> start first node
--> start first node
--> start first node
--> start another node
--> start another node
--> start another node
--> start another node
--> start another node
--> start another node
--> start another node
--> start another node
--> start another node
--> start another node
--> start another node
--> start another node
--> start another node
--> start another node
--> start another node
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> add another node, should increase the number of replicas
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> adding five nodes on same zone_1
--> closing one node
--> closing one node
--> closing one node
--> closing one node
--> closing one node
--> closing one node
--> closing one node
--> closing one node
--> closing one node
--> closing one node
--> closing one node
--> closing one node
--> closing one node
--> closing one node
--> closing one node
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
using cache to retrieve node list
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> adding five nodes on same zone_2
--> closing another node
--> closing another node
--> closing another node
--> closing another node
--> closing another node
--> closing another node
--> closing another node
--> closing another node
--> closing another node
--> closing another node
--> closing another node
--> closing another node
--> closing another node
--> closing another node
--> closing another node
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
start building nodes list using Azure API
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> adding five nodes on same zone_3
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
--> creating index test with auto expand replicas set to 0-2
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
Azure discovery service has been disabled. Returning empty list of nodes.
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> adding cluster manager node on zone_1
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> add two more nodes
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> adding cluster manager node on zone_2
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> update the auto expand replicas to 0-3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding cluster manager node on zone_3
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
--> adding four data nodes on zone_1
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
clearing existing metadata
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_2
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
--> adding four data nodes on zone_3
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
updating global metadata doc
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> submit task to restore cluster-manager
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> waiting for listener to be called and cluster state being blocked
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> realising task to restore cluster-manager
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> creating test index that cannot be allocated
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> updating test index settings to allow allocation
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> deleting test index....
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
--> creating test index with invalid settings
no network address found. ignoring [web-server-01]...
no network address found. ignoring [db-server-03]...
no network address found. ignoring [app-server-05]...
no network address found. ignoring [mail-server-02]...
no network address found. ignoring [proxy-server-04]...
no network address found. ignoring [dns-server-01]...
no network address found. ignoring [ftp-server-03]...
no network address found. ignoring [ssh-server-02]...
no network address found. ignoring [ldap-server-04]...
no network address found. ignoring [vpn-server-05]...
no network address found. ignoring [firewall-server-01]...
no network address found. ignoring [load-balancer-server-03]...
no network address found. ignoring [backup-server-02]...
no network address found. ignoring [monitoring-server-04]...
no network address found. ignoring [logging-server-05]...
renewing connections
renewing connections
renewing connections
renewing connections
renewing connections
renewing connections
renewing connections
renewing connections
renewing connections
renewing connections
renewing connections
renewing connections
renewing connections
renewing connections
renewing connections
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
--> creating test index with valid settings
ClusterState: ([node_1, node_2, node_3], [index_1, index_2, index_3])
ClusterState: ([node_4, node_5, node_6], [index_4, index_5, index_6])
ClusterState: ([node_7, node_8, node_9], [index_7, index_8, index_9])
ClusterState: ([node_10, node_11, node_12], [index_10, index_11, index_12])
ClusterState: ([node_13, node_14, node_15], [index_13, index_14, index_15])
ClusterState: ([node_16, node_17, node_18], [index_16, index_17, index_18])
ClusterState: ([node_19, node_20, node_21], [index_19, index_20, index_21])
ClusterState: ([node_22, node_23, node_24], [index_22, index_23, index_24])
ClusterState: ([node_25, node_26, node_27], [index_25, index_26, index_27])
ClusterState: ([node_a, node_b, node_c], [index_a, index_b, index_c])
ClusterState: ([node_d, node_e, node_f], [index_d, index_e, index_f])
ClusterState: ([node_g, node_h, node_i], [index_g, index_h, index_i])
ClusterState: ([node_j, node_k, node_l], [index_j, index_k, index_l])
ClusterState: ([node_m, node_n, node_o], [index_m, index_n, index_o])
ClusterState: ([node_p, node_q, node_r], [index_p, index_q,
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: now optimize
test: test done
test: test done
test: test done
test: test done
test: test done
test: test done
test: test done
test: test done
test: test done
test: test done
test: test done
test: test done
test: test done
test: test done
test: test done
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
now, start one more node, check that rebalancing will happen because we set it to always
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
cannot write incremental state
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> force merging to a single segment
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> refreshing
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> verifying that cache size is 0
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> making sure that shard and its replica are allocated on node_1 and node_2
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
--> starting node server3
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
restart all the primary shards, replicas will start initializing
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
--> running cluster_health
start the replica shards
start the replica shards
start the replica shards
start the replica shards
start the replica shards
start the replica shards
start the replica shards
start the replica shards
start the replica shards
start the replica shards
start the replica shards
start the replica shards
start the replica shards
start the replica shards
start the replica shards
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
--> move shard from node_1 to node_3, and wait for relocation to finish
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
complete rebalancing
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
--> stopping disruption
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
closing PersistedClusterStateService.Writer
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
starting azure classic discovery plugin...
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
start all the primary shards, replicas will start initializing
rebalancing
rebalancing
rebalancing
rebalancing
rebalancing
rebalancing
rebalancing
rebalancing
rebalancing
rebalancing
rebalancing
rebalancing
rebalancing
rebalancing
rebalancing
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
creating an index with 1 shard, no replica
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
--> waiting for relocation to start
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
adding two nodes and performing rerouting
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
--> waiting for relocation to finish
start primary shard
start primary shard
start primary shard
start primary shard
start primary shard
start primary shard
start primary shard
start primary shard
start primary shard
start primary shard
start primary shard
start primary shard
start primary shard
start primary shard
start primary shard
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
--> relocation completed (but cluster state processing block still in place)
move the shard
move the shard
move the shard
move the shard
move the shard
move the shard
move the shard
move the shard
move the shard
move the shard
move the shard
move the shard
move the shard
move the shard
move the shard
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
prevent shard active request from being sent
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
finish moving the shard
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
--> building initial routing table
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
finding seed nodes ...
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> adding 3 nodes on same rack and do rerouting
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> making sure that shard is not allocated on server3
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-existent node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating to non-data node, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> allocating non-existing shard, should fail
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> making sure that shard and its replica exist on server1, server2 and server3
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> allocating non-existing index, should fail
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> starting node node_4
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> allocating empty primary with acceptDataLoss flag set to false
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> making sure that shard and its replica are allocated on server1 and server3 but not on server2
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> allocating stale primary with acceptDataLoss flag set to false
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> shutting down two random nodes
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> allocating empty primary with acceptDataLoss flag set to true
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> verifying index is red
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> start the primary shard
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on the primary shard node, should fail
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> allocate the replica shard on on the second node
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> start the replica shard
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> starting the two old nodes back
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> verify that we fail when there are no unassigned shards
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> waiting for the lost shard to be recovered
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> adding 3 nodes
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> allocating empty primary shard with accept_data_loss flag set to true
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
--> cancel primary allocation, make sure it fails...
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
Checking if shards aren't removed
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the relocation allocation
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel the primary being replicated, make sure it fails
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> cancel allocation of the replica shard
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> put template_1 and template_2
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> move the replica shard
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> explicitly delete template_1
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> cancel the move of the replica shard
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> put template_1 back
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> move the replica shard again
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> delete template*
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> cancel the source replica shard
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> delete * with no templates, make sure we don't get a failure
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
--> start the former target replica shard
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
Using default credentials provider
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> put template_1
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
--> cancel the primary allocation (with allow_primary set to true)
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Register _ec2_, _ec2:xxx_ network names
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
Local node is not elected cluster manager. Exiting
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> get template template_1
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> adding two nodes
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> get non-existing-template
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> executing move allocation command to non-data node
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> put template_2
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> executing move allocation command from non-data node
--> put template3
--> put template3
--> put template3
--> put template3
--> put template3
--> put template3
--> put template3
--> put template3
--> put template3
--> put template3
--> put template3
--> put template3
--> put template3
--> put template3
--> put template3
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
--> allocating same index primary in multiple commands should fail
en_US: IndexMetadata uploaded successfully for products
fr_FR: IndexMetadata uploaded successfully for livres
de_DE: IndexMetadata uploaded successfully for filme
es_ES: IndexMetadata uploaded successfully for noticias
it_IT: IndexMetadata uploaded successfully for sport
pt_BR: IndexMetadata uploaded successfully for viagens
nl_NL: IndexMetadata uploaded successfully for gezondheid
sv_SE: IndexMetadata uploaded successfully for spel
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> get template template_*
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> subsequent replica allocation fails as all configured replicas have been allocated
--> get all templates
--> get all templates
--> get all templates
--> get all templates
--> get all templates
--> get all templates
--> get all templates
--> get all templates
--> get all templates
--> get all templates
--> get all templates
--> get all templates
--> get all templates
--> get all templates
--> get all templates
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded1'
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
There is no valid previous cluster UUID
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> get templates template_1 and template_2
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> adding two nodes on same rack and do rerouting
--> get template null
--> get template null
--> get template null
--> get template null
--> get template null
--> get template null
--> get template null
--> get template null
--> get template null
--> get template null
--> get template null
--> get template null
--> get template null
--> get template null
--> get template null
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> start the shards (primaries)
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> get template empty
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> start the shards (replicas)
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> get template 'a', '', 'c'
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> add a new node with a new rack and reroute
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> get template 'a', null, 'c'
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> complete relocation
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
--> do another reroute, make sure nothing moves
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
Delete stale cluster metadata task is already in progress.
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
--> add another node with a new rack, make sure nothing moves
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded2'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded3'
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
waiting for the tasks to be running
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disable persistent tasks assignment
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
disabling GCE discovery. Can not get list of nodes
restart the cluster
restart the cluster
restart the cluster
restart the cluster
restart the cluster
restart the cluster
restart the cluster
restart the cluster
restart the cluster
restart the cluster
restart the cluster
restart the cluster
restart the cluster
restart the cluster
restart the cluster
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
persistent tasks assignment is still disabled
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
No stale Remote Cluster Metadata files found
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
persistent tasks are not assigned
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
enable persistent tasks assignment
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
Complete all tasks
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> complete initializing
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
--> run it again, since we still might have relocation
Failing the running task
Failing the running task
Failing the running task
Failing the running task
Failing the running task
Failing the running task
Failing the running task
Failing the running task
Failing the running task
Failing the running task
Failing the running task
Failing the running task
Failing the running task
Failing the running task
Failing the running task
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
--> add another node with a new rack, some more relocation should happen
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
using cache to retrieve client
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded4'
unassignedShard[0]: ignoring allocation, can't be allocated on any node
unassignedShard[1]: ignoring allocation, can't be allocated on any node
unassignedShard[2]: ignoring allocation, can't be allocated on any node
unassignedShard[3]: ignoring allocation, can't be allocated on any node
unassignedShard[4]: ignoring allocation, can't be allocated on any node
unassignedShard[5]: ignoring allocation, can't be allocated on any node
unassignedShard[6]: ignoring allocation, can't be allocated on any node
unassignedShard[7]: ignoring allocation, can't be allocated on any node
unassignedShard[8]: ignoring allocation, can't be allocated on any node
unassignedShard[9]: ignoring allocation, can't be allocated on any node
unassignedShard[10]: ignoring allocation, can't be allocated on any node
unassignedShard[11]: ignoring allocation, can't be allocated on any node
unassignedShard[12]: ignoring allocation, can't be allocated on any node
unassignedShard[13]: ignoring allocation, can't be allocated on any node
unassignedShard[14]: ignoring allocation, can't be allocated on any node
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Simulating errant completion notification
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded5'
Updating the task states
Updating the task states
Updating the task states
Updating the task states
Updating the task states
Updating the task states
Updating the task states
Updating the task states
Updating the task states
Updating the task states
Updating the task states
Updating the task states
Updating the task states
Updating the task states
Updating the task states
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
--> add another node with a new rack, we will have another relocation
Completing the running task
Completing the running task
Completing the running task
Completing the running task
Completing the running task
Completing the running task
Completing the running task
Completing the running task
Completing the running task
Completing the running task
Completing the running task
Completing the running task
Completing the running task
Completing the running task
Completing the running task
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
starting GCE discovery service
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
--> make sure another reroute does not move things
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Cancelling the running task
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'moveShardOnceNewNodeWithAttributeAdded6'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
Building initial routing table for 'fullAwareness1'
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
--> replica will not start because we have only one rack value
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
Building initial routing table for 'fullAwareness2'
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
--> now start adding nodes
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
Building initial routing table for 'fullAwareness3'
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
--> refreshing and checking data
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
Building initial routing table for 'testUnbalancedZones'
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> stopped two nodes, verifying data
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> adding two nodes in different zones and do rerouting
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> one node left, verifying data
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> all replicas are allocated and started since we have on node in each zone
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> add a new node in zone 'a' and reroute
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
--> starting initializing shards on the new node
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> adding 5 nodes in different zones and do rerouting
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
--> start the shard (primary)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
configure GceModule (bind compute service)
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
--> all replicas are allocated and started since we have one node in each zone and rack
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
Building initial routing table for 'testAllocationExplainForUnassignedShardsWithUnbalancedZones'
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
start building nodes list using GCE API
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
--> adding 3 nodes in different zones and do rerouting
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
Expected assertion failure
0 shard state info found: [null]
1 shard state info found: [active]
2 shard state info found: [inactive]
3 shard state info found: [rebuilding]
4 shard state info found: [corrupted]
5 shard state info found: [unknown]
6 shard state info found: [active, version=1.2.3]
7 shard state info found: [inactive, version=1.2.4]
8 shard state info found: [rebuilding, version=1.2.5]
9 shard state info found: [corrupted, version=1.2.6]
10 shard state info found: [unknown, version=1.2.7]
11 shard state info found: [active, version=1.3.0, size=10MB]
12 shard state info found: [inactive, version=1.3.1, size=20MB]
13 shard state info found: [rebuilding, version=1.3.2, size=30MB]
14 shard state info found: [corrupted, version=1.3.3, size=40MB]
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
Unexpected assertion failure
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
now, start 1 more node, check that rebalancing will happen because we set it to always
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
use the new allocator and check if it moves shards
exception while closing channels java.io.IOException: Broken pipe
exception while closing channels java.lang.NullPointerException: null
exception while closing channels java.net.SocketException: Connection reset
exception while closing channels java.nio.channels.ClosedChannelException
exception while closing channels java.lang.IllegalStateException: Channel already closed
exception while closing channels java.lang.InterruptedException: Interrupted while waiting for channel to close
exception while closing channels java.util.concurrent.TimeoutException: Timeout exceeded while closing channel
exception while closing channels java.lang.RuntimeException: Unexpected error while closing channel
exception while closing channels java.io.EOFException: End of file reached before channel closed
exception while closing channels java.net.SocketTimeoutException: Read timed out
exception while closing channels javax.net.ssl.SSLException: SSL handshake failed
exception while closing channels java.io.FileNotFoundException: File not found
exception while closing channels java.lang.SecurityException: Permission denied
exception while closing channels java.io.UnsupportedEncodingException: Invalid encoding
exception while closing channels org.apache.commons.compress.archivers.ArchiveException: Archive format not supported
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Building initial routing table
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 1
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
Identity plugins size is 0
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
No auth token could be extracted
Line [34]: NullPointerException
Line [12]: ArrayIndexOutOfBoundsException
Line [56]: ArithmeticException
Line [78]: IOException
Line [23]: NumberFormatException
Line [45]: ClassNotFoundException
Line [67]: FileNotFoundException
Line [89]: SQLException
Line [11]: IllegalArgumentException
Line [32]: SecurityException
Line [54]: OutOfMemoryError
Line [76]: StackOverflowError
Line [98]: AssertionError
Line [21]: MalformedURLException
Line [43]: UnknownHostException
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> flushing the index ....
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> allow 2 nodes for index [test] ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> waiting for GREEN health status ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> marking and waiting for indexing threads to stop ...
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> indexing threads stopped
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> refreshing the index
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> verifying indexed content
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 4 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> allow 3 nodes for index [test] ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> waiting for relocations ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> allow 1 nodes for index [test] ...
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
--> bump up number of replicas to 1 and allow all nodes to hold the index
start two nodes
start two nodes
start two nodes
start two nodes
start two nodes
start two nodes
start two nodes
start two nodes
start two nodes
start two nodes
start two nodes
start two nodes
start two nodes
start two nodes
start two nodes
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start all the primary shards for test1, replicas will start initializing
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
start the test1 replica shards
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
now, start 1 more node, check that rebalancing will happen (for test1) because we set it to always
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
start all the primary shards for test2, replicas will start initializing
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to primaries_active
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
start the test2 replica shards
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
now, start 1 more node, check that rebalancing will not happen (for test1) because we set it to all_active
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
start all the primary shards for test
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
now, start 1 more node, check that rebalancing will not happen since we unassigned shards
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
reroute and check that nothing has changed
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start previous cluster-manager node again
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (1)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> start cluster-manager node (2)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> closing cluster-manager node (1)
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> start cluster-manager node / non data
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
--> creating index [test] with one shard and on replica
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
shutting down indexers
Indexing exceptions during disruption: sb-1
Indexing exceptions during disruption: sb-2
Indexing exceptions during disruption: sb-3
Indexing exceptions during disruption: sb-4
Indexing exceptions during disruption: sb-5
Indexing exceptions during disruption: sb-6
Indexing exceptions during disruption: sb-7
Indexing exceptions during disruption: sb-8
Indexing exceptions during disruption: sb-9
Indexing exceptions during disruption: sb-10
Indexing exceptions during disruption: sb-11
Indexing exceptions during disruption: sb-12
Indexing exceptions during disruption: sb-13
Indexing exceptions during disruption: sb-14
Indexing exceptions during disruption: sb-15
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
waiting for indexing requests to complete
stopping disruption
stopping disruption
stopping disruption
stopping disruption
stopping disruption
stopping disruption
stopping disruption
stopping disruption
stopping disruption
stopping disruption
stopping disruption
stopping disruption
stopping disruption
stopping disruption
stopping disruption
validating successful docs
validating successful docs
validating successful docs
validating successful docs
validating successful docs
validating successful docs
validating successful docs
validating successful docs
validating successful docs
validating successful docs
validating successful docs
validating successful docs
validating successful docs
validating successful docs
validating successful docs
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
waiting for nodes to elect a new cluster-manager
issue a reroute
issue a reroute
issue a reroute
issue a reroute
issue a reroute
issue a reroute
issue a reroute
issue a reroute
issue a reroute
issue a reroute
issue a reroute
issue a reroute
issue a reroute
issue a reroute
issue a reroute
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
OpenSearch keystore password changed successfully.
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
waiting for cluster to reform
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
applying disruption while cluster is forming ...
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election to make sure "preferred" cluster-manager is elected
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
--> forcing a complete election again
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
healing partition and checking cluster reforms
injecting failures
injecting failures
injecting failures
injecting failures
injecting failures
injecting failures
injecting failures
injecting failures
injecting failures
injecting failures
injecting failures
injecting failures
injecting failures
injecting failures
injecting failures
stopping indexing
stopping indexing
stopping indexing
stopping indexing
stopping indexing
stopping indexing
stopping indexing
stopping indexing
stopping indexing
stopping indexing
stopping indexing
stopping indexing
stopping indexing
stopping indexing
stopping indexing
full cluster restart
full cluster restart
full cluster restart
full cluster restart
full cluster restart
full cluster restart
full cluster restart
full cluster restart
full cluster restart
full cluster restart
full cluster restart
full cluster restart
full cluster restart
full cluster restart
full cluster restart
stopping failures
stopping failures
stopping failures
stopping failures
stopping failures
stopping failures
stopping failures
stopping failures
stopping failures
stopping failures
stopping failures
stopping failures
stopping failures
stopping failures
stopping failures
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for global checkpoint sampler
waiting for green
waiting for green
waiting for green
waiting for green
waiting for green
waiting for green
waiting for green
waiting for green
waiting for green
waiting for green
waiting for green
waiting for green
waiting for green
waiting for green
waiting for green
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting disruption
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> starting snapshot
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> waiting for disruption to start
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> verify that snapshot was successful or no longer exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> done verifying, snapshot doesn't exist
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> stopping disrupting
--> done
--> done
--> done
--> done
--> done
--> done
--> done
--> done
--> done
--> done
--> done
--> done
--> done
--> done
--> done
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
--> recreate the index with potentially different shard counts
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
Nothing to publish. What is already published matches this node's view.
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> run a snapshot that fails to finalize but succeeds on the data node
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> create a snapshot expected to be successful
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> making sure snapshot delete works out cleanly
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
--> create snapshot via cluster-manager node client
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
no nodes to set, nodes will be updated at the next sniffing round
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
I am no longer master, nothing to do
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
--> make sure isolated cluster-manager responds to snapshot request
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Exiting without modifying keystore.
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
Terminal.Verbosity.NORMAL Keystore is password-protected
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
--> done verifying, snapshot exists
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
Exiting without creating keystore.
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
--> stopping current cluster-manager
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
Plugins are packaged as zip files. Each packaged plugin must contain a plugin properties file.
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
The install command takes a plugin id, which may be any of the following:
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
An official opensearch plugin name
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
--> waiting for cluster-manager to remove it
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
Maven coordinates to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A URL to a plugin zip
A local zip file
A local zip file
A local zip file
A local zip file
A local zip file
A local zip file
A local zip file
A local zip file
A local zip file
A local zip file
A local zip file
A local zip file
A local zip file
A local zip file
A local zip file
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
The following official plugins may be installed by name:
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
Creating index [test1] with alias [test]
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
lifecycle is stopping. exiting
--> creating index test
--> creating index test
--> creating index test
--> creating index test
--> creating index test
--> creating index test
--> creating index test
--> creating index test
--> creating index test
--> creating index test
--> creating index test
--> creating index test
--> creating index test
--> creating index test
--> creating index test
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Indexing [type1/1]
Refreshing
Refreshing
Refreshing
Refreshing
Refreshing
Refreshing
Refreshing
Refreshing
Refreshing
Refreshing
Refreshing
Refreshing
Refreshing
Refreshing
Refreshing
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
--> index exists?, fake index
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Clearing cache
Force Merging
Force Merging
Force Merging
Force Merging
Force Merging
Force Merging
Force Merging
Force Merging
Force Merging
Force Merging
Force Merging
Force Merging
Force Merging
Force Merging
Force Merging
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
failed to schedule process
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1]
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/1] with script
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
Get [type1/2] (should be empty)
[WorkerThread-1]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-2]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-3]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-4]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-5]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-6]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-7]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-8]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-9]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-10]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-11]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-12]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-13]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-14]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
[WorkerThread-15]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Delete [type1/1]
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
Get [type1/1] (should be empty)
[snapshot] finalizing snapshot in repository, state: [SUCCESS], failure[null]
[snapshot] finalizing snapshot in repository, state: [FAILED], failure[IOException]
[snapshot] finalizing snapshot in repository, state: [ABORTED], failure[InterruptedException]
[snapshot] finalizing snapshot in repository, state: [PARTIAL], failure[TimeoutException]
[snapshot] finalizing snapshot in repository, state: [IN_PROGRESS], failure[null]
[snapshot] finalizing snapshot in repository, state: [FAILED], failure[OutOfMemoryError]
[snapshot] finalizing snapshot in repository, state: [SUCCESS], failure[null]
[snapshot] finalizing snapshot in repository, state: [FAILED], failure[SecurityException]
[snapshot] finalizing snapshot in repository, state: [ABORTED], failure[IllegalStateException]
[snapshot] finalizing snapshot in repository, state: [PARTIAL], failure[NetworkException]
[snapshot] finalizing snapshot in repository, state: [IN_PROGRESS], failure[null]
[snapshot] finalizing snapshot in repository, state: [FAILED], failure[FileNotFoundException]
[snapshot] finalizing snapshot in repository, state: [SUCCESS], failure[null]
[snapshot] finalizing snapshot in repository, state: [FAILED], failure[NullPointerException]
[snapshot] finalizing snapshot in repository, state: [ABORTED], failure[AssertionError]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/1]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Index [type1/2]
Flushing
Flushing
Flushing
Flushing
Flushing
Flushing
Flushing
Flushing
Flushing
Flushing
Flushing
Flushing
Flushing
Flushing
Flushing
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
Get [type1/1] and [type1/2]
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
-> running Cluster Health
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
Warning: sha512 not found, falling back to sha1. This behavior is deprecated and will be removed in a future release. Please update the plugin to use a sha512 checksum.
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> starting one node
--> creating index
--> creating index
--> creating index
--> creating index
--> creating index
--> creating index
--> creating index
--> creating index
--> creating index
--> creating index
--> creating index
--> creating index
--> creating index
--> creating index
--> creating index
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
searching in other folders to find if plugin exists with custom folder name
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> restarting the node without the data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
--> start the node again with data and cluster-manager roles
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
adding snapshot completion listener to wait for deleted snapshot to finish
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
--> indexing a simple document
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
deleted snapshot completed - deleting files
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> restarting the node without the data role
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> starting two nodes
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
--> restarting node with node.data=false and node.master=false
cluster-manager failover before deleted snapshot could complete: NullPointerException
cluster-manager failover before deleted snapshot could complete: TimeoutException
cluster-manager failover before deleted snapshot could complete: IOException
cluster-manager failover before deleted snapshot could complete: OutOfMemoryError
cluster-manager failover before deleted snapshot could complete: IllegalStateException
cluster-manager failover before deleted snapshot could complete: InterruptedException
cluster-manager failover before deleted snapshot could complete: AssertionError
cluster-manager failover before deleted snapshot could complete: ClassNotFoundException
cluster-manager failover before deleted snapshot could complete: NoSuchMethodError
cluster-manager failover before deleted snapshot could complete: StackOverflowError
cluster-manager failover before deleted snapshot could complete: NoClassDefFoundError
cluster-manager failover before deleted snapshot could complete: NoSuchFieldError
cluster-manager failover before deleted snapshot could complete: NumberFormatException
cluster-manager failover before deleted snapshot could complete: ArrayIndexOutOfBoundsException
cluster-manager failover before deleted snapshot could complete: ArithmeticException
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
Looking for an elasticsearch installation ...
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Repurposing node 1
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Starting node after repurpose
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> Restarting and repurposing other node
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> starting 1 nodes
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> creating test index, with meta routing
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
--> verify meta _routing required exists
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
Importing JVM options ...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> restarting nodes...
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> waiting for yellow status
--> creating test index
--> creating test index
--> creating test index
--> creating test index
--> creating test index
--> creating test index
--> creating test index
--> creating test index
--> creating test index
--> creating test index
--> creating test index
--> creating test index
--> creating test index
--> creating test index
--> creating test index
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
Importing keystore settings ...
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
--> waiting for green status
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
No elasticsearch keystore settings to import.
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
--> closing test index...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
Importing log4j.properties ...
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
--> verifying that the state is green
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
Importing settings from elasticsearch.yml ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
--> trying to index into a closed index ...
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
Import settings cancelled by user
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
--> creating another index (test2) by indexing into it
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
Installing core plugins ...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> opening the first index again...
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> trying to get the indexed document on the first index
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> waiting for two nodes and green status
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> opening index...
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
--> trying to get the indexed document on the first round (before close and shutdown)
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
Stop the running elasticsearch on this node.
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
--> cleaning nodes
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
Start OpenSearch on this node.
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
--> starting 1 cluster-manager node non data
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
Verifying the details ...
--> create an index
--> create an index
--> create an index
--> create an index
--> create an index
--> create an index
--> create an index
--> create an index
--> create an index
--> create an index
--> create an index
--> create an index
--> create an index
--> create an index
--> create an index
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
Unable to detect installed elasticsearch version.
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
--> restarting cluster-manager node
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
OpenSearch config directory is set inside the installation directory. It is recommended to use an external config directory and set the environment variable OPENSEARCH_PATH_CONF to it.
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
--> waiting for test index to be created
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
+----------------------- SUMMARY -----------------------+
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> verify we have an index
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
--> opening the index...
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
Please verify if everything above looks good.
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> restart a random date node, deleting the index in between stopping and restarting
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> delete index and verify it is deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> index deleted
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> wait until all nodes are back online
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node
Unable to retrieve available index folders from the node Error: Connection refused
Unable to retrieve available index folders from the node Error: Invalid credentials
Unable to retrieve available index folders from the node Error: Timeout
Unable to retrieve available index folders from the node Error: No such file or directory
Unable to retrieve available index folders from the node Error: Permission denied
Unable to retrieve available index folders from the node Error: Out of memory
Unable to retrieve available index folders from the node Error: Disk full
Unable to retrieve available index folders from the node Error: Network unreachable
Unable to retrieve available index folders from the node Error: File corrupted
Unable to retrieve available index folders from the node Error: Index locked
Unable to retrieve available index folders from the node Error: Node offline
Unable to retrieve available index folders from the node Error: Node overloaded
Unable to retrieve available index folders from the node Error: Node incompatible
Unable to retrieve available index folders from the node Error: Node not found
Unable to retrieve available index folders from the node Error: Unknown error
relocating index...
relocating index...
relocating index...
relocating index...
relocating index...
relocating index...
relocating index...
relocating index...
relocating index...
relocating index...
relocating index...
relocating index...
relocating index...
relocating index...
relocating index...
not active
not active
not active
not active
not active
not active
not active
not active
not active
not active
not active
not active
not active
not active
not active
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for green index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> wait for meta state written for index
--> close index
--> close index
--> close index
--> close index
--> close index
--> close index
--> close index
--> close index
--> close index
--> close index
--> close index
--> close index
--> close index
--> close index
--> close index
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> restart all nodes
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
--> running cluster_health (wait for the shards to startup)
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
checking for jar hell...
no jar hell found
no jar hell found
no jar hell found
no jar hell found
no jar hell found
no jar hell found
no jar hell found
no jar hell found
no jar hell found
no jar hell found
no jar hell found
no jar hell found
no jar hell found
no jar hell found
no jar hell found
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> one node is closed -- index 1 document into the remaining nodes
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> all nodes are started back, verifying we got the latest version
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (1)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (2)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start node (3)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start cluster_manager_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (1)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start data_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
--> start cluster_manager_node (2)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Running Cluster Health (wait for the shards to startup)
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
Ensure all primaries have been started
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> closing first node, and indexing more data to the second node
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> one node is closed - start indexing data into the second one
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> refreshing all indices after indexing is complete
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> checking if documents exist, there should be 3
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> add some metadata and additional template
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> stopping the second node
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> starting the two nodes back
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> indexing docs
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> restart replica node
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> non realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, implicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no source, explicit)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime get 1 (no type)
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> realtime fetch of field & source
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> refresh the index, so we load it from it
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> highlighting and searching on field0
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> non realtime get 1 (loaded from index)
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> highlighting and searching on field1
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> realtime fetch of field (loaded from index)
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> highlighting and searching on field4
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> realtime fetch of field & source (loaded from index)
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
--> update doc 1 again
indexing documents
indexing documents
indexing documents
indexing documents
indexing documents
indexing documents
indexing documents
indexing documents
indexing documents
indexing documents
indexing documents
indexing documents
indexing documents
indexing documents
indexing documents
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
checking real time retrieval
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
Resource stats already updated.
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
waiting for recoveries to complete
flushing
flushing
flushing
flushing
flushing
flushing
flushing
flushing
flushing
flushing
flushing
flushing
flushing
flushing
flushing
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
checking post-flush retrieval
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
// This file is auto-generated. Do not edit.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
The following API is available in all contexts.
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
==== Static Methods
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
The following methods are directly callable without a class/instance qualifier. Note parameters denoted by a (*) are treated as read-only values.
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
==== Classes By Package
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
The following classes are available grouped by their respective packages. Click on a class to view details about the available methods and fields.
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
include::packages.asciidoc[]
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index closed, re-opening...
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
--> index re-opened
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
[cols="<3,^3,^3"]
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
--> settings updated and files moved, re-opening index
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Remote clusters initialized successfully.
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
Connection validation was skipped
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> performed extra flushing on replica
--> restarting node
--> restarting node
--> restarting node
--> restarting node
--> restarting node
--> restarting node
--> restarting node
--> restarting node
--> restarting node
--> restarting node
--> restarting node
--> restarting node
--> restarting node
--> restarting node
--> restarting node
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-search. Clean-up of file cache and corresponding index metadata will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
Node is being re-purposed as no-cluster-manager and no-data. Clean-up of index data will be performed.
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
percolating empty doc
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
Node is being re-purposed as no-cluster-manager, no-data and no-search. Clean-up of index data and file cache will be performed.
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
percolating doc with 1 field
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
Node successfully repurposed to no-cluster-manager and no-search.
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
percolating doc with 2 fields
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager and no-data.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
Node successfully repurposed to no-cluster-manager, no-data and no-search.
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
percolating empty doc with source disabled
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-search. Clean-up of file cache data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
Node is being re-purposed as cluster-manager and no-data. Clean-up of shard data will be performed.
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
--> starting the replica node to test recovery
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node is being re-purposed as cluster-manager, no-data and no-search. Clean-up of shard data and file cache data will be performed.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-search.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager and no-data.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
Node successfully repurposed to cluster-manager, no-data and no-search.
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> corrupting translog
--> starting node
--> starting node
--> starting node
--> starting node
--> starting node
--> starting node
--> starting node
--> starting node
--> starting node
--> starting node
--> starting node
--> starting node
--> starting node
--> starting node
--> starting node
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
--> cluster has [3] data nodes, corrupted primary will be overwritten
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
Use -v to see list of paths and indices affected
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
No response from extension to request.
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Awaiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
Done waiting for all actions to start
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
ExtensionsManager initialized
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Simulate issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
--> Done simulating issuing cancel request on the node that is about to leave the cluster
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Interrupted while waiting for corruption
Registering: GET /users/John
Registering: POST /products/Apple
Registering: PUT /orders/1234
Registering: DELETE /comments/5678
Registering: PATCH /settings/DarkMode
Registering: HEAD /images/logo.png
Registering: OPTIONS /api/docs
Registering: TRACE /debug/info
Registering: CONNECT /proxy/https
Registering: COPY /files/report.docx
Registering: MOVE /folders/photos
Registering: LINK /resources/css
Registering: UNLINK /resources/js
Registering: LOCK /accounts/admin
[task1]: finishing early because the task was cancelled
[task2]: finishing early because the task was cancelled
[task3]: finishing early because the task was cancelled
[task4]: finishing early because the task was cancelled
[task5]: finishing early because the task was cancelled
[task6]: finishing early because the task was cancelled
[task7]: finishing early because the task was cancelled
[task8]: finishing early because the task was cancelled
[task9]: finishing early because the task was cancelled
[task10]: finishing early because the task was cancelled
[task11]: finishing early because the task was cancelled
[task12]: finishing early because the task was cancelled
[task13]: finishing early because the task was cancelled
[task14]: finishing early because the task was cancelled
[task15]: finishing early because the task was cancelled
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
Throw ConnectTransportException
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
found a duplicate id:
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
will not print anymore in case more duplicates are found.
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
Checking currently running tasks
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
verifying indexed content
search for all docs types failed: TimeoutError
search for all docs types failed: PermissionError
search for all docs types failed: FileNotFoundError
search for all docs types failed: MemoryError
search for all docs types failed: ConnectionError
search for all docs types failed: KeyError
search for all docs types failed: ValueError
search for all docs types failed: SyntaxError
search for all docs types failed: NameError
search for all docs types failed: IndexError
search for all docs types failed: AttributeError
search for all docs types failed: ImportError
search for all docs types failed: OSError
search for all docs types failed: ZeroDivisionError
search for all docs types failed: AssertionError
[123]: refreshing
[123]: refreshing
[456]: refreshing
[789]: refreshing
[1011]: refreshing
[1213]: refreshing
[1415]: refreshing
[1617]: refreshing
[1819]: refreshing
[2021]: refreshing
[2223]: refreshing
[2425]: refreshing
[2627]: refreshing
[2829]: refreshing
[3031]: refreshing
[3233]: refreshing
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
Throwing exception from taskOperation
running search with all types
running search with all types
running search with all types
running search with all types
running search with all types
running search with all types
running search with all types
running search with all types
running search with all types
running search with all types
running search with all types
running search with all types
running search with all types
running search with all types
running search with all types
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
Calling listener synchronously with exception from taskOperation
[1234]: finishing without any catastrophic failures
[123]: finishing without any catastrophic failures
[456]: finishing without any catastrophic failures
[789]: finishing without any catastrophic failures
[1011]: finishing without any catastrophic failures
[1213]: finishing without any catastrophic failures
[1415]: finishing without any catastrophic failures
[1617]: finishing without any catastrophic failures
[1819]: finishing without any catastrophic failures
[2021]: finishing without any catastrophic failures
[2223]: finishing without any catastrophic failures
[2425]: finishing without any catastrophic failures
[2627]: finishing without any catastrophic failures
[2829]: finishing without any catastrophic failures
[3031]: finishing without any catastrophic failures
[3233]: finishing without any catastrophic failures
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
Calling listener asynchronously with exception from taskOperation
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
No extension found for remote reindex listener
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
running search with a specific type
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
ReindexPlugin reloadSPI called
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the documents are there
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
checking all the fields are in the mappings
starting to wait
starting to wait
starting to wait
starting to wait
starting to wait
starting to wait
starting to wait
starting to wait
starting to wait
starting to wait
starting to wait
starting to wait
starting to wait
starting to wait
starting to wait
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
--> resetting breaker settings
timed out
timed out
timed out
timed out
timed out
timed out
timed out
timed out
timed out
timed out
timed out
timed out
timed out
timed out
timed out
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
--> noop breakers used, skipping test
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Unable to find any implementation for RemoteReindexExtension
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation failed - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Index creation timed out waiting for primaries to start - only index one doc and expect searches to fail
Start Refresh
Start Refresh
Start Refresh
Start Refresh
Start Refresh
Start Refresh
Start Refresh
Start Refresh
Start Refresh
Start Refresh
Start Refresh
Start Refresh
Start Refresh
Start Refresh
Start Refresh
--> simulating failure on replica with [NullPointerException]
--> simulating failure on replica with [IOException]
--> simulating failure on replica with [TimeoutException]
--> simulating failure on replica with [IndexOutOfBoundsException]
--> simulating failure on replica with [ArithmeticException]
--> simulating failure on replica with [ClassNotFoundException]
--> simulating failure on replica with [SQLException]
--> simulating failure on replica with [NumberFormatException]
--> simulating failure on replica with [ConcurrentModificationException]
--> simulating failure on replica with [IllegalStateException]
--> simulating failure on replica with [NoSuchElementException]
--> simulating failure on replica with [UnsupportedOperationException]
--> simulating failure on replica with [IllegalArgumentException]
--> simulating failure on replica with [SecurityException]
--> simulating failure on replica with [OutOfMemoryError]
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
Shut down remote connection
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
waiting for updates to be blocked
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> start nodes
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> restarting cluster
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> request recoveries
--> start node A
--> start node A
--> start node A
--> start node A
--> start node A
--> start node A
--> start node A
--> start node A
--> start node A
--> start node A
--> start node A
--> start node A
--> start node A
--> start node A
--> start node A
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
unblocking the blocked update
checking
checking
checking
checking
checking
checking
checking
checking
checking
checking
checking
checking
checking
checking
checking
passed
passed
passed
passed
passed
passed
passed
passed
passed
passed
passed
passed
passed
passed
passed
--> start node B
--> start node B
--> start node B
--> start node B
--> start node B
--> start node B
--> start node B
--> start node B
--> start node B
--> start node B
--> start node B
--> start node B
--> start node B
--> start node B
--> start node B
--> start node C
--> start node C
--> start node C
--> start node C
--> start node C
--> start node C
--> start node C
--> start node C
--> start node C
--> start node C
--> start node C
--> start node C
--> start node C
--> start node C
--> start node C
--> restart node B
--> restart node B
--> restart node B
--> restart node B
--> restart node B
--> restart node B
--> restart node B
--> restart node B
--> restart node B
--> restart node B
--> restart node B
--> restart node B
--> restart node B
--> restart node B
--> restart node B
allocated dangled
allocated dangled
allocated dangled
allocated dangled
allocated dangled
allocated dangled
allocated dangled
allocated dangled
allocated dangled
allocated dangled
allocated dangled
allocated dangled
allocated dangled
allocated dangled
allocated dangled
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
--> slowing down recoveries
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
now starting the operation that acquires all permits and sets the block in the cluster state
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
--> waiting for recovery to start both on source and target
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
releasing delayed operations
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
--> request node recovery stats
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
waiting for all operations to terminate
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> checking throttling increases
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> speeding up recoveries
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> bump replica count
--> create repository
--> create repository
--> create repository
--> create repository
--> create repository
--> create repository
--> create repository
--> create repository
--> create repository
--> create repository
--> create repository
--> create repository
--> create repository
--> create repository
--> create repository
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
caught unprepared task, retrying until prepared
--> restore
--> restore
--> restore
--> restore
--> restore
--> restore
--> restore
--> restore
--> restore
--> restore
--> restore
--> restore
--> restore
--> restore
--> restore
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
--> indexing sample data
Normal output
Normal output
Normal output
Normal output
Normal output
Normal output
Normal output
Normal output
Normal output
Normal output
Normal output
Normal output
Normal output
Normal output
Normal output
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Blocking bulk so we start to get bulk rejections
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_periods filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see nr_throttled filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
Expected to see throttled_time filed but found nothing
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpuacct] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [cpu] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
no [memory] data found in cgroup stats
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initializing HTTP handlers ...
initialized
initialized
initialized
initialized
initialized
initialized
initialized
initialized
initialized
initialized
initialized
initialized
initialized
initialized
initialized
starting ...
starting ...
starting ...
starting ...
starting ...
starting ...
starting ...
starting ...
starting ...
starting ...
starting ...
starting ...
starting ...
starting ...
starting ...
started
started
started
started
started
started
started
started
started
started
started
started
started
started
started
stopping ...
stopping ...
stopping ...
stopping ...
stopping ...
stopping ...
stopping ...
stopping ...
stopping ...
stopping ...
stopping ...
stopping ...
stopping ...
stopping ...
stopping ...
stopped
stopped
stopped
stopped
stopped
stopped
stopped
stopped
stopped
stopped
stopped
stopped
stopped
stopped
stopped
closing ...
closing ...
closing ...
closing ...
closing ...
closing ...
closing ...
closing ...
closing ...
closing ...
closing ...
closing ...
closing ...
closing ...
closing ...
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
only a single data node is present, allowing allocation
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
cluster info unavailable for disk threshold decider, allowing allocation.
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
unable to determine disk usages for disk-aware allocation, allowing allocation
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
Evaluating force allocation for primary shard.
checkFinished
checkFinished
checkFinished
checkFinished
checkFinished
checkFinished
checkFinished
checkFinished
checkFinished
checkFinished
checkFinished
checkFinished
checkFinished
checkFinished
checkFinished
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as a check is already in progress
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
skipping monitor as no disk usage information is available
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
processing new cluster info
no reroute required
no reroute required
no reroute required
no reroute required
no reroute required
no reroute required
no reroute required
no reroute required
no reroute required
no reroute required
no reroute required
no reroute required
no reroute required
no reroute required
no reroute required
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
Expected one argument. Usage: java -jar reaper.jar <DIR_OF_REAPING_COMMANDS>
no auto-release required
no auto-release required
no auto-release required
no auto-release required
no auto-release required
no auto-release required
no auto-release required
no auto-release required
no auto-release required
no auto-release required
no auto-release required
no auto-release required
no auto-release required
no auto-release required
no auto-release required
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
Exec output and error:
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
cancelling existing delayed reroute task
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
no need to schedule reroute - no delayed unassigned shards
Resetting repository generation tracker because we failed to read generation [0]java.io.FileNotFoundException
Resetting repository generation tracker because we failed to read generation [1]java.io.IOException
Resetting repository generation tracker because we failed to read generation [2]java.nio.file.NoSuchFileException
Resetting repository generation tracker because we failed to read generation [3]java.nio.file.AccessDeniedException
Resetting repository generation tracker because we failed to read generation [4]java.io.EOFException
Resetting repository generation tracker because we failed to read generation [5]java.io.SyncFailedException
Resetting repository generation tracker because we failed to read generation [6]java.io.InterruptedIOException
Resetting repository generation tracker because we failed to read generation [7]java.io.UTFDataFormatException
Resetting repository generation tracker because we failed to read generation [8]java.io.NotSerializableException
Resetting repository generation tracker because we failed to read generation [9]java.io.InvalidClassException
Resetting repository generation tracker because we failed to read generation [10]java.io.OptionalDataException
Resetting repository generation tracker because we failed to read generation [11]java.io.StreamCorruptedException
Resetting repository generation tracker because we failed to read generation [12]java.io.WriteAbortedException
Resetting repository generation tracker because we failed to read generation [13]java.io.ObjectStreamException
Resetting repository generation tracker because we failed to read generation [14]java.io.IOException
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Third party audit passed successfully
Successfully loaded all snapshot's version information for [1, 2, 3, 4] from snapshot metadata
Successfully loaded all snapshot's version information for [5, 6, 7, 8] from snapshot metadata
Successfully loaded all snapshot's version information for [9, 10, 11, 12] from snapshot metadata
Successfully loaded all snapshot's version information for [13, 14, 15, 16] from snapshot metadata
Successfully loaded all snapshot's version information for [17, 18, 19, 20] from snapshot metadata
Successfully loaded all snapshot's version information for [21, 22, 23, 24] from snapshot metadata
Successfully loaded all snapshot's version information for [25, 26, 27, 28] from snapshot metadata
Successfully loaded all snapshot's version information for [29, 30, 31, 32] from snapshot metadata
Successfully loaded all snapshot's version information for [33, 34, 35, 36] from snapshot metadata
Successfully loaded all snapshot's version information for [37, 38, 39, 40] from snapshot metadata
Successfully loaded all snapshot's version information for [41, 42, 43, 44] from snapshot metadata
Successfully loaded all snapshot's version information for [45, 46, 47, 48] from snapshot metadata
Successfully loaded all snapshot's version information for [49, 50, 51, 52] from snapshot metadata
Successfully loaded all snapshot's version information for [53, 54, 55, 56] from snapshot metadata
Successfully loaded all snapshot's version information for [57, 58, 59, 60] from snapshot metadata
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
----------Validation Errors-----------
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
Success! No validation errors found.
add weighted routing weights in metadata [newWeightedRouting=0.5]
add weighted routing weights in metadata [newWeightedRouting=0.8]
add weighted routing weights in metadata [newWeightedRouting=0.2]
add weighted routing weights in metadata [newWeightedRouting=0.6]
add weighted routing weights in metadata [newWeightedRouting=0.4]
add weighted routing weights in metadata [newWeightedRouting=0.7]
add weighted routing weights in metadata [newWeightedRouting=0.3]
add weighted routing weights in metadata [newWeightedRouting=0.9]
add weighted routing weights in metadata [newWeightedRouting=0.1]
add weighted routing weights in metadata [newWeightedRouting=1.0]
add weighted routing weights in metadata [newWeightedRouting=0.01]
add weighted routing weights in metadata [newWeightedRouting=0.99]
add weighted routing weights in metadata [newWeightedRouting=0.11]
add weighted routing weights in metadata [newWeightedRouting=0.22]
add weighted routing weights in metadata [newWeightedRouting=0.33]
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
---------- Validation Report -----------
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
Some API names were found that, when client code is generated for these APIS,
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
could conflict with the reserved words in some programming languages. It may
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
still be possible to use these API names, but you will need to verify whether
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
the API name (and its components) can be used as method names, and update the
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
list of keywords below. The safest action is to rename the API to avoid conflicts.
building cluster state with weighted routing weights [newWeightedRouting=0.5]
building cluster state with weighted routing weights [newWeightedRouting=0.8]
building cluster state with weighted routing weights [newWeightedRouting=0.2]
building cluster state with weighted routing weights [newWeightedRouting=0.9]
building cluster state with weighted routing weights [newWeightedRouting=0.3]
building cluster state with weighted routing weights [newWeightedRouting=0.7]
building cluster state with weighted routing weights [newWeightedRouting=0.4]
building cluster state with weighted routing weights [newWeightedRouting=0.6]
building cluster state with weighted routing weights [newWeightedRouting=1.0]
building cluster state with weighted routing weights [newWeightedRouting=0.1]
building cluster state with weighted routing weights [newWeightedRouting=0.55]
building cluster state with weighted routing weights [newWeightedRouting=0.75]
building cluster state with weighted routing weights [newWeightedRouting=0.25]
building cluster state with weighted routing weights [newWeightedRouting=0.95]
building cluster state with weighted routing weights [newWeightedRouting=0.05]
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
cluster weighted routing weights metadata change is processed by all the nodes
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
Deleting weighted routing metadata from the cluster state
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
building cluster state with weighted routing weights deleted
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
---------- Validation Errors -----------
[0] [1] Aborted on the file data.csv, exiting
[2] [3] Aborted on the file config.json, exiting
[4] [5] Aborted on the file image.png, exiting
[6] [7] Aborted on the file report.docx, exiting
[8] [9] Aborted on the file video.mp4, exiting
[10] [11] Aborted on the file music.mp3, exiting
[12] [13] Aborted on the file script.py, exiting
[14] [15] Aborted on the file log.txt, exiting
[16] [17] Aborted on the file index.html, exiting
[18] [19] Aborted on the file style.css, exiting
[20] [21] Aborted on the file game.exe, exiting
[22] [23] Aborted on the file model.h5, exiting
[24] [25] Aborted on the file backup.zip, exiting
[26] [27] Aborted on the file resume.pdf, exiting
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
cluster weighted routing metadata change is processed by all the nodes
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Waiting for reaper to exit normally
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Copying reaper.jar...
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
Starting to wait for cluster to form
[0] [snapshot_20211023] failed to delete file [segments_1] during snapshot cleanup
[1] [snapshot_20211024] failed to delete file [segments_2] during snapshot cleanup
[2] [snapshot_20211025] failed to delete file [segments_3] during snapshot cleanup
[3] [snapshot_20211026] failed to delete file [segments_4] during snapshot cleanup
[4] [snapshot_20211027] failed to delete file [segments_5] during snapshot cleanup
[5] [snapshot_20211028] failed to delete file [segments_6] during snapshot cleanup
[6] [snapshot_20211029] failed to delete file [segments_7] during snapshot cleanup
[7] [snapshot_20211030] failed to delete file [segments_8] during snapshot cleanup
[8] [snapshot_20211031] failed to delete file [segments_9] during snapshot cleanup
[9] [snapshot_20211101] failed to delete file [segments_10] during snapshot cleanup
[10] [snapshot_20211102] failed to delete file [segments_11] during snapshot cleanup
[11] [snapshot_20211103] failed to delete file [segments_12] during snapshot cleanup
[12] [snapshot_20211104] failed to delete file [segments_13] during snapshot cleanup
[13] [snapshot_20211105] failed to delete file [segments_14] during snapshot cleanup
[14] [snapshot_20211106] failed to delete file [segments_15] during snapshot cleanup
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
the repository location is missing, it should point to a shared file system location that is available on all cluster-manager and data nodes
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Skipping cluster manager throttling as at least one node < 2.5.0 is present in cluster
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Starting cluster manager throttling as all nodes are higher than or equal to 2.5.0
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Process was not running when we tried to terminate it.
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
Not stopping clusters, disabled by property
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: [search|bulk]
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'bulk' benchmarkTargetHostIp indexFilePath indexName numberOfDocuments bulkSize
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
usage: 'search' benchmarkTargetHostIp indexName searchRequestBody throughputRates
No results.
No results.
No results.
No results.
No results.
No results.
No results.
No results.
No results.
No results.
No results.
No results.
No results.
No results.
No results.
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
Input streams cannot be closed since they are not yet set for multi stream upload
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
task cancellation limit reached
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
heap size couldn't be determined
failure in search search backpressure: NullPointerException
failure in search search backpressure: OutOfMemoryError
failure in search search backpressure: TimeoutException
failure in search search backpressure: IndexOutOfBoundsException
failure in search search backpressure: IOException
failure in search search backpressure: IllegalArgumentException
failure in search search backpressure: IllegalStateException
failure in search search backpressure: AssertionError
failure in search search backpressure: ClassCastException
failure in search search backpressure: NumberFormatException
failure in search search backpressure: StackOverflowError
failure in search search backpressure: SecurityException
failure in search search backpressure: UnsupportedOperationException
failure in search search backpressure: ConcurrentModificationException
failure in search search backpressure: SQLException
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> starting 4 nodes on different zones
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for nodes to form a cluster
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> waiting for shards to be allocated
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting 2 nodes on zones 'a' & 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting another node in zone 'b'
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting a dedicated cluster manager node
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> starting 15 nodes on zones 'a' & 'b' & 'c'
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> create an index with 1 shard, 1 replica, nothing should allocate
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> explicitly allocate shard 1, *under dry_run*
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> get the state, verify nothing changed because of the dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> explicitly allocate shard 1, actually allocating, no dry run
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> get the state, verify shard 1 primary allocated
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> move shard 1 primary from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> get the state, verify shard 1 primary moved from node1 to node2
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> starting 4 nodes
--> create indices
--> create indices
--> create indices
--> create indices
--> create indices
--> create indices
--> create indices
--> create indices
--> create indices
--> create indices
--> create indices
--> create indices
--> create indices
--> create indices
--> create indices
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> stopping node1
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> closing all nodes
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> starting nodes back, will not allocate the shard since it has no data, but the index will be there
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> explicitly allocate primary
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> starting a node
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> create an index with 1 shard
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> starting a second node
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> try to move the shard from node1 to node2
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> create an index with 1 shard and 0 replicas
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the index has 1 shard
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> check that the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> retrieve the node where the shard is allocated
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> creating an index with no replicas
--> index some data
--> index some data
--> index some data
--> index some data
--> index some data
--> index some data
--> index some data
--> index some data
--> index some data
--> index some data
--> index some data
--> index some data
--> index some data
--> index some data
--> index some data
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> decommission the second node
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> verify all are allocated on node1 now
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> creating an index with auto-expand replicas
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> filter out the second node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> remove index from the first node
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> verify all shards are allocated on node_1 now
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> disable allocation filtering
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> verify that there are shards allocated on both nodes now
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> updating settings
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> waiting for relocation
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> updating settings with random persistent setting
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> start 3 cluster manager nodes on zones 'd' & 'e' & 'f'
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster health on an index that does not exists
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> running cluster wide health
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> Creating index test1 with zero replicas
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
--> running cluster health on an index that does exists and an index that doesn't exists
Cluster state: ACTIVE Cluster state from diffs: ACTIVE
Cluster state: PASSIVE Cluster state from diffs: PASSIVE
Cluster state: ACTIVE Cluster state from diffs: PASSIVE
Cluster state: PASSIVE Cluster state from diffs: ACTIVE
Cluster state: RECOVERING Cluster state from diffs: RECOVERING
Cluster state: RECOVERING Cluster state from diffs: ACTIVE
Cluster state: RECOVERING Cluster state from diffs: PASSIVE
Cluster state: FAILED Cluster state from diffs: FAILED
Cluster state: FAILED Cluster state from diffs: ACTIVE
Cluster state: FAILED Cluster state from diffs: PASSIVE
Cluster state: FAILED Cluster state from diffs: RECOVERING
Cluster state: ACTIVE Cluster state from diffs: FAILED
Cluster state: PASSIVE Cluster state from diffs: FAILED
Cluster state: RECOVERING Cluster state from diffs: FAILED
Cluster state: UNKNOWN Cluster state from diffs: UNKNOWN
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
--> starting data node each on zones 'a' & 'b' & 'c'
cluster restored
cluster restored
cluster restored
cluster restored
cluster restored
cluster restored
cluster restored
cluster restored
cluster restored
cluster restored
cluster restored
cluster restored
cluster restored
cluster restored
cluster restored
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 4 data nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> starting 1 nodes each on zones 'a' & 'b' & 'c'
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Received LANGUID event
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Decommission status is successful
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Got cluster state with 4 nodes.
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Cluster Manager node found after decommission
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Verified the decommissioned node has in_progress state.
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Got LANGUID event
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> Deleting decommission done.
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
--> setting shard routing weights
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
exclusion already cleared
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
decommission status has already turned false
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
Triggering decommission action
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> indexing a doc
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> delete index and recreate it
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> letting cluster proceed
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start 1st cluster-manager-eligible node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start one data-only node
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> start 2nd and 3rd cluster-manager-eligible nodes and bootstrap
--> create index test
--> create index test
--> create index test
--> create index test
--> create index test
--> create index test
--> create index test
--> create index test
--> create index test
--> create index test
--> create index test
--> create index test
--> create index test
--> create index test
--> create index test
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> stop 2nd and 3d cluster-manager eligible node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> ensure NO_MASTER_BLOCK on data-only node
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> try to unsafely bootstrap 1st cluster-manager-eligible node, while node lock is held
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> stop 1st cluster-manager-eligible node and data-only node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> unsafely-bootstrap 1st cluster-manager-eligible node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> detach-cluster on data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> start data-only node
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
--> ensure there is no NO_MASTER_BLOCK and unsafe-bootstrap is reflected in cluster state
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
We maxed out the number of bulk retries and got rejected (this is ok).
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> ensure index test is green
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> detach-cluster on 2nd and 3rd cluster-manager-eligible nodes
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start 2nd and 3rd cluster-manager-eligible nodes and ensure 4 nodes stable cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start mixed data and cluster-manager-eligible node and bootstrap cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> start data-only node and ensure 2 nodes stable cluster
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> index 1 doc and ensure index is green
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> verify 1 doc in the index
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop data-only node and detach it from the old cluster
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> stop cluster-manager-eligible node, clear its data and start it again - new cluster should form
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> start data-only only node and ensure 2 nodes stable cluster
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify that the dangling index exists and has green status
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> verify the doc is there
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> request node discovery stats
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> should be blocked, no cluster-manager...
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> start second node, cluster should be formed
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> verify we get the data back
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> add voting config exclusion for non-cluster-manager node, to be sure it's not elected
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> stop cluster-manager node, no cluster-manager block should appear
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> starting the previous cluster-manager node again...
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> verify we get the data back after cluster reform
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> clearing voting config exclusions
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> add voting config exclusion for cluster-manager node, to be sure it's not elected
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> stop non-cluster-manager node, no cluster-manager block should appear
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> verify we the data back
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start first 2 nodes
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> start one more node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> verify that there is no cluster-manager anymore on remaining node
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> start back the 2 nodes
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> submitting for cluster state to be rejected
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> starting the disruption, preventing cluster state publishing
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> waiting for cluster state to be processed/rejected
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> check that there is no cluster-manager in minor partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> wait for cluster-manager to be elected in major partition
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> waiting for cluster to heal
--> here 3
--> here 3
--> here 3
--> here 3
--> here 3
--> here 3
--> here 3
--> here 3
--> here 3
--> here 3
--> here 3
--> here 3
--> here 3
--> here 3
--> here 3
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> index is confirmed read-only, releasing disk space
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> balance index [test_1]
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> disabling allocation to capture shard failure
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> waiting for a yellow index
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> enabling allocation
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> partitioning node with primary shard from rest of cluster
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> index a document into previous replica shard (that is now primary)
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> shut down node that has new acknowledged document
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> waiting for node with old primary shard to rejoin the cluster
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> check that old primary shard does not get promoted to primary again
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting 3 nodes, 1 cluster-manager, 2 data
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> starting node that reuses data folder with the up-to-date primary shard
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> check that the up-to-date primary shard gets promoted and that documents are available
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> create single shard index
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> force allocation of stale copy to node that does not have shard copy
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> wait until shard is failed and becomes unassigned again
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> explicitly promote old primary shard
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> check that the stale primary shard gets allocated and that documents are available
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> starting node that reuses data folder with the up-to-date shard
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> indexing...
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> creating index with 1 primary and 2 replicas
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> removing 2 nodes from cluster
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> checking that index still gets allocated with only 1 shard copy being available
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> starting 1 node
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> creating index with 1 primary and 0 replicas
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
--> update the settings to prevent allocation to the data node
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
reroute after snapshot shard size update completed
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> full cluster restart
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> checking that the primary shard is force allocated to the data node despite being blocked by the exclude filter
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> Indexing with gap in seqno to ensure that some operations will be replayed in resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> isolating some replicas during primary-replica resync
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> stop disrupting network and re-enable allocation
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 6 nodes on different zones
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 1 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> starting 2 nodes on zones 'a' & 'b' & 'c'
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is started
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> network disruption is stopped
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
--> starting 3 nodes on different zones
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using transient settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
Using persistent settings
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start data node / non cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> start cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
--> stop cluster-manager node
Terminal.Verbosity.VERBOSE custom metadata names: [index-1, index-2, index-3]
Terminal.Verbosity.VERBOSE custom metadata names: [index-4, index-5, index-6, index-7]
Terminal.Verbosity.VERBOSE custom metadata names: [index-8, index-9]
Terminal.Verbosity.VERBOSE custom metadata names: [index-10, index-11, index-12]
Terminal.Verbosity.VERBOSE custom metadata names: [index-13, index-14, index-15, index-16]
Terminal.Verbosity.VERBOSE custom metadata names: [index-17, index-18]
Terminal.Verbosity.VERBOSE custom metadata names: [index-19, index-20, index-21, index-22, index-23]
Terminal.Verbosity.VERBOSE custom metadata names: [index-24, index-25]
Terminal.Verbosity.VERBOSE custom metadata names: [index-26, index-27, index-28]
Terminal.Verbosity.VERBOSE custom metadata names: [index-29, index-30, index-31]
Terminal.Verbosity.VERBOSE custom metadata names: [index-32, index-33]
Terminal.Verbosity.VERBOSE custom metadata names: [index-34, index-35, index-36, index-37]
Terminal.Verbosity.VERBOSE custom metadata names: [index-38, index-39]
Terminal.Verbosity.VERBOSE custom metadata names: [index-40, index-41, index-42]
Terminal.Verbosity.VERBOSE custom metadata names: [index-43, index-44]
can't find replica source node because primary shard 0 is assigned to an unknown node.
can't find replica source node because primary shard 1 is assigned to an unknown node.
can't find replica source node because primary shard 2 is assigned to an unknown node.
can't find replica source node because primary shard 3 is assigned to an unknown node.
can't find replica source node because primary shard 4 is assigned to an unknown node.
can't find replica source node because primary shard 5 is assigned to an unknown node.
can't find replica source node because primary shard 6 is assigned to an unknown node.
can't find replica source node because primary shard 7 is assigned to an unknown node.
can't find replica source node because primary shard 8 is assigned to an unknown node.
can't find replica source node because primary shard 9 is assigned to an unknown node.
can't find replica source node because primary shard 10 is assigned to an unknown node.
can't find replica source node because primary shard 11 is assigned to an unknown node.
can't find replica source node because primary shard 12 is assigned to an unknown node.
can't find replica source node because primary shard 13 is assigned to an unknown node.
can't find replica source node because primary shard 14 is assigned to an unknown node.
using indexing buffer size [1024] with indices.memory.shard_inactive_time [5m], indices.memory.interval [10s]
using indexing buffer size [512] with indices.memory.shard_inactive_time [10m], indices.memory.interval [5s]
using indexing buffer size [2048] with indices.memory.shard_inactive_time [15m], indices.memory.interval [15s]
using indexing buffer size [4096] with indices.memory.shard_inactive_time [20m], indices.memory.interval [20s]
using indexing buffer size [256] with indices.memory.shard_inactive_time [30m], indices.memory.interval [30s]
using indexing buffer size [128] with indices.memory.shard_inactive_time [1h], indices.memory.interval [1m]
using indexing buffer size [64] with indices.memory.shard_inactive_time [2h], indices.memory.interval [2m]
using indexing buffer size [32] with indices.memory.shard_inactive_time [4h], indices.memory.interval [4m]
using indexing buffer size [16] with indices.memory.shard_inactive_time [8h], indices.memory.interval [8m]
using indexing buffer size [8] with indices.memory.shard_inactive_time [16h], indices.memory.interval [16m]
using indexing buffer size [4] with indices.memory.shard_inactive_time [24h], indices.memory.interval [24m]
using indexing buffer size [2] with indices.memory.shard_inactive_time [48h], indices.memory.interval [48m]
using indexing buffer size [1] with indices.memory.shard_inactive_time [72h], indices.memory.interval [72m]
using indexing buffer size [0.5] with indices.memory.shard_inactive_time [96h], indices.memory.interval [96m]
write indexing buffer to disk for shard [0] to free up its [1.2 GB] indexing buffer
write indexing buffer to disk for shard [3] to free up its [2.5 GB] indexing buffer
write indexing buffer to disk for shard [1] to free up its [3.1 GB] indexing buffer
write indexing buffer to disk for shard [4] to free up its [1.8 GB] indexing buffer
write indexing buffer to disk for shard [2] to free up its [2.9 GB] indexing buffer
write indexing buffer to disk for shard [5] to free up its [2.3 GB] indexing buffer
write indexing buffer to disk for shard [6] to free up its [1.5 GB] indexing buffer
write indexing buffer to disk for shard [7] to free up its [2.7 GB] indexing buffer
write indexing buffer to disk for shard [8] to free up its [1.9 GB] indexing buffer
write indexing buffer to disk for shard [9] to free up its [2.1 GB] indexing buffer
write indexing buffer to disk for shard [10] to free up its [2.4 GB] indexing buffer
write indexing buffer to disk for shard [11] to free up its [1.7 GB] indexing buffer
write indexing buffer to disk for shard [12] to free up its [2.8 GB] indexing buffer
write indexing buffer to disk for shard [13] to free up its [1.6 GB] indexing buffer
write indexing buffer to disk for shard [14] to free up its [3.0 GB] indexing buffer
registering decommission metadata [decommissionAttributeMetadata{attributeId=1, attributeType=STRING, attributeValue='foo'}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=2, attributeType=INTEGER, attributeValue=42}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=3, attributeType=BOOLEAN, attributeValue=true}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=4, attributeType=FLOAT, attributeValue=3.14}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=5, attributeType=DATE, attributeValue='2023-10-25'}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=6, attributeType=LIST, attributeValue=[1, 2, 3]}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=7, attributeType=MAP, attributeValue={'key': 'value'}}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=8, attributeType=ENUM, attributeValue='RED'}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=9, attributeType=BINARY, attributeValue='01010101'}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=10, attributeType=NULL, attributeValue=null}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=11, attributeType=STRING, attributeValue='bar'}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=12, attributeType=INTEGER, attributeValue=-1}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=13, attributeType=BOOLEAN, attributeValue=false}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=14, attributeType=FLOAT, attributeValue=-2.71}] to execute action
registering decommission metadata [decommissionAttributeMetadata{attributeId=15, attributeType=DATE, attributeValue='2020-01-01'}] to execute action
now throttling indexing for shard [0]: segment writing can't keep up
now throttling indexing for shard [1]: segment writing can't keep up
now throttling indexing for shard [2]: segment writing can't keep up
now throttling indexing for shard [3]: segment writing can't keep up
now throttling indexing for shard [4]: segment writing can't keep up
now throttling indexing for shard [5]: segment writing can't keep up
now throttling indexing for shard [6]: segment writing can't keep up
now throttling indexing for shard [7]: segment writing can't keep up
now throttling indexing for shard [8]: segment writing can't keep up
now throttling indexing for shard [9]: segment writing can't keep up
now throttling indexing for shard [10]: segment writing can't keep up
now throttling indexing for shard [11]: segment writing can't keep up
now throttling indexing for shard [12]: segment writing can't keep up
now throttling indexing for shard [13]: segment writing can't keep up
now throttling indexing for shard [14]: segment writing can't keep up
stop throttling indexing for shard [0]
stop throttling indexing for shard [1]
stop throttling indexing for shard [2]
stop throttling indexing for shard [3]
stop throttling indexing for shard [4]
stop throttling indexing for shard [5]
stop throttling indexing for shard [6]
stop throttling indexing for shard [7]
stop throttling indexing for shard [8]
stop throttling indexing for shard [9]
stop throttling indexing for shard [10]
stop throttling indexing for shard [11]
stop throttling indexing for shard [12]
stop throttling indexing for shard [13]
stop throttling indexing for shard [14]
creating Index [products], shards [5]/[1] - reason [API]
creating Index [users], shards [3]/[2] - reason [AUTO]
creating Index [orders], shards [4]/[1] - reason [RESTORE]
creating Index [reviews], shards [2]/[3] - reason [REINDEX]
creating Index [inventory], shards [6]/[1] - reason [CLONE]
creating Index [logs], shards [8]/[2] - reason [SNAPSHOT]
creating Index [analytics], shards [4]/[2] - reason [TEMPLATE]
creating Index [settings], shards [1]/[1] - reason [UPDATE]
creating Index [categories], shards [3]/[1] - reason [MAPPING]
creating Index [customers], shards [5]/[2] - reason [ALIAS]
creating Index [sales], shards [6]/[2] - reason [SHRINK]
creating Index [reports], shards [2]/[2] - reason [SPLIT]
creating Index [notifications], shards [4]/[1] - reason [RELOCATE]
creating Index [messages], shards [3]/[3] - reason [MERGE]
creating Index [documents], shards [7]/[1] - reason [DELETE]
[products] closing ... (reason [index corrupted])
[customers] closing ... (reason [disk full])
[orders] closing ... (reason [shard relocation])
[reviews] closing ... (reason [flushing])
[users] closing ... (reason [snapshot restore])
[blogs] closing ... (reason [merge failed])
[news] closing ... (reason [translog sync])
[events] closing ... (reason [force merge])
[books] closing ... (reason [index deleted])
[movies] closing ... (reason [node shutdown])
[songs] closing ... (reason [allocation failed])
[photos] closing ... (reason [refresh failed])
[videos] closing ... (reason [circuit breaker tripped])
[articles] closing ... (reason [index closed])
[podcasts] closing ... (reason [replica sync])
index closed... (reason [NO_SHARD_AVAILABLE][Failed to execute fetch phase])
index closed... (reason [CLUSTER_RELOCATION][Shard relocated to another node])
index closed... (reason [INDEX_NOT_FOUND_EXCEPTION][No such index [test]])
index closed... (reason [TOO_MANY_REQUESTS][Rejected execution of search request])
index closed... (reason [VERSION_CONFLICT_ENGINE_EXCEPTION][Version conflict, current version [1] is different than the one provided [2]])
index closed... (reason [SNAPSHOT_IN_PROGRESS_EXCEPTION][Cannot delete indices that are being snapshotted])
index closed... (reason [INDEX_CLOSED_BLOCK_EXCEPTION][Closed by API])
index closed... (reason [RESOURCE_NOT_FOUND_EXCEPTION][Resource not found])
index closed... (reason [ILLEGAL_ARGUMENT_EXCEPTION][Invalid query])
index closed... (reason [SECURITY_EXCEPTION][Missing authentication credentials])
index closed... (reason [INDEX_SHARD_RECOVERING_EXCEPTION][Shard is still recovering])
index closed... (reason [REMOTE_TRANSPORT_EXCEPTION][Failed to connect to remote cluster])
index closed... (reason [DOCUMENT_MISSING_EXCEPTION][Document not found])
index closed... (reason [QUERY_SHARD_EXCEPTION][Query returned no results])
index closed... (reason [INDEX_READ_ONLY_BLOCK_EXCEPTION][Index is read-only due to disk usage exceeding flood stage])
shardId 0 deleting shard reason [replica already exists]
shardId 1 deleting shard reason [no longer primary]
shardId 2 deleting shard reason [index deleted]
shardId 3 deleting shard reason [shard failure]
shardId 4 deleting shard reason [allocation cancelled]
shardId 5 deleting shard reason [node left]
shardId 6 deleting shard reason [relocation completed]
shardId 7 deleting shard reason [disk full]
shardId 8 deleting shard reason [corrupted data]
shardId 9 deleting shard reason [merge conflict]
shardId 10 deleting shard reason [low priority]
shardId 11 deleting shard reason [timeout exceeded]
shardId 12 deleting shard reason [user request]
shardId 13 deleting shard reason [cluster state changed]
shardId 14 deleting shard reason [invalid configuration]
shard: 1 size: 10GB reserved: 2GB
shard: 2 size: 8GB reserved: 1.5GB
shard: 3 size: 12GB reserved: 3GB
shard: 4 size: 9GB reserved: 2.5GB
shard: 5 size: 11GB reserved: 2.8GB
shard: 6 size: 7GB reserved: 1.2GB
shard: 7 size: 13GB reserved: 3.5GB
shard: 8 size: 10.5GB reserved: 2.7GB
shard: 9 size: 8.5GB reserved: 1.8GB
shard: 10 size: 12.5GB reserved: 3.2GB
shard: 11 size: 9.5GB reserved: 2.6GB
shard: 12 size: 11.5GB reserved: 3GB
shard: 13 size: 7.5GB reserved: 1.4GB
shard: 14 size: 14GB reserved: 4GB
shard: 15 size: 10.8GB reserved: 2.9GB
Query timed out, invalidating cache entry for request on shard [1]: /users/123/profile
Query timed out, invalidating cache entry for request on shard [2]: /products/456/reviews
Query timed out, invalidating cache entry for request on shard [3]: /search?q=books
Query timed out, invalidating cache entry for request on shard [4]: /orders/789/details
Query timed out, invalidating cache entry for request on shard [5]: /cart/987/items
Query timed out, invalidating cache entry for request on shard [6]: /categories/654/subcategories
Query timed out, invalidating cache entry for request on shard [7]: /coupons/321/apply
Query timed out, invalidating cache entry for request on shard [8]: /notifications/432/read
Query timed out, invalidating cache entry for request on shard [9]: /settings/543/update
Query timed out, invalidating cache entry for request on shard [10]: /favorites/234/add
Query timed out, invalidating cache entry for request on shard [11]: /comments/345/post
Query timed out, invalidating cache entry for request on shard [12]: /messages/456/send
Query timed out, invalidating cache entry for request on shard [13]: /friends/567/invite
Query timed out, invalidating cache entry for request on shard [14]: /reports/678/generate
adding data stream [login]
adding data stream [signup]
adding data stream [profile]
adding data stream [search]
adding data stream [upload]
adding data stream [download]
adding data stream [comment]
adding data stream [like]
adding data stream [share]
adding data stream [follow]
adding data stream [message]
adding data stream [notification]
adding data stream [settings]
adding data stream [feedback]
adding data stream [logout]
writing out dangling indices state for index products, triggered 0 ms ago
writing out dangling indices state for index users, triggered -10 ms ago
writing out dangling indices state for index orders, triggered -5 ms ago
writing out dangling indices state for index reviews, triggered -15 ms ago
writing out dangling indices state for index inventory, triggered -20 ms ago
writing out dangling indices state for index sales, triggered -25 ms ago
writing out dangling indices state for index customers, triggered -30 ms ago
writing out dangling indices state for index transactions, triggered -35 ms ago
writing out dangling indices state for index categories, triggered -40 ms ago
writing out dangling indices state for index ratings, triggered -45 ms ago
writing out dangling indices state for index posts, triggered -50 ms ago
writing out dangling indices state for index comments, triggered -55 ms ago
writing out dangling indices state for index tags, triggered -60 ms ago
writing out dangling indices state for index authors, triggered -65 ms ago
writing out dangling indices state for index books, triggered -70 ms ago
executing IndexCreationTask for [create index [test], cause [api], templates [], shards [1]/[0], mappings []] against cluster state version [1]
executing IndexCreationTask for [delete index [.kibana_1], cause [api call], templates [], shards [0]/[0], mappings []] against cluster state version [2]
executing IndexCreationTask for [create index [.kibana_2], cause [rollover_index], templates [.kibana_template], shards [1]/[1], mappings [_doc]] against cluster state version [3]
executing IndexCreationTask for [create index [logs-2023-10-25], cause [auto(bulk api)], templates [logs_template], shards [5]/[1], mappings [_doc, _source, _meta]] against cluster state version [4]
executing IndexCreationTask for [delete index [logs-2023-10-24], cause [delete indices request], templates [], shards [0]/[0], mappings []] against cluster state version [5]
executing IndexCreationTask for [create index [.security-7], cause [update_mapping], templates [.security_template], shards [1]/[0], mappings [_doc, _meta]] against cluster state version [6]
executing IndexCreationTask for [create index [.monitoring-es-7-2023.10.25], cause [auto(date histogram)], templates [.monitoring-es], shards [1]/[0], mappings [_doc, _source, _meta]] against cluster state version [7]
executing IndexCreationTask for [create index [.async-search], cause [create index api call], templates [], shards [1]/[1], mappings [_doc, _source, _meta]] against cluster state version [8]
executing IndexCreationTask for [delete index [.async-search], cause [delete expired data by retention policy trigger], templates [], shards [0]/[0], mappings []] against cluster state version [9]
executing IndexCreationTask for [create index [.ml-anomalies-shared], cause [auto create action], templates [.ml-anomalies-*, .ml-meta, .ml-state, .ml-stats, .ml-notifications-*], shards [5]/[1], mappings [_doc, _source, _meta]] against cluster state version [10]
executing IndexCreationTask for [create index [.ml-config], cause [put job api call], templates [.ml-config, .ml-meta, .ml-state, .ml-stats, .ml-notifications-*], shards [1]/[0], mappings [_doc, _source, _meta]] against cluster state version [11]
executing IndexCreationTask for [create index [.transform-notifications-000002], cause [rollover action request], templates [.transform-notifications-*], shards [1]/[0], mappings [_doc, _source, _meta]] against cluster state version [12]
delaying recovery of shard-1 as it is not listed as assigned to target node node-3
delaying recovery of shard-5 as it is not listed as assigned to target node node-2
delaying recovery of shard-2 as it is not listed as assigned to target node node-4
delaying recovery of shard-6 as it is not listed as assigned to target node node-1
delaying recovery of shard-3 as it is not listed as assigned to target node node-5
delaying recovery of shard-7 as it is not listed as assigned to target node node-6
delaying recovery of shard-4 as it is not listed as assigned to target node node-7
delaying recovery of shard-8 as it is not listed as assigned to target node node-8
delaying recovery of shard-9 as it is not listed as assigned to target node node-9
delaying recovery of shard-10 as it is not listed as assigned to target node node-10
delaying recovery of shard-11 as it is not listed as assigned to target node node-11
delaying recovery of shard-12 as it is not listed as assigned to target node node-12
delaying recovery of shard-13 as it is not listed as assigned to target node node-13
delaying recovery of shard-14 as it is not listed as assigned to target node node-14
delaying recovery of shard-15 as it is not listed as assigned to target node node-15
INFO[my_index] creating index, cause [api], templates [template_1, template_2], shards [5]/[1]
DEBUG[test_index] creating index, cause [auto(bulk api)], templates [], shards [3]/[2]
INFO[log_index] creating index, cause [ilm], templates [template_3], shards [1]/[0]
DEBUG[user_index] creating index, cause [reindex], templates [template_4, template_5], shards [4]/[3]
INFO[product_index] creating index, cause [snapshot restore], templates [], shards [2]/[1]
DEBUG[order_index] creating index, cause [rollover], templates [template_6], shards [6]/[2]
INFO[news_index] creating index, cause [api], templates [template_7, template_8], shards [3]/[1]
DEBUG[comment_index] creating index, cause [auto(bulk api)], templates [], shards [2]/[2]
INFO[tweet_index] creating index, cause [ilm], templates [template_9], shards [4]/[0]
DEBUG[profile_index] creating index, cause [reindex], templates [template_10, template_11], shards [5]/[4]
INFO[book_index] creating index, cause [snapshot restore], templates [], shards [3]/[2]
DEBUG[movie_index] creating index, cause [rollover], templates [template_12], shards [7]/[3]
INFO[song_index] creating index, cause [api], templates [template_13, template_14], shards [4]/[1]
DEBUG[podcast_index] creating index, cause [auto(bulk api)], templates [], shards [2]/[3]
INFO[blog_index] creating index, cause [ilm], templates [template_15], shards [5]/[0]
applying create index request using legacy templates [user, product, order]
applying create index request using legacy templates [blog, comment, tag]
applying create index request using legacy templates [book, author, genre]
applying create index request using legacy templates [student, course, grade]
applying create index request using legacy templates [employee, department, salary]
applying create index request using legacy templates [movie, review, rating]
applying create index request using legacy templates [song, artist, album]
applying create index request using legacy templates [game, player, score]
applying create index request using legacy templates [news, category, source]
applying create index request using legacy templates [recipe, ingredient, nutrition]
applying create index request using legacy templates [contact, email, phone]
applying create index request using legacy templates [event, date, location]
applying create index request using legacy templates [task, status, priority]
applying create index request using legacy templates [car, model, year]
applying create index request using legacy templates [animal, name, type]
applying create index request using composable template [product_catalog]
applying create index request using composable template [user_profile]
applying create index request using composable template [blog_posts]
applying create index request using composable template [order_history]
applying create index request using composable template [news_feed]
applying create index request using composable template [inventory_status]
applying create index request using composable template [customer_reviews]
applying create index request using composable template [event_calendar]
applying create index request using composable template [social_media]
applying create index request using composable template [weather_forecast]
applying create index request using composable template [email_campaign]
applying create index request using composable template [shopping_cart]
applying create index request using composable template [web_analytics]
applying create index request using composable template [movie_ratings]
applying create index request using composable template [book_recommendations]
applying create index request using existing index [products] metadata
applying create index request using existing index [users] metadata
applying create index request using existing index [orders] metadata
applying create index request using existing index [reviews] metadata
applying create index request using existing index [inventory] metadata
applying create index request using existing index [categories] metadata
applying create index request using existing index [customers] metadata
applying create index request using existing index [sales] metadata
applying create index request using existing index [transactions] metadata
applying create index request using existing index [employees] metadata
applying create index request using existing index [suppliers] metadata
applying create index request using existing index [shippers] metadata
applying create index request using existing index [regions] metadata
applying create index request using existing index [territories] metadata
applying create index request using existing index [products_suppliers] metadata
delaying recovery of [index_1][0] as source shard is not marked yet as relocating to [node_1][1]
delaying recovery of [index_2][2] as source shard is not marked yet as relocating to [node_2][3]
delaying recovery of [index_3][4] as source shard is not marked yet as relocating to [node_3][5]
delaying recovery of [index_4][6] as source shard is not marked yet as relocating to [node_4][7]
delaying recovery of [index_5][8] as source shard is not marked yet as relocating to [node_5][9]
delaying recovery of [index_6][10] as source shard is not marked yet as relocating to [node_6][11]
delaying recovery of [index_7][12] as source shard is not marked yet as relocating to [node_7][13]
delaying recovery of [index_8][14] as source shard is not marked yet as relocating to [node_8][15]
delaying recovery of [index_9][16] as source shard is not marked yet as relocating to [node_9][17]
delaying recovery of [index_10][18] as source shard is not marked yet as relocating to [node_10][19]
delaying recovery of [index_11][20] as source shard is not marked yet as relocating to [node_11][21]
delaying recovery of [index_12][22] as source shard is not marked yet as relocating to [node_12][23]
delaying recovery of [index_13][24] as source shard is not marked yet as relocating to [node_13][25]
delaying recovery of [index_14][26] as source shard is not marked yet as relocating to [node_14][27]
delaying recovery of [index_15][28] as source shard is not marked yet as relocating to [node_15][29]
[blog][0] starting recovery to node-1
[news][1] starting recovery to node-2
[shop][2] starting recovery to node-3
[forum][3] starting recovery to node-4
[wiki][4] starting recovery to node-5
[video][5] starting recovery to node-6
[social][6] starting recovery to node-7
[game][7] starting recovery to node-8
[music][8] starting recovery to node-9
[photo][9] starting recovery to node-10
[mail][10] starting recovery to node-11
[chat][11] starting recovery to node-12
[book][12] starting recovery to node-13
[map][13] starting recovery to node-14
[search][14] starting recovery to node-15
adding block user to indices [admin, guest, root]
adding block product to indices [catalog, inventory, sales]
adding block event to indices [calendar, reminder, notification]
adding block comment to indices [post, reply, review]
adding block order to indices [customer, payment, shipment]
adding block article to indices [title, author, content]
adding block message to indices [sender, receiver, timestamp]
adding block photo to indices [album, tag, location]
adding block video to indices [channel, category, duration]
adding block book to indices [isbn, title, author]
adding block song to indices [artist, genre, lyrics]
adding block game to indices [name, platform, rating]
adding block recipe to indices [name, ingredients, steps]
adding block contact to indices [name, phone, email]
adding block task to indices [name, priority, deadline]
unexpected error while preparing shard for peer recovery, failing recovery java.lang.IllegalStateException: Index shard [test][0] is closed
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.transport.RemoteTransportException: [node-1][127.0.0.1:9300][internal:index/shard/recovery/start_recovery]
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.index.engine.RecoveryEngineException: Phase[1] prepare target failed
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.index.shard.IndexShardRecoveringException: CurrentState[RECOVERING] Already recovering
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.index.snapshots.IndexShardRestoreFailedException: failed to restore snapshot [snapshot_2023-10-25/9XQJwFZsQZyL9f8xqXx7qg]
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.indices.recovery.RecoverFilesRecoveryException: Failed to transfer [12] files with total size of [1.2gb]
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.index.translog.TranslogCorruptedException: translog corruption while reading from stream
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.index.seqno.RetentionLeaseNotFoundException: retention lease with ID [peer-recovery/9XQJwFZsQZyL9f8xqXx7qg] not found
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper: failed to read [id:12, file:/data/nodes/0/indices/test/_state/state-12.st]
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.action.UnavailableShardsException: [test][1] primary shard is not active Timeout: [1m], request: [BulkShardRequest [[test][1]] containing [index {[test][_doc][1], source[n/a, actual length: [2.9kb], max length: 2kb]}]]
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.cluster.routing.RoutingValidationException: [NO(target node version [7.14.2] is older than source node version [7.15.0])]
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.index.shard.ShardNotFoundException: no such shard
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.ElasticsearchTimeoutException: no activity after [30s]
unexpected error while preparing shard for peer recovery, failing recovery org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [<transport_request>] would be [123456789/117.7mb], which is larger than the limit of [12345678/11.7mb], real usage: [12345678/11.7mb], new bytes reserved: [111111111/105.9mb], usages [request=0/0b, fielddata=0/0b, in_flight_requests=111111111/105.9mb, model_inference=0/0b, accounting=0/0b]
unexpected error while preparing shard for peer recovery, failing recovery java.nio.file.AccessDeniedException: /data/nodes/0/indices/test/_state/state-12.st
verification of shards before closing [products] succeeded but index is already closed
verification of shards before closing [users] succeeded but index is already closed
verification of shards before closing [orders] succeeded but index is already closed
verification of shards before closing [news] succeeded but index is already closed
verification of shards before closing [events] succeeded but index is already closed
verification of shards before closing [blogs] succeeded but index is already closed
verification of shards before closing [reviews] succeeded but index is already closed
verification of shards before closing [books] succeeded but index is already closed
verification of shards before closing [movies] succeeded but index is already closed
verification of shards before closing [songs] succeeded but index is already closed
verification of shards before closing [photos] succeeded but index is already closed
verification of shards before closing [videos] succeeded but index is already closed
verification of shards before closing [tweets] succeeded but index is already closed
verification of shards before closing [posts] succeeded but index is already closed
verification of shards before closing [comments] succeeded but index is already closed
verification of shards before closing [users] succeeded but index is being restored in the meantime
verification of shards before closing [products] succeeded but index is being restored in the meantime
verification of shards before closing [orders] succeeded but index is being restored in the meantime
verification of shards before closing [reviews] succeeded but index is being restored in the meantime
verification of shards before closing [inventory] succeeded but index is being restored in the meantime
verification of shards before closing [customers] succeeded but index is being restored in the meantime
verification of shards before closing [sales] succeeded but index is being restored in the meantime
verification of shards before closing [categories] succeeded but index is being restored in the meantime
verification of shards before closing [tags] succeeded but index is being restored in the meantime
verification of shards before closing [posts] succeeded but index is being restored in the meantime
verification of shards before closing [comments] succeeded but index is being restored in the meantime
verification of shards before closing [likes] succeeded but index is being restored in the meantime
verification of shards before closing [messages] succeeded but index is being restored in the meantime
verification of shards before closing [notifications] succeeded but index is being restored in the meantime
verification of shards before closing [settings] succeeded but index is being restored in the meantime
verification of shards before closing [product] succeeded but index is being snapshot in the meantime
verification of shards before closing [user] succeeded but index is being snapshot in the meantime
verification of shards before closing [order] succeeded but index is being snapshot in the meantime
verification of shards before closing [inventory] succeeded but index is being snapshot in the meantime
verification of shards before closing [review] succeeded but index is being snapshot in the meantime
verification of shards before closing [blog] succeeded but index is being snapshot in the meantime
verification of shards before closing [comment] succeeded but index is being snapshot in the meantime
verification of shards before closing [news] succeeded but index is being snapshot in the meantime
verification of shards before closing [event] succeeded but index is being snapshot in the meantime
verification of shards before closing [message] succeeded but index is being snapshot in the meantime
verification of shards before closing [profile] succeeded but index is being snapshot in the meantime
verification of shards before closing [transaction] succeeded but index is being snapshot in the meantime
verification of shards before closing [notification] succeeded but index is being snapshot in the meantime
verification of shards before closing [report] succeeded but index is being snapshot in the meantime
verification of shards before closing [feedback] succeeded but index is being snapshot in the meantime
1 recovery done from node-0, took 1,2s
0 recovery done from node-1, took 12.3s
5 recovery done from node-4, took 8.7s
2 recovery done from node-3, took 10.5s
7 recovery done from node-2, took 9.2s
4 recovery done from node-5, took 11.8s
1 recovery done from node-6, took 13.1s
6 recovery done from node-7, took 7.9s
3 recovery done from node-8, took 12.6s
8 recovery done from node-9, took 8.4s
9 recovery done from node-10, took 10.2s
10 recovery done from node-11, took 9.5s
11 recovery done from node-12, took 11.3s
12 recovery done from node-13, took 13.4s
verification of shards before blocking index 0 failed [timeout]
verification of shards before blocking index 1 failed [checksum mismatch]
verification of shards before blocking index 2 failed [connection error]
verification of shards before blocking index 3 failed [invalid shard size]
verification of shards before blocking index 4 failed [out of memory]
verification of shards before blocking index 5 failed [access denied]
verification of shards before blocking index 6 failed [corrupted data]
verification of shards before blocking index 7 failed [disk full]
verification of shards before blocking index 8 failed [network failure]
verification of shards before blocking index 9 failed [internal error]
verification of shards before blocking index 10 failed [unsupported format]
verification of shards before blocking index 11 failed [missing shard]
verification of shards before blocking index 12 failed [duplicate shard]
verification of shards before blocking index 13 failed [unknown error]
verification of shards before blocking index 14 failed [shard locked]
Snapshot differs from actual index for file: products.json meta: {id=1, name=Apple, price=0.99, category=Fruits}
Snapshot differs from actual index for file: users.csv meta: {id=2, name=Bob, email=bob@gmail.com, role=Admin}
Snapshot differs from actual index for file: orders.xml meta: {id=3, date=2023-10-25, customer=2, items=[1, 4, 5], total=15.97}
Snapshot differs from actual index for file: reviews.txt meta: {id=4, product=1, rating=5, comment=Great product!}
Snapshot differs from actual index for file: settings.ini meta: {id=5, theme=Dark, language=Portuguese, notifications=True}
Snapshot differs from actual index for file: photos.zip meta: {id=6, size=12.3 MB, format=JPEG, resolution=1920x1080}
Snapshot differs from actual index for file: music.mp3 meta: {id=7, title=Happy Birthday, artist=Alice, genre=Pop, duration=3:15}
Snapshot differs from actual index for file: videos.mov meta: {id=8, title=Cats and Dogs, director=Charlie, genre=Comedy, duration=1:30:00}
Snapshot differs from actual index for file: books.epub meta: {id=9, title=Pride and Prejudice, author=Jane Austen, genre=Romance, pages=432}
Snapshot differs from actual index for file: games.exe meta: {id=10, title=Pac-Man, developer=Namco, genre=Arcade, release_date=1980-05-22}
Snapshot differs from actual index for file: documents.docx meta: {id=11, title=Report on Sales Performance, author=Eve, company=MegaCorp, date_created=2023-10-24}
Snapshot differs from actual index for file: slides.pptx meta: {id=12, title=Presentation on New Product Launch, author=Eve, company=MegaCorp, date_modified=2023-10-25}
Snapshot differs from actual index for file: spreadsheets.xlsx meta: {id=13, title=Budget Forecast for Q4 2023, author=Eve, company=MegaCorp, date_accessed=2023-10-25}
Snapshot differs from actual index for file: scripts.py meta: {id=14, name=simulate_logs.py, function=simulate_logs(template, parameter), description=A script to generate simulated logs based on a template and a parameter list}
Snapshot differs from actual index for file: logs.log meta: {id=15, level=INFO, message="Generated 15 simulated logs", timestamp="2023-10-25 11:00"}
skipping [phase1] since source and target have identical sync id [a3b5c7d9]
skipping [phase1] since source and target have identical sync id [f8e9d0c1]
skipping [phase1] since source and target have identical sync id [4a6b8c0e]
skipping [phase1] since source and target have identical sync id [9d7f5e3c]
skipping [phase1] since source and target have identical sync id [2b4c6a8e]
skipping [phase1] since source and target have identical sync id [c9d8f7b5]
skipping [phase1] since source and target have identical sync id [6a7b9c4d]
skipping [phase1] since source and target have identical sync id [e8f9d0a3]
skipping [phase1] since source and target have identical sync id [3c5e7a9b]
skipping [phase1] since source and target have identical sync id [b7d6f5e9]
skipping [phase1] since source and target have identical sync id [5a6b8c2f]
skipping [phase1] since source and target have identical sync id [d9e8f7c3]
skipping [phase1] since source and target have identical sync id [7b9c4e6d]
skipping [phase1] since source and target have identical sync id [f0a3d8e9]
skipping [phase1] since source and target have identical sync id [4e6d9b7c]
completed adding block product to indices [catalog, inventory]
completed adding block user to indices [profile, activity]
completed adding block order to indices [history, payment]
completed adding block review to indices [rating, feedback]
completed adding block category to indices [navigation, filter]
completed adding block cart to indices [session, checkout]
completed adding block coupon to indices [discount, promotion]
completed adding block banner to indices [homepage, advertisement]
completed adding block article to indices [blog, news]
completed adding block comment to indices [discussion, reply]
completed adding block tag to indices [keyword, search]
completed adding block image to indices [gallery, thumbnail]
completed adding block video to indices [streaming, playback]
completed adding block audio to indices [podcast, transcript]
completed adding block event to indices [calendar, reminder]
removing component template [login-form]
removing component template [navbar]
removing component template [footer]
removing component template [carousel]
removing component template [blog-post]
removing component template [contact-form]
removing component template [product-card]
removing component template [modal-dialog]
removing component template [sidebar-menu]
removing component template [newsletter-signup]
removing component template [comment-section]
removing component template [rating-stars]
removing component template [search-bar]
removing component template [dropdown-menu]
removing component template [social-media-icons]
legacy template user and composable template blog would overlap: user-* <=> blog-*
legacy template product and composable template review would overlap: product-* <=> review-*
legacy template order and composable template invoice would overlap: order-* <=> invoice-*
legacy template event and composable template calendar would overlap: event-* <=> calendar-*
legacy template book and composable template author would overlap: book-* <=> author-*
legacy template movie and composable template genre would overlap: movie-* <=> genre-*
legacy template song and composable template artist would overlap: song-* <=> artist-*
legacy template game and composable template platform would overlap: game-* <=> platform-*
legacy template recipe and composable template ingredient would overlap: recipe-* <=> ingredient-*
legacy template animal and composable template habitat would overlap: animal-* <=> habitat-*
legacy template plant and composable template climate would overlap: plant-* <=> climate-*
legacy template country and composable template continent would overlap: country-* <=> continent-*
legacy template city and composable template population would overlap: city-* <=> population-*
legacy template sport and composable template team would overlap: sport-* <=> team-*
legacy template car and composable template model would overlap: car-* <=> model-*
removing index template [user-profiles]
removing index template [product-catalog]
removing index template [logs-2023-10-25]
removing index template [tweets]
removing index template [orders]
removing index template [events]
removing index template [books]
removing index template [movies]
removing index template [reviews]
removing index template [invoices]
removing index template [contacts]
removing index template [emails]
removing index template [news]
removing index template [photos]
removing index template [songs]
adding template [user_search] for index patterns [users, profiles, preferences]
adding template [product_review] for index patterns [products, reviews, ratings]
adding template [order_confirmation] for index patterns [orders, customers, payments]
adding template [blog_post] for index patterns [blogs, posts, comments]
adding template [weather_report] for index patterns [weather, locations, forecasts]
adding template [stock_quote] for index patterns [stocks, prices, volumes]
adding template [movie_recommendation] for index patterns [movies, genres, ratings]
adding template [email_notification] for index patterns [emails, recipients, subjects]
adding template [event_registration] for index patterns [events, attendees, tickets]
adding template [book_summary] for index patterns [books, authors, summaries]
adding template [news_article] for index patterns [news, sources, topics]
adding template [game_score] for index patterns [games, players, scores]
adding template [travel_plan] for index patterns [travels, destinations, bookings]
adding template [music_playlist] for index patterns [music, artists, songs]
adding template [shopping_list] for index patterns [shopping, items, prices]
cloned primary's retention lease as [retention-lease-1]
cloned primary's retention lease as [retention-lease-2]
cloned primary's retention lease as [retention-lease-3]
cloned primary's retention lease as [retention-lease-4]
cloned primary's retention lease as [retention-lease-5]
cloned primary's retention lease as [retention-lease-6]
cloned primary's retention lease as [retention-lease-7]
cloned primary's retention lease as [retention-lease-8]
cloned primary's retention lease as [retention-lease-9]
cloned primary's retention lease as [retention-lease-10]
cloned primary's retention lease as [retention-lease-11]
cloned primary's retention lease as [retention-lease-12]
cloned primary's retention lease as [retention-lease-13]
cloned primary's retention lease as [retention-lease-14]
cloned primary's retention lease as [retention-lease-15]
product create_mapping
user create_mapping
order create_mapping
review create_mapping
category create_mapping
inventory create_mapping
cart create_mapping
payment create_mapping
shipment create_mapping
customer create_mapping
coupon create_mapping
wishlist create_mapping
feedback create_mapping
product_view create_mapping
search_query create_mapping
reset of recovery with shard 0 and id [1]
reset of recovery with shard 1 and id [2]
reset of recovery with shard 2 and id [3]
reset of recovery with shard 3 and id [4]
reset of recovery with shard 4 and id [5]
reset of recovery with shard 5 and id [6]
reset of recovery with shard 6 and id [7]
reset of recovery with shard 7 and id [8]
reset of recovery with shard 8 and id [9]
reset of recovery with shard 9 and id [10]
reset of recovery with shard 10 and id [11]
reset of recovery with shard 11 and id [12]
reset of recovery with shard 12 and id [13]
reset of recovery with shard 13 and id [14]
reset of recovery with shard 14 and id [15]
updating number_of_replicas to [2] for indices [logstash-2023.10.25]
updating number_of_replicas to [3] for indices [customer, product, order]
updating number_of_replicas to [1] for indices [twitter, facebook, instagram]
updating number_of_replicas to [4] for indices [bank, transaction, account]
updating number_of_replicas to [2] for indices [weather, traffic, news]
updating number_of_replicas to [3] for indices [book, movie, music]
updating number_of_replicas to [1] for indices [sensor, device, alert]
updating number_of_replicas to [4] for indices [stock, market, trade]
updating number_of_replicas to [2] for indices [employee, department, salary]
updating number_of_replicas to [3] for indices [student, course, grade]
updating number_of_replicas to [1] for indices [hospital, patient, diagnosis]
updating number_of_replicas to [4] for indices [hotel, reservation, review]
updating number_of_replicas to [2] for indices [recipe, ingredient, nutrition]
updating number_of_replicas to [3] for indices [game, player, score]
updating number_of_replicas to [1] for indices [shop, product, review]
new recovery target cancelled for shard 0 while waiting on old recovery target with id [1] to close
new recovery target cancelled for shard 3 while waiting on old recovery target with id [2] to close
new recovery target cancelled for shard 5 while waiting on old recovery target with id [3] to close
new recovery target cancelled for shard 7 while waiting on old recovery target with id [4] to close
new recovery target cancelled for shard 9 while waiting on old recovery target with id [5] to close
new recovery target cancelled for shard 11 while waiting on old recovery target with id [6] to close
new recovery target cancelled for shard 13 while waiting on old recovery target with id [7] to close
new recovery target cancelled for shard 15 while waiting on old recovery target with id [8] to close
new recovery target cancelled for shard 17 while waiting on old recovery target with id [9] to close
new recovery target cancelled for shard 19 while waiting on old recovery target with id [10] to close
new recovery target cancelled for shard 21 while waiting on old recovery target with id [11] to close
new recovery target cancelled for shard 23 while waiting on old recovery target with id [12] to close
new recovery target cancelled for shard 25 while waiting on old recovery target with id [13] to close
new recovery target cancelled for shard 27 while waiting on old recovery target with id [14] to close
new recovery target cancelled for shard 29 while waiting on old recovery target with id [15] to close
Error updating template [T-456], request was not acknowledged
Error updating template [T-789], request was not acknowledged
Error updating template [T-123], request was not acknowledged
Error updating template [T-321], request was not acknowledged
Error updating template [T-654], request was not acknowledged
Error updating template [T-987], request was not acknowledged
Error updating template [T-147], request was not acknowledged
Error updating template [T-258], request was not acknowledged
Error updating template [T-369], request was not acknowledged
Error updating template [T-159], request was not acknowledged
Error updating template [T-753], request was not acknowledged
Error updating template [T-951], request was not acknowledged
Error updating template [T-357], request was not acknowledged
Error updating template [T-852], request was not acknowledged
Error updating template [T-963], request was not acknowledged
canceled order #4567 (reason [out of stock])
canceled subscription to Netflix (reason [payment declined])
canceled flight AA1234 (reason [bad weather])
canceled meeting with John (reason [conflicting schedule])
canceled appointment with Dr. Smith (reason [emergency])
canceled reservation at The Blue Moon (reason [change of plans])
canceled download of file.zip (reason [insufficient space])
canceled upload of photo.jpg (reason [network error])
canceled delivery of pizza (reason [wrong address])
canceled membership at Gold's Gym (reason [moving away])
canceled request for refund (reason [expired])
canceled bid on eBay (reason [outbid])
canceled alarm at 7:00 AM (reason [weekend])
canceled backup of data (reason [low battery])
canceled call to mom (reason [busy])
connectDisconnectedTargets: {node1: [target1, target2, target3]}
connectDisconnectedTargets: {node2: [target4, target5]}
connectDisconnectedTargets: {node3: [target6, target7, target8, target9]}
connectDisconnectedTargets: {node4: [target10]}
connectDisconnectedTargets: {node5: [target11, target12]}
connectDisconnectedTargets: {node6: [target13, target14, target15]}
connectDisconnectedTargets: {node7: [target16, target17]}
connectDisconnectedTargets: {node8: [target18, target19, target20]}
connectDisconnectedTargets: {node9: [target21]}
connectDisconnectedTargets: {node10: [target22, target23, target24]}
connectDisconnectedTargets: {node11: [target25, target26]}
connectDisconnectedTargets: {node12: [target27, target28, target29]}
connectDisconnectedTargets: {node13: [target30]}
connectDisconnectedTargets: {node14: [target31, target32]}
connectDisconnectedTargets: {node15: [target33, target34, target35]}
connecting to discoveryNode-1
connecting to discoveryNode-2
connecting to discoveryNode-3
connecting to discoveryNode-4
connecting to discoveryNode-5
connecting to discoveryNode-6
connecting to discoveryNode-7
connecting to discoveryNode-8
connecting to discoveryNode-9
connecting to discoveryNode-10
connecting to discoveryNode-11
connecting to discoveryNode-12
connecting to discoveryNode-13
connecting to discoveryNode-14
connecting to discoveryNode-15
connected to [node-1]
connected to [node-2]
connected to [node-3]
connected to [node-4]
connected to [node-5]
connected to [node-6]
connected to [node-7]
connected to [node-8]
connected to [node-9]
connected to [node-10]
connected to [node-11]
connected to [node-12]
connected to [node-13]
connected to [node-14]
connected to [node-15]
still connected to discoveryNode [1]
still connected to discoveryNode [2]
still connected to discoveryNode [3]
still connected to discoveryNode [4]
still connected to discoveryNode [5]
still connected to discoveryNode [6]
still connected to discoveryNode [7]
still connected to discoveryNode [8]
still connected to discoveryNode [9]
still connected to discoveryNode [10]
still connected to discoveryNode [11]
still connected to discoveryNode [12]
still connected to discoveryNode [13]
still connected to discoveryNode [14]
still connected to discoveryNode [15]
disconnected from discoveryNode[1]
disconnected from discoveryNode[2]
disconnected from discoveryNode[3]
disconnected from discoveryNode[4]
disconnected from discoveryNode[5]
disconnected from discoveryNode[6]
disconnected from discoveryNode[7]
disconnected from discoveryNode[8]
disconnected from discoveryNode[9]
disconnected from discoveryNode[10]
disconnected from discoveryNode[11]
disconnected from discoveryNode[12]
disconnected from discoveryNode[13]
disconnected from discoveryNode[14]
disconnected from discoveryNode[15]
checking integrity for file md5 after remove corruption exception
checking integrity for file md4 after remove corruption exception
checking integrity for file md3 after remove corruption exception
checking integrity for file md2 after remove corruption exception
checking integrity for file md1 after remove corruption exception
checking integrity for file md0 after remove corruption exception
checking integrity for file md6 after remove corruption exception
checking integrity for file md7 after remove corruption exception
checking integrity for file md8 after remove corruption exception
checking integrity for file md9 after remove corruption exception
checking integrity for file md10 after remove corruption exception
checking integrity for file md11 after remove corruption exception
checking integrity for file md12 after remove corruption exception
checking integrity for file md13 after remove corruption exception
checking integrity for file md14 after remove corruption exception
shard-1 Corrupted file detected md5 checksum mismatch
shard-2 Corrupted file detected sha1 checksum mismatch
shard-3 Corrupted file detected crc32 checksum mismatch
shard-4 Corrupted file detected md5 checksum mismatch
shard-5 Corrupted file detected sha256 checksum mismatch
shard-6 Corrupted file detected md5 checksum mismatch
shard-7 Corrupted file detected sha1 checksum mismatch
shard-8 Corrupted file detected crc32 checksum mismatch
shard-9 Corrupted file detected md5 checksum mismatch
shard-10 Corrupted file detected sha256 checksum mismatch
shard-11 Corrupted file detected md5 checksum mismatch
shard-12 Corrupted file detected sha1 checksum mismatch
shard-13 Corrupted file detected crc32 checksum mismatch
shard-14 Corrupted file detected md5 checksum mismatch
shard-15 Corrupted file detected sha256 checksum mismatch
Cannot move away shard [[index][test][0]] Skipping this shard
Cannot move away shard [[index][test][1]] Skipping this shard
Cannot move away shard [[index][test][2]] Skipping this shard
Cannot move away shard [[index][test][3]] Skipping this shard
Cannot move away shard [[index][test][4]] Skipping this shard
Cannot move away shard [[index][prod][0]] Skipping this shard
Cannot move away shard [[index][prod][1]] Skipping this shard
Cannot move away shard [[index][prod][2]] Skipping this shard
Cannot move away shard [[index][prod][3]] Skipping this shard
Cannot move away shard [[index][prod][4]] Skipping this shard
Cannot move away shard [[index2][test2][0]] Skipping this shard
Cannot move away shard [[index2][test2][1]] Skipping this shard
Cannot move away shard [[index2][test2][2]] Skipping this shard
Cannot move away shard [[index2][test2][3]] Skipping this shard
Cannot move away shard [[index2][test2][4]] Skipping this shard
Error attempting to fail shard [primary] [index][0] reason [master marked shard as stale]
Error attempting to fail shard [replica] [index][1] reason [failed recovery]
Error attempting to fail shard [primary] [index][2] reason [shard failure, reason [index_failed_engine_exception]]
Error attempting to fail shard [replica] [index][3] reason [shard failure, reason [corrupt_index_exception]]
Error attempting to fail shard [primary] [index][4] reason [failed to perform indices:data/write/bulk[s] on replica]
Error attempting to fail shard [replica] [index][5] reason [failed to perform indices:data/write/bulk[s] on primary]
Error attempting to fail shard [primary] [index][6] reason [shard failure, reason [too_many_clauses: maxClauseCount is set to 1024]]
Error attempting to fail shard [replica] [index][7] reason [shard failure, reason [circuit_breaking_exception: Data too large]]
Error attempting to fail shard [primary] [index][8] reason [failed recovery, source node [[node-1]]]
Error attempting to fail shard [replica] [index][9] reason [failed recovery, source node [[node-2]]]
Error attempting to fail shard [primary] [index][10] reason [shard failure, reason [null_pointer_exception: null]]
Error attempting to fail shard [replica] [index][11] reason [shard failure, reason [illegal_argument_exception: Invalid format]]
Error attempting to fail shard [primary] [index][12] reason [failed recovery, source node [[node-3]], allocation id [_na_]]
Error attempting to fail shard [replica] [index][13] reason [failed recovery, source node [[node-4]], allocation id [_na_]]
Error attempting to fail shard [primary] [index][14] reason [shard failure, reason
Moved shard [0][p][index1][node1] to node [node2]
Moved shard [1][r][index2][node3] to node [node4]
Moved shard [2][p][index3][node5] to node [node6]
Moved shard [3][r][index4][node7] to node [node8]
Moved shard [4][p][index5][node9] to node [node10]
Moved shard [5][r][index6][node11] to node [node12]
Moved shard [6][p][index7][node13] to node [node14]
Moved shard [7][r][index8][node15] to node [node16]
Moved shard [8][p][index9][node17] to node [node18]
Moved shard [9][r][index10][node19] to node [node20]
Moved shard [10][p][index11][node21] to node [node22]
Moved shard [11][r][index12][node23] to node [node24]
Moved shard [12][p][index13][node25] to node [node26]
Moved shard [13][r][index14][node27] to node [node28]
Moved shard [14][p][index15][node29] to node [node30]
Assigned shard [1] to node [node-01]
Assigned shard [2] to node [node-02]
Assigned shard [3] to node [node-03]
Assigned shard [4] to node [node-04]
Assigned shard [5] to node [node-05]
Assigned shard [6] to node [node-06]
Assigned shard [7] to node [node-07]
Assigned shard [8] to node [node-08]
Assigned shard [9] to node [node-09]
Assigned shard [10] to node [node-10]
Assigned shard [11] to node [node-11]
Assigned shard [12] to node [node-12]
Assigned shard [13] to node [node-13]
Assigned shard [14] to node [node-14]
Assigned shard [15] to node [node-15]
No eligible node found to assign shard [0] allocation_status [NO_VALID_SHARD_COPY]
No eligible node found to assign shard [1] allocation_status [DECIDERS_NO]
No eligible node found to assign shard [2] allocation_status [THROTTLED]
No eligible node found to assign shard [3] allocation_status [FETCHING_SHARD_DATA]
No eligible node found to assign shard [4] allocation_status [NO_ATTEMPT]
No eligible node found to assign shard [5] allocation_status [AWAITING_INFO]
No eligible node found to assign shard [6] allocation_status [YES]
No eligible node found to assign shard [7] allocation_status [ALLOCATION_FAILED]
No eligible node found to assign shard [8] allocation_status [NO]
No eligible node found to assign shard [9] allocation_status [DELAYED_ALLOCATION]
No eligible node found to assign shard [10] allocation_status [EXISTING_RELOCATING_SHARD]
No eligible node found to assign shard [11] allocation_status [REPLICA_NOT_ASSIGNED]
No eligible node found to assign shard [12] allocation_status [PRIMARY_FAILED]
No eligible node found to assign shard [13] allocation_status [NODE_LEFT]
No eligible node found to assign shard [14] allocation_status [REROUTE_CANCELLED]
shard exists request meant for cluster[prod], but this is cluster[dev], ignoring request
shard exists request meant for cluster[eu-west-1], but this is cluster[us-east-2], ignoring request
shard exists request meant for cluster[test], but this is cluster[staging], ignoring request
shard exists request meant for cluster[asia], but this is cluster[europe], ignoring request
shard exists request meant for cluster[main], but this is cluster[backup], ignoring request
shard exists request meant for cluster[alpha], but this is cluster[beta], ignoring request
shard exists request meant for cluster[blue], but this is cluster[green], ignoring request
shard exists request meant for cluster[old], but this is cluster[new], ignoring request
shard exists request meant for cluster[foo], but this is cluster[bar], ignoring request
shard exists request meant for cluster[app1], but this is cluster[app2], ignoring request
shard exists request meant for cluster[demo], but this is cluster[live], ignoring request
shard exists request meant for cluster[north], but this is cluster[south], ignoring request
shard exists request meant for cluster[master], but this is cluster[slave], ignoring request
shard exists request meant for cluster[gold], but this is cluster[silver], ignoring request
shard exists request meant for cluster[red], but this is cluster[yellow], ignoring request
Relocate [shard1] from [node5] to [node3]
Relocate [shard2] from [node7] to [node4]
Relocate [shard3] from [node6] to [node2]
Relocate [shard4] from [node8] to [node1]
Relocate [shard5] from [node9] to [node6]
Relocate [shard6] from [node10] to [node5]
Relocate [shard7] from [node11] to [node8]
Relocate [shard8] from [node12] to [node7]
Relocate [shard9] from [node13] to [node10]
Relocate [shard10] from [node14] to [node9]
Relocate [shard11] from [node15] to [node12]
Relocate [shard12] from [node16] to [node11]
Relocate [shard13] from [node17] to [node14]
Relocate [shard14] from [node18] to [node13]
Relocate [shard15] from [node19] to [node16]
listing store meta data for shardId 0
listing store meta data for shardId 1
listing store meta data for shardId 2
listing store meta data for shardId 3
listing store meta data for shardId 4
listing store meta data for shardId 5
listing store meta data for shardId 6
listing store meta data for shardId 7
listing store meta data for shardId 8
listing store meta data for shardId 9
listing store meta data for shardId 10
listing store meta data for shardId 11
listing store meta data for shardId 12
listing store meta data for shardId 13
listing store meta data for shardId 14
shard1 loaded store meta data (took 0.12s)
shard2 loaded store meta data (took 0.15s)
shard3 loaded store meta data (took 0.09s)
shard4 loaded store meta data (took 0.11s)
shard5 loaded store meta data (took 0.13s)
shard6 loaded store meta data (took 0.14s)
shard7 loaded store meta data (took 0.10s)
shard8 loaded store meta data (took 0.16s)
shard9 loaded store meta data (took 0.08s)
shard10 loaded store meta data (took 0.17s)
shard11 loaded store meta data (took 0.07s)
shard12 loaded store meta data (took 0.18s)
shard13 loaded store meta data (took 0.06s)
shard14 loaded store meta data (took 0.19s)
index [users] is a system index because it matches index pattern [.kibana*] with description [Kibana system indices]
index [logs] is a system index because it matches index pattern [.logs*] with description [Logstash system indices]
index [metrics] is a system index because it matches index pattern [.monitoring*] with description [Monitoring system indices]
index [security] is a system index because it matches index pattern [.security*] with description [Security system indices]
index [alerts] is a system index because it matches index pattern [.alerts*] with description [Alerts system indices]
index [events] is a system index because it matches index pattern [.events*] with description [Events system indices]
index [tasks] is a system index because it matches index pattern [.tasks*] with description [Tasks system indices]
index [snapshots] is a system index because it matches index pattern [.snapshots*] with description [Snapshots system indices]
index [config] is a system index because it matches index pattern [.config*] with description [Configuration system indices]
index [audit] is a system index because it matches index pattern [.audit*] with description [Audit system indices]
index [ml] is a system index because it matches index pattern [.ml*] with description [Machine learning system indices]
index [ilm] is a system index because it matches index pattern [.ilm*] with description [Index lifecycle management system indices]
index [watcher] is a system index because it matches index pattern [.watcher*] with description [Watcher system indices]
index [rollup] is a system index because it matches index pattern [.rollup*] with description [Rollup system indices]
index [transform] is a system index because it matches index pattern [.transform*] with description [Transform system indices]
Cannot move shard: [index][0] to node: [node_1]. Decisions: [THROTTLE]
Cannot move shard: [logs][3] to node: [node_2]. Decisions: [NO]
Cannot move shard: [users][1] to node: [node_3]. Decisions: [YES, THROTTLE]
Cannot move shard: [products][2] to node: [node_4]. Decisions: [NO, NO, THROTTLE]
Cannot move shard: [orders][4] to node: [node_5]. Decisions: [YES, YES, YES]
Cannot move shard: [reviews][5] to node: [node_6]. Decisions: [NO, YES, NO]
Cannot move shard: [sales][6] to node: [node_7]. Decisions: [THROTTLE, THROTTLE, THROTTLE]
Cannot move shard: [inventory][7] to node: [node_8]. Decisions: [YES, NO, YES]
Cannot move shard: [customers][8] to node: [node_9]. Decisions: [NO, THROTTLE, NO]
Cannot move shard: [payments][9] to node: [node_10]. Decisions: [YES, YES, NO]
Cannot move shard: [reports][10] to node: [node_11]. Decisions: [NO, NO, YES]
Cannot move shard: [settings][11] to node: [node_12]. Decisions: [YES, NO, THROTTLE]
Cannot move shard: [notifications][12] to node: [node_13]. Decisions: [NO, YES, YES]
Moving shard: [index-0] from node: [node-1] to node: [node-3]
Moving shard: [index-4] from node: [node-2] to node: [node-5]
Moving shard: [index-7] from node: [node-4] to node: [node-6]
Moving shard: [index-3] from node: [node-5] to node: [node-1]
Moving shard: [index-6] from node: [node-3] to node: [node-4]
Moving shard: [index-9] from node: [node-6] to node: [node-2]
Moving shard: [index-2] from node: [node-1] to node: [node-6]
Moving shard: [index-5] from node: [node-2] to node: [node-3]
Moving shard: [index-8] from node: [node-4] to node: [node-5]
Moving shard: [index-1] from node: [node-3] to node: [node-2]
Moving shard: [index-10] from node: [node-5] to node: [node-4]
Moving shard: [index-11] from node: [node-6] to node: [node-1]
Moving shard: [index-12] from node: [node-1] to node: [node-5]
Moving shard: [index-13] from node: [node-2] to node: [node-6]
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
Performing balancing for remote shards.
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
No eligible remote nodes found to perform balancing
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
bypassing refresh_interval
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
getFreePhysicalMemorySize is not available
exception retrieving free physical memory: java.lang.NullPointerException
exception retrieving free physical memory: java.lang.OutOfMemoryError
exception retrieving free physical memory: java.io.IOException
exception retrieving free physical memory: java.lang.SecurityException
exception retrieving free physical memory: java.lang.IllegalArgumentException
exception retrieving free physical memory: java.lang.ClassNotFoundException
exception retrieving free physical memory: java.lang.NoSuchMethodError
exception retrieving free physical memory: java.lang.StackOverflowError
exception retrieving free physical memory: java.lang.ArithmeticException
exception retrieving free physical memory: java.lang.NumberFormatException
exception retrieving free physical memory: java.lang.IllegalStateException
exception retrieving free physical memory: java.lang.UnsupportedOperationException
exception retrieving free physical memory: java.util.ConcurrentModificationException
exception retrieving free physical memory: java.util.NoSuchElementException
exception retrieving free physical memory: java.util.MissingResourceException
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getTotalPhysicalMemorySize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getFreeSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
getTotalSwapSpaceSize is not available
chunk [0] gone, updating session ids [ 123456 -> 654321 ]
chunk [1] gone, updating session ids [ 789012 -> 210987 ]
chunk [2] gone, updating session ids [ 345678 -> 876543 ]
chunk [3] gone, updating session ids [ 901234 -> 432109 ]
chunk [4] gone, updating session ids [ 567890 -> 098765 ]
chunk [5] gone, updating session ids [ 234567 -> 765432 ]
chunk [6] gone, updating session ids [ 890123 -> 321098 ]
chunk [7] gone, updating session ids [ 456789 -> 987654 ]
chunk [8] gone, updating session ids [ 678901 -> 109876 ]
chunk [9] gone, updating session ids [ 012345 -> 543210 ]
chunk [10] gone, updating session ids [ 135792 -> 297531 ]
chunk [11] gone, updating session ids [ 246801 -> 108642 ]
chunk [12] gone, updating session ids [ 357913 -> 319573 ]
chunk [13] gone, updating session ids [ 468024 -> 420864 ]
chunk [14] gone, updating session ids [ 579135 -> 531975 ]
removing index template [logstash-2023.10.22]
removing index template [kibana-2023.10.22]
removing index template [metricbeat-2023.10.22]
removing index template [filebeat-2023.10.22]
removing index template [auditbeat-2023.10.22]
removing index template [packetbeat-2023.10.22]
removing index template [winlogbeat-2023.10.22]
removing index template [heartbeat-2023.10.22]
removing index template [apm-2023.10.22]
removing index template [security-2023.10.22]
removing index template [system-2023.10.22]
removing index template [nginx-2023.10.22]
removing index template [mysql-2023.10.22]
removing index template [mongodb-2023.10.22]
removing index template [redis-2023.10.22]
Skipping task backup since it does not match current OS platform
Skipping task update since it does not match current OS platform
Skipping task scan since it does not match current OS platform
Skipping task install since it does not match current OS platform
Skipping task uninstall since it does not match current OS platform
Skipping task sync since it does not match current OS platform
Skipping task encrypt since it does not match current OS platform
Skipping task decrypt since it does not match current OS platform
Skipping task compress since it does not match current OS platform
Skipping task decompress since it does not match current OS platform
Skipping task clean since it does not match current OS platform
Skipping task optimize since it does not match current OS platform
Skipping task debug since it does not match current OS platform
Skipping task test since it does not match current OS platform
Skipping task monitor since it does not match current OS platform
Adding configuration to HDFS Client Configuration : fs.defaultFS = hdfs://localhost:9000
Adding configuration to HDFS Client Configuration : dfs.replication = 1
Adding configuration to HDFS Client Configuration : dfs.blocksize = 64m
Adding configuration to HDFS Client Configuration : dfs.namenode.name.dir = /home/hadoop/hdfs/name
Adding configuration to HDFS Client Configuration : dfs.datanode.data.dir = /home/hadoop/hdfs/data
Adding configuration to HDFS Client Configuration : dfs.webhdfs.enabled = true
Adding configuration to HDFS Client Configuration : dfs.permissions.enabled = false
Adding configuration to HDFS Client Configuration : dfs.client.use.datanode.hostname = true
Adding configuration to HDFS Client Configuration : dfs.namenode.rpc-bind-host = 0.0.0.0
Adding configuration to HDFS Client Configuration : dfs.namenode.servicerpc-bind-host = 0.0.0.0
Adding configuration to HDFS Client Configuration : dfs.namenode.http-bind-host = 0.0.0.0
Adding configuration to HDFS Client Configuration : dfs.namenode.https-bind-host = 0.0.0.0
Adding configuration to HDFS Client Configuration : dfs.datanode.use.datanode.hostname = true
Adding configuration to HDFS Client Configuration : dfs.datanode.address = 0.0.0.0:50010
Adding configuration to HDFS Client Configuration : dfs.datanode.http.address = 0.0.0.0:50075
processing [cluster state update task [id: 1]]: took [0.5s] done applying updated cluster state (version: 2 , uuid: 3a4b5c6d )
processing [shard-failed ([test][0], node[xyz], [P], s[STARTED], a[id=123]) reason [failed recovery]]: took [1.2s] done applying updated cluster state (version: 3 , uuid: 7e8f9g0h )
processing [create-index [demo], cause [api]]: took [2.4s] done applying updated cluster state (version: 4 , uuid: 1i2j3k4l )
processing [put-mapping [test]]: took [0.8s] done applying updated cluster state (version: 5 , uuid: 5m6n7o8p )
processing [delete-index [[test]]]: took [1.6s] done applying updated cluster state (version: 6 , uuid: 9q0r1s2t )
processing [cluster_reroute(async_shard_fetch)]]: took [3.2s] done applying updated cluster state (version: 7 , uuid: 3u4v5w6x )
processing [node-join]: took [0.9s] done applying updated cluster state (version: 8 , uuid: 7y8z9a0b )
processing [node-left]: took [1.3s] done applying updated cluster state (version: 9 , uuid: 1c2d3e4f )
processing [shard-started ([test][1], node[abc], [P], s[INITIALIZING]), reason [after recovery from store]]]: took [2.1s] done applying updated cluster state (version: 10 , uuid: 5g6h7i8j )
processing [shard-failed ([demo][0], node[def], [R], s[STARTED], a[id=456]) reason [[demo][0] failed to perform indices:data/write/bulk[s] on replica, message [[IllegalArgumentException][Document contains at least one immense term in field=\"content\" (whose UTF8 encoding is longer than the max length 32766)]]]]]: took [4.5s] done applying updated cluster state (version: 11 , uuid: 9k0l1m2n )
processing [update-mapping [_doc]]: took [1.7s] done applying updated cluster state (version: 12 , uuid: 3o4p5q6r )
processing [cluster_update_settings]: took [0.6s] done applying updated cluster state (version: 13 , uuid: 7s8t9u0v )
processing [indices_store ([[test]][[0]])]: took [2.3s] done applying updated cluster state (version: 14 , uuid: 1w2x3y4z )
processing [shard-started ([demo][1], node[ghi], [R], s[INITIALIZING]), reason [master {node-1}{abc}{localhost}{127.0.0.1} marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]]]: took [3.4s] done applying updated cluster state (version: 15 , uuid: 5a6b7c8d )
[shard1] [snapshot-20211022] failed to list directory - some of files might not be deleted
[shard2] [snapshot-20211021] failed to list directory - some of files might not be deleted
[shard3] [snapshot-20211023] failed to list directory - some of files might not be deleted
[shard4] [snapshot-20211020] failed to list directory - some of files might not be deleted
[shard5] [snapshot-20211019] failed to list directory - some of files might not be deleted
[shard6] [snapshot-20211018] failed to list directory - some of files might not be deleted
[shard7] [snapshot-20211017] failed to list directory - some of files might not be deleted
[shard8] [snapshot-20211016] failed to list directory - some of files might not be deleted
[shard9] [snapshot-20211015] failed to list directory - some of files might not be deleted
[shard10] [snapshot-20211014] failed to list directory - some of files might not be deleted
[shard11] [snapshot-20211013] failed to list directory - some of files might not be deleted
[shard12] [snapshot-20211012] failed to list directory - some of files might not be deleted
[shard13] [snapshot-20211011] failed to list directory - some of files might not be deleted
[shard14] [snapshot-20211010] failed to list directory - some of files might not be deleted
[shard15] [snapshot-20211009] failed to list directory - some of files might not be deleted
Task execution finished on thread. Task: 1001 , Thread: 12
Task execution finished on thread. Task: 2002 , Thread: 23
Task execution finished on thread. Task: 3003 , Thread: 34
Task execution finished on thread. Task: 4004 , Thread: 45
Task execution finished on thread. Task: 5005 , Thread: 56
Task execution finished on thread. Task: 6006 , Thread: 67
Task execution finished on thread. Task: 7007 , Thread: 78
Task execution finished on thread. Task: 8008 , Thread: 89
Task execution finished on thread. Task: 9009 , Thread: 90
Task execution finished on thread. Task: 1010 , Thread: 01
Task execution finished on thread. Task: 1111 , Thread: 02
Task execution finished on thread. Task: 1212 , Thread: 03
Task execution finished on thread. Task: 1313 , Thread: 04
Task execution finished on thread. Task: 1414 , Thread: 05
Task execution finished on thread. Task: 1515 , Thread: 06
registering repository [my-app]
registering repository [spring-boot-starter]
registering repository [maven-central]
registering repository [junit-jupiter]
registering repository [log4j-core]
registering repository [commons-lang3]
registering repository [hibernate-core]
registering repository [mysql-connector-java]
registering repository [lombok]
registering repository [gson]
registering repository [slf4j-api]
registering repository [spring-security-core]
registering repository [thymeleaf]
registering repository [h2-database]
registering repository [mockito-core]
cluster state updated, source [summary] nodes joined: 2, nodes left: 1, version: 5
cluster state updated, source [newClusterState] cluster uuid: 6a7b8c9d, metadata version: 4
cluster state updated, source [summary] nodes joined: 0, nodes left: 0, version: 6
cluster state updated, source [newClusterState] cluster uuid: 6a7b8c9d, metadata version: 5
cluster state updated, source [summary] nodes joined: 1, nodes left: 0, version: 7
cluster state updated, source [newClusterState] cluster uuid: 6a7b8c9d, metadata version: 6
cluster state updated, source [summary] nodes joined: 0, nodes left: 1, version: 8
cluster state updated, source [newClusterState] cluster uuid: 6a7b8c9d, metadata version: 7
cluster state updated, source [summary] nodes joined: 3, nodes left: 0, version: 9
cluster state updated, source [newClusterState] cluster uuid: 6a7b8c9d, metadata version: 8
cluster state updated, source [summary] nodes joined: 0, nodes left: 2, version: 10
cluster state updated, source [newClusterState] cluster uuid: 6a7b8c9d, metadata version: 9
cluster state updated, source [summary] nodes joined: 2, nodes left: 0, version: 11
cluster state updated, source [newClusterState] cluster uuid: 6a7b8c9d, metadata version: 10
cluster state updated, source [summary] nodes joined: 1, nodes left: 1, version: 12
adding node [0]
adding node [1]
adding node [2]
adding node [3]
adding node [4]
adding node [5]
adding node [6]
adding node [7]
adding node [8]
adding node [9]
adding node [10]
adding node [11]
adding node [12]
adding node [13]
adding node [14]
0x4a3f deleted shard reason [timeout]
0x7b2c deleted shard reason [corruption]
0x9d1e deleted shard reason [replication failure]
0x6f4d deleted shard reason [disk full]
0x8c3a deleted shard reason [user request]
0x5b1f deleted shard reason [merge conflict]
0x3e2d deleted shard reason [network error]
0x2d4e deleted shard reason [memory overflow]
0x1f6c deleted shard reason [invalid data]
0x4e7b deleted shard reason [system crash]
0x9a3d deleted shard reason [security breach]
0x8b5f deleted shard reason [maintenance mode]
0x7c6e deleted shard reason [rebalancing]
0x6d8c deleted shard reason [upgrade]
0x5e9a deleted shard reason [migration]
--> checking iteration 0
--> checking iteration 1
--> checking iteration 2
--> checking iteration 3
--> checking iteration 4
--> checking iteration 5
--> checking iteration 6
--> checking iteration 7
--> checking iteration 8
--> checking iteration 9
--> checking iteration 10
--> checking iteration 11
--> checking iteration 12
--> checking iteration 13
--> checking iteration 14
failure updating cluster state java.lang.IllegalStateException: No master node detected
failure updating cluster state org.elasticsearch.cluster.block.ClusterBlockException: blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];
failure updating cluster state org.elasticsearch.transport.NodeDisconnectedException: [node-1][127.0.0.1:9300][cluster:monitor/state] disconnected
failure updating cluster state org.elasticsearch.ElasticsearchTimeoutException: timed out waiting for all nodes to process published state [123] within [30s]
failure updating cluster state org.elasticsearch.cluster.coordination.FailedToCommitClusterStateException: publication failed
failure updating cluster state java.io.IOException: failed to obtain in-memory shard lock
failure updating cluster state org.elasticsearch.action.UnavailableShardsException: [index][0] primary shard is not active Timeout
failure updating cluster state org.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException: failed to process cluster event (create-index [index], cause [api]) within 1m
failure updating cluster state org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [<transport_request>] would be [123456789/117.7mb], which is larger than the limit of [123456789/117.7mb], real usage: [123456789/117.7mb], new bytes reserved: [0/0b], usages [request=0/0b, fielddata=0/0b, in_flight_requests=0/0b, model_inference=0/0b, accounting=0/0b]
failure updating cluster state org.elasticsearch.cluster.coordination.CoordinationStateRejectedException: join validation on cluster state with a different cluster uuid ZjZkMzEzYjEtYjQ5Zi00YjI5LTkxMzAtZmUyNzg4NjQwMjM2 than local cluster uuid MmUxZDkxZTctNzEwYS00MmQyLWI3YjAtN2E3ZTg4MDQwNzQw, rejecting
failure updating cluster state org.elasticsearch.cluster.coordination.NoMasterBlockService$NoMasterBlockException: no master
failure updating cluster state org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$RetryOnPrimaryException: primary term [1] did not match current primary term [2]
failure updating cluster state org.elasticsearch.indices.IndexClosedException: closed
failure updating cluster state org.elasticsearch.snapshots.SnapshotCreationException: [repository:index-20211022/YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXo=-VXa6nqfQc6f9tKlO8Xl9A] failed to create snapshot
failure updating cluster state org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: rejected execution of coordinating operation for [<*>] on [<*>]
all expected nodes acknowledged cluster_state update (version: 12)
all expected nodes acknowledged cluster_state update (version: 34)
all expected nodes acknowledged cluster_state update (version: 56)
all expected nodes acknowledged cluster_state update (version: 78)
all expected nodes acknowledged cluster_state update (version: 90)
all expected nodes acknowledged cluster_state update (version: 11)
all expected nodes acknowledged cluster_state update (version: 33)
all expected nodes acknowledged cluster_state update (version: 55)
all expected nodes acknowledged cluster_state update (version: 77)
all expected nodes acknowledged cluster_state update (version: 99)
all expected nodes acknowledged cluster_state update (version: 13)
all expected nodes acknowledged cluster_state update (version: 35)
all expected nodes acknowledged cluster_state update (version: 57)
all expected nodes acknowledged cluster_state update (version: 79)
applying settings from cluster state with version 12
applying settings from cluster state with version 7
applying settings from cluster state with version 15
applying settings from cluster state with version 9
applying settings from cluster state with version 11
applying settings from cluster state with version 10
applying settings from cluster state with version 8
applying settings from cluster state with version 13
applying settings from cluster state with version 6
applying settings from cluster state with version 14
applying settings from cluster state with version 4
applying settings from cluster state with version 5
applying settings from cluster state with version 3
applying settings from cluster state with version 2
applying settings from cluster state with version 1
unregistering repository [test]
unregistering repository [demo]
unregistering repository [backup]
unregistering repository [main]
unregistering repository [config]
unregistering repository [logs]
unregistering repository [data]
unregistering repository [temp]
unregistering repository [cache]
unregistering repository [docs]
unregistering repository [src]
unregistering repository [bin]
unregistering repository [lib]
unregistering repository [dist]
unregistering repository [web]
failed to process shard failure to (potentially) send back shard failure on corruption inner
failed to process shard failure to (potentially) send back shard failure on corruption inner exception
failed to process shard failure to (potentially) send back shard failure on corruption inner error
failed to process shard failure to (potentially) send back shard failure on corruption inner cause
failed to process shard failure to (potentially) send back shard failure on corruption inner reason
failed to process shard failure to (potentially) send back shard failure on corruption inner message
failed to process shard failure to (potentially) send back shard failure on corruption inner detail
failed to process shard failure to (potentially) send back shard failure on corruption inner info
failed to process shard failure to (potentially) send back shard failure on corruption inner log
failed to process shard failure to (potentially) send back shard failure on corruption inner trace
failed to process shard failure to (potentially) send back shard failure on corruption inner stack
failed to process shard failure to (potentially) send back shard failure on corruption inner source
failed to process shard failure to (potentially) send back shard failure on corruption inner code
failed to process shard failure to (potentially) send back shard failure on corruption inner line
failed to process shard failure to (potentially) send back shard failure on corruption inner status
node: [1] most available path has less than 0 total bytes of disk [0], skipping
node: [2] most available path has less than 0 total bytes of disk [0], skipping
node: [3] most available path has less than 0 total bytes of disk [0], skipping
node: [4] most available path has less than 0 total bytes of disk [0], skipping
node: [5] most available path has less than 0 total bytes of disk [0], skipping
node: [6] most available path has less than 0 total bytes of disk [0], skipping
node: [7] most available path has less than 0 total bytes of disk [0], skipping
node: [8] most available path has less than 0 total bytes of disk [0], skipping
node: [9] most available path has less than 0 total bytes of disk [0], skipping
node: [10] most available path has less than 0 total bytes of disk [0], skipping
node: [11] most available path has less than 0 total bytes of disk [-1], skipping
node: [12] most available path has less than 0 total bytes of disk [-2], skipping
node: [13] most available path has less than 0 total bytes of disk [-3], skipping
node: [14] most available path has less than 0 total bytes of disk [-4], skipping
node: [15] most available path has less than 0 total bytes of disk [-5], skipping
Failed to delete file /home/user/documents/report.pdf on stream failure: java.io.IOException: Stream closed
Failed to delete file /var/log/syslog on stream failure: java.nio.file.AccessDeniedException: Permission denied
Failed to delete file /tmp/cache/data.bin on stream failure: java.lang.NullPointerException: No such file or directory
Failed to delete file /opt/app/config.xml on stream failure: java.util.concurrent.TimeoutException: Operation timed out
Failed to delete file /mnt/usb/photos/image.jpg on stream failure: java.io.FileNotFoundException: Device not found
Failed to delete file /root/.bashrc on stream failure: java.security.AccessControlException: Access denied
Failed to delete file /media/cdrom/install.exe on stream failure: java.io.EOFException: End of file reached
Failed to delete file /usr/local/bin/script.sh on stream failure: java.lang.InterruptedException: Interrupted by signal
Failed to delete file /etc/hosts on stream failure: java.net.SocketException: Connection reset
Failed to delete file /dev/sda1 on stream failure: java.lang.IllegalArgumentException: Invalid argument
Failed to delete file /proc/cpuinfo on stream failure: java.io.UnsupportedEncodingException: Invalid encoding
Failed to delete file /srv/http/index.html on stream failure: java.net.MalformedURLException: Bad URL format
Failed to delete file /lib/modules/kernel.o on stream failure: java.lang.UnsatisfiedLinkError: Library not loaded
Failed to delete file /boot/grub/grub.cfg on stream failure: java.util.zip.ZipException: Corrupted zip file
Failed to delete file /data/db/mongo.log on stream failure: com.mongodb.MongoException: Database error
Failed to abort stream before closing ConnectionResetError(104, 'Connection reset by peer')
Failed to abort stream before closing TimeoutError(110, 'Connection timed out')
Failed to abort stream before closing OSError(9, 'Bad file descriptor')
Failed to abort stream before closing ValueError('Invalid file format')
Failed to abort stream before closing RuntimeError('Maximum recursion depth exceeded')
Failed to abort stream before closing KeyboardInterrupt
Failed to abort stream before closing MemoryError
Failed to abort stream before closing FileNotFoundError(2, 'No such file or directory')
Failed to abort stream before closing PermissionError(13, 'Permission denied')
Failed to abort stream before closing AttributeError("'NoneType' object has no attribute 'close'")
Failed to abort stream before closing ImportError('No module named \'requests\'')
Failed to abort stream before closing AssertionError('Stream is already closed')
Failed to abort stream before closing NameError('name \'stream\' is not defined')
Failed to abort stream before closing SyntaxError('invalid syntax')
Failed to abort stream before closing ZeroDivisionError('division by zero')
Rest specs for project [src/main/java/com/example/demo] will be copied to the test resources from the published jar (version: [1.0.0]).
Rest specs for project [src/test/java/com/example/test] will be copied to the test resources from the published jar (version: [1.0.1]).
Rest specs for project [src/main/resources/com/example/config] will be copied to the test resources from the published jar (version: [1.0.2]).
Rest specs for project [src/test/resources/com/example/data] will be copied to the test resources from the published jar (version: [1.0.3]).
Rest specs for project [src/main/java/com/example/service] will be copied to the test resources from the published jar (version: [1.0.4]).
Rest specs for project [src/test/java/com/example/mock] will be copied to the test resources from the published jar (version: [1.0.5]).
Rest specs for project [src/main/resources/com/example/properties] will be copied to the test resources from the published jar (version: [1.0.6]).
Rest specs for project [src/test/resources/com/example/json] will be copied to the test resources from the published jar (version: [1.0.7]).
Rest specs for project [src/main/java/com/example/controller] will be copied to the test resources from the published jar (version: [1.0.8]).
Rest specs for project [src/test/java/com/example/integration] will be copied to the test resources from the published jar (version: [1.0.9]).
Rest specs for project [src/main/resources/com/example/swagger] will be copied to the test resources from the published jar (version: [1.1.0]).
Rest specs for project [src/test/resources/com/example/xml] will be copied to the test resources from the published jar (version: [1.1.1]).
Rest specs for project [src/main/java/com/example/model] will be copied to the test resources from the published jar (version: [1.1.2]).
Rest specs for project [src/test/java/com/example/unit] will be copied to the test resources from the published jar (version: [1.1.3]).
Rest specs for project [src/main/resources/com/example/logback] will be copied to the test resources from the published jar (version: [1.1.4]).
start filtering instance webserver with tags prod, nginx, us-east-1.
start filtering instance database with tags dev, mysql, eu-west-2.
start filtering instance appserver with tags test, nodejs, ap-south-1.
start filtering instance backup with tags prod, s3, us-west-2.
start filtering instance analytics with tags dev, spark, eu-central-1.
start filtering instance frontend with tags test, react, ap-northeast-1.
start filtering instance loadbalancer with tags prod, haproxy, us-east-2.
start filtering instance security with tags dev, firewall, eu-west-1.
start filtering instance api with tags test, flask, ap-southeast-1.
start filtering instance monitoring with tags prod, grafana, us-west-1.
start filtering instance chatbot with tags dev, rasa, eu-central-2.
start filtering instance email with tags test, postfix, ap-northeast-2.
start filtering instance storage with tags prod, ebs, us-east-1.
start filtering instance logging with tags dev, elasticsearch, eu-west-2.
failed creating missing peer recovery retention leases java.lang.NullPointerException
failed creating missing peer recovery retention leases org.elasticsearch.index.shard.ShardNotFoundException
failed creating missing peer recovery retention leases org.elasticsearch.action.UnavailableShardsException
failed creating missing peer recovery retention leases java.io.IOException
failed creating missing peer recovery retention leases org.elasticsearch.index.engine.EngineException
failed creating missing peer recovery retention leases org.elasticsearch.cluster.block.ClusterBlockException
failed creating missing peer recovery retention leases org.elasticsearch.index.IndexNotFoundException
failed creating missing peer recovery retention leases org.elasticsearch.transport.NodeDisconnectedException
failed creating missing peer recovery retention leases org.elasticsearch.common.util.concurrent.EsRejectedExecutionException
failed creating missing peer recovery retention leases org.elasticsearch.index.translog.TranslogException
failed creating missing peer recovery retention leases java.lang.IllegalStateException
failed creating missing peer recovery retention leases org.elasticsearch.index.seqno.RetentionLeaseInvalidRetainingSeqNoException
failed creating missing peer recovery retention leases org.elasticsearch.index.seqno.RetentionLeaseNotFoundException
failed creating missing peer recovery retention leases org.elasticsearch.index.seqno.RetentionLeaseSyncFailedException
failed creating missing peer recovery retention leases java.lang.OutOfMemoryError
[1] [snapshot-20211020] not_recovering file [segments_1] from [_0.cfe], exists in local store and is same
[2] [snapshot-20211021] not_recovering file [segments_2] from [_1.cfs], exists in local store and is same
[3] [snapshot-20211022] not_recovering file [segments_3] from [_2.si], exists in local store and is same
[4] [snapshot-20211023] not_recovering file [segments_4] from [_3.fdx], exists in local store and is same
[5] [snapshot-20211024] not_recovering file [segments_5] from [_4.fdt], exists in local store and is same
[6] [snapshot-20211025] not_recovering file [segments_6] from [_5.doc], exists in local store and is same
[7] [snapshot-20211026] not_recovering file [segments_7] from [_6.pos], exists in local store and is same
[8] [snapshot-20211027] not_recovering file [segments_8] from [_7.pay], exists in local store and is same
[9] [snapshot-20211028] not_recovering file [segments_9] from [_8.nvd], exists in local store and is same
[10] [snapshot-20211029] not_recovering file [segments_10] from [_9.nvm], exists in local store and is same
[11] [snapshot-20211030] not_recovering file [segments_11] from [_10.dvd], exists in local store and is same
[12] [snapshot-20211031] not_recovering file [segments_12] from [_11.dvm], exists in local store and is same
[13] [snapshot-20211101] not_recovering file [segments_13] from [_12.tip], exists in local store and is same
[14] [snapshot-20211102] not_recovering file [segments_14] from [_13.dim], exists in local store and is same
[15] [snapshot-20211103] not_recovering file [segments_15] from [_14.fnm], exists in local store and is same
Found missing classes, but task is configured to ignore all of them: [com.example.Foo, com.example.Bar, com.example.Baz]
Found missing classes, but task is configured to ignore all of them: [org.apache.commons.lang3.StringUtils, org.apache.commons.io.FileUtils]
Found missing classes, but task is configured to ignore all of them: [java.util.List, java.util.Map, java.util.Set]
Found missing classes, but task is configured to ignore all of them: [android.app.Activity, android.content.Intent, android.os.Bundle]
Found missing classes, but task is configured to ignore all of them: [javax.swing.JFrame, javax.swing.JButton, javax.swing.JLabel]
Found missing classes, but task is configured to ignore all of them: [java.lang.String, java.lang.Integer, java.lang.Double]
Found missing classes, but task is configured to ignore all of them: [com.google.gson.Gson, com.google.gson.JsonObject, com.google.gson.JsonArray]
Found missing classes, but task is configured to ignore all of them: [org.junit.Test, org.junit.Assert, org.junit.Before]
Found missing classes, but task is configured to ignore all of them: [java.io.File, java.io.FileReader, java.io.FileWriter]
Found missing classes, but task is configured to ignore all of them: [java.net.URL, java.net.HttpURLConnection, java.net.URLEncoder]
Found missing classes, but task is configured to ignore all of them: [java.sql.Connection, java.sql.Statement, java.sql.ResultSet]
Found missing classes, but task is configured to ignore all of them: [java.awt.Graphics, java.awt.Color, java.awt.Font]
Found missing classes, but task is configured to ignore all of them: [java.math.BigInteger, java.math.BigDecimal, java.math.RoundingMode]
Found missing classes, but task is configured to ignore all of them: [java.security.MessageDigest, java.security.NoSuchAlgorithmException, java.security.SecureRandom]
Found missing classes, but task is configured to ignore all of them: [java.time.LocalDate, java.time.LocalDateTime, java.time.format.DateTimeFormatter]
--> indexing with id [1], and routing [user_123]
--> indexing with id [1], and routing [null]
--> indexing with id [1], and routing [product_456]
--> indexing with id [1], and routing [order_789]
--> indexing with id [1], and routing [category_abc]
--> indexing with id [1], and routing [tag_xyz]
--> indexing with id [1], and routing [location_usa]
--> indexing with id [1], and routing [date_20211022]
--> indexing with id [1], and routing [status_active]
--> indexing with id [1], and routing [type_image]
--> indexing with id [1], and routing [source_bing]
--> indexing with id [1], and routing [language_en]
--> indexing with id [1], and routing [format_json]
--> indexing with id [1], and routing [size_10kb]
--> indexing with id [1], and routing [hash_abcdefg]
creating shard_id 0
creating shard_id 1
creating shard_id 2
creating shard_id 3
creating shard_id 4
creating shard_id 5
creating shard_id 6
creating shard_id 7
creating shard_id 8
creating shard_id 9
creating shard_id 10
creating shard_id 11
creating shard_id 12
creating shard_id 13
creating shard_id 14
Component: Database
Component: Web Server
Component: Load Balancer
Component: Cache
Component: Firewall
Component: Router
Component: Switch
Component: Application
Component: Authentication
Component: Encryption
Component: Logging
Component: Monitoring
Component: Backup
Component: Scheduler
Component: Notification
checking for index products with docId 4567
checking for index users with docId 1234
checking for index orders with docId 7890
checking for index reviews with docId 2345
checking for index categories with docId 6789
checking for index articles with docId 3456
checking for index events with docId 8901
checking for index books with docId 4568
checking for index movies with docId 1235
checking for index songs with docId 7891
checking for index games with docId 2346
checking for index photos with docId 6780
checking for index videos with docId 3457
checking for index podcasts with docId 8902
checking for index recipes with docId 4569
deleting custom index 1 directory [/home/user1/indexes]
deleting custom index 2 directory [/var/log/indexes]
deleting custom index 3 directory [/tmp/indexes]
deleting custom index 4 directory [/opt/indexes]
deleting custom index 5 directory [/data/indexes]
deleting custom index 6 directory [/home/user2/indexes]
deleting custom index 7 directory [/var/cache/indexes]
deleting custom index 8 directory [/tmp/user1/indexes]
deleting custom index 9 directory [/opt/user2/indexes]
deleting custom index 10 directory [/data/user3/indexes]
deleting custom index 11 directory [/home/user4/indexes]
deleting custom index 12 directory [/var/log/user5/indexes]
deleting custom index 13 directory [/tmp/user6/indexes]
deleting custom index 14 directory [/opt/user7/indexes]
deleting custom index 15 directory [/data/user8/indexes]
Setting up tests for src node 1 and target node 2
Setting up tests for src node 3 and target node 4
Setting up tests for src node 5 and target node 6
Setting up tests for src node 7 and target node 8
Setting up tests for src node 9 and target node 10
Setting up tests for src node 11 and target node 12
Setting up tests for src node 13 and target node 14
Setting up tests for src node 15 and target node 16
Setting up tests for src node 17 and target node 18
Setting up tests for src node 19 and target node 20
Setting up tests for src node 21 and target node 22
Setting up tests for src node 23 and target node 24
Setting up tests for src node 25 and target node 26
Setting up tests for src node 27 and target node 28
Setting up tests for src node 29 and target node 30
The exception from search phase results processor [Facet] in the search pipeline [ProductSearch] was ignored java.lang.NullPointerException
The exception from search phase results processor [SpellCheck] in the search pipeline [QuerySuggestion] was ignored org.apache.solr.common.SolrException
The exception from search phase results processor [Highlight] in the search pipeline [DocumentSearch] was ignored java.io.IOException
The exception from search phase results processor [Ranking] in the search pipeline [WebSearch] was ignored java.lang.IllegalArgumentException
The exception from search phase results processor [Filter] in the search pipeline [ImageSearch] was ignored java.lang.ClassCastException
The exception from search phase results processor [Grouping] in the search pipeline [NewsSearch] was ignored java.util.ConcurrentModificationException
The exception from search phase results processor [Pagination] in the search pipeline [VideoSearch] was ignored java.lang.IndexOutOfBoundsException
The exception from search phase results processor [Aggregation] in the search pipeline [AnalyticsSearch] was ignored java.lang.ArithmeticException
The exception from search phase results processor [Sorting] in the search pipeline [ShoppingSearch] was ignored java.util.NoSuchElementException
The exception from search phase results processor [Relevance] in the search pipeline [SocialSearch] was ignored java.lang.OutOfMemoryError
The exception from search phase results processor [Snippet] in the search pipeline [MapSearch] was ignored java.net.SocketTimeoutException
The exception from search phase results processor [Deduplication] in the search pipeline [MusicSearch] was ignored java.lang.SecurityException
The exception from search phase results processor [Personalization] in the search pipeline [ProfileSearch] was ignored java.lang.UnsupportedOperationException
The exception from search phase results processor [Translation] in the search pipeline [LanguageSearch] was ignored java.util.MissingResourceException
The exception from search phase results processor [Clustering] in the search pipeline [TopicSearch] was ignored org.apache.lucene.queryparser.classic.ParseException
[user] Cleaned up stale index [111]
[user] Cleaned up stale index [123]
[product] Cleaned up stale index [456]
[order] Cleaned up stale index [789]
[customer] Cleaned up stale index [1011]
[review] Cleaned up stale index [1213]
[category] Cleaned up stale index [1415]
[inventory] Cleaned up stale index [1617]
[cart] Cleaned up stale index [1819]
[payment] Cleaned up stale index [2021]
[shipment] Cleaned up stale index [2223]
[coupon] Cleaned up stale index [2425]
[wishlist] Cleaned up stale index [2627]
[feedback] Cleaned up stale index [2829]
[profile] Cleaned up stale index [3031]
[notification] Cleaned up stale index [3233]
exception error from blob container for file data.csv
exception error from blob container for file image.jpg
exception error from blob container for file report.docx
exception error from blob container for file video.mp4
exception error from blob container for file music.mp3
exception error from blob container for file index.html
exception error from blob container for file script.js
exception error from blob container for file style.css
exception error from blob container for file config.ini
exception error from blob container for file log.txt
exception error from blob container for file backup.zip
exception error from blob container for file game.exe
exception error from blob container for file resume.pdf
exception error from blob container for file icon.ico
exception error from blob container for file code.py
Repository [my-repo] writing new index generational blob [index-1]
Repository [test-repo] writing new index generational blob [index-2]
Repository [backup-repo] writing new index generational blob [index-3]
Repository [demo-repo] writing new index generational blob [index-4]
Repository [data-repo] writing new index generational blob [index-5]
Repository [code-repo] writing new index generational blob [index-6]
Repository [docs-repo] writing new index generational blob [index-7]
Repository [media-repo] writing new index generational blob [index-8]
Repository [config-repo] writing new index generational blob [index-9]
Repository [logs-repo] writing new index generational blob [index-10]
Repository [user-repo] writing new index generational blob [index-11]
Repository [admin-repo] writing new index generational blob [index-12]
Repository [temp-repo] writing new index generational blob [index-13]
Repository [cache-repo] writing new index generational blob [index-14]
Repository [archive-repo] writing new index generational blob [index-15]
non-critical exceptions: 0
non-critical exceptions: 1
non-critical exceptions: 2
non-critical exceptions: 3
non-critical exceptions: 4
non-critical exceptions: 5
non-critical exceptions: 6
non-critical exceptions: 7
non-critical exceptions: 8
non-critical exceptions: 9
non-critical exceptions: 10
non-critical exceptions: 11
non-critical exceptions: 12
non-critical exceptions: 13
non-critical exceptions: 14
non-critical exceptions: 0
non-critical exceptions: 3
non-critical exceptions: 1
non-critical exceptions: 2
non-critical exceptions: 4
non-critical exceptions: 5
non-critical exceptions: 6
non-critical exceptions: 7
non-critical exceptions: 8
non-critical exceptions: 9
non-critical exceptions: 10
non-critical exceptions: 11
non-critical exceptions: 12
non-critical exceptions: 13
non-critical exceptions: 14
Registered new Setting: language successfully
Registered new Setting: theme successfully
Registered new Setting: font_size successfully
Registered new Setting: notification successfully
Registered new Setting: sound successfully
Registered new Setting: privacy successfully
Registered new Setting: security successfully
Registered new Setting: backup successfully
Registered new Setting: sync successfully
Registered new Setting: display successfully
Registered new Setting: mode successfully
Registered new Setting: filter successfully
Registered new Setting: shortcut successfully
Registered new Setting: history successfully
Registered new Setting: bookmark successfully
Registered new Setting: language successfully
Registered new Setting: theme successfully
Registered new Setting: notifications successfully
Registered new Setting: privacy successfully
Registered new Setting: security successfully
Registered new Setting: backup successfully
Registered new Setting: sync successfully
Registered new Setting: display successfully
Registered new Setting: sound successfully
Registered new Setting: network successfully
Registered new Setting: storage successfully
Registered new Setting: accessibility successfully
Registered new Setting: developer successfully
Registered new Setting: location successfully
Registered new Setting: account successfully
--> indexing 12 rollback docs
--> indexing 7 rollback docs
--> indexing 0 rollback docs
--> indexing 3 rollback docs
--> indexing 9 rollback docs
--> indexing 5 rollback docs
--> indexing 10 rollback docs
--> indexing 4 rollback docs
--> indexing 8 rollback docs
--> indexing 1 rollback docs
--> indexing 6 rollback docs
--> indexing 11 rollback docs
--> indexing 2 rollback docs
--> indexing 13 rollback docs
--> indexing 14 rollback docs
applying create index request using existing index [products] metadata
applying create index request using existing index [users] metadata
applying create index request using existing index [orders] metadata
applying create index request using existing index [reviews] metadata
applying create index request using existing index [inventory] metadata
applying create index request using existing index [categories] metadata
applying create index request using existing index [customers] metadata
applying create index request using existing index [sales] metadata
applying create index request using existing index [transactions] metadata
applying create index request using existing index [employees] metadata
applying create index request using existing index [suppliers] metadata
applying create index request using existing index [shippers] metadata
applying create index request using existing index [regions] metadata
applying create index request using existing index [territories] metadata
applying create index request using existing index [contacts] metadata
notifying [listener-1] of new cluster info
notifying [listener-2] of new cluster info
notifying [listener-3] of new cluster info
notifying [listener-4] of new cluster info
notifying [listener-5] of new cluster info
notifying [listener-6] of new cluster info
notifying [listener-7] of new cluster info
notifying [listener-8] of new cluster info
notifying [listener-9] of new cluster info
notifying [listener-10] of new cluster info
notifying [listener-11] of new cluster info
notifying [listener-12] of new cluster info
notifying [listener-13] of new cluster info
notifying [listener-14] of new cluster info
notifying [listener-15] of new cluster info
Using file-system [hdfs] for URI [hdfs://localhost:9000] , path [/user/hadoop/input.txt]
Using file-system [s3a] for URI [s3a://mybucket] , path [/data/2023-10-27.csv]
Using file-system [local] for URI [file:///] , path [/home/user/Desktop/config.json]
Using file-system [ftp] for URI [ftp://example.com] , path [/pub/software/hadoop-3.3.1.tar.gz]
Using file-system [webhdfs] for URI [webhdfs://namenode:50070] , path [/user/hive/warehouse/orders.parquet]
Using file-system [gs] for URI [gs://my-project] , path [/logs/2023-10-27.log]
Using file-system [adl] for URI [adl://myaccount.azuredatalakestore.net] , path [/clusters/spark2/conf/spark-defaults.conf]
Using file-system [wasb] for URI [wasb://container@storageaccount.blob.core.windows.net] , path [/images/cat.jpg]
Using file-system [abfs] for URI [abfs://mycontainer@myaccount.dfs.core.windows.net] , path [/videos/movie.mp4]
Using file-system [swift] for URI [swift://container.sahara] , path [/models/mlp.pkl]
Using file-system [kudu] for URI [kudu://master-1.example.com,master-2.example.com,master-3.example.com:7051/] , path [/tables/customers]
Using file-system [cos] for URI [cos://mybucket.service/] , path [/reports/sales.xlsx]
Using file-system [oss] for URI [oss://mybucket.oss-cn-hangzhou.aliyuncs.com/] , path [/docs/manual.pdf]
Using file-system [sftp] for URI [sftp://user@host/] , path [/backup/database.sql]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/project/project-id]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/instance/hostname]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/instance/network-interfaces/0/access-configs/0/external-ip]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/instance/tags]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/instance/machine-type]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/instance/id]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/instance/attributes/kube-env]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/project/attributes/google-compute-default-region]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/project/attributes/google-compute-default-zone]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/project/numeric-project-id]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/email]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/scopes]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/project/attributes/default-service-account]
--> Simulate GCE Auth/Metadata response for [http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/identity?audience=example.com&format=full]
interrupted while connecting to nodes, continuing java.net.SocketTimeoutException: Read timed out
interrupted while connecting to nodes, continuing java.io.IOException: Connection reset by peer
interrupted while connecting to nodes, continuing org.apache.http.NoHttpResponseException: The target server failed to respond
interrupted while connecting to nodes, continuing javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake
interrupted while connecting to nodes, continuing java.net.ConnectException: Connection refused
interrupted while connecting to nodes, continuing org.elasticsearch.transport.NodeNotConnectedException: [node-1][127.0.0.1:9300] Node not connected
interrupted while connecting to nodes, continuing java.net.UnknownHostException: Unable to resolve host "example.com": No address associated with hostname
interrupted while connecting to nodes, continuing org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available
interrupted while connecting to nodes, continuing java.lang.InterruptedException: sleep interrupted
interrupted while connecting to nodes, continuing org.elasticsearch.cluster.block.ClusterBlockException: blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];
interrupted while connecting to nodes, continuing org.elasticsearch.transport.ReceiveTimeoutTransportException: [node-2][127.0.0.1:9301][cluster:monitor/nodes/stats] request_id [42] timed out after [15000ms]
interrupted while connecting to nodes, continuing org.elasticsearch.ElasticsearchSecurityException: missing authentication credentials for REST request [/index/_search]
interrupted while connecting to nodes, continuing org.elasticsearch.ElasticsearchStatusException: Elasticsearch exception [type=search_phase_execution_exception, reason=all shards failed]
interrupted while connecting to nodes, continuing org.elasticsearch.ElasticsearchParseException: Failed to parse content to map
interrupted while connecting to nodes, continuing org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [<http_request>] would be [123456789/117.7mb], which is larger than the limit of [104857600/100mb]
completing the future after sleeping 10 ms
completing the future after sleeping 25 ms
completing the future after sleeping 15 ms
completing the future after sleeping 30 ms
completing the future after sleeping 12 ms
completing the future after sleeping 18 ms
completing the future after sleeping 20 ms
completing the future after sleeping 22 ms
completing the future after sleeping 27 ms
completing the future after sleeping 35 ms
completing the future after sleeping 13 ms
completing the future after sleeping 17 ms
completing the future after sleeping 24 ms
completing the future after sleeping 28 ms
completing the future after sleeping 32 ms
index products is already closed, ignoring
index users is already closed, ignoring
index orders is already closed, ignoring
index reviews is already closed, ignoring
index categories is already closed, ignoring
index news is already closed, ignoring
index blogs is already closed, ignoring
index events is already closed, ignoring
index books is already closed, ignoring
index movies is already closed, ignoring
index songs is already closed, ignoring
index games is already closed, ignoring
index photos is already closed, ignoring
index videos is already closed, ignoring
index podcasts is already closed, ignoring
--> indexed 100 docs, 80 to keep
--> indexed 250 docs, 200 to keep
--> indexed 50 docs, 40 to keep
--> indexed 300 docs, 240 to keep
--> indexed 150 docs, 120 to keep
--> indexed 200 docs, 160 to keep
--> indexed 75 docs, 60 to keep
--> indexed 125 docs, 100 to keep
--> indexed 175 docs, 140 to keep
--> indexed 225 docs, 180 to keep
--> indexed 275 docs, 220 to keep
--> indexed 325 docs, 260 to keep
--> indexed 25 docs, 20 to keep
--> indexed 350 docs, 280 to keep
--> indexed 400 docs, 320 to keep
Keys to override: [name, age, gender]
Keys to override: [color, size, shape]
Keys to override: [id, status, priority]
Keys to override: [title, author, genre]
Keys to override: [date, time, location]
Keys to override: [username, password, email]
Keys to override: [price, quantity, discount]
Keys to override: [type, value, unit]
Keys to override: [source, destination, mode]
Keys to override: [level, score, rank]
Keys to override: [brand, model, year]
Keys to override: [language, country, currency]
Keys to override: [category, tag, rating]
Keys to override: [url, title, description]
Keys to override: [width, height, depth]
Successfully instantiated the SpanExporter class com.microsoft.azure.monitor.opentelemetry.exporter.AzureMonitorTraceExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.jaeger.JaegerGrpcSpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.otlp.trace.OtlpGrpcSpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.zipkin.ZipkinSpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.logging.LoggingSpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.prometheus.PrometheusCollector
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.aws.AwsXraySpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.kafka.KafkaSpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.elastic.ElasticsearchSpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.influx.InfluxDbSpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.datadog.DatadogSpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.newrelic.NewRelicSpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.honeycomb.HoneycombSpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.splunk.SplunkSpanExporter
Successfully instantiated the SpanExporter class io.opentelemetry.exporter.signalfx.SignalFxSpanExporter
[ Debug mode] cancelling task [T-123] due to high resource consumption [Memory usage exceeded 90%]
[ Normal mode] cancelling task [T-456] due to high resource consumption [CPU usage exceeded 80%]
[ Safe mode] cancelling task [T-789] due to high resource consumption [Disk space exceeded 95%]
[ Test mode] cancelling task [T-101] due to high resource consumption [Network bandwidth exceeded 70%]
[ Recovery mode] cancelling task [T-112] due to high resource consumption [Power consumption exceeded 85%]
[ Maintenance mode] cancelling task [T-131] due to high resource consumption [Temperature exceeded 60C]
[ Performance mode] cancelling task [T-415] due to high resource consumption [Thread count exceeded 1000]
[ Silent mode] cancelling task [T-161] due to high resource consumption [Sound volume exceeded 50%]
[ Custom mode] cancelling task [T-718] due to high resource consumption [User-defined limit exceeded]
[ Monitor mode] cancelling task [T-192] due to high resource consumption [Screen brightness exceeded 75%]
[ Backup mode] cancelling task [T-211] due to high resource consumption [Storage quota exceeded 50GB]
[ Offline mode] cancelling task [T-232] due to high resource consumption [Battery level below 20%]
[ Online mode] cancelling task [T-253] due to high resource consumption [Ping time above 100ms]
[ Secure mode] cancelling task [T-274] due to high resource consumption [Encryption level below AES-256]
[ Fast mode] cancelling task [T-295] due to high resource consumption [Execution time above 10s]
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
Terminal.Verbosity.VERBOSE Removing data
--> 0 docs indexed
--> 1 docs indexed
--> 2 docs indexed
--> 3 docs indexed
--> 4 docs indexed
--> 5 docs indexed
--> 6 docs indexed
--> 7 docs indexed
--> 8 docs indexed
--> 9 docs indexed
--> 10 docs indexed
--> 11 docs indexed
--> 12 docs indexed
--> 13 docs indexed
--> 14 docs indexed
removing node [A1B2]
removing node [C3D4]
removing node [E5F6]
removing node [G7H8]
removing node [I9J0]
removing node [K1L2]
removing node [M3N4]
removing node [O5P6]
removing node [Q7R8]
removing node [S9T0]
removing node [U1V2]
removing node [W3X4]
removing node [Y5Z6]
removing node [A7B8]
removing node [C9D0]
skipping node [a1b2c3] with http disabled
skipping node [d4e5f6] with http disabled
skipping node [g7h8i9] with http disabled
skipping node [j0k1l2] with http disabled
skipping node [m3n4o5] with http disabled
skipping node [p6q7r8] with http disabled
skipping node [s9t0u1] with http disabled
skipping node [v2w3x4] with http disabled
skipping node [y5z6a7] with http disabled
skipping node [b8c9d0] with http disabled
skipping node [e1f2g3] with http disabled
skipping node [h4i5j6] with http disabled
skipping node [k7l8m9] with http disabled
skipping node [n0o1p2] with http disabled
skipping node [q3r4s5] with http disabled
using config [/home/user/config], data [[data1.txt, data2.txt, data3.txt]], logs [/home/user/logs], plugins [/home/user/plugins]
using config [C:\Users\user\config], data [[data4.csv, data5.csv]], logs [C:\Users\user\logs], plugins [C:\Users\user\plugins]
using config [/etc/config], data [[data6.json, data7.json]], logs [/var/log], plugins [/usr/lib/plugins]
using config [D:\config], data [[data8.xml, data9.xml, data10.xml]], logs [D:\logs], plugins [D:\plugins]
using config [/opt/config], data [[data11.dat, data12.dat]], logs [/opt/logs], plugins [/opt/plugins]
using config [E:\Users\user\config], data [[data13.xlsx, data14.xlsx, data15.xlsx]], logs [E:\Users\user\logs], plugins [E:\Users\user\plugins]
using config [/Users/user/config], data [[data16.csv, data17.csv, data18.csv]], logs [/Users/user/logs], plugins [/Users/user/plugins]
using config [F:\config], data [[data19.json, data20.json]], logs [F:\logs], plugins [F:\plugins]
using config [/root/config], data [[data21.xml, data22.xml]], logs [/root/logs], plugins [/root/plugins]
using config [G:\Users\user\config], data [[data23.dat, data24.dat, data25.dat]], logs [G:\Users\user\logs], plugins [G:\Users\user\plugins]
using config [/tmp/config], data [[data26.xlsx, data27.xlsx]], logs [/tmp/logs], plugins [/tmp/plugins]
using config [H:\config], data [[data28.csv, data29.csv, data30.csv]], logs [H:\logs], plugins [H:\plugins]
using config [/mnt/config], data [[data31.json, data32.json]], logs [/mnt/logs], plugins [/mnt/plugins]
using config [I:\Users\user\config], data [[data33.xml, data34.xml, data35.xml]], logs [I:\Users\user\logs], plugins [I:\Users\user\plugins]
using config [/media/config], data [[data36.dat, data37.dat]], logs [/media/logs], plugins [/media/plugins]
Unknown client type [Android]
Unknown client type [iOS]
Unknown client type [Windows]
Unknown client type [Linux]
Unknown client type [MacOS]
Unknown client type [ChromeOS]
Unknown client type [Web]
Unknown client type [Bot]
Unknown client type [TV]
Unknown client type [Console]
Unknown client type [Wearable]
Unknown client type [Car]
Unknown client type [Router]
Unknown client type [Printer]
Unknown client type [Camera]
index 0 already has block 0x1234 , ignoring
index 1 already has block 0x5678 , ignoring
index 2 already has block 0x9ABC , ignoring
index 3 already has block 0xDEF0 , ignoring
index 4 already has block 0x1357 , ignoring
index 5 already has block 0x2468 , ignoring
index 6 already has block 0xACEF , ignoring
index 7 already has block 0xBDF1 , ignoring
index 8 already has block 0xCAB2 , ignoring
index 9 already has block 0xDAB3 , ignoring
index 10 already has block 0xEAB4 , ignoring
index 11 already has block 0xFAB5 , ignoring
index 12 already has block 0xABC9 , ignoring
index 13 already has block 0xDEF6 , ignoring
index 14 already has block 0x135A , ignoring
noop (seq# [1])
noop (seq# [2])
noop (seq# [3])
noop (seq# [4])
noop (seq# [5])
noop (seq# [6])
noop (seq# [7])
noop (seq# [8])
noop (seq# [9])
noop (seq# [10])
noop (seq# [11])
noop (seq# [12])
noop (seq# [13])
noop (seq# [14])
noop (seq# [15])
Safe commit [Added new feature], last commit [Fixed bug #123]
Safe commit [Refactored code], last commit [Updated documentation]
Safe commit [Merged branch dev], last commit [Added unit tests]
Safe commit [Reverted to previous version], last commit [Broke the build]
Safe commit [Implemented security patch], last commit [Resolved conflict]
Safe commit [Optimized performance], last commit [Changed UI design]
Safe commit [Deleted unused files], last commit [Renamed variables]
Safe commit [Fixed memory leak], last commit [Added comments]
Safe commit [Improved user experience], last commit [Modified database schema]
Safe commit [Enhanced accessibility], last commit [Removed deprecated code]
Safe commit [Updated dependencies], last commit [Added logging]
Safe commit [Fixed typo], last commit [Made minor changes]
Safe commit [Added validation], last commit [Fixed edge case]
Safe commit [Completed milestone], last commit [Reviewed code quality]
Safe commit [Deployed to production], last commit [Passed all tests]
Keywords source: {"name": "apple", "score": 0.95}
Keywords source: {"name": "banana", "score": 0.87}
Keywords source: {"name": "orange", "score": 0.92}
Keywords source: {"name": "grape", "score": 0.89}
Keywords source: {"name": "pear", "score": 0.91}
Keywords source: {"name": "watermelon", "score": 0.94}
Keywords source: {"name": "strawberry", "score": 0.88}
Keywords source: {"name": "pineapple", "score": 0.93}
Keywords source: {"name": "mango", "score": 0.86}
Keywords source: {"name": "kiwi", "score": 0.90}
Keywords source: {"name": "peach", "score": 0.85}
Keywords source: {"name": "cherry", "score": 0.84}
Keywords source: {"name": "lemon", "score": 0.83}
Keywords source: {"name": "coconut", "score": 0.82}
Keywords source: {"name": "plum", "score": 0.81}
Using non-concurrent search over segments for request with context id 0x7f8a3b4c
Using non-concurrent search over segments for request with context id 0x9d6e2f1a
Using non-concurrent search over segments for request with context id 0x4a5b3c2d
Using non-concurrent search over segments for request with context id 0x6c7d8e9f
Using non-concurrent search over segments for request with context id 0x1b2a3f4c
Using non-concurrent search over segments for request with context id 0x3c4d5e6a
Using non-concurrent search over segments for request with context id 0x5e6f7d8b
Using non-concurrent search over segments for request with context id 0x7f8a9b6c
Using non-concurrent search over segments for request with context id 0x9d6e4c7a
Using non-concurrent search over segments for request with context id 0x4a5b6d8c
Using non-concurrent search over segments for request with context id 0x6c7d2e9b
Using non-concurrent search over segments for request with context id 0x1b2a5f6c
Using non-concurrent search over segments for request with context id 0x3c4d8e7a
Using non-concurrent search over segments for request with context id 0x5e6f3d8b
Using non-concurrent search over segments for request with context id 0x7f8a2b4c
creating Index [products], shards [5]/[1] - reason [API]
creating Index [users], shards [3]/[2] - reason [AUTO]
creating Index [orders], shards [4]/[1] - reason [RESTORE]
creating Index [reviews], shards [2]/[2] - reason [REINDEX]
creating Index [inventory], shards [6]/[1] - reason [TEMPLATE]
creating Index [logs], shards [10]/[0] - reason [API]
creating Index [tweets], shards [1]/[1] - reason [AUTO]
creating Index [news], shards [3]/[3] - reason [RESTORE]
creating Index [books], shards [2]/[2] - reason [REINDEX]
creating Index [movies], shards [4]/[2] - reason [TEMPLATE]
creating Index [music], shards [5]/[1] - reason [API]
creating Index [photos], shards [2]/[2] - reason [AUTO]
creating Index [videos], shards [3]/[3] - reason [RESTORE]
creating Index [games], shards [4]/[1] - reason [REINDEX]
creating Index [blogs], shards [6]/[2] - reason [TEMPLATE]
[4231]: sending [12] entry, [1.2MB] bulk request
[5678]: sending [8] entry, [800KB] bulk request
[1234]: sending [10] entry, [1MB] bulk request
[8765]: sending [9] entry, [900KB] bulk request
[4321]: sending [11] entry, [1.1MB] bulk request
[6789]: sending [7] entry, [700KB] bulk request
[2345]: sending [13] entry, [1.3MB] bulk request
[7654]: sending [6] entry, [600KB] bulk request
[3456]: sending [14] entry, [1.4MB] bulk request
[6543]: sending [5] entry, [500KB] bulk request
[4567]: sending [15] entry, [1.5MB] bulk request
[5432]: sending [4] entry, [400KB] bulk request
[5670]: sending [16] entry, [1.6MB] bulk request
[4320]: sending [3] entry, [300KB] bulk request
[6700]: sending [17] entry, [1.7MB] bulk request
Failed to call listener on atomic field data loading java.lang.NullPointerException
Failed to call listener on atomic field data loading java.io.IOException: Stream closed
Failed to call listener on atomic field data loading java.lang.IllegalArgumentException: Invalid field name
Failed to call listener on atomic field data loading java.lang.ClassCastException: Cannot cast java.lang.String to java.lang.Integer
Failed to call listener on atomic field data loading java.util.concurrent.TimeoutException: Timeout waiting for data
Failed to call listener on atomic field data loading java.lang.OutOfMemoryError: Java heap space
Failed to call listener on atomic field data loading java.net.SocketException: Connection reset
Failed to call listener on atomic field data loading java.lang.SecurityException: Permission denied
Failed to call listener on atomic field data loading org.json.JSONException: A JSONArray text must start with '[' at 1 [character 2 line 1]
Failed to call listener on atomic field data loading javax.xml.parsers.ParserConfigurationException: Feature 'http://javax.xml.XMLConstants/feature/secure-processing' is not recognized.
Failed to call listener on atomic field data loading java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost/test
Failed to call listener on atomic field data loading java.lang.NoSuchMethodError: No static method load(Ljava/lang/String;)Ljava/lang/Class; in class Ljava/lang/Class; or its super classes (declaration of 'java.lang.Class' appears in /system/framework/core-libart.jar)
Failed to call listener on atomic field data loading java.lang.NoClassDefFoundError: Could not initialize class com.example.MyClass
Failed to call listener on atomic field data loading java.lang.StackOverflowError
Failed to call listener on atomic field data loading org.apache.commons.math3.exception.MathParseException: Parse error at position 5 in expression 'x + y *'
Adding additional 5 nodes, nothing should change
Adding additional 10 nodes, nothing should change
Adding additional 3 nodes, nothing should change
Adding additional 7 nodes, nothing should change
Adding additional 8 nodes, nothing should change
Adding additional 4 nodes, nothing should change
Adding additional 6 nodes, nothing should change
Adding additional 9 nodes, nothing should change
Adding additional 2 nodes, nothing should change
Adding additional 11 nodes, nothing should change
Adding additional 12 nodes, nothing should change
Adding additional 13 nodes, nothing should change
Adding additional 14 nodes, nothing should change
Adding additional 15 nodes, nothing should change
scheduling next cluster info refresh in [10 minutes]
scheduling next cluster info refresh in [15 seconds]
scheduling next cluster info refresh in [1 hour]
scheduling next cluster info refresh in [5 minutes]
scheduling next cluster info refresh in [30 seconds]
scheduling next cluster info refresh in [2 hours]
scheduling next cluster info refresh in [20 minutes]
scheduling next cluster info refresh in [45 seconds]
scheduling next cluster info refresh in [3 hours]
scheduling next cluster info refresh in [1 minute]
scheduling next cluster info refresh in [40 seconds]
scheduling next cluster info refresh in [4 hours]
scheduling next cluster info refresh in [25 minutes]
scheduling next cluster info refresh in [50 seconds]
scheduling next cluster info refresh in [5 hours]
--> Indexing data for 10 iterations with flush= true
--> Indexing data for 5 iterations with flush= false
--> Indexing data for 20 iterations with flush= true
--> Indexing data for 15 iterations with flush= false
--> Indexing data for 12 iterations with flush= true
--> Indexing data for 8 iterations with flush= false
--> Indexing data for 18 iterations with flush= true
--> Indexing data for 6 iterations with flush= false
--> Indexing data for 25 iterations with flush= true
--> Indexing data for 7 iterations with flush= false
--> Indexing data for 16 iterations with flush= true
--> Indexing data for 9 iterations with flush= false
--> Indexing data for 22 iterations with flush= true
--> Indexing data for 11 iterations with flush= false
--> Indexing data for 19 iterations with flush= true
registered decommission metadata for attribute [name] with status [success]
registered decommission metadata for attribute [age] with status [failure]
registered decommission metadata for attribute [gender] with status [pending]
registered decommission metadata for attribute [email] with status [success]
registered decommission metadata for attribute [phone] with status [failure]
registered decommission metadata for attribute [address] with status [pending]
registered decommission metadata for attribute [salary] with status [success]
registered decommission metadata for attribute [department] with status [failure]
registered decommission metadata for attribute [position] with status [pending]
registered decommission metadata for attribute [id] with status [success]
registered decommission metadata for attribute [date_of_birth] with status [failure]
registered decommission metadata for attribute [nationality] with status [pending]
registered decommission metadata for attribute [education] with status [success]
registered decommission metadata for attribute [skills] with status [failure]
registered decommission metadata for attribute [experience] with status [pending]
failed to notify listeners on shutdown java.lang.NullPointerException
failed to notify listeners on shutdown java.io.IOException: Stream closed
failed to notify listeners on shutdown java.lang.IllegalStateException: Already shut down
failed to notify listeners on shutdown java.lang.InterruptedException
failed to notify listeners on shutdown java.util.concurrent.TimeoutException: Timeout waiting for task
failed to notify listeners on shutdown java.lang.RuntimeException: Unexpected error
failed to notify listeners on shutdown java.net.SocketException: Connection reset
failed to notify listeners on shutdown java.lang.OutOfMemoryError
failed to notify listeners on shutdown java.lang.SecurityException: Permission denied
failed to notify listeners on shutdown java.lang.ClassNotFoundException: com.example.Listener
failed to notify listeners on shutdown java.lang.NoSuchMethodError: com.example.Listener.onShutdown()
failed to notify listeners on shutdown java.lang.IllegalArgumentException: Invalid listener
failed to notify listeners on shutdown java.lang.StackOverflowError
failed to notify listeners on shutdown java.lang.UnsupportedOperationException: Not implemented
failed to notify listeners on shutdown java.lang.Error: Unresolved compilation problem
checking strictWarningsMode=[true] and warnings= [DEPRECATED: Use of the 'var' keyword is discouraged.]
checking strictWarningsMode=[false] and warnings= [WARNING: Unhandled promise rejection.]
checking strictWarningsMode=[true] and warnings= [DEPRECATED: Use of the 'eval' function is discouraged.]
checking strictWarningsMode=[false] and warnings= [WARNING: Possible memory leak detected.]
checking strictWarningsMode=[true] and warnings= [DEPRECATED: Use of the 'with' statement is discouraged.]
checking strictWarningsMode=[false] and warnings= [WARNING: Circular reference found.]
checking strictWarningsMode=[true] and warnings= [DEPRECATED: Use of the 'arguments' object is discouraged.]
checking strictWarningsMode=[false] and warnings= [WARNING: Undefined variable used.]
checking strictWarningsMode=[true] and warnings= [DEPRECATED: Use of the 'new' operator is discouraged.]
checking strictWarningsMode=[false] and warnings= [WARNING: Missing semicolon.]
checking strictWarningsMode=[true] and warnings= [DEPRECATED: Use of the 'function' keyword is discouraged.]
checking strictWarningsMode=[false] and warnings= [WARNING: Implicit conversion of types.]
checking strictWarningsMode=[true] and warnings= [DEPRECATED: Use of the 'this' keyword is discouraged.]
checking strictWarningsMode=[false] and warnings= [WARNING: Duplicate key in object literal.]
checking strictWarningsMode=[true] and warnings= [DEPRECATED: Use of the 'delete' operator is discouraged.]
applying create index request using composable template [blog_posts]
applying create index request using composable template [product_catalog]
applying create index request using composable template [user_profiles]
applying create index request using composable template [weather_data]
applying create index request using composable template [news_articles]
applying create index request using composable template [social_media]
applying create index request using composable template [financial_transactions]
applying create index request using composable template [medical_records]
applying create index request using composable template [movie_reviews]
applying create index request using composable template [sports_scores]
applying create index request using composable template [travel_bookings]
applying create index request using composable template [online_courses]
applying create index request using composable template [music_library]
applying create index request using composable template [e-commerce_orders]
applying create index request using composable template [event_logs]
corrupting [delete] to node-12 . file name: [report.pdf]
corrupting [rename] to node-7 . file name: [image.jpg]
corrupting [copy] to node-3 . file name: [data.csv]
corrupting [move] to node-9 . file name: [video.mp4]
corrupting [update] to node-5 . file name: [index.html]
corrupting [create] to node-10 . file name: [script.py]
corrupting [read] to node-8 . file name: [book.txt]
corrupting [write] to node-4 . file name: [log.txt]
corrupting [append] to node-6 . file name: [message.txt]
corrupting [truncate] to node-11 . file name: [table.xlsx]
corrupting [encrypt] to node-2 . file name: [secret.txt]
corrupting [decrypt] to node-1 . file name: [password.txt]
corrupting [compress] to node-14 . file name: [archive.zip]
corrupting [decompress] to node-13 . file name: [folder.zip]
corrupting [scan] to node-15 . file name: [virus.exe]
filtering out instance webserver based tags [env:prod, role:web] , not part of [env:dev, role:db]
filtering out instance database based tags [env:dev, role:db] , not part of [env:test, role:app]
filtering out instance appserver based tags [env:test, role:app] , not part of [env:prod, role:web]
filtering out instance backup based tags [env:prod, role:backup] , not part of [env:test, role:db]
filtering out instance loadbalancer based tags [env:test, role:lb] , not part of [env:dev, role:app]
filtering out instance monitor based tags [env:dev, role:monitor] , not part of [env:test, role:lb]
filtering out instance analytics based tags [env:test, role:analytics] , not part of [env:prod, role:monitor]
filtering out instance gateway based tags [env:prod, role:gateway] , not part of [env:test, role:analytics]
filtering out instance worker based tags [env:test, role:worker] , not part of [env:dev, role:gateway]
filtering out instance scheduler based tags [env:dev, role:scheduler] , not part of [env:test, role:worker]
filtering out instance frontend based tags [env:test, role:frontend] , not part of [env:test, role:scheduler]
filtering out instance backend based tags [env:test, role:backend] , not part of [env:test, role:scheduler]
filtering out instance admin based tags [env:test, role:admin] , not part of [env:test, role:scheduler]
filtering out instance auth based tags [env:test, role:auth] , not part of [env:test, role:scheduler]
filtering out instance cache based tags [env:test, role:caching] , not part of [env:test, role:scheduler]
using script cache with max_size [1000], expire [3600]
using script cache with max_size [500], expire [1800]
using script cache with max_size [2000], expire [7200]
using script cache with max_size [1500], expire [3000]
using script cache with max_size [800], expire [2400]
using script cache with max_size [1200], expire [4800]
using script cache with max_size [600], expire [1200]
using script cache with max_size [2500], expire [9000]
using script cache with max_size [100], expire [600]
using script cache with max_size [300], expire [1500]
using script cache with max_size [400], expire [2000]
using script cache with max_size [700], expire [2100]
using script cache with max_size [900], expire [2700]
using script cache with max_size [1100], expire [3300]
using script cache with max_size [1300], expire [3900]
executing cluster state update for [create index]
executing cluster state update for [delete index]
executing cluster state update for [update mapping]
executing cluster state update for [update settings]
executing cluster state update for [rebalance shards]
executing cluster state update for [allocate replica]
executing cluster state update for [close index]
executing cluster state update for [open index]
executing cluster state update for [add alias]
executing cluster state update for [remove alias]
executing cluster state update for [start snapshot]
executing cluster state update for [restore snapshot]
executing cluster state update for [delete snapshot]
executing cluster state update for [upgrade index]
executing cluster state update for [rollover index]
Successful shards: [5] numShards: [10]
Successful shards: [8] numShards: [12]
Successful shards: [7] numShards: [9]
Successful shards: [6] numShards: [8]
Successful shards: [9] numShards: [11]
Successful shards: [4] numShards: [7]
Successful shards: [10] numShards: [10]
Successful shards: [3] numShards: [6]
Successful shards: [11] numShards: [13]
Successful shards: [2] numShards: [5]
Successful shards: [12] numShards: [14]
Successful shards: [1] numShards: [4]
Successful shards: [13] numShards: [15]
Successful shards: [0] numShards: [3]
Successful shards: [14] numShards: [16]
Line [23]: NullPointerException
Line [45]: ArrayIndexOutOfBoundsException
Line [67]: ArithmeticException
Line [89]: IOException
Line [12]: ClassNotFoundException
Line [34]: NumberFormatException
Line [56]: IllegalArgumentException
Line [78]: FileNotFoundException
Line [91]: SQLException
Line [14]: MalformedURLException
Line [36]: SecurityException
Line [58]: InterruptedException
Line [81]: SocketException
Line [16]: OutOfMemoryError
Line [39]: StackOverflowError
time: [2023-10-27 11:40:12]
time: [2023-10-27 11:41:05]
time: [2023-10-27 11:42:23]
time: [2023-10-27 11:43:47]
time: [2023-10-27 11:44:32]
time: [2023-10-27 11:45:18]
time: [2023-10-27 11:46:04]
time: [2023-10-27 11:46:51]
time: [2023-10-27 11:47:39]
time: [2023-10-27 11:48:26]
time: [2023-10-27 11:49:14]
time: [2023-10-27 11:50:01]
time: [2023-10-27 11:50:49]
time: [2023-10-27 11:51:36]
time: [2023-10-27 11:52:24]
Error closing Netty Event Loop group java.lang.IllegalStateException: Shutdown in progress
Error closing Netty Event Loop group java.lang.InterruptedException: Thread interrupted
Error closing Netty Event Loop group java.io.IOException: Connection reset by peer
Error closing Netty Event Loop group java.net.SocketException: Socket closed
Error closing Netty Event Loop group java.util.concurrent.TimeoutException: Future timed out after 10 seconds
Error closing Netty Event Loop group java.lang.NullPointerException: No event loop group specified
Error closing Netty Event Loop group java.lang.UnsupportedOperationException: Not supported by this event loop type
Error closing Netty Event Loop group java.nio.channels.ClosedChannelException: Channel closed before complete shutdown
Error closing Netty Event Loop group io.netty.channel.ChannelException: Failed to create a new selector
Error closing Netty Event Loop group io.netty.util.concurrent.RejectedExecutionException: Task rejected by event executor
Error closing Netty Event Loop group io.netty.handler.codec.DecoderException: Invalid message format
Error closing Netty Event Loop group io.netty.handler.ssl.NotSslRecordException: Not an SSL/TLS record
Error closing Netty Event Loop group io.netty.handler.timeout.IdleStateEvent@7f31245a
Error closing Netty Event Loop group io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: no further information
Error closing Netty Event Loop group io.netty.channel.ChannelPipelineException: Handler is not a @Sharable handler, so can't be added or removed multiple times.
sending full cluster state version [12] to [node-1]
sending full cluster state version [13] to [node-2]
sending full cluster state version [14] to [node-3]
sending full cluster state version [15] to [node-4]
sending full cluster state version [16] to [node-5]
sending full cluster state version [17] to [node-6]
sending full cluster state version [18] to [node-7]
sending full cluster state version [19] to [node-8]
sending full cluster state version [20] to [node-9]
sending full cluster state version [21] to [node-10]
sending full cluster state version [22] to [node-11]
sending full cluster state version [23] to [node-12]
sending full cluster state version [24] to [node-13]
sending full cluster state version [25] to [node-14]
sending full cluster state version [26] to [node-15]
index products has since been deleted, ignoring
index users has since been deleted, ignoring
index orders has since been deleted, ignoring
index reviews has since been deleted, ignoring
index categories has since been deleted, ignoring
index posts has since been deleted, ignoring
index comments has since been deleted, ignoring
index events has since been deleted, ignoring
index books has since been deleted, ignoring
index movies has since been deleted, ignoring
index songs has since been deleted, ignoring
index articles has since been deleted, ignoring
index photos has since been deleted, ignoring
index videos has since been deleted, ignoring
index games has since been deleted, ignoring
[metadata.name()] Unknown blob in the repository: blobName
[User] Unknown blob in the repository: profile.jpg
[Admin] Unknown blob in the repository: backup.zip
[Guest] Unknown blob in the repository: document.docx
[Server] Unknown blob in the repository: log.txt
[Client] Unknown blob in the repository: image.png
[Database] Unknown blob in the repository: data.csv
[Web] Unknown blob in the repository: index.html
[API] Unknown blob in the repository: response.json
[App] Unknown blob in the repository: config.ini
[Test] Unknown blob in the repository: report.pdf
[Email] Unknown blob in the repository: attachment.eml
[Chat] Unknown blob in the repository: message.xml
[Video] Unknown blob in the repository: clip.mp4
[Audio] Unknown blob in the repository: song.mp3
12 addresses added
7 addresses added
9 addresses added
10 addresses added
8 addresses added
11 addresses added
6 addresses added
13 addresses added
14 addresses added
5 addresses added
4 addresses added
15 addresses added
3 addresses added
2 addresses added
CalculatorTest is a test because it extends TestCase
HelloTest is a test because it extends JUnit4TestAdapter
FibonacciTest is a test because it extends Parameterized
PrimeNumberTest is a test because it extends TestSuite
FactorialTest is a test because it extends TestNG
StringUtilsTest is a test because it extends Assert
MathUtilsTest is a test because it extends JUnit5
ArrayUtilsTest is a test because it extends TestRule
DateUtilsTest is a test because it extends TestWatcher
NumberUtilsTest is a test because it extends TestRunner
CollectionUtilsTest is a test because it extends TestFactory
FileIOUtilsTest is a test because it extends TestMethodOrder
RegexUtilsTest is a test because it extends TestInstance
CryptoUtilsTest is a test because it extends TestInfo
JsonUtilsTest is a test because it extends TestReporter
missing id [a3b5c7] on shard [node-1, shard-2]
missing id [f9d8e7] on shard [node-3, shard-4]
missing id [c4d6e8] on shard [node-2, shard-1]
missing id [b2a1c3] on shard [node-4, shard-3]
missing id [e7f8g9] on shard [node-1, shard-4]
missing id [d5e6f7] on shard [node-3, shard-2]
missing id [a9b8c7] on shard [node-2, shard-3]
missing id [g6f5e4] on shard [node-4, shard-1]
missing id [h7g8f9] on shard [node-1, shard-3]
missing id [j8h9g8] on shard [node-3, shard-1]
missing id [k9j0h9] on shard [node-2, shard-4]
missing id [l0k1j0] on shard [node-4, shard-2]
missing id [m1l2k1] on shard [node-1, shard-1]
missing id [n2m3l2] on shard [node-3, shard-3]
missing id [o3n4m3] on shard [node-2, shard-2]
applying create index request using legacy templates [blog, user, product]
applying create index request using legacy templates [news, comment, tag]
applying create index request using legacy templates [order, item, review]
applying create index request using legacy templates [book, author, genre]
applying create index request using legacy templates [movie, actor, rating]
applying create index request using legacy templates [game, developer, platform]
applying create index request using legacy templates [event, ticket, venue]
applying create index request using legacy templates [post, category, media]
applying create index request using legacy templates [recipe, ingredient, nutrition]
applying create index request using legacy templates [job, resume, skill]
applying create index request using legacy templates [course, student, grade]
applying create index request using legacy templates [email, contact, attachment]
applying create index request using legacy templates [photo, album, filter]
applying create index request using legacy templates [song, artist, playlist]
applying create index request using legacy templates [tweet, user, hashtag]
cluster state updated, version [1], source [local-gateway-elected-state]
cluster state updated, version [2], source [zen-disco-node-join]
cluster state updated, version [3], source [zen-disco-receive(from master)]
cluster state updated, version [4], source [zen-disco-failed]
cluster state updated, version [5], source [api(restore_snapshot)]
cluster state updated, version [6], source [api(close_index)]
cluster state updated, version [7], source [api(open_index)]
cluster state updated, version [8], source [api(delete_index)]
cluster state updated, version [9], source [api(create_index)]
cluster state updated, version [10], source [api(update_mapping)]
cluster state updated, version [11], source [api(update_settings)]
cluster state updated, version [12], source [api(update_aliases)]
cluster state updated, version [13], source [api(rollover_index)]
cluster state updated, version [14], source [api(shrink_index)]
cluster state updated, version [15], source [api(split_index)]
new commit on flush, hasUncommittedChanges: true , force: false , shouldPeriodicallyFlush: true
new commit on flush, hasUncommittedChanges: false , force: true , shouldPeriodicallyFlush: false
new commit on flush, hasUncommittedChanges: true , force: true , shouldPeriodicallyFlush: false
new commit on flush, hasUncommittedChanges: false , force: false , shouldPeriodicallyFlush: true
new commit on flush, hasUncommittedChanges: true , force: false , shouldPeriodicallyFlush: false
new commit on flush, hasUncommittedChanges: false , force: true , shouldPeriodicallyFlush: true
new commit on flush, hasUncommittedChanges: true , force: true , shouldPeriodicallyFlush: true
new commit on flush, hasUncommittedChanges: false , force: false , shouldPeriodicallyFlush: false
new commit on flush, hasUncommittedChanges: null , force: false , shouldPeriodicallyFlush: true
new commit on flush, hasUncommittedChanges: null , force: true , shouldPeriodicallyFlush: false
new commit on flush, hasUncommittedChanges: null , force: true , shouldPeriodicallyFlush: true
new commit on flush, hasUncommittedChanges: null , force: false , shouldPeriodicallyFlush: false
new commit on flush, hasUncommittedChanges: undefined , force: undefined , shouldPeriodicallyFlush: undefined
new commit on flush, hasUncommittedChanges: undefined , force: undefined , shouldPeriodicallyFlush: true
delete [user123] (seq no [45])
delete [admin] (seq no [12])
delete [guest] (seq no [67])
delete [user456] (seq no [23])
delete [user789] (seq no [89])
delete [user101] (seq no [34])
delete [user102] (seq no [56])
delete [user103] (seq no [78])
delete [user104] (seq no [90])
delete [user105] (seq no [12])
delete [user106] (seq no [45])
delete [user107] (seq no [67])
delete [user108] (seq no [89])
delete [user109] (seq no [23])
delete [user110] (seq no [34])
no peer-recovery retention lease for [0aX4bZ]
no peer-recovery retention lease for [3cY7dW]
no peer-recovery retention lease for [5eZ9fQ]
no peer-recovery retention lease for [7gX1hS]
no peer-recovery retention lease for [9iY3jU]
no peer-recovery retention lease for [1kZ5lW]
no peer-recovery retention lease for [2mX6nY]
no peer-recovery retention lease for [4oZ8pQ]
no peer-recovery retention lease for [6qX0rS]
no peer-recovery retention lease for [8sY2tU]
no peer-recovery retention lease for [0uZ4vW]
no peer-recovery retention lease for [2wX6xY]
no peer-recovery retention lease for [4yZ8zQ]
no peer-recovery retention lease for [6aX0bS]
no peer-recovery retention lease for [8cY2dU]
add weighted routing weights in metadata [0.5]
add weighted routing weights in metadata [0.25]
add weighted routing weights in metadata [0.75]
add weighted routing weights in metadata [0.1]
add weighted routing weights in metadata [0.9]
add weighted routing weights in metadata [0.4]
add weighted routing weights in metadata [0.6]
add weighted routing weights in metadata [0.2]
add weighted routing weights in metadata [0.8]
add weighted routing weights in metadata [0.3]
add weighted routing weights in metadata [0.7]
add weighted routing weights in metadata [0.15]
add weighted routing weights in metadata [0.85]
add weighted routing weights in metadata [0.05]
add weighted routing weights in metadata [0.95]
Expected to find the rounding in 100 iterations but didn't for 1634228800000 using TimeIntervalRounding{interval=1d, offset=0, timeZone=UTC}
Expected to find the rounding in 100 iterations but didn't for 1634315200000 using TimeIntervalRounding{interval=1h, offset=0, timeZone=America/New_York}
Expected to find the rounding in 100 iterations but didn't for 1634401600000 using TimeIntervalRounding{interval=15m, offset=0, timeZone=Asia/Tokyo}
Expected to find the rounding in 100 iterations but didn't for 1634488000000 using TimeIntervalRounding{interval=1w, offset=0, timeZone=Europe/London}
Expected to find the rounding in 100 iterations but didn't for 1634574400000 using TimeIntervalRounding{interval=1M, offset=0, timeZone=Australia/Sydney}
Expected to find the rounding in 100 iterations but didn't for 1634660800000 using TimeIntervalRounding{interval=1y, offset=0, timeZone=Africa/Cairo}
Expected to find the rounding in 100 iterations but didn't for 1634747200000 using TimeIntervalRounding{interval=30m, offset=0, timeZone=America/Los_Angeles}
Expected to find the rounding in 100 iterations but didn't for 1634833600000 using TimeIntervalRounding{interval=5m, offset=0, timeZone=Asia/Shanghai}
Expected to find the rounding in 100 iterations but didn't for 1634920000000 using TimeIntervalRounding{interval=12h, offset=0, timeZone=Europe/Berlin}
Expected to find the rounding in 100 iterations but didn't for 1635006400000 using TimeIntervalRounding{interval=2h, offset=0, timeZone=Africa/Johannesburg}
Expected to find the rounding in 100 iterations but didn't for 1635092800000 using TimeIntervalRounding{interval=10m, offset=0, timeZone=Pacific/Auckland}
Expected to find the rounding in 100 iterations but didn't for 1635179200000 using TimeIntervalRounding{interval=3d, offset=0, timeZone=Etc/GMT+5}
Expected to find the rounding in 100 iterations but didn't for 1635265600000 using TimeIntervalRounding{interval=6h, offset=0, timeZone=Etc/GMT-2}
Expected to find the rounding in 100 iterations but didn't for 1635352000000 using TimeIntervalRounding{interval=4h, offset=0, timeZone=Etc/GMT+8}
Expected to find the rounding in 100 iterations but didn't for 1635438400000 using TimeIntervalRounding{interval=2d, offset=0, timeZone=Etc/GMT-7}
Determined repository generation [12] from repository contents but correct generation must be at least [13]
Determined repository generation [7] from repository contents but correct generation must be at least [9]
Determined repository generation [4] from repository contents but correct generation must be at least [5]
Determined repository generation [10] from repository contents but correct generation must be at least [11]
Determined repository generation [8] from repository contents but correct generation must be at least [10]
Determined repository generation [6] from repository contents but correct generation must be at least [7]
Determined repository generation [9] from repository contents but correct generation must be at least [10]
Determined repository generation [5] from repository contents but correct generation must be at least [6]
Determined repository generation [11] from repository contents but correct generation must be at least [12]
Determined repository generation [3] from repository contents but correct generation must be at least [4]
Determined repository generation [14] from repository contents but correct generation must be at least [15]
Determined repository generation [2] from repository contents but correct generation must be at least [3]
Determined repository generation [13] from repository contents but correct generation must be at least [14]
Determined repository generation [1] from repository contents but correct generation must be at least [2]
Determined repository generation [15] from repository contents but correct generation must be at least [16]
failed to close shard IndexOutOfBoundsException
failed to close shard NullPointerException
failed to close shard IOException
failed to close shard ElasticsearchException
failed to close shard ShardNotFoundException
failed to close shard AlreadyClosedException
failed to close shard CorruptIndexException
failed to close shard IndexShardClosedException
failed to close shard IndexShardRelocatedException
failed to close shard IndexShardRecoveringException
failed to close shard IndexShardNotStartedException
failed to close shard IndexShardSnapshotFailedException
failed to close shard SnapshotCreationException
failed to close shard SnapshotRestoreException
failed to close shard SnapshotMissingException
failed to invoke before index created callback java.lang.NullPointerException
failed to invoke before index created callback org.elasticsearch.ElasticsearchException
failed to invoke before index created callback java.io.IOException
failed to invoke before index created callback java.lang.IllegalArgumentException
failed to invoke before index created callback org.springframework.dao.DataAccessException
failed to invoke before index created callback java.lang.InterruptedException
failed to invoke before index created callback java.util.concurrent.TimeoutException
failed to invoke before index created callback java.lang.ClassNotFoundException
failed to invoke before index created callback org.hibernate.HibernateException
failed to invoke before index created callback java.sql.SQLException
failed to invoke before index created callback java.lang.OutOfMemoryError
failed to invoke before index created callback java.lang.StackOverflowError
failed to invoke before index created callback javax.validation.ValidationException
failed to invoke before index created callback org.apache.commons.lang3.SerializationException
failed to invoke before index created callback java.lang.UnsupportedOperationException
User is a test because it has method named ' testGetName '
Calculator is a test because it has method named ' testAdd '
Book is a test because it has method named ' testGetAuthor '
Animal is a test because it has method named ' testMakeSound '
Customer is a test because it has method named ' testGetBalance '
Game is a test because it has method named ' testPlay '
Student is a test because it has method named ' testGetGrade '
Product is a test because it has method named ' testGetPrice '
Car is a test because it has method named ' testDrive '
Shape is a test because it has method named ' testGetArea '
Employee is a test because it has method named ' testGetSalary '
Movie is a test because it has method named ' testGetRating '
Bank is a test because it has method named ' testDeposit '
Person is a test because it has method named ' testGetAge '
Song is a test because it has method named ' testGetLyrics '
User is a test because it has method ' testGetName ' annotated with ' @Test '
Calculator is a test because it has method ' testAdd ' annotated with ' @Test '
Book is a test because it has method ' testGetAuthor ' annotated with ' @Test '
Student is a test because it has method ' testGetGrade ' annotated with ' @Test '
Employee is a test because it has method ' testGetSalary ' annotated with ' @Test '
Animal is a test because it has method ' testMakeSound ' annotated with ' @Test '
Car is a test because it has method ' testDrive ' annotated with ' @Test '
BankAccount is a test because it has method ' testDeposit ' annotated with ' @Test '
Product is a test because it has method ' testGetPrice ' annotated with ' @Test '
Game is a test because it has method ' testPlay ' annotated with ' @Test '
Customer is a test because it has method ' testBuy ' annotated with ' @Test '
Shape is a test because it has method ' testGetArea ' annotated with ' @Test '
Movie is a test because it has method ' testGetRating ' annotated with ' @Test '
Order is a test because it has method ' testGetTotal ' annotated with ' @Test '
Remote clusters initialization failed partially java.lang.NullPointerException
Remote clusters initialization failed partially java.net.SocketTimeoutException
Remote clusters initialization failed partially org.apache.zookeeper.KeeperException$ConnectionLossException
Remote clusters initialization failed partially java.io.IOException: Broken pipe
Remote clusters initialization failed partially org.elasticsearch.transport.NodeDisconnectedException
Remote clusters initialization failed partially java.lang.IllegalStateException: Cluster state not recovered yet
Remote clusters initialization failed partially org.elasticsearch.cluster.block.ClusterBlockException
Remote clusters initialization failed partially java.lang.OutOfMemoryError
Remote clusters initialization failed partially org.elasticsearch.action.search.SearchPhaseExecutionException
Remote clusters initialization failed partially java.net.UnknownHostException
Remote clusters initialization failed partially javax.net.ssl.SSLHandshakeException
Remote clusters initialization failed partially org.elasticsearch.common.breaker.CircuitBreakingException
Remote clusters initialization failed partially java.lang.SecurityException: access denied
Remote clusters initialization failed partially org.elasticsearch.ElasticsearchStatusException
Remote clusters initialization failed partially java.util.concurrent.TimeoutException
NodeStatsAction timed out for ClusterInfoUpdateJob java.net.SocketTimeoutException: Read timed out
NodeStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.transport.ReceiveTimeoutTransportException: [node-1][127.0.0.1:9300][cluster:monitor/nodes/stats[n]] request_id [123] timed out after [15000ms]
NodeStatsAction timed out for ClusterInfoUpdateJob java.io.IOException: Connection reset by peer
NodeStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.cluster.block.ClusterBlockException: blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];
NodeStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.ElasticsearchTimeoutException: Timeout waiting for task.
NodeStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.transport.NodeDisconnectedException: [node-2][127.0.0.2:9300][cluster:monitor/nodes/stats[n]] disconnected
NodeStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.action.NoShardAvailableActionException: No shard available for [org.elasticsearch.action.admin.cluster.node.stats.NodesStatsRequest@1a2b3c4d]
NodeStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: rejected execution of org.elasticsearch.transport.TransportService$7@5f6a7b8d on EsThreadPoolExecutor[name = node-3/write, queue capacity = 200, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@6e7a8b9f[Running, pool size = 8, active threads = 8, queued tasks = 200, completed tasks = 123456]]
NodeStatsAction timed out for ClusterInfoUpdateJob java.lang.OutOfMemoryError: Java heap space
NodeStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.cluster.coordination.FailedToCommitClusterStateException: publication failed
NodeStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.action.UnavailableShardsException: [index-1][0] primary shard is not active Timeout: [1m], request: [org.elasticsearch.action.admin.cluster.node.stats.NodesStatsRequest@7d8a9b0c]
NodeStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.discovery.MasterNotDiscoveredException: null
NodeStatsAction timed out for ClusterInfoUpdateJob java.lang.IllegalStateException: cluster service closed while executing stats
NodeStatsAction timed out for ClusterInfoUpdateJob org.elasticsearch.transport.RemoteTransportException: [node-4][127.0.0.4:9300][cluster:monitor/nodes/stats[n]]
NodeStatsAction timed out for ClusterInfoUpdateJob java.lang.NullPointerException
Warmup trial run 1 / 10
Warmup trial run 2 / 10
Warmup trial run 3 / 10
Warmup trial run 4 / 10
Warmup trial run 5 / 10
Warmup trial run 6 / 10
Warmup trial run 7 / 10
Warmup trial run 8 / 10
Warmup trial run 9 / 10
Warmup trial run 10 / 10
Warmup trial run 11 / 15
Warmup trial run 12 / 15
Warmup trial run 13 / 15
Warmup trial run 14 / 15
Warmup trial run 15 / 15
--> got seqID: 1001
--> got seqID: 2002
--> got seqID: 3003
--> got seqID: 4004
--> got seqID: 5005
--> got seqID: 6006
--> got seqID: 7007
--> got seqID: 8008
--> got seqID: 9009
--> got seqID: 1010
--> got seqID: 1111
--> got seqID: 1212
--> got seqID: 1313
--> got seqID: 1414
--> got seqID: 1515
global-ordinals [title][123456789] took [0.5s]
global-ordinals [content][987654321] took [1.2s]
global-ordinals [author][456789123] took [0.8s]
global-ordinals [date][789123456] took [0.6s]
global-ordinals [category][123789456] took [0.9s]
global-ordinals [tag][654321789] took [1.1s]
global-ordinals [rating][321789654] took [0.7s]
global-ordinals [comment][987456321] took [1.3s]
global-ordinals [url][456321987] took [0.4s]
global-ordinals [image][789654321] took [1.4s]
global-ordinals [video][654789123] took [1.5s]
global-ordinals [audio][321654987] took [0.3s]
global-ordinals [location][987321654] took [1.6s]
global-ordinals [language][456987321] took [0.2s]
global-ordinals [source][789321456] took [1.7s]
Setup test with 3 shards and 2 replicas.
Setup test with 5 shards and 2 replicas.
Setup test with 2 shards and 3 replicas.
Setup test with 4 shards and 2 replicas.
Setup test with 6 shards and 4 replicas.
Setup test with 2 shards and 4 replicas.
Setup test with 3 shards and 3 replicas.
Setup test with 5 shards and 2 replicas.
Setup test with 4 shards and 3 replicas.
Setup test with 6 shards and 2 replicas.
Setup test with 2 shards and 4 replicas.
Setup test with 7 shards and 5 replicas.
Setup test with 5 shards and 5 replicas.
Setup test with 8 shards and 7 replicas.
resolveConfiguredHosts.doRun: lifecycle is STARTING , not proceeding
resolveConfiguredHosts.doRun: lifecycle is STOPPED , not proceeding
resolveConfiguredHosts.doRun: lifecycle is RESTARTING , not proceeding
resolveConfiguredHosts.doRun: lifecycle is PAUSED , not proceeding
resolveConfiguredHosts.doRun: lifecycle is RESUMING , not proceeding
resolveConfiguredHosts.doRun: lifecycle is SHUTTING_DOWN , not proceeding
resolveConfiguredHosts.doRun: lifecycle is FAILED , not proceeding
resolveConfiguredHosts.doRun: lifecycle is UNKNOWN , not proceeding
resolveConfiguredHosts.doRun: lifecycle is RUNNING , not proceeding
resolveConfiguredHosts.doRun: lifecycle is INITIALIZING , not proceeding
resolveConfiguredHosts.doRun: lifecycle is TERMINATED , not proceeding
resolveConfiguredHosts.doRun: lifecycle is SUSPENDED , not proceeding
resolveConfiguredHosts.doRun: lifecycle is ACTIVE , not proceeding
resolveConfiguredHosts.doRun: lifecycle is INACTIVE , not proceeding
resolveConfiguredHosts.doRun: lifecycle is DELETED , not proceeding
failed to update search pipelines java.lang.NullPointerException
failed to update search pipelines org.elasticsearch.ElasticsearchException: cluster block exception
failed to update search pipelines java.net.SocketTimeoutException: Read timed out
failed to update search pipelines java.io.IOException: No space left on device
failed to update search pipelines org.apache.lucene.index.CorruptIndexException: checksum failed
failed to update search pipelines java.lang.OutOfMemoryError: Java heap space
failed to update search pipelines org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
failed to update search pipelines java.lang.IllegalArgumentException: invalid pipeline id
failed to update search pipelines org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large
failed to update search pipelines java.lang.InterruptedException: interrupted while waiting for latch
failed to update search pipelines org.elasticsearch.transport.NodeDisconnectedException: [node-1][127.0.0.1:9300][indices:data/write/bulk] disconnected
failed to update search pipelines java.util.concurrent.ExecutionException: org.elasticsearch.index.engine.VersionConflictEngineException
failed to update search pipelines java.lang.SecurityException: access denied
failed to update search pipelines org.elasticsearch.index.mapper.MapperParsingException: failed to parse field [content]
failed to update search pipelines java.lang.UnsupportedOperationException: pipeline execution is not supported for this type of request
took [3.5s] to [load the page] for [user 5678]
took [12ms] to [query the database] for [product 4321]
took [7.8s] to [send an email] for [order confirmation]
took [1.2s] to [render the chart] for [sales report]
took [4.3s] to [login] for [admin 1234]
took [9.1s] to [upload a file] for [document 8765]
took [15ms] to [validate the input] for [form submission]
took [6.7s] to [download a video] for [streaming service]
took [2.4s] to [generate a QR code] for [payment request]
took [5.6s] to [scan a barcode] for [inventory check]
took [8.9s] to [process an image] for [face recognition]
took [11ms] to [calculate the sum] for [math problem]
took [3.2s] to [play a sound] for [alarm notification]
took [10.5s] to [connect to a server] for [remote access]
took [14ms] to [encrypt the data] for [security purpose]
recovered maximum sequence number [123456] and local checkpoint [654321]
recovered maximum sequence number [234567] and local checkpoint [765432]
recovered maximum sequence number [345678] and local checkpoint [876543]
recovered maximum sequence number [456789] and local checkpoint [987654]
recovered maximum sequence number [567890] and local checkpoint [109876]
recovered maximum sequence number [678901] and local checkpoint [210987]
recovered maximum sequence number [789012] and local checkpoint [321098]
recovered maximum sequence number [890123] and local checkpoint [432109]
recovered maximum sequence number [901234] and local checkpoint [543210]
recovered maximum sequence number [102345] and local checkpoint [654321]
recovered maximum sequence number [203456] and local checkpoint [765432]
recovered maximum sequence number [304567] and local checkpoint [876543]
recovered maximum sequence number [405678] and local checkpoint [987654]
recovered maximum sequence number [506789] and local checkpoint [109876]
recovered maximum sequence number [607890] and local checkpoint [210987]
index products has been blocked before closing and is already closed, ignoring
index users has been blocked before closing and is already closed, ignoring
index orders has been blocked before closing and is already closed, ignoring
index reviews has been blocked before closing and is already closed, ignoring
index categories has been blocked before closing and is already closed, ignoring
index posts has been blocked before closing and is already closed, ignoring
index comments has been blocked before closing and is already closed, ignoring
index tags has been blocked before closing and is already closed, ignoring
index books has been blocked before closing and is already closed, ignoring
index authors has been blocked before closing and is already closed, ignoring
index articles has been blocked before closing and is already closed, ignoring
index events has been blocked before closing and is already closed, ignoring
index movies has been blocked before closing and is already closed, ignoring
index actors has been blocked before closing and is already closed, ignoring
index songs has been blocked before closing and is already closed, ignoring
0 deleting shard reason [no replicas available]
1 deleting shard reason [disk space exceeded]
2 deleting shard reason [corrupted data]
3 deleting shard reason [user request]
4 deleting shard reason [shard migration]
5 deleting shard reason [index closed]
6 deleting shard reason [node failure]
7 deleting shard reason [cluster rebalance]
8 deleting shard reason [index deleted]
9 deleting shard reason [shard split]
10 deleting shard reason [shard merge]
11 deleting shard reason [index reopened]
12 deleting shard reason [index restored]
13 deleting shard reason [shard recovery]
14 deleting shard reason [shard reassignment]
Shard stats [index1 0 p STARTED  1000 500kb 127.0.0.1 node1]
Shard stats [index2 1 r UNASSIGNED]
Shard stats [index3 2 p INITIALIZING  2000 1mb 127.0.0.2 node2]
Shard stats [index4 3 r STARTED  3000 1.5mb 127.0.0.3 node3]
Shard stats [index5 4 p RELOCATING 4000 2mb 127.0.0.4 node4 -> 127.0.0.5 node5]
Shard stats [index6 5 r STARTED 5000 2.5mb 127.0.0.5 node5]
Shard stats [index7 6 p STARTED 6000 3mb 127.0.0.6 node6]
Shard stats [index8 7 r UNASSIGNED]
Shard stats [index9 8 p INITIALIZING 7000 3.5mb 127.0.0.7 node7]
Shard stats [index10 9 r STARTED 8000 4mb 127.0.0.8 node8]
Shard stats [index11 10 p RELOCATING 9000 4.5mb 127.0.0.9 node9 -> 127.0.0.10 node10]
Shard stats [index12 11 r STARTED 10000 5mb 127.0.0.10 node10]
Shard stats [index13 12 p STARTED 11000 5.5mb 127.0.0.11 node11]
Shard stats [index14 13 r UNASSIGNED]
Shard stats [index15 14 p INITIALIZING   -    -    -    - ]
failed to invoke before index removed callback java.lang.NullPointerException
failed to invoke before index removed callback java.lang.IllegalArgumentException
failed to invoke before index removed callback java.io.IOException
failed to invoke before index removed callback java.lang.OutOfMemoryError
failed to invoke before index removed callback java.lang.ClassNotFoundException
failed to invoke before index removed callback java.lang.NoSuchMethodError
failed to invoke before index removed callback java.lang.StackOverflowError
failed to invoke before index removed callback java.lang.UnsupportedOperationException
failed to invoke before index removed callback java.util.ConcurrentModificationException
failed to invoke before index removed callback java.lang.SecurityException
failed to invoke before index removed callback java.lang.ArithmeticException
failed to invoke before index removed callback java.net.SocketTimeoutException
failed to invoke before index removed callback java.sql.SQLException
failed to invoke before index removed callback java.lang.AssertionError
failed to invoke before index removed callback java.lang.RuntimeException
compiling lang: [python] type: [script] script: print("Hello world")
compiling lang: [java] type: [class] script: HelloWorld.java
compiling lang: [c++] type: [executable] script: main.cpp
compiling lang: [ruby] type: [gem] script: hello.rb
compiling lang: [javascript] type: [module] script: index.js
compiling lang: [swift] type: [app] script: MyApp.swift
compiling lang: [go] type: [binary] script: hello.go
compiling lang: [r] type: [function] script: mean.R
compiling lang: [perl] type: [regex] script: match.pl
compiling lang: [php] type: [webpage] script: index.php
compiling lang: [haskell] type: [program] script: main.hs
compiling lang: [rust] type: [crate] script: hello.rs
compiling lang: [scala] type: [object] script: Hello.scala
compiling lang: [lua] type: [script] script: hello.lua
compiling lang: [c#] type: [assembly] script: Program.cs
starting with resumable upload id [a3b5c7d9]
starting with resumable upload id [f4e6d8c2]
starting with resumable upload id [b1c3e5a7]
starting with resumable upload id [d2f4a6b8]
starting with resumable upload id [e9c8b7a6]
starting with resumable upload id [c7a9f6e8]
starting with resumable upload id [a8b6c4d2]
starting with resumable upload id [f9e7d5c3]
starting with resumable upload id [b2c4e6a8]
starting with resumable upload id [d3f5a7b9]
starting with resumable upload id [e8c7b6a5]
starting with resumable upload id [c6a8f7e9]
starting with resumable upload id [a7b5c3d1]
starting with resumable upload id [f8e6d4c2]
starting with resumable upload id [b1c3e5a7]
Replaced context [Home] with new settings
Replaced context [Work] with new settings
Replaced context [Gaming] with new settings
Replaced context [Music] with new settings
Replaced context [Travel] with new settings
Replaced context [Fitness] with new settings
Replaced context [Shopping] with new settings
Replaced context [Reading] with new settings
Replaced context [News] with new settings
Replaced context [Social] with new settings
Replaced context [Weather] with new settings
Replaced context [Calendar] with new settings
Replaced context [Email] with new settings
Replaced context [Photos] with new settings
Replaced context [Videos] with new settings
--> resyncing replicas seqno_stats primary [local_checkpoint=100, max_seq_no=120, global_checkpoint=90] replica [local_checkpoint=80, max_seq_no=110, global_checkpoint=70]
--> resyncing replicas seqno_stats primary [local_checkpoint=200, max_seq_no=210, global_checkpoint=190] replica [local_checkpoint=150, max_seq_no=180, global_checkpoint=160]
--> resyncing replicas seqno_stats primary [local_checkpoint=300, max_seq_no=320, global_checkpoint=280] replica [local_checkpoint=250, max_seq_no=290, global_checkpoint=260]
--> resyncing replicas seqno_stats primary [local_checkpoint=400, max_seq_no=410, global_checkpoint=390] replica [local_checkpoint=350, max_seq_no=380, global_checkpoint=360]
--> resyncing replicas seqno_stats primary [local_checkpoint=500, max_seq_no=520, global_checkpoint=480] replica [local_checkpoint=450, max_seq_no=490, global_checkpoint=460]
--> resyncing replicas seqno_stats primary [local_checkpoint=600, max_seq_no=620, global_checkpoint=580] replica [local_checkpoint=550, max_seq_no=590, global_checkpoint=560]
--> resyncing replicas seqno_stats primary [local_checkpoint=700, max_seq_no=720, global_checkpoint=680] replica [local_checkpoint=650, max_seq_no=690, global_checkpoint=660]
--> resyncing replicas seqno_stats primary [local_checkpoint=800, max_seq_no=820, global_checkpoint=780] replica [local_checkpoint=750, max_seq_no=790, global_checkpoint=760]
--> resyncing replicas seqno_stats primary [local_checkpoint=900, max_seq_no=920, global_checkpoint=880] replica [local_checkpoint=850, max_seq_no=890, global_checkpoint=860]
--> resyncing replicas seqno_stats primary [local_checkpoint=1000, max_seq_no=1020, global_checkpoint=980] replica [local_checkpoint=950, max_seq_no=990, global_checkpoint=960]
Overwriting username to: admin
Overwriting username to: guest
Overwriting username to: user123
Overwriting username to: alice
Overwriting username to: bob
Overwriting username to: charlie
Overwriting username to: david
Overwriting username to: eve
Overwriting username to: frank
Overwriting username to: george
Overwriting username to: harry
Overwriting username to: iris
Overwriting username to: jack
Overwriting username to: kate
Overwriting username to: leo
blue nodes: [a, b, c, d]
blue nodes: [x, y, z]
blue nodes: [p, q, r, s, t]
blue nodes: [m, n]
blue nodes: [e, f, g, h, i, j]
blue nodes: [k, l]
blue nodes: [u, v, w]
blue nodes: [o]
blue nodes: []
blue nodes: [a, b, x, y]
blue nodes: [c, d, z]
blue nodes: [e, f, g, p, q]
blue nodes: [h, i, j, r, s]
blue nodes: [k, l, m, n]
blue nodes: [o, t, u]
Loaded extension with uniqueId 1234 : com.example.foo
Loaded extension with uniqueId 5678 : org.bar.baz
Loaded extension with uniqueId 9012 : net.qux.quux
Loaded extension with uniqueId 3456 : io.corge.grault
Loaded extension with uniqueId 7890 : edu.garply.waldo
Loaded extension with uniqueId 4321 : com.example.bar
Loaded extension with uniqueId 8765 : org.foo.baz
Loaded extension with uniqueId 2109 : net.quux.qux
Loaded extension with uniqueId 6543 : io.grault.corge
Loaded extension with uniqueId 0987 : edu.waldo.garply
Loaded extension with uniqueId 1357 : com.example.baz
Loaded extension with uniqueId 2468 : org.qux.foo
Loaded extension with uniqueId 8642 : net.corge.bar
Loaded extension with uniqueId 9753 : io.waldo.quux
Loaded extension with uniqueId 7531 : edu.grault.qux
recovery of 0 from [node-1] interrupted by network disconnect, will retry in [5s]; cause: [Connection reset by peer]
recovery of 3 from [node-4] interrupted by network disconnect, will retry in [10s]; cause: [No route to host]
recovery of 1 from [node-2] interrupted by network disconnect, will retry in [15s]; cause: [Socket timeout]
recovery of 2 from [node-3] interrupted by network disconnect, will retry in [20s]; cause: [Network is unreachable]
recovery of 4 from [node-5] interrupted by network disconnect, will retry in [25s]; cause: [Broken pipe]
recovery of 5 from [node-6] interrupted by network disconnect, will retry in [30s]; cause: [Connection refused]
recovery of 6 from [node-7] interrupted by network disconnect, will retry in [35s]; cause: [Host is down]
recovery of 7 from [node-8] interrupted by network disconnect, will retry in [40s]; cause: [Network dropped connection on reset]
recovery of 8 from [node-9] interrupted by network disconnect, will retry in [45s]; cause: [Connection aborted]
recovery of 9 from [node-10] interrupted by network disconnect, will retry in [50s]; cause: [Remote host closed connection unexpectedly]
recovery of 10 from [node-11] interrupted by network disconnect, will retry in [55s]; cause: [Network error]
recovery of 11 from [node-12] interrupted by network disconnect, will retry in [60s]; cause: [Connection closed gracefully]
recovery of 12 from [node-13] interrupted by network disconnect, will retry in [65s]; cause: [Connection reset]
recovery of 13 from [node-14] interrupted by network disconnect, will retry in [70s]; cause: [Host unreachable]
recovery of 14 from [node-15] interrupted by network disconnect, will retry in [75s]; cause: [Connection timed out]
Path 1 [/home/user/documents]
Path 1 [/var/log/syslog]
Path 1 [/etc/passwd]
Path 1 [/usr/bin/python3]
Path 1 [/dev/sda1]
Path 1 [/tmp/file.txt]
Path 1 [/opt/java/bin/java]
Path 1 [/root/.bashrc]
Path 1 [/media/cdrom/autorun.inf]
Path 1 [/proc/meminfo]
Path 1 [/boot/grub/grub.cfg]
Path 1 [/lib/modules/5.4.0-91-generic/kernel/drivers/net/ethernet/intel/e1000e/e1000e.ko]
Path 1 [/srv/http/index.html]
Path 1 [/mnt/backup/data.tar.gz]
Path 1 [/run/user/1000/gvfs]
merge failure action rejected NullPointerException
merge failure action rejected OutOfMemoryError
merge failure action rejected ConcurrentModificationException
merge failure action rejected IOException
merge failure action rejected IllegalArgumentException
merge failure action rejected IndexOutOfBoundsException
merge failure action rejected ClassCastException
merge failure action rejected AssertionError
merge failure action rejected StackOverflowError
merge failure action rejected FileNotFoundException
merge failure action rejected SQLException
merge failure action rejected NumberFormatException
merge failure action rejected SecurityException
merge failure action rejected TimeoutException
merge failure action rejected UnsupportedOperationException
freeing search context [0x7f8a4c003b20]
freeing search context [0x7f8a4c0045a0]
freeing search context [0x7f8a4c005120]
freeing search context [0x7f8a4c005c80]
freeing search context [0x7f8a4c0067e0]
freeing search context [0x7f8a4c007340]
freeing search context [0x7f8a4c007ea0]
freeing search context [0x7f8a4c008a00]
freeing search context [0x7f8a4c009560]
freeing search context [0x7f8a4c00a0c0]
freeing search context [0x7f8a4c00ac20]
freeing search context [0x7f8a4c00b780]
freeing search context [0x7f8a4c00c2e0]
freeing search context [0x7f8a4c00ce40]
freeing search context [0x7f8a4c00d9a0]
Using javaHomeEnv: /usr/lib/jvm/java-11-openjdk-amd64
Using javaHomeEnv: C:\Program Files\Java\jdk-15.0.2
Using javaHomeEnv: /Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home
Using javaHomeEnv: /opt/jdk1.8.0_281
Using javaHomeEnv: /home/user/.sdkman/candidates/java/current
Using javaHomeEnv: C:\Users\user\.jenv\versions\1.7
Using javaHomeEnv: /usr/local/bin/java
Using javaHomeEnv: /Applications/Xcode.app/Contents/Developer/usr/lib/jvm/java.home
Using javaHomeEnv: /usr/libexec/java_home
Using javaHomeEnv: C:\cygwin64\usr\local\jdk8
Using javaHomeEnv: /usr/java/latest
Using javaHomeEnv: /etc/alternatives/java_sdk
Using javaHomeEnv: C:\Windows\System32\java.exe
Using javaHomeEnv: /usr/lib/jvm/default-java
Using javaHomeEnv: /opt/amazon-corretto-11
exception thrown by listener while notifying on all nodes acked inner
exception thrown by listener while notifying on all nodes acked inner: java.lang.NullPointerException
exception thrown by listener while notifying on all nodes acked inner: java.io.IOException
exception thrown by listener while notifying on all nodes acked inner: java.net.SocketTimeoutException
exception thrown by listener while notifying on all nodes acked inner: java.lang.IllegalArgumentException
exception thrown by listener while notifying on all nodes acked inner: java.util.ConcurrentModificationException
exception thrown by listener while notifying on all nodes acked inner: java.lang.ClassNotFoundException
exception thrown by listener while notifying on all nodes acked inner: java.lang.OutOfMemoryError
exception thrown by listener while notifying on all nodes acked inner: java.lang.StackOverflowError
exception thrown by listener while notifying on all nodes acked inner: java.lang.UnsupportedOperationException
exception thrown by listener while notifying on all nodes acked inner: java.lang.ArithmeticException
exception thrown by listener while notifying on all nodes acked inner: java.lang.SecurityException
exception thrown by listener while notifying on all nodes acked inner: java.lang.NoSuchMethodError
exception thrown by listener while notifying on all nodes acked inner: java.lang.NoSuchFieldError
exception thrown by listener while notifying on all nodes acked inner: java.lang.VerifyError
clean up failed stateLocation.resolve(file1.txt)
clean up failed stateLocation.resolve(data.csv)
clean up failed stateLocation.resolve(image.jpg)
clean up failed stateLocation.resolve(report.docx)
clean up failed stateLocation.resolve(video.mp4)
clean up failed stateLocation.resolve(config.ini)
clean up failed stateLocation.resolve(log.txt)
clean up failed stateLocation.resolve(temp.zip)
clean up failed stateLocation.resolve(script.py)
clean up failed stateLocation.resolve(folder1)
clean up failed stateLocation.resolve(folder2)
clean up failed stateLocation.resolve(folder3)
clean up failed stateLocation.resolve(backup.tar.gz)
clean up failed stateLocation.resolve(index.html)
clean up failed stateLocation.resolve(style.css)
checking error for runner 1
checking error for runner 2
checking error for runner 3
checking error for runner 4
checking error for runner 5
checking error for runner 6
checking error for runner 7
checking error for runner 8
checking error for runner 9
checking error for runner 10
checking error for runner 11
checking error for runner 12
checking error for runner 13
checking error for runner 14
checking error for runner 15
Written config file: app.config for Main
Written config file: user.config for User
Written config file: db.config for Database
Written config file: log.config for Logger
Written config file: settings.config for Settings
Written config file: network.config for Network
Written config file: security.config for Security
Written config file: theme.config for Theme
Written config file: backup.config for Backup
Written config file: cache.config for Cache
Written config file: report.config for Report
Written config file: email.config for Email
Written config file: web.config for Web
Written config file: test.config for Test
Written config file: debug.config for Debug
closing IndexOutput file [segment_0]
closing IndexOutput file [index_1]
closing IndexOutput file [doc_2]
closing IndexOutput file [term_3]
closing IndexOutput file [field_4]
closing IndexOutput file [segment_5]
closing IndexOutput file [index_6]
closing IndexOutput file [doc_7]
closing IndexOutput file [term_8]
closing IndexOutput file [field_9]
closing IndexOutput file [segment_10]
closing IndexOutput file [index_11]
closing IndexOutput file [doc_12]
closing IndexOutput file [term_13]
closing IndexOutput file [field_14]
Loading keywords from sports.json
Loading keywords from music.json
Loading keywords from movies.json
Loading keywords from books.json
Loading keywords from games.json
Loading keywords from travel.json
Loading keywords from news.json
Loading keywords from weather.json
Loading keywords from shopping.json
Loading keywords from health.json
Loading keywords from education.json
Loading keywords from finance.json
Loading keywords from social.json
Loading keywords from art.json
Loading keywords from science.json
removed [user123] from cache, reason: [EXPIRED]
removed [order456] from cache, reason: [SIZE]
removed [product789] from cache, reason: [COLLECTED]
removed [message101] from cache, reason: [REPLACED]
removed [comment102] from cache, reason: [INVALIDATED]
removed [image103] from cache, reason: [EVICTED]
removed [video104] from cache, reason: [ERROR]
removed [post105] from cache, reason: [EXPLICIT]
removed [review106] from cache, reason: [STALE]
removed [cart107] from cache, reason: [CLEARED]
removed [coupon108] from cache, reason: [USED]
removed [profile109] from cache, reason: [DELETED]
removed [tag110] from cache, reason: [RENAMED]
removed [category111] from cache, reason: [MERGED]
removed [rating112] from cache, reason: [UPDATED]
successfully removed decommissioned cluster manager eligible nodes [[node-1, node-3, node-5]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-2, node-4, node-6]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-7, node-8, node-9]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-10, node-11, node-12]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-13, node-14, node-15]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-16, node-17, node-18]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-19, node-20, node-21]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-22, node-23, node-24]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-25, node-26, node-27]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-28, node-29, node-30]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-31, node-32, node-33]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-34, node-35, node-36]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-37, node-38, node-39]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-40, node-41, node-42]] from voting config
successfully removed decommissioned cluster manager eligible nodes [[node-43, node-44, node-45]] from voting config
[1] [s1] restoring from to an empty shard
[2] [s2] restoring from to an empty shard
[3] [s3] restoring from to an empty shard
[4] [s4] restoring from to an empty shard
[5] [s5] restoring from to an empty shard
[6] [s6] restoring from to an empty shard
[7] [s7] restoring from to an empty shard
[8] [s8] restoring from to an empty shard
[9] [s9] restoring from to an empty shard
[10] [s10] restoring from to an empty shard
[11] [s11] restoring from to an empty shard
[12] [s12] restoring from to an empty shard
[13] [s13] restoring from to an empty shard
[14] [s14] restoring from to an empty shard
[15] [s15] restoring from to an empty shard
using bucket [mybucket], chunk_size [64MB], server_side_encryption [AES256], buffer_size [16MB], cannedACL [public-read], storageClass [STANDARD]
using bucket [testbucket], chunk_size [128MB], server_side_encryption [None], buffer_size [32MB], cannedACL [private], storageClass [GLACIER]
using bucket [backupbucket], chunk_size [256MB], server_side_encryption [aws:kms], buffer_size [64MB], cannedACL [bucket-owner-full-control], storageClass [INTELLIGENT_TIERING]
using bucket [photobucket], chunk_size [32MB], server_side_encryption [None], buffer_size [8MB], cannedACL [public-read-write], storageClass [STANDARD_IA]
using bucket [videobucket], chunk_size [512MB], server_side_encryption [AES256], buffer_size [128MB], cannedACL [authenticated-read], storageClass [ONEZONE_IA]
using bucket [logsbucket], chunk_size [16MB], server_side_encryption [aws:kms], buffer_size [4MB], cannedACL [log-delivery-write], storageClass [STANDARD]
using bucket [archivebucket], chunk_size [1GB], server_side_encryption [None], buffer_size [256MB], cannedACL [private], storageClass [DEEP_ARCHIVE]
using bucket [musicbucket], chunk_size [64MB], server_side_encryption [AES256], buffer_size [16MB], cannedACL [public-read-write], storageClass [INTELLIGENT_TIERING]
using bucket [databucket], chunk_size [128MB], server_side_encryption [aws:kms], buffer_size [32MB], cannedACL [bucket-owner-read], storageClass [GLACIER]
using indexing buffer size [512 MB] with indices.memory.shard_inactive_time [5m], indices.memory.interval [10s]
using indexing buffer size [1 GB] with indices.memory.shard_inactive_time [30m], indices.memory.interval [1m]
using indexing buffer size [256 MB] with indices.memory.shard_inactive_time [10m], indices.memory.interval [30s]
using indexing buffer size [2 GB] with indices.memory.shard_inactive_time [1h], indices.memory.interval [5m]
using indexing buffer size [128 MB] with indices.memory.shard_inactive_time [15m], indices.memory.interval [15s]
using indexing buffer size [4 GB] with indices.memory.shard_inactive_time [2h], indices.memory.interval [10m]
using indexing buffer size [64 MB] with indices.memory.shard_inactive_time [20m], indices.memory.interval [20s]
using indexing buffer size [8 GB] with indices.memory.shard_inactive_time [4h], indices.memory.interval [15m]
using indexing buffer size [32 MB] with indices.memory.shard_inactive_time [25m], indices.memory.interval [25s]
using indexing buffer size [16 GB] with indices.memory.shard_inactive_time [8h], indices.memory.interval [20m]
using indexing buffer size [16 MB] with indices.memory.shard_inactive_time [30s], indices.memory.interval [5s]
using indexing buffer size [32 GB] with indices.memory.shard_inactive_time [12h], indices.memory.interval [30m]
using indexing buffer size [8 MB] with indices.memory.shard_inactive_time [45s], indices.memory.interval [10s]
using indexing buffer size [64 GB] with indices.memory.shard_inactive_time [16h], indices.memory.interval [40m]
using indexing buffer size [4 MB] with indices.memory.shard_inactive_time [1m], indices.memory.interval [15s]
[0] still has shard stores, leaving as is
[1] still has shard stores, leaving as is
[2] still has shard stores, leaving as is
[3] still has shard stores, leaving as is
[4] still has shard stores, leaving as is
[5] still has shard stores, leaving as is
[6] still has shard stores, leaving as is
[7] still has shard stores, leaving as is
[8] still has shard stores, leaving as is
[9] still has shard stores, leaving as is
[10] still has shard stores, leaving as is
[11] still has shard stores, leaving as is
[12] still has shard stores, leaving as is
[13] still has shard stores, leaving as is
[14] still has shard stores, leaving as is
0 cluster-manager marked shard as initializing, but shard has state [STARTED], resending shard started to 1
2 cluster-manager marked shard as initializing, but shard has state [RELOCATED], resending shard started to 3
4 cluster-manager marked shard as initializing, but shard has state [UNASSIGNED], resending shard started to 5
6 cluster-manager marked shard as initializing, but shard has state [INITIALIZING], resending shard started to 7
8 cluster-manager marked shard as initializing, but shard has state [FAILED], resending shard started to 9
10 cluster-manager marked shard as initializing, but shard has state [RECOVERING], resending shard started to 11
12 cluster-manager marked shard as initializing, but shard has state [STARTED], resending shard started to 13
14 cluster-manager marked shard as initializing, but shard has state [RELOCATED], resending shard started to 15
16 cluster-manager marked shard as initializing, but shard has state [UNASSIGNED], resending shard started to 17
18 cluster-manager marked shard as initializing, but shard has state [INITIALIZING], resending shard started to 19
20 cluster-manager marked shard as initializing, but shard has state [FAILED], resending shard started to 21
22 cluster-manager marked shard as initializing, but shard has state [RECOVERING], resending shard started to 23
24 cluster-manager marked shard as initializing, but shard has state [STARTED], resending shard started to 25
26 cluster-manager marked shard as initializing, but shard has state [RELOCATED], resending shard started to 27
28 cluster-manager marked shard as initializing, but shard has state [UNASSIGNED], resending shard started to 29
Using kerberos principal [hdfs@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/hdfs.headless.keytab]
Using kerberos principal [hive@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/hive.service.keytab]
Using kerberos principal [spark@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/spark.headless.keytab]
Using kerberos principal [yarn@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/yarn.service.keytab]
Using kerberos principal [zookeeper@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/zookeeper.service.keytab]
Using kerberos principal [kafka@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/kafka.headless.keytab]
Using kerberos principal [hbase@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/hbase.headless.keytab]
Using kerberos principal [flink@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/flink.service.keytab]
Using kerberos principal [kudu@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/kudu.headless.keytab]
Using kerberos principal [impala@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/impala.service.keytab]
Using kerberos principal [hue@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/hue.service.keytab]
Using kerberos principal [oozie@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/oozie.service.keytab]
Using kerberos principal [solr@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/solr.headless.keytab]
Using kerberos principal [nifi@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/nifi.service.keytab]
Using kerberos principal [atlas@EXAMPLE.COM] and keytab located at [/etc/security/keytabs/atlas.service.keytab]
--> starting 5 concurrent decommission action in zone 'a'
--> starting 3 concurrent decommission action in zone 'a'
--> starting 7 concurrent decommission action in zone 'a'
--> starting 4 concurrent decommission action in zone 'a'
--> starting 6 concurrent decommission action in zone 'a'
--> starting 8 concurrent decommission action in zone 'a'
--> starting 2 concurrent decommission action in zone 'a'
--> starting 9 concurrent decommission action in zone 'a'
--> starting 10 concurrent decommission action in zone 'a'
--> starting 1 concurrent decommission action in zone 'a'
--> starting 12 concurrent decommission action in zone 'a'
--> starting 11 concurrent decommission action in zone 'a'
--> starting 13 concurrent decommission action in zone 'a'
--> starting 14 concurrent decommission action in zone 'a'
--> starting 15 concurrent decommission action in zone 'a'
-> Installed Calculator with folder name calc
-> Installed Weather with folder name weather
-> Installed Calendar with folder name cal
-> Installed Music with folder name music
-> Installed Camera with folder name cam
-> Installed Gallery with folder name gallery
-> Installed Maps with folder name maps
-> Installed Browser with folder name browser
-> Installed Clock with folder name clock
-> Installed Contacts with folder name contacts
-> Installed Notes with folder name notes
-> Installed Games with folder name games
-> Installed Email with folder name email
-> Installed Settings with folder name settings
-> Installed News with folder name news
snapshot [snp-1234567890abcdef0] completed with state [completed]
snapshot [snp-0987654321fedcba0] completed with state [error]
snapshot [snp-0a1b2c3d4e5f6a7b8] completed with state [pending]
snapshot [snp-8a7b6e5f4d3c2b1a0] completed with state [cancelled]
snapshot [snp-11111111111111111] completed with state [in-progress]
snapshot [snp-22222222222222222] completed with state [failed]
snapshot [snp-33333333333333333] completed with state [timed-out]
snapshot [snp-44444444444444444] completed with state [success]
snapshot [snp-55555555555555555] completed with state [aborted]
snapshot [snp-66666666666666666] completed with state [paused]
snapshot [snp-77777777777777777] completed with state [resumed]
snapshot [snp-88888888888888888] completed with state [restarted]
snapshot [snp-99999999999999999] completed with state [skipped]
snapshot [snp-aabbccddeeff001122] completed with state [partial]
snapshot [snp-112200ffeeddccbbaa] completed with state [full]
Moving on to finalizing next snapshot [0x7f8c]
Moving on to finalizing next snapshot [0x9a3d]
Moving on to finalizing next snapshot [0x4b6e]
Moving on to finalizing next snapshot [0x1c8f]
Moving on to finalizing next snapshot [0x6d10]
Moving on to finalizing next snapshot [0x8e31]
Moving on to finalizing next snapshot [0x5f52]
Moving on to finalizing next snapshot [0x2a73]
Moving on to finalizing next snapshot [0x7b94]
Moving on to finalizing next snapshot [0x9cb5]
Moving on to finalizing next snapshot [0x4dd6]
Moving on to finalizing next snapshot [0x1ef7]
Moving on to finalizing next snapshot [0x6f18]
Moving on to finalizing next snapshot [0x8f39]
Moving on to finalizing next snapshot [0x5a5a]
Starting [shard-1] on [node-3] with generation [5]
Starting [shard-2] on [node-1] with generation [7]
Starting [shard-4] on [node-2] with generation [6]
Starting [shard-3] on [node-4] with generation [8]
Starting [shard-5] on [node-5] with generation [9]
Starting [shard-6] on [node-6] with generation [10]
Starting [shard-7] on [node-7] with generation [11]
Starting [shard-8] on [node-8] with generation [12]
Starting [shard-9] on [node-9] with generation [13]
Starting [shard-10] on [node-10] with generation [14]
Starting [shard-11] on [node-11] with generation [15]
Starting [shard-12] on [node-12] with generation [16]
Starting [shard-13] on [node-13] with generation [17]
Starting [shard-14] on [node-14] with generation [18]
Starting [shard-15] on [node-15] with generation [19]
Error closing tracer java.io.IOException: Stream closed
Error closing tracer java.lang.NullPointerException: No tracer found
Error closing tracer java.net.SocketException: Connection reset
Error closing tracer java.lang.IllegalStateException: Tracer already closed
Error closing tracer java.lang.InterruptedException: Thread interrupted
Error closing tracer java.util.ConcurrentModificationException: Tracer modified by another thread
Error closing tracer java.lang.SecurityException: Permission denied
Error closing tracer java.io.FileNotFoundException: No such file or directory
Error closing tracer java.lang.OutOfMemoryError: Java heap space
Error closing tracer java.lang.ClassNotFoundException: Tracer class not found
Error closing tracer java.lang.NoSuchMethodError: Tracer method not found
Error closing tracer java.io.EOFException: End of file reached
Error closing tracer java.lang.StackOverflowError: Recursive call to tracer
Error closing tracer java.lang.UnsupportedOperationException: Tracer operation not supported
Error closing tracer java.lang.IllegalArgumentException: Invalid tracer argument
unregistering node 1 after connection close and marking as disconnected
unregistering node 7 after connection close and marking as disconnected
unregistering node 12 after connection close and marking as disconnected
unregistering node 5 after connection close and marking as disconnected
unregistering node 9 after connection close and marking as disconnected
unregistering node 3 after connection close and marking as disconnected
unregistering node 10 after connection close and marking as disconnected
unregistering node 4 after connection close and marking as disconnected
unregistering node 8 after connection close and marking as disconnected
unregistering node 6 after connection close and marking as disconnected
unregistering node 2 after connection close and marking as disconnected
unregistering node 11 after connection close and marking as disconnected
unregistering node 13 after connection close and marking as disconnected
unregistering node 14 after connection close and marking as disconnected
unregistering node 15 after connection close and marking as disconnected
--> closing the index [users] before updating data_path
--> closing the index [products] before updating data_path
--> closing the index [orders] before updating data_path
--> closing the index [reviews] before updating data_path
--> closing the index [inventory] before updating data_path
--> closing the index [customers] before updating data_path
--> closing the index [sales] before updating data_path
--> closing the index [categories] before updating data_path
--> closing the index [transactions] before updating data_path
--> closing the index [logs] before updating data_path
--> closing the index [settings] before updating data_path
--> closing the index [reports] before updating data_path
--> closing the index [analytics] before updating data_path
--> closing the index [notifications] before updating data_path
--> closing the index [messages] before updating data_path
unable to lock all shards for index products
unable to lock all shards for index users
unable to lock all shards for index orders
unable to lock all shards for index reviews
unable to lock all shards for index inventory
unable to lock all shards for index sales
unable to lock all shards for index customers
unable to lock all shards for index categories
unable to lock all shards for index transactions
unable to lock all shards for index analytics
unable to lock all shards for index logs
unable to lock all shards for index settings
unable to lock all shards for index reports
unable to lock all shards for index notifications
unable to lock all shards for index backups
lock assertion failed: NullPointerException
lock assertion failed: AssertionError
lock assertion failed: OutOfMemoryError
lock assertion failed: IllegalMonitorStateException
lock assertion failed: InterruptedException
lock assertion failed: TimeoutException
lock assertion failed: ConcurrentModificationException
lock assertion failed: ClassCastException
lock assertion failed: StackOverflowError
lock assertion failed: NoSuchMethodError
lock assertion failed: IOException
lock assertion failed: IllegalArgumentException
lock assertion failed: UnsupportedOperationException
lock assertion failed: IndexOutOfBoundsException
lock assertion failed: SecurityException
[123][login] sent response
[456][logout] sent response
[789][search] sent response
[101][update] sent response
[112][delete] sent response
[131][create] sent response
[415][download] sent response
[161][upload] sent response
[718][view] sent response
[192][edit] sent response
[212][share] sent response
[232][comment] sent response
[252][like] sent response
[272][report] sent response
[292][block] sent response
Loaded extension with uniqueId 5a7b9c: Calculator
Loaded extension with uniqueId 3f6d8e: Weather
Loaded extension with uniqueId 9c4a2b: Calendar
Loaded extension with uniqueId 6e3b7a: Translator
Loaded extension with uniqueId 8d2c5f: Music Player
Loaded extension with uniqueId 4b9e6c: Photo Editor
Loaded extension with uniqueId 7a8f3d: Email Client
Loaded extension with uniqueId 2c5d8e: Browser
Loaded extension with uniqueId 5f6a9b: Alarm Clock
Loaded extension with uniqueId 9b7c4a: Notes
Loaded extension with uniqueId 3a6d9e: Contacts
Loaded extension with uniqueId 6c4b7a: Camera
Loaded extension with uniqueId 8e2f5c: Maps
Loaded extension with uniqueId 4d9e6b: Podcasts
Loaded extension with uniqueId 7f8a3d: Games
Couldn't get list of tasks java.lang.NullPointerException
Couldn't get list of tasks java.io.IOException: Connection refused
Couldn't get list of tasks org.springframework.dao.DataAccessException: SQL error
Couldn't get list of tasks java.lang.IllegalArgumentException: Invalid task ID
Couldn't get list of tasks java.util.concurrent.TimeoutException: Task timed out
Couldn't get list of tasks java.lang.OutOfMemoryError: Java heap space
Couldn't get list of tasks java.net.SocketException: Broken pipe
Couldn't get list of tasks javax.security.auth.login.LoginException: Authentication failed
Couldn't get list of tasks org.apache.http.client.HttpResponseException: Server error
Couldn't get list of tasks java.lang.ClassNotFoundException: com.example.Task
Couldn't get list of tasks java.lang.SecurityException: Access denied
Couldn't get list of tasks org.json.JSONException: Malformed JSON
Couldn't get list of tasks java.lang.InterruptedException: Thread interrupted
Couldn't get list of tasks java.util.NoSuchElementException: No task found
Couldn't get list of tasks java.lang.StackOverflowError
Registering: GET /users with deprecation message Use /api/users instead
Registering: POST /login with deprecation message This endpoint is insecure, use /auth/login instead
Registering: PUT /products/:id with deprecation message This method is not supported, use PATCH instead
Registering: DELETE /orders/:id with deprecation message This action is irreversible, use /orders/:id/cancel instead
Registering: PATCH /settings with deprecation message This endpoint is outdated, use /config instead
Registering: HEAD /health with deprecation message This endpoint is redundant, use /status instead
Registering: OPTIONS /help with deprecation message This endpoint is unnecessary, use /docs instead
Registering: TRACE /debug with deprecation message This endpoint is deprecated, use /log instead
Registering: CONNECT /proxy with deprecation message This endpoint is risky, use /tunnel instead
Registering: LINK /files with deprecation message This method is obsolete, use POST instead
Registering: UNLINK /files/:id with deprecation message This method is obsolete, use DELETE instead
Registering: COPY /images/:id with deprecation message This method is inefficient, use MOVE instead
Registering: MOVE /images/:id with deprecation message This method is slow, use RENAME instead
Registering: LOCK /resources/:id with deprecation message This method is prone to deadlock, use ACQUIRE instead
Registering: UNLOCK /resources/:id with deprecation message This method is prone to race condition, use RELEASE instead
Failed to properly stop client thread [main]
Failed to properly stop client thread [worker-1]
Failed to properly stop client thread [pool-2-thread-3]
Failed to properly stop client thread [http-nio-8080-exec-5]
Failed to properly stop client thread [Timer-0]
Failed to properly stop client thread [AWT-EventQueue-0]
Failed to properly stop client thread [RMI TCP Connection(2)-127.0.0.1]
Failed to properly stop client thread [Finalizer]
Failed to properly stop client thread [Signal Dispatcher]
Failed to properly stop client thread [GC Thread#0]
Failed to properly stop client thread [Attach Listener]
Failed to properly stop client thread [Reference Handler]
Failed to properly stop client thread [Monitor Ctrl-Break]
Failed to properly stop client thread [ForkJoinPool.commonPool-worker-7]
Failed to properly stop client thread [DestroyJavaVM]
--> will temporarily interrupt recovery action between blue & red on [reboot]
--> will temporarily interrupt recovery action between blue & red on [sync]
--> will temporarily interrupt recovery action between blue & red on [backup]
--> will temporarily interrupt recovery action between blue & red on [restore]
--> will temporarily interrupt recovery action between blue & red on [update]
--> will temporarily interrupt recovery action between blue & red on [repair]
--> will temporarily interrupt recovery action between blue & red on [reset]
--> will temporarily interrupt recovery action between blue & red on [scan]
--> will temporarily interrupt recovery action between blue & red on [clean]
--> will temporarily interrupt recovery action between blue & red on [format]
--> will temporarily interrupt recovery action between blue & red on [encrypt]
--> will temporarily interrupt recovery action between blue & red on [decrypt]
--> will temporarily interrupt recovery action between blue & red on [compress]
--> will temporarily interrupt recovery action between blue & red on [decompress]
--> will temporarily interrupt recovery action between blue & red on [verify]
term update already queued (setting term to 5)
term update already queued (setting term to 9)
term update already queued (setting term to 3)
term update already queued (setting term to 7)
term update already queued (setting term to 4)
term update already queued (setting term to 8)
term update already queued (setting term to 6)
term update already queued (setting term to 10)
term update already queued (setting term to 2)
term update already queued (setting term to 11)
term update already queued (setting term to 1)
term update already queued (setting term to 12)
term update already queued (setting term to 13)
term update already queued (setting term to 14)
term update already queued (setting term to 15)
state recovery failed: invalid state file
state recovery failed: disk read error
state recovery failed: checksum mismatch
state recovery failed: file not found
state recovery failed: permission denied
state recovery failed: out of memory
state recovery failed: corrupted data
state recovery failed: timeout exceeded
state recovery failed: network failure
state recovery failed: unsupported format
state recovery failed: incompatible version
state recovery failed: internal error
state recovery failed: interrupted by signal
state recovery failed: no space left on device
state recovery failed: operation not permitted
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
failed send response for allocating dangled inner
creating index user_name with background indexing
creating index product_id with background indexing
creating index order_date with background indexing
creating index customer_email with background indexing
creating index review_rating with background indexing
creating index category_name with background indexing
creating index price_range with background indexing
creating index stock_status with background indexing
creating index sales_volume with background indexing
creating index delivery_time with background indexing
creating index payment_method with background indexing
creating index coupon_code with background indexing
creating index feedback_comment with background indexing
creating index product_image with background indexing
creating index search_keyword with background indexing
releasing recovery of shard 0
releasing recovery of shard 1
releasing recovery of shard 2
releasing recovery of shard 3
releasing recovery of shard 4
releasing recovery of shard 5
releasing recovery of shard 6
releasing recovery of shard 7
releasing recovery of shard 8
releasing recovery of shard 9
releasing recovery of shard 10
releasing recovery of shard 11
releasing recovery of shard 12
releasing recovery of shard 13
releasing recovery of shard 14
no private ip provided. ignoring [web-server-01]...
no private ip provided. ignoring [db-server-02]...
no private ip provided. ignoring [app-server-03]...
no private ip provided. ignoring [load-balancer-04]...
no private ip provided. ignoring [monitoring-server-05]...
no private ip provided. ignoring [backup-server-06]...
no private ip provided. ignoring [proxy-server-07]...
no private ip provided. ignoring [mail-server-08]...
no private ip provided. ignoring [file-server-09]...
no private ip provided. ignoring [dns-server-10]...
no private ip provided. ignoring [vpn-server-11]...
no private ip provided. ignoring [firewall-server-12]...
no private ip provided. ignoring [storage-server-13]...
no private ip provided. ignoring [analytics-server-14]...
no private ip provided. ignoring [media-server-15]...
summary , term: 3 , version: 1.2.4 , reason: cluster state update
summary , term: 5 , version: 1.3.1 , reason: node join
summary , term: 4 , version: 1.2.7 , reason: shard allocation
summary , term: 6 , version: 1.3.3 , reason: node leave
summary , term: 7 , version: 1.4.0 , reason: index creation
summary , term: 8 , version: 1.4.2 , reason: index deletion
summary , term: 9 , version: 1.5.1 , reason: mapping update
summary , term: 10 , version: 1.5.4 , reason: settings update
summary , term: 11 , version: 1.6.0 , reason: cluster settings update
summary , term: 12 , version: 1.6.3 , reason: cluster reroute
summary , term: 13 , version: 1.7.1 , reason: snapshot restore
summary , term: 14 , version: 1.7.5 , reason: snapshot deletion
summary , term: 15 , version: 1.8.0 , reason: template creation
summary , term: 16 , version: 1.8.2 , reason: template deletion
summary , term: 17 , version: 1.9.0 , reason: alias creation
Checking node.roles setting: Terminal.Verbosity.VERBOSE
Checking node.roles setting: Terminal.Verbosity.DEBUG
Checking node.roles setting: Terminal.Verbosity.INFO
Checking node.roles setting: Terminal.Verbosity.WARN
Checking node.roles setting: Terminal.Verbosity.ERROR
Checking node.roles setting: Terminal.Verbosity.FATAL
Checking node.roles setting: Terminal.Verbosity.OFF
Checking node.roles setting: Terminal.Verbosity.ALL
Checking node.roles setting: Terminal.Verbosity.TRACE
Checking node.roles setting: Terminal.Verbosity.SILENT
Checking node.roles setting: Terminal.Verbosity.DEFAULT
Checking node.roles setting: Terminal.Verbosity.CUSTOM
Checking node.roles setting: Terminal.Verbosity.NONE
Checking node.roles setting: Terminal.Verbosity.UNKNOWN
Checking node.roles setting: Terminal.Verbosity.INVALID
Not all shards are closed yet, waited 5sec - stopping service
Not all shards are closed yet, waited 10sec - stopping service
Not all shards are closed yet, waited 15sec - stopping service
Not all shards are closed yet, waited 20sec - stopping service
Not all shards are closed yet, waited 25sec - stopping service
Not all shards are closed yet, waited 30sec - stopping service
Not all shards are closed yet, waited 35sec - stopping service
Not all shards are closed yet, waited 40sec - stopping service
Not all shards are closed yet, waited 45sec - stopping service
Not all shards are closed yet, waited 50sec - stopping service
Not all shards are closed yet, waited 55sec - stopping service
Not all shards are closed yet, waited 60sec - stopping service
Not all shards are closed yet, waited 65sec - stopping service
Not all shards are closed yet, waited 70sec - stopping service
Not all shards are closed yet, waited 75sec - stopping service
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: java.lang.NullPointerException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: java.net.SocketTimeoutException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: org.elasticsearch.ElasticsearchException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: java.io.IOException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: java.lang.OutOfMemoryError
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: java.lang.InterruptedException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: org.elasticsearch.cluster.block.ClusterBlockException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: java.lang.IllegalArgumentException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: org.elasticsearch.transport.NodeDisconnectedException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: java.util.concurrent.ExecutionException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: java.lang.SecurityException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: org.elasticsearch.action.ActionRequestValidationException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: java.lang.ClassNotFoundException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: org.elasticsearch.common.breaker.CircuitBreakingException
Failed to execute NodeStatsAction for ClusterInfoUpdateJob: java.lang.UnsupportedOperationException
index deleting index store reason [disk full]
index deleting index store reason [corrupted data]
index deleting index store reason [user request]
index deleting index store reason [expired data]
index deleting index store reason [redundant data]
index deleting index store reason [migration]
index deleting index store reason [optimization]
index deleting index store reason [error]
index deleting index store reason [maintenance]
index deleting index store reason [backup]
index deleting index store reason [security]
index deleting index store reason [policy change]
index deleting index store reason [system crash]
index deleting index store reason [upgrade]
index deleting index store reason [performance]
index_products is closed, no need to wait for shards, ignoring
index_users is closed, no need to wait for shards, ignoring
index_orders is closed, no need to wait for shards, ignoring
index_news is closed, no need to wait for shards, ignoring
index_events is closed, no need to wait for shards, ignoring
index_logs is closed, no need to wait for shards, ignoring
index_comments is closed, no need to wait for shards, ignoring
index_reviews is closed, no need to wait for shards, ignoring
index_articles is closed, no need to wait for shards, ignoring
index_videos is closed, no need to wait for shards, ignoring
index_photos is closed, no need to wait for shards, ignoring
index_tweets is closed, no need to wait for shards, ignoring
index_posts is closed, no need to wait for shards, ignoring
index_messages is closed, no need to wait for shards, ignoring
index_emails is closed, no need to wait for shards, ignoring
reassigning 0 persistent tasks
reassigning 1 persistent tasks
reassigning 2 persistent tasks
reassigning 3 persistent tasks
reassigning 4 persistent tasks
reassigning 5 persistent tasks
reassigning 6 persistent tasks
reassigning 7 persistent tasks
reassigning 8 persistent tasks
reassigning 9 persistent tasks
reassigning 10 persistent tasks
reassigning 11 persistent tasks
reassigning 12 persistent tasks
reassigning 13 persistent tasks
reassigning 14 persistent tasks
Unable to start allocated task [DataProcessing] with id [4567] and allocation id [1234] Error: OutOfMemoryException
Unable to start allocated task [ImageRecognition] with id [8910] and allocation id [5678] Error: FileNotFoundException
Unable to start allocated task [WebCrawling] with id [1112] and allocation id [9101] Error: SocketTimeoutException
Unable to start allocated task [MachineLearning] with id [1314] and allocation id [1121] Error: InvalidInputException
Unable to start allocated task [VideoEditing] with id [1516] and allocation id [3141] Error: CodecNotFoundException
Unable to start allocated task [TextAnalysis] with id [1718] and allocation id [5161] Error: EncodingNotSupportedException
Unable to start allocated task [AudioProcessing] with id [1920] and allocation id [7181] Error: DeviceNotAvailableException
Unable to start allocated task [DatabaseQuerying] with id [2122] and allocation id [9202] Error: SQLException
Unable to start allocated task [NetworkTesting] with id [2324] and allocation id [1223] Error: ConnectionRefusedException
Unable to start allocated task [GameDevelopment] with id [2526] and allocation id [3242] Error: GraphicsInitializationException
Unable to start allocated task [DocumentScanning] with id [2728] and allocation id [5262] Error: ScannerNotDetectedException
Unable to start allocated task [EmailSending] with id [2930] and allocation id [7282] Error: SMTPAuthenticationException
Unable to start allocated task [FileCompression] with id [3132] and allocation id [0303] Error: ZipException
Unable to start allocated task [PasswordCracking] with id [3334] and allocation id [2323] Error: IllegalAccessError
Unable to start allocated task [VirusScanning] with id [3536] and allocation id [4343] Error: SecurityException
high disk watermark [90%] no longer exceeded on /dev/sda1, but low disk watermark [85%] is still exceeded
high disk watermark [95%] no longer exceeded on /dev/sdb2, but low disk watermark [80%] is still exceeded
high disk watermark [92%] no longer exceeded on /dev/sdc3, but low disk watermark [75%] is still exceeded
high disk watermark [88%] no longer exceeded on /dev/sdd4, but low disk watermark [70%] is still exceeded
high disk watermark [94%] no longer exceeded on /dev/sde5, but low disk watermark [65%] is still exceeded
high disk watermark [91%] no longer exceeded on /dev/sdf6, but low disk watermark [60%] is still exceeded
high disk watermark [89%] no longer exceeded on /dev/sdg7, but low disk watermark [55%] is still exceeded
high disk watermark [93%] no longer exceeded on /dev/sdh8, but low disk watermark [50%] is still exceeded
high disk watermark [87%] no longer exceeded on /dev/sdi9, but low disk watermark [45%] is still exceeded
high disk watermark [96%] no longer exceeded on /dev/sdj10, but low disk watermark [40%] is still exceeded
high disk watermark [90%] no longer exceeded on /dev/sdk11, but low disk watermark [35%] is still exceeded
high disk watermark [92%] no longer exceeded on /dev/sdl12, but low disk watermark [30%] is still exceeded
high disk watermark [86%] no longer exceeded on /dev/sdm13, but low disk watermark [25%] is still exceeded
high disk watermark [95%] no longer exceeded on /dev/sdn14, but low disk watermark [20%] is still exceeded
high disk watermark [97%] no longer exceeded on /dev/sdo15, but low disk watermark [15%] is still exceeded
Found completed persistent task [delete-index] with id [xQa7wY9aQ4WZ0g6l2n8q7w] and allocation id [1] - removing
Found completed persistent task [update-settings] with id [yQb8xZ0bR5XZ1g7m3n9r8x] and allocation id [2] - removing
Found completed persistent task [reindex] with id [zQc9yA1cS6YZ2h8n4o0s9y] and allocation id [3] - removing
Found completed persistent task [create-snapshot] with id [aRd0zB2dT7AZ3i9o5p1t0z] and allocation id [4] - removing
Found completed persistent task [restore-snapshot] with id [bSe1aC3eU8BA4j0p6q2u1a] and allocation id [5] - removing
Found completed persistent task [rollover-index] with id [cTf2bD4fV9CA5k1q7r3v2b] and allocation id [6] - removing
Found completed persistent task [shrink-index] with id [dUg3cE5gW0DA6l2r8s4w3c] and allocation id [7] - removing
Found completed persistent task [split-index] with id [eVh4dF6hX1EA7m3s9t5x4d] and allocation id [8] - removing
Found completed persistent task [freeze-index] with id [fWi5eG7iY2FA8n4t0u6y5e] and allocation id [9] - removing
Found completed persistent task [unfreeze-index] with id [gXj6fH8jZ3GA9o5u1v7z6f] and allocation id [10] - removing
Found completed persistent task [close-index] with id [hYk7gI9kA4HA0p6v2w8a7g] and allocation id [11] - removing
Found completed persistent task [open-index] with id [iZl8hJ0lB5IA1q7w3x9b8h] and allocation id [12] - removing
Found completed persistent task [flush-index] with id [jAm9iK1mC6JA2r8x4y0c9i] and allocation id [13] - removing
Found completed persistent task [refresh-index] with id [kBn0jL2nD7KA3s9y5z1d0j] and allocation id [14] - removing
Found completed persistent task [force-merge-index] with id [lCo1kM3oE8LA4t0z6a2e1k] and allocation id [15] - removing
weights are same, not updating weighted routing weights [0.5] in metadata
weights are same, not updating weighted routing weights [0.25] in metadata
weights are same, not updating weighted routing weights [0.75] in metadata
weights are same, not updating weighted routing weights [0.1] in metadata
weights are same, not updating weighted routing weights [0.9] in metadata
weights are same, not updating weighted routing weights [0.4] in metadata
weights are same, not updating weighted routing weights [0.6] in metadata
weights are same, not updating weighted routing weights [0.2] in metadata
weights are same, not updating weighted routing weights [0.8] in metadata
weights are same, not updating weighted routing weights [0.3] in metadata
weights are same, not updating weighted routing weights [0.7] in metadata
weights are same, not updating weighted routing weights [0.15] in metadata
weights are same, not updating weighted routing weights [0.85] in metadata
weights are same, not updating weighted routing weights [0.05] in metadata
weights are same, not updating weighted routing weights [0.95] in metadata
[metadata.name()] Unknown blob in the repository: blobName
[user1] Unknown blob in the repository: image.jpg
[config] Unknown blob in the repository: settings.ini
[metadata.name()] Unknown blob in the repository: video.mp4
[user2] Unknown blob in the repository: document.docx
[metadata.name()] Unknown blob in the repository: music.mp3
[user3] Unknown blob in the repository: archive.zip
[metadata.name()] Unknown blob in the repository: script.py
[user4] Unknown blob in the repository: logo.png
[metadata.name()] Unknown blob in the repository: data.csv
[user5] Unknown blob in the repository: presentation.pptx
[metadata.name()] Unknown blob in the repository: code.java
[user6] Unknown blob in the repository: report.pdf
[metadata.name()] Unknown blob in the repository: game.exe
[user7] Unknown blob in the repository: model.h5
Rest tests for project [src/main/java/com/opensearch] will be copied to the test resources from the published jar (version: [1.2.3]).
Rest tests for project [src/test/java/com/opensearch] will be copied to the test resources from the published jar (version: [1.2.4]).
Rest tests for project [src/main/resources/com/opensearch] will be copied to the test resources from the published jar (version: [1.2.5]).
Rest tests for project [src/test/resources/com/opensearch] will be copied to the test resources from the published jar (version: [1.2.6]).
Rest tests for project [src/main/java/com/opensearch/client] will be copied to the test resources from the published jar (version: [1.2.7]).
Rest tests for project [src/test/java/com/opensearch/client] will be copied to the test resources from the published jar (version: [1.2.8]).
Rest tests for project [src/main/resources/com/opensearch/client] will be copied to the test resources from the published jar (version: [1.2.9]).
Rest tests for project [src/test/resources/com/opensearch/client] will be copied to the test resources from the published jar (version: [1.3.0]).
Rest tests for project [src/main/java/com/opensearch/common] will be copied to the test resources from the published jar (version: [1.3.1]).
Rest tests for project [src/test/java/com/opensearch/common] will be copied to the test resources from the published jar (version: [1.3.2]).
Rest tests for project [src/main/resources/com/opensearch/common] will be copied to the test resources from the published jar (version: [1.3.3]).
Rest tests for project [src/test/resources/com/opensearch/common] will be copied to the test resources from the published jar (version: [1.3.4]).
Rest tests for project [src/main/java/com/opensearch/search] will be copied to the test resources from the published jar (version: [1.3.5]).
Rest tests for project [src/test/java/com/opensearch/search] will be copied to the test resources from the published jar (version: [1.3.6]).
Rest tests for project [src/main/resources/com/opensearch/search] will be copied to the test resources from the published jar (version: [1.3.7]).
expecting 3 acknowledgements for cluster_state update (version: 5)
expecting 5 acknowledgements for cluster_state update (version: 7)
expecting 2 acknowledgements for cluster_state update (version: 4)
expecting 4 acknowledgements for cluster_state update (version: 6)
expecting 6 acknowledgements for cluster_state update (version: 8)
expecting 1 acknowledgements for cluster_state update (version: 3)
expecting 7 acknowledgements for cluster_state update (version: 9)
expecting 8 acknowledgements for cluster_state update (version: 10)
expecting 9 acknowledgements for cluster_state update (version: 11)
expecting 10 acknowledgements for cluster_state update (version: 12)
expecting 11 acknowledgements for cluster_state update (version: 13)
expecting 12 acknowledgements for cluster_state update (version: 14)
expecting 13 acknowledgements for cluster_state update (version: 15)
expecting 14 acknowledgements for cluster_state update (version: 16)
expecting 15 acknowledgements for cluster_state update (version: 17)
compiling lang: [Python] type: [script] script: print("Hello world")
compiling lang: [Java] type: [class] script: HelloWorld.java
compiling lang: [C++] type: [executable] script: main.cpp
compiling lang: [Ruby] type: [script] script: puts "Hello world"
compiling lang: [JavaScript] type: [function] script: function hello() {console.log("Hello world")}
compiling lang: [C#] type: [assembly] script: Program.cs
compiling lang: [Perl] type: [script] script: print "Hello world\n"
compiling lang: [PHP] type: [web page] script: index.php
compiling lang: [Swift] type: [app] script: AppDelegate.swift
compiling lang: [Rust] type: [library] script: lib.rs
compiling lang: [Go] type: [package] script: main.go
compiling lang: [Kotlin] type: [object] script: Hello.kt
compiling lang: [Scala] type: [trait] script: Greeter.scala
compiling lang: [Haskell] type: [module] script: Main.hs
success count = 12, error count = 3
success count = 8, error count = 5
success count = 15, error count = 0
success count = 10, error count = 2
success count = 9, error count = 4
success count = 11, error count = 1
success count = 7, error count = 6
success count = 13, error count = 2
success count = 14, error count = 1
success count = 6, error count = 7
success count = 5, error count = 8
success count = 4, error count = 9
success count = 3, error count = 10
success count = 2, error count = 11
success count = 1, error count = 12
--> getting cluster health on [node1]
--> getting cluster health on [node2]
--> getting cluster health on [node3]
--> getting cluster health on [node4]
--> getting cluster health on [node5]
--> getting cluster health on [node6]
--> getting cluster health on [node7]
--> getting cluster health on [node8]
--> getting cluster health on [node9]
--> getting cluster health on [node10]
--> getting cluster health on [master-node]
--> getting cluster health on [backup-node]
--> getting cluster health on [worker-node]
--> getting cluster health on [client-node]
--> getting cluster health on [test-node]
--> got cluster health on [node1]
--> got cluster health on [node2]
--> got cluster health on [node3]
--> got cluster health on [node4]
--> got cluster health on [node5]
--> got cluster health on [node6]
--> got cluster health on [node7]
--> got cluster health on [node8]
--> got cluster health on [node9]
--> got cluster health on [node10]
--> got cluster health on [node11]
--> got cluster health on [node12]
--> got cluster health on [node13]
--> got cluster health on [node14]
--> got cluster health on [node15]
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> delete index before restoring
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
--> waiting for no relocation
set task custom to null
set task custom to null
set task custom to null
set task custom to null
set task custom to null
set task custom to null
set task custom to null
set task custom to null
set task custom to null
set task custom to null
set task custom to null
set task custom to null
set task custom to null
set task custom to null
set task custom to null
Opening translog at /var/log/translog_20210102.log
Opening translog at /var/log/translog_20210103.log
Opening translog at /var/log/translog_20210104.log
Opening translog at /var/log/translog_20210105.log
Opening translog at /var/log/translog_20210106.log
Opening translog at /var/log/translog_20210107.log
Opening translog at /var/log/translog_20210108.log
Opening translog at /var/log/translog_20210109.log
Opening translog at /var/log/translog_20210110.log
Opening translog at /var/log/translog_20210111.log
Opening translog at /var/log/translog_20210112.log
Opening translog at /var/log/translog_20210113.log
Opening translog at /var/log/translog_20210114.log
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> check that all shards were recovered
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> starting 1 node on a different rack
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> wait for restore to finish
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
--> starting 2 nodes on the same rack
>> Lucene index is Index Rebuilt at /var/lucene/index
>> Lucene index is Indexing Failed at /var/lucene/index
>> Lucene index is Index Not Found at /var/lucene/index
>> Lucene index is Index Locked at /var/lucene/index
>> Lucene index is Index Corrupted at /var/lucene/index
>> Lucene index is Index Deleted at /var/lucene/index
>> Lucene index is Index Validation Failed at /var/lucene/index
>> Lucene index is Index Already Exists at /var/lucene/index
>> Lucene index is Indexing Completed at /var/lucene/index
>> Lucene index is Index Reopened at /var/lucene/index
>> Lucene index is Index Optimization Failed at /var/lucene/index
>> Lucene index is Index Created at /var/lucene/index
>> Lucene index is Index Cleared at /var/lucene/index
>> Lucene index is Index Unlocked at /var/lucene/index
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
--> close index while restore is running
removed unassigned node 456
removed unassigned node 789
removed unassigned node 321
removed unassigned node 654
removed unassigned node 987
removed unassigned node 543
removed unassigned node 876
removed unassigned node 109
removed unassigned node 210
removed unassigned node 876
removed unassigned node 543
removed unassigned node 987
removed unassigned node 654
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
added random unassignable task
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> unblocking all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
--> execution will be blocked on all data nodes
Opening Lucene index at /var/index2
Opening Lucene index at D:/data/index3
Opening Lucene index at /home/user2/index4
Opening Lucene index at E:/index5
Opening Lucene index at /mnt/index6
Opening Lucene index at F:/data/index7
Opening Lucene index at /usr/index8
Opening Lucene index at G:/index9
Opening Lucene index at /opt/index10
Opening Lucene index at H:/data/index11
Opening Lucene index at /tmp/index12
Opening Lucene index at I:/index13
Opening Lucene index at /archive/index14
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
--> deleting indices before restoring
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
Please make a complete backup of your index before using this tool.
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> adding [week_20] alias to [2017-05-20]
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
--> waiting for snapshot to finish
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
added unassignable task with custom assignment message
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> creating index [2017-05-20]
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
--> delete index while non-partial snapshot is running
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
This tool attempts to detect and remove unrecoverable corrupted data in a shard.
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> getting * for index *bac
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> close index while non-partial snapshot is running
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> wait for block to kick in
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> checking that _current no longer returns the snapshot
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> getting foo for index foobar
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> checking snapshot status after it is done with empty repository
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> getting f* for index *bac
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> checking snapshot status again after snapshot is done
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> getting f* for index *bar
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> checking that _current returns the currently running snapshot
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> getting *b* for index *bar
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> checking snapshot status for all currently running and snapshot with empty repository
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting *b* for index baz*
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> getting bar and baz for index bazbar
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> creating aliases [bar, baz, foo]
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> try making another snapshot
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> getting all aliases that start with alias*
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> trying to create a repository with different name
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> creating aliases [alias1, alias2]
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> in-use repository replacement failed
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
--> creating indices [foobar, test, test123, foobarbaz, bazbar]
Exception in RemoteStoreRefreshListener.afterRefresh() IOException
Exception in RemoteStoreRefreshListener.afterRefresh() NullPointerException
Exception in RemoteStoreRefreshListener.afterRefresh() ArrayIndexOutOfBoundsException
Exception in RemoteStoreRefreshListener.afterRefresh() IllegalArgumentException
Exception in RemoteStoreRefreshListener.afterRefresh() IndexOutOfBoundsException
Exception in RemoteStoreRefreshListener.afterRefresh() FileNotFoundException
Exception in RemoteStoreRefreshListener.afterRefresh() ClassCastException
Exception in RemoteStoreRefreshListener.afterRefresh() NoSuchElementException
Exception in RemoteStoreRefreshListener.afterRefresh() UnsupportedOperationException
Exception in RemoteStoreRefreshListener.afterRefresh() ConcurrentModificationException
Exception in RemoteStoreRefreshListener.afterRefresh() NullPointerException
Exception in RemoteStoreRefreshListener.afterRefresh() IOException
Exception in RemoteStoreRefreshListener.afterRefresh() ClassNotFoundException
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> trying to move repository to another location
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> deleting alias1 which does not exist
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> in-use repository deletion failed
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
--> Fix file system disruption
Skipped syncing segments with primaryMode=true indexShardState=INITIALIZING
Skipped syncing segments with primaryMode=false indexShardState=RECOVERING
Skipped syncing segments with primaryMode=true indexShardState=STARTED
Skipped syncing segments with primaryMode=true indexShardState=RELOCATED
Skipped syncing segments with primaryMode=false indexShardState=CLOSED
Skipped syncing segments with primaryMode=true indexShardState=INITIALIZING
Skipped syncing segments with primaryMode=false indexShardState=RECOVERING
Skipped syncing segments with primaryMode=true indexShardState=STARTED
Skipped syncing segments with primaryMode=false indexShardState=RELOCATED
Skipped syncing segments with primaryMode=false indexShardState=CLOSED
Skipped syncing segments with primaryMode=true indexShardState=INITIALIZING
Skipped syncing segments with primaryMode=false indexShardState=RECOVERING
Skipped syncing segments with primaryMode=true indexShardState=STARTED
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> verify that filter was updated
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> recreating alias1 with a different filter
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> replace mock repository with real one at the same location
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> recreating alias1 with the same filter
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> Initial health status prior to the first monitor run
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
--> modifying alias1 to have a filter
Exception while initialising RemoteSegmentStoreDirectory NullPointerException
Exception while initialising RemoteSegmentStoreDirectory ClassNotFoundException
Exception while initialising RemoteSegmentStoreDirectory IllegalStateException
Exception while initialising RemoteSegmentStoreDirectory ArrayIndexOutOfBoundsException
Exception while initialising RemoteSegmentStoreDirectory NumberFormatException
Exception while initialising RemoteSegmentStoreDirectory IllegalArgumentException
Exception while initialising RemoteSegmentStoreDirectory OutOfMemoryError
Exception while initialising RemoteSegmentStoreDirectory StackOverflowError
Exception while initialising RemoteSegmentStoreDirectory NoSuchMethodError
Exception while initialising RemoteSegmentStoreDirectory NoClassDefFoundError
Exception while initialising RemoteSegmentStoreDirectory UnsupportedClassVersionError
Exception while initialising RemoteSegmentStoreDirectory SecurityException
Exception while initialising RemoteSegmentStoreDirectory NoSuchFieldException
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
No error processing checkpoint info
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
--> adding [foo] alias to [foo_foo] and [bar_bar]
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
-->  closing index test-idx-closed
error firing refresh listener IOException
error firing refresh listener NullPointerException
error firing refresh listener ArrayIndexOutOfBoundsException
error firing refresh listener ClassNotFoundException
error firing refresh listener NoSuchMethodException
error firing refresh listener IllegalArgumentException
error firing refresh listener FileNotFoundException
error firing refresh listener NumberFormatException
error firing refresh listener InvalidClassException
error firing refresh listener OutOfMemoryError
error firing refresh listener StackOverflowError
error firing refresh listener RuntimeException
error firing refresh listener ArrayStoreException
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> creating index [foo_foo] and [bar_bar]
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> delete all snapshots except the first one and last one
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> creating index [test1] and [test2]
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> checking counts before delete
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> creating index [test1] and [test2
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> checking filtering alias for multiple indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
--> adding filtering aliases to indices
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
-->  creating index that cannot be allocated
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> adding aliases to indices
--> Index more docs 200 and replicate segments
--> Index more docs 300 and replicate segments
--> Index more docs 400 and replicate segments
--> Index more docs 500 and replicate segments
--> Index more docs 600 and replicate segments
--> Index more docs 700 and replicate segments
--> Index more docs 800 and replicate segments
--> Index more docs 900 and replicate segments
--> Index more docs 1000 and replicate segments
--> Index more docs 1100 and replicate segments
--> Index more docs 1200 and replicate segments
--> Index more docs 1300 and replicate segments
--> Index more docs 1400 and replicate segments
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> trying to restore index again
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for both indices
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> checking filtering alias for two indices and non-filtering alias for one index
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> wait for the index to appear
--> Index numDocs 200 and flush
--> Index numDocs 300 and flush
--> Index numDocs 400 and flush
--> Index numDocs 500 and flush
--> Index numDocs 600 and flush
--> Index numDocs 700 and flush
--> Index numDocs 800 and flush
--> Index numDocs 900 and flush
--> Index numDocs 1000 and flush
--> Index numDocs 1100 and flush
--> Index numDocs 1200 and flush
--> Index numDocs 1300 and flush
--> Index numDocs 1400 and flush
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
--> checking filtering alias for two indices and one complete index
Returning 7 merges for end of upgrade
Returning 1 merges for end of upgrade
Returning 10 merges for end of upgrade
Returning 5 merges for end of upgrade
Returning 2 merges for end of upgrade
Returning 9 merges for end of upgrade
Returning 4 merges for end of upgrade
Returning 8 merges for end of upgrade
Returning 6 merges for end of upgrade
Returning 12 merges for end of upgrade
Returning 11 merges for end of upgrade
Returning 15 merges for end of upgrade
Returning 14 merges for end of upgrade
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
-->  update repository with mock version
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> flushing shard (translog/soft-deletes will be trimmed)
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
--> checking filtering alias for one index
Returning 2 merges for upgrade
Returning 5 merges for upgrade
Returning 8 merges for upgrade
Returning 10 merges for upgrade
Returning 3 merges for upgrade
Returning 6 merges for upgrade
Returning 1 merges for upgrade
Returning 4 merges for upgrade
Returning 7 merges for upgrade
Returning 9 merges for upgrade
Returning 12 merges for upgrade
Returning 11 merges for upgrade
Returning 14 merges for upgrade
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
--> checking filtering alias for two indices
Adding segment authentication to be upgraded
Adding segment dashboard to be upgraded
Adding segment settings to be upgraded
Adding segment notifications to be upgraded
Adding segment billing to be upgraded
Adding segment support to be upgraded
Adding segment analytics to be upgraded
Adding segment chat to be upgraded
Adding segment search to be upgraded
Adding segment payments to be upgraded
Adding segment inventory to be upgraded
Adding segment orders to be upgraded
Adding segment reviews to be upgraded
performing partial recovery (2500 bytes of 48000)
performing partial recovery (500 bytes of 7000)
performing partial recovery (1500 bytes of 32000)
performing partial recovery (800 bytes of 10000)
performing partial recovery (3000 bytes of 60000)
performing partial recovery (2000 bytes of 15000)
performing partial recovery (750 bytes of 9000)
performing partial recovery (400 bytes of 8000)
performing partial recovery (100 bytes of 1200)
performing partial recovery (600 bytes of 10000)
performing partial recovery (3500 bytes of 60000)
performing partial recovery (900 bytes of 9500)
performing partial recovery (1800 bytes of 42000)
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test2]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> adding filtering aliases to index [test1]
--> caught a top level exception, asserting what's expected ArrayIndexOutOfBoundsException
--> caught a top level exception, asserting what's expected NumberFormatException
--> caught a top level exception, asserting what's expected FileNotFoundException
--> caught a top level exception, asserting what's expected IllegalArgumentException
--> caught a top level exception, asserting what's expected IndexOutOfBoundsException
--> caught a top level exception, asserting what's expected NoSuchElementException
--> caught a top level exception, asserting what's expected ClassCastException
--> caught a top level exception, asserting what's expected ArithmeticException
--> caught a top level exception, asserting what's expected InterruptedException
--> caught a top level exception, asserting what's expected OutOfMemoryError
--> caught a top level exception, asserting what's expected StackOverflowError
--> caught a top level exception, asserting what's expected AssertionError
--> caught a top level exception, asserting what's expected UnsupportedOperationException
Exception while reading checksum of file: data.docx, this can happen if file is corrupted
Exception while reading checksum of file: image.jpg, this can happen if file is corrupted
Exception while reading checksum of file: config.ini, this can happen if file is corrupted
Exception while reading checksum of file: log.log, this can happen if file is corrupted
Exception while reading checksum of file: script.py, this can happen if file is corrupted
Exception while reading checksum of file: invoice.pdf, this can happen if file is corrupted
Exception while reading checksum of file: presentation.pptx, this can happen if file is corrupted
Exception while reading checksum of file: archive.zip, this can happen if file is corrupted
Exception while reading checksum of file: database.sqlite, this can happen if file is corrupted
Exception while reading checksum of file: video.mov, this can happen if file is corrupted
Exception while reading checksum of file: code.java, this can happen if file is corrupted
Exception while reading checksum of file: spreadsheet.xlsx, this can happen if file is corrupted
Exception while reading checksum of file: backup.bak, this can happen if file is corrupted
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
--> checking index and alias wildcard search
Memory size: 256MB
Memory size: 1024MB
Memory size: 128MB
Memory size: 768MB
Memory size: 2048MB
Memory size: 384MB
Memory size: 1536MB
Memory size: 640MB
Memory size: 3072MB
Memory size: 896MB
Memory size: 1920MB
Memory size: 448MB
Memory size: 2304MB
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> checking index and filtering alias search
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> validated that the cache file path doesn't exist
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> checking non-filtering alias and filtering alias search
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> validate cache file path is deleted
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
--> checking single non-filtering alias search
Final cluster state: INACTIVE
Final cluster state: ERROR
Final cluster state: REBALANCING
Final cluster state: SHUTTING DOWN
Final cluster state: UNKNOWN
Final cluster state: STANDBY
Final cluster state: ONLINE
Final cluster state: OFFLINE
Final cluster state: DEGRADED
Final cluster state: SYNCING
Final cluster state: MAINTENANCE
Final cluster state: TERMINATING
Final cluster state: SUSPENDED
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> restore indices as 'remote_snapshot'
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with non-global facets
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
--> checking single filtering alias search with global facets and sort
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
Downloading segments from given remote segment store
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
--> checking single filtering alias search with global facets
Thread got semi-unexpected circuit breaking exception TimeoutException
Thread got semi-unexpected circuit breaking exception IllegalArgumentException
Thread got semi-unexpected circuit breaking exception ArrayIndexOutOfBoundsException
Thread got semi-unexpected circuit breaking exception ArithmeticException
Thread got semi-unexpected circuit breaking exception FileNotFoundException
Thread got semi-unexpected circuit breaking exception ClassNotFoundException
Thread got semi-unexpected circuit breaking exception NoSuchMethodException
Thread got semi-unexpected circuit breaking exception NumberFormatException
Thread got semi-unexpected circuit breaking exception NullPointerException
Thread got semi-unexpected circuit breaking exception TimeoutException
Thread got semi-unexpected circuit breaking exception IllegalArgumentException
Thread got semi-unexpected circuit breaking exception ArrayIndexOutOfBoundsException
Thread got semi-unexpected circuit breaking exception ArithmeticException
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
Downloading segments from remote segment store
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> add 3 new search nodes
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
--> checking single filtering alias search with sort
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
refresh with source [schedule]
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> stop the last search node
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> checking single filtering alias wildcard search
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> stop a random search node
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> checking single filtering alias search
--> parent tripped: false, total trip count: 1 (expecting 1-2 for each)
--> parent tripped: true, total trip count: 1 (expecting 1-2 for each)
--> parent tripped: false, total trip count: 2 (expecting 1-2 for each)
--> parent tripped: true, total trip count: 2 (expecting 1-2 for each)
--> parent tripped: false, total trip count: 1 (expecting 1-2 for each)
--> parent tripped: true, total trip count: 2 (expecting 1-2 for each)
--> parent tripped: false, total trip count: 1 (expecting 1-2 for each)
--> parent tripped: true, total trip count: 1 (expecting 1-2 for each)
--> parent tripped: false, total trip count: 2 (expecting 1-2 for each)
--> parent tripped: true, total trip count: 1 (expecting 1-2 for each)
--> parent tripped: false, total trip count: 2 (expecting 1-2 for each)
--> parent tripped: true, total trip count: 2 (expecting 1-2 for each)
--> parent tripped: false, total trip count: 1 (expecting 1-2 for each)
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
--> checking consistency between settings and blocks
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
submitting async flush request
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> adding filtering aliases to index [test]
--> child breaker: used: 75, limit: 150
--> child breaker: used: 30, limit: 60
--> child breaker: used: 80, limit: 160
--> child breaker: used: 25, limit: 50
--> child breaker: used: 60, limit: 120
--> child breaker: used: 45, limit: 90
--> child breaker: used: 70, limit: 140
--> child breaker: used: 35, limit: 70
--> child breaker: used: 90, limit: 180
--> child breaker: used: 40, limit: 80
--> child breaker: used: 55, limit: 110
--> child breaker: used: 85, limit: 170
--> child breaker: used: 95, limit: 190
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
--> aliasing index [test] with [alias1] and empty filter
failed to roll translog generation Out of memory
failed to roll translog generation Permission denied
failed to roll translog generation Corrupted data
failed to roll translog generation Invalid argument
failed to roll translog generation Disk full
failed to roll translog generation Network error
failed to roll translog generation Timeout
failed to roll translog generation Connection refused
failed to roll translog generation File not found
failed to roll translog generation Authentication failed
failed to roll translog generation Invalid credentials
failed to roll translog generation Access denied
failed to roll translog generation Invalid request
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
--> making sure that filter was stored with alias [alias1] and filter [user:foobar]
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
submitting async roll translog generation request
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> restore index with additional block changes
--> applying changed block settings high
--> applying changed block settings low
--> applying changed block settings custom
--> applying changed block settings medium
--> applying changed block settings advanced
--> applying changed block settings basic
--> applying changed block settings standard
--> applying changed block settings premium
--> applying changed block settings professional
--> applying changed block settings ultimate
--> applying changed block settings enterprise
--> applying changed block settings developer
--> applying changed block settings personal
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
--> aliasing index [test] with [alias1] and filter [user:foobar]
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
operation execution has been combined with primary term update
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> remove blocks and delete index
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> indexing against [alias1], should work against [test_x]
--> NUM_THREADS: 5, BYTES_PER_THREAD: 2048, TOTAL_BYTES: 10240, PARENT_LIMIT: 200, CHILD_LIMIT: 100
--> NUM_THREADS: 3, BYTES_PER_THREAD: 4096, TOTAL_BYTES: 12288, PARENT_LIMIT: 150, CHILD_LIMIT: 75
--> NUM_THREADS: 8, BYTES_PER_THREAD: 512, TOTAL_BYTES: 4096, PARENT_LIMIT: 120, CHILD_LIMIT: 60
--> NUM_THREADS: 4, BYTES_PER_THREAD: 256, TOTAL_BYTES: 1024, PARENT_LIMIT: 80, CHILD_LIMIT: 40
--> NUM_THREADS: 12, BYTES_PER_THREAD: 1024, TOTAL_BYTES: 12288, PARENT_LIMIT: 180, CHILD_LIMIT: 90
--> NUM_THREADS: 6, BYTES_PER_THREAD: 2048, TOTAL_BYTES: 12288, PARENT_LIMIT: 180, CHILD_LIMIT: 90
--> NUM_THREADS: 9, BYTES_PER_THREAD: 512, TOTAL_BYTES: 4608, PARENT_LIMIT: 140, CHILD_LIMIT: 70
--> NUM_THREADS: 2, BYTES_PER_THREAD: 4096, TOTAL_BYTES: 8192, PARENT_LIMIT: 100, CHILD_LIMIT: 50
--> NUM_THREADS: 7, BYTES_PER_THREAD: 256, TOTAL_BYTES: 1792, PARENT_LIMIT: 100, CHILD_LIMIT: 50
--> NUM_THREADS: 11, BYTES_PER_THREAD: 512, TOTAL_BYTES: 5632, PARENT_LIMIT: 160, CHILD_LIMIT: 80
--> NUM_THREADS: 15, BYTES_PER_THREAD: 256, TOTAL_BYTES: 3840, PARENT_LIMIT: 180, CHILD_LIMIT: 90
--> NUM_THREADS: 13, BYTES_PER_THREAD: 1024, TOTAL_BYTES: 13312, PARENT_LIMIT: 200, CHILD_LIMIT: 100
--> NUM_THREADS: 1, BYTES_PER_THREAD: 2048, TOTAL_BYTES: 2048, PARENT_LIMIT: 80, CHILD_LIMIT: 40
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> remove [alias1], Aliasing index [test_x] with [alias1]
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
--> apply initial blocks to index
detected new primary with primary term 7, global checkpoint 250, max_seq_no 50
detected new primary with primary term 15, global checkpoint 700, max_seq_no 150
detected new primary with primary term 9, global checkpoint 400, max_seq_no 80
detected new primary with primary term 18, global checkpoint 900, max_seq_no 200
detected new primary with primary term 5, global checkpoint 200, max_seq_no 40
detected new primary with primary term 11, global checkpoint 450, max_seq_no 90
detected new primary with primary term 14, global checkpoint 650, max_seq_no 140
detected new primary with primary term 6, global checkpoint 300, max_seq_no 60
detected new primary with primary term 10, global checkpoint 500, max_seq_no 100
detected new primary with primary term 16, global checkpoint 800, max_seq_no 170
detected new primary with primary term 9, global checkpoint 400, max_seq_no 80
detected new primary with primary term 13, global checkpoint 600, max_seq_no 130
detected new primary with primary term 7, global checkpoint 250, max_seq_no 50
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> add index [test_x] with [alias1] as write-index
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> remove aliasing index [test_x] with [alias1]
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> deleting against [alias1], should fail now
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> add index [test_x] with [alias1]
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
--> indexing against [alias1], should work now
exception while notifying engine failure ArrayIndexOutOfBoundsException
exception while notifying engine failure NumberFormatException
exception while notifying engine failure FileNotFoundException
exception while notifying engine failure ClassCastException
exception while notifying engine failure IllegalArgumentException
exception while notifying engine failure NoSuchElementException
exception while notifying engine failure TimeoutException
exception while notifying engine failure IOException
exception while notifying engine failure IndexOutOfBoundsException
exception while notifying engine failure ArithmeticException
exception while notifying engine failure RuntimeException
exception while notifying engine failure InvalidKeyException
exception while notifying engine failure OutOfMemoryError
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> assert that correct settings are restored and index is still functional
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> indexing against [alias1], should fail now
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> delete the index and recreate it while deleting all index settings
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> aliasing index [test] with [alias1]
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> assert that correct settings are restored
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
--> restore index with correct settings from the snapshot
checksum passed: 0x7c
checksum passed: 0xf9
checksum passed: 0x5e
checksum passed: 0x81
checksum passed: 0x3d
checksum passed: 0xb6
checksum passed: 0x98
checksum passed: 0x1f
checksum passed: 0x6a
checksum passed: 0x49
checksum passed: 0xcf
checksum passed: 0xad
checksum passed: 0xe6
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
Checking best terms by highest to lowest idf ...
checksum failed: image.png
checksum failed: data.csv
checksum failed: log.txt
checksum failed: document.docx
checksum failed: code.py
checksum failed: settings.json
checksum failed: video.mp4
checksum failed: audio.wav
checksum failed: presentation.ppt
checksum failed: spreadsheet.xlsx
checksum failed: archive.zip
checksum failed: program.exe
checksum failed: database.db
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of replicas to a negative number - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
--> try restoring while changing the number of shards - should fail
Indexing 200 documents with tags of increasing dfs ...
Indexing 300 documents with tags of increasing dfs ...
Indexing 400 documents with tags of increasing dfs ...
Indexing 500 documents with tags of increasing dfs ...
Indexing 600 documents with tags of increasing dfs ...
Indexing 700 documents with tags of increasing dfs ...
Indexing 800 documents with tags of increasing dfs ...
Indexing 900 documents with tags of increasing dfs ...
Indexing 1000 documents with tags of increasing dfs ...
Indexing 1100 documents with tags of increasing dfs ...
Indexing 1200 documents with tags of increasing dfs ...
Indexing 1300 documents with tags of increasing dfs ...
Indexing 1400 documents with tags of increasing dfs ...
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
--> delete the index and recreate it while changing refresh interval and analyzer
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
Checking best tags by highest to lowest term freq ...
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
--> create test index with case-preserving search analyzer
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
created missing peer recovery retention leases
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
Indexing one document with tags of increasing frequencies ...
failed creating missing peer recovery retention leases OutOfMemoryError
failed creating missing peer recovery retention leases NullPointerException
failed creating missing peer recovery retention leases IllegalArgumentException
failed creating missing peer recovery retention leases IndexOutOfBoundsException
failed creating missing peer recovery retention leases FileNotFoundException
failed creating missing peer recovery retention leases ArrayIndexOutOfBoundsException
failed creating missing peer recovery retention leases ClassCastException
failed creating missing peer recovery retention leases NoSuchElementException
failed creating missing peer recovery retention leases NumberFormatException
failed creating missing peer recovery retention leases AssertionError
failed creating missing peer recovery retention leases StackOverflowError
failed creating missing peer recovery retention leases NoClassDefFoundError
failed creating missing peer recovery retention leases ArithmeticException
numDocs=20 moreDocs=15
numDocs=5 moreDocs=2
numDocs=8 moreDocs=3
numDocs=15 moreDocs=10
numDocs=12 moreDocs=7
numDocs=3 moreDocs=1
numDocs=25 moreDocs=20
numDocs=6 moreDocs=4
numDocs=18 moreDocs=13
numDocs=7 moreDocs=3
numDocs=22 moreDocs=17
numDocs=4 moreDocs=2
numDocs=14 moreDocs=9
numDocs=9 moreDocs=5
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
Checking best tags by longest to shortest size ...
syncing global checkpoint for [Memory Overflow]
syncing global checkpoint for [Disk Error]
syncing global checkpoint for [Power Outage]
syncing global checkpoint for [Security Breach]
syncing global checkpoint for [Software Update]
syncing global checkpoint for [Hardware Failure]
syncing global checkpoint for [Data Corruption]
syncing global checkpoint for [System Crash]
syncing global checkpoint for [Insufficient Resources]
syncing global checkpoint for [Application Error]
syncing global checkpoint for [User Request]
syncing global checkpoint for [Database Lock]
syncing global checkpoint for [Network Congestion]
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
--> try renaming indices into existing alias of itself, but don't restore aliases
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
Indexing one document with tags of increasing length ...
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
--> try renaming indices into existing alias of another restored index
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
Setting up the index ...
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> try renaming indices into existing alias of itself
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> index doc 1 again, so increasing the version
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
--> try renaming indices into existing alias name
All md files intro.md
All md files features.md
All md files installation.md
All md files usage.md
All md files configuration.md
All md files troubleshooting.md
All md files FAQ.md
All md files examples.md
All md files support.md
All md files changelog.md
All md files license.md
All md files contributors.md
All md files readme.md
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
--> try renaming indices using invalid index name
Done Cluster Health, status GREEN
Done Cluster Health, status YELLOW
Done Cluster Health, status RED
Done Cluster Health, status GREEN
Done Cluster Health, status YELLOW
Done Cluster Health, status RED
Done Cluster Health, status GREEN
Done Cluster Health, status YELLOW
Done Cluster Health, status RED
Done Cluster Health, status GREEN
Done Cluster Health, status YELLOW
Done Cluster Health, status RED
Done Cluster Health, status GREEN
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> try renaming indices using the same name
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> and try to restore these indices again
--> test done. total ops written [8]
--> test done. total ops written [21]
--> test done. total ops written [12]
--> test done. total ops written [3]
--> test done. total ops written [17]
--> test done. total ops written [9]
--> test done. total ops written [5]
--> test done. total ops written [27]
--> test done. total ops written [11]
--> test done. total ops written [19]
--> test done. total ops written [6]
--> test done. total ops written [14]
--> test done. total ops written [23]
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
--> close just restored indices
Failed to perform engine refresh: OutOfMemoryException
Failed to perform engine refresh: InvalidCastException
Failed to perform engine refresh: FileNotFoundException
Failed to perform engine refresh: ArgumentException
Failed to perform engine refresh: IndexOutOfRangeException
Failed to perform engine refresh: InvalidOperationException
Failed to perform engine refresh: DivideByZeroException
Failed to perform engine refresh: StackOverflowException
Failed to perform engine refresh: ArgumentNullException
Failed to perform engine refresh: KeyNotFoundException
Failed to perform engine refresh: FormatException
Failed to perform engine refresh: IOException
Failed to perform engine refresh: NotImplementedException
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> waiting for readers to stop
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> restore indices with different names
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> waiting for threads to stop
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
--> check that template is restored
failed to turn off translog retention: IllegalStateException
failed to turn off translog retention: IndexOutOfBoundsException
failed to turn off translog retention: UnsupportedOperationException
failed to turn off translog retention: IllegalArgumentException
failed to turn off translog retention: ClassCastException
failed to turn off translog retention: ArrayIndexOutOfBoundsException
failed to turn off translog retention: NoSuchElementException
failed to turn off translog retention: ConcurrentModificationException
failed to turn off translog retention: OutOfMemoryError
failed to turn off translog retention: StackOverflowError
failed to turn off translog retention: ArithmeticException
failed to turn off translog retention: NoClassDefFoundError
failed to turn off translog retention: VerifyError
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
--> waiting for new cluster-manager to be elected
Broken barrier RuntimeException
Broken barrier IOException
Broken barrier NullPointerException
Broken barrier ArrayIndexOutOfBoundsException
Broken barrier FileNotFoundException
Broken barrier NumberFormatException
Broken barrier SQLException
Broken barrier IndexOutOfBoundsException
Broken barrier NoSuchElementException
Broken barrier TimeoutException
Broken barrier AssertionError
Broken barrier ClassCastException
Broken barrier IllegalStateException
Broken barrier ConcurrentModificationException
Broken barrier InvalidParameterException
failed to flush shard on inactive NullPointerException
failed to flush shard on inactive IOException
failed to flush shard on inactive ArrayIndexOutOfBoundsException
failed to flush shard on inactive ClassNotFoundException
failed to flush shard on inactive SQLException
failed to flush shard on inactive NumberFormatException
failed to flush shard on inactive FileNotFoundException
failed to flush shard on inactive IllegalArgumentException
failed to flush shard on inactive AssertionError
failed to flush shard on inactive IndexOutOfBoundsException
failed to flush shard on inactive OutOfMemoryError
failed to flush shard on inactive NoSuchElementException
failed to flush shard on inactive UnsupportedOperationException
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
--> check that aliases are not restored and existing aliases still exist
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
flushing shard on inactive
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
--> restore snapshot without aliases
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
-->  delete and close indices
[translog] recover op update
[translog] recover op delete
[translog] recover op truncate
[translog] recover op commit
[translog] recover op rollback
[translog] recover op create
[translog] recover op drop
[translog] recover op alter
[translog] recover op rename
[translog] recover op index
[translog] recover op analyze
[translog] recover op vacuum
[translog] recover op optimize
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
--> wait for all nodes to join the cluster
Barrier interrupted IOException
Barrier interrupted NullPointerException
Barrier interrupted ArrayIndexOutOfBoundsException
Barrier interrupted SQLException
Barrier interrupted FileNotFoundException
Barrier interrupted InterruptedException
Barrier interrupted NumberFormatException
Barrier interrupted RuntimeException
Barrier interrupted NoSuchElementException
Barrier interrupted ClassCastException
Barrier interrupted SecurityException
Barrier interrupted IllegalArgumentException
Barrier interrupted UnsupportedOperationException
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
--> start 4 nodes, 3 cluster-manager, 1 data
ignoring recovery of a corrupt translog entry Error
ignoring recovery of a corrupt translog entry InvalidArgumentException
ignoring recovery of a corrupt translog entry NullPointerException
ignoring recovery of a corrupt translog entry ClassCastException
ignoring recovery of a corrupt translog entry ArrayIndexOutOfBoundsException
ignoring recovery of a corrupt translog entry FileNotFoundException
ignoring recovery of a corrupt translog entry NumberFormatException
ignoring recovery of a corrupt translog entry AssertionError
ignoring recovery of a corrupt translog entry IOException
ignoring recovery of a corrupt translog entry SecurityException
ignoring recovery of a corrupt translog entry IllegalStateException
ignoring recovery of a corrupt translog entry NoSuchElementException
ignoring recovery of a corrupt translog entry IllegalArgumentException
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> check that aliases are restored
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> ensure the create index request completes
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> restore snapshot with aliases
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> wait until the cluster state contains the new index
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
--> start the index creation process
using [7] readers. [3] writers. flushing every ~[50] ops.
using [15] readers. [8] writers. flushing every ~[200] ops.
using [6] readers. [4] writers. flushing every ~[75] ops.
using [12] readers. [6] writers. flushing every ~[150] ops.
using [8] readers. [2] writers. flushing every ~[40] ops.
using [9] readers. [7] writers. flushing every ~[90] ops.
using [5] readers. [3] writers. flushing every ~[50] ops.
using [11] readers. [9] writers. flushing every ~[225] ops.
using [14] readers. [7] writers. flushing every ~[175] ops.
using [7] readers. [5] writers. flushing every ~[75] ops.
using [13] readers. [4] writers. flushing every ~[100] ops.
using [6] readers. [2] writers. flushing every ~[25] ops.
using [9] readers. [6] writers. flushing every ~[150] ops.
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old settings are restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> assert that old mapping is restored
--> index id=456 seq_no=2
--> index id=789 seq_no=3
--> index id=101112 seq_no=4
--> index id=131415 seq_no=5
--> index id=161718 seq_no=6
--> index id=192021 seq_no=7
--> index id=222324 seq_no=8
--> index id=252627 seq_no=9
--> index id=282930 seq_no=10
--> index id=313233 seq_no=11
--> index id=343536 seq_no=12
--> index id=373839 seq_no=13
--> index id=404142 seq_no=14
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
--> delete the index and recreate it with foo field
testing with [5] threads, each doing [50] ops
testing with [2] threads, each doing [200] ops
testing with [4] threads, each doing [75] ops
testing with [6] threads, each doing [40] ops
testing with [1] threads, each doing [300] ops
testing with [8] threads, each doing [25] ops
testing with [10] threads, each doing [20] ops
testing with [7] threads, each doing [30] ops
testing with [9] threads, each doing [15] ops
testing with [12] threads, each doing [12] ops
testing with [15] threads, each doing [10] ops
testing with [11] threads, each doing [13] ops
testing with [13] threads, each doing [11] ops
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
--> create index with baz field
Path ['/var/www/index.html']
Path ['/data/images/picture.jpg']
Path ['/usr/local/bin/app.exe']
Path ['/opt/config.properties']
Path ['/tmp/logs/log.txt']
Path ['/home/user/documents/report.docx']
Path ['/var/log/syslog']
Path ['/data/files/archive.zip']
Path ['/usr/share/fonts/arial.ttf']
Path ['/opt/scripts/script.sh']
Path ['/tmp/images/photo.png']
Path ['/home/user/music/song.mp3']
Path ['/var/www/public/index.php']
Path ['/data/videos/movie.mp4']
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
skip local recovery as no safe commit found
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> adding some more documents to test index
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
--> corrupt random shard copies
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating read-only repository that cannot read any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
-->  creating repository that cannot write any files, but suppress verification - should be acked
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
skip local recovery as no index commit found
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
-->  creating read-only repository that cannot read any files - should fail
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
Shard routing is marked primary thus cannot perform segment replication as replica
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
-->  creating repository that cannot write any files - should fail
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
Shard is in primary mode and cannot perform segment replication as a replica.
--> Index 2000 documents on primary
--> Index 3000 documents on primary
--> Index 4000 documents on primary
--> Index 5000 documents on primary
--> Index 6000 documents on primary
--> Index 7000 documents on primary
--> Index 8000 documents on primary
--> Index 9000 documents on primary
--> Index 10000 documents on primary
--> Index 11000 documents on primary
--> Index 12000 documents on primary
--> Index 13000 documents on primary
--> Index 14000 documents on primary
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
-->  deleting repository test-repo-1 with standard timeout - should ack
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
Attempting to perform segment replication when it is not enabled on the index
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  deleting repository test-repo-2 with 0s timeout - shouldn't ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
-->  creating repository test-repo-2 with standard timeout - should ack
Error Fetching SegmentInfos and latest checkpoint IOException
Error Fetching SegmentInfos and latest checkpoint NullPointerException
Error Fetching SegmentInfos and latest checkpoint NoSuchElementException
Error Fetching SegmentInfos and latest checkpoint IllegalArgumentException
Error Fetching SegmentInfos and latest checkpoint ArrayIndexOutOfBoundsException
Error Fetching SegmentInfos and latest checkpoint ClassCastException
Error Fetching SegmentInfos and latest checkpoint RuntimeException
Error Fetching SegmentInfos and latest checkpoint OutOfMemoryError
Error Fetching SegmentInfos and latest checkpoint StackOverflowError
Error Fetching SegmentInfos and latest checkpoint NoClassDefFoundError
Error Fetching SegmentInfos and latest checkpoint AssertionError
Error Fetching SegmentInfos and latest checkpoint ArithmeticException
Error Fetching SegmentInfos and latest checkpoint IndexOutOfBoundsException
Error Fetching SegmentInfos and latest checkpoint UnsupportedOperationException
Unexpected error computing CopyState IndexOutOfBoundsException
Unexpected error computing CopyState IllegalArgumentException
Unexpected error computing CopyState ArrayIndexOutOfBoundsException
Unexpected error computing CopyState StringIndexOutOfBoundsException
Unexpected error computing CopyState NoSuchElementException
Unexpected error computing CopyState NumberFormatException
Unexpected error computing CopyState ClassCastException
Unexpected error computing CopyState InterruptedException
Unexpected error computing CopyState UnsupportedOperationException
Unexpected error computing CopyState ArithmeticException
Unexpected error computing CopyState NoClassDefFoundError
Unexpected error computing CopyState FileNotFoundException
Unexpected error computing CopyState ArrayStoreException
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
-->  creating repository test-repo-1 with 0s timeout - shouldn't ack
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating fs repository with location that is not registered in path.repo setting
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
--> trying creating repository with incorrect settings
total: 250
total: 500
total: 750
total: 1000
total: 1250
total: 1500
total: 1750
total: 2000
total: 2250
total: 2500
total: 2750
total: 3000
total: 3250
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
--> make sure that number of files is back to what it was when the first snapshot was made
FAILED: ArrayIndexOutOfBoundsException
FAILED: FileNotFoundException
FAILED: IllegalArgumentException
FAILED: UnsupportedOperationException
FAILED: ClassCastException
FAILED: IndexOutOfBoundsException
FAILED: StackOverflowError
FAILED: ConcurrentModificationException
FAILED: NoSuchMethodException
FAILED: NumberFormatException
FAILED: AssertionError
FAILED: IOException
FAILED: OutOfMemoryError
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
-->  restoring a snapshot is blocked when the cluster is read only
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> delete the bulk of the snapshots
--> Ingest 2000 docs again
--> Ingest 3000 docs again
--> Ingest 4000 docs again
--> Ingest 5000 docs again
--> Ingest 6000 docs again
--> Ingest 7000 docs again
--> Ingest 8000 docs again
--> Ingest 9000 docs again
--> Ingest 10000 docs again
--> Ingest 11000 docs again
--> Ingest 12000 docs again
--> Ingest 13000 docs again
--> Ingest 14000 docs again
flush with POST
flush with DELETE
flush with PUT
flush with PATCH
flush with HEAD
flush with OPTIONS
flush with TRACE
flush with CONNECT
flush with FETCH
flush with UPDATE
flush with SUBSCRIBE
flush with UNSUBSCRIBE
flush with MERGE
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  deleting a snapshot is allowed when the cluster is read only
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
-->  creating a snapshot is blocked when an index is blocked for reads
--> Inserting documents 20
--> Inserting documents 30
--> Inserting documents 40
--> Inserting documents 50
--> Inserting documents 60
--> Inserting documents 70
--> Inserting documents 80
--> Inserting documents 90
--> Inserting documents 100
--> Inserting documents 110
--> Inserting documents 120
--> Inserting documents 130
--> Inserting documents 140
refresh with source [api.json]
refresh with source [database]
refresh with source [archive.zip]
refresh with source [backup.sql]
refresh with source [logs.txt]
refresh with source [images]
refresh with source [config.ini]
refresh with source [templates]
refresh with source [scripts]
refresh with source [cache]
refresh with source [documents]
refresh with source [codebase]
refresh with source [messages]
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is not blocked when an index is read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
-->  creating a snapshot is allowed when the cluster is not read only
--> indexed 2000 docs, 1000 to keep
--> indexed 3000 docs, 1500 to keep
--> indexed 4000 docs, 2000 to keep
--> indexed 5000 docs, 2500 to keep
--> indexed 6000 docs, 3000 to keep
--> indexed 7000 docs, 3500 to keep
--> indexed 8000 docs, 4000 to keep
--> indexed 9000 docs, 4500 to keep
--> indexed 10000 docs, 5000 to keep
--> indexed 11000 docs, 5500 to keep
--> indexed 12000 docs, 6000 to keep
--> indexed 13000 docs, 6500 to keep
--> indexed 14000 docs, 7000 to keep
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
--> creating first snapshot
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
-->  creating a snapshot is allowed when the cluster is read only
delete [c562e9db-ee99-469a-8e3d-47eca58beba2] (seq no [2])
delete [ea7f9433-fb7c-4f05-8f1d-f848c74cbbb3] (seq no [3])
delete [d3a8d3d2-31dc-4e75-8251-862c5c9b304a] (seq no [4])
delete [c7389e3a-fee5-485f-b4f2-022e447ec108] (seq no [5])
delete [f8c2b8e6-5cc8-4cac-b838-8431efde2c1f] (seq no [6])
delete [ea57b1b2-a615-4920-8fc3-46277719b8f0] (seq no [7])
delete [70f23dbb-0202-4e2a-9a6d-02141a0421ce] (seq no [8])
delete [f5e7a13e-ef65-4aa0-afcd-6d2a15f7e4eb] (seq no [9])
delete [613805c5-e8ff-42df-9944-106965300b80] (seq no [10])
delete [2eeb5287-dc3f-4b97-a465-52a6efb9e5cc] (seq no [11])
delete [d132f8e3-66cb-4670-ab62-6afba879af6f] (seq no [12])
delete [5f8e8b5c-8ceb-461e-b8c6-7d7283c210f1] (seq no [13])
delete [94392ff6-8cba-40e4-bfe6-c90d7e8a7b70] (seq no [14])
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
--> creating index-0 and ingest data
Replication error: IndexOutOfBoundsException
Replication error: SQLException
Replication error: ArrayIndexOutOfBoundsException
Replication error: IllegalArgumentException
Replication error: ClassCastException
Replication error: NoSuchMethodException
Replication error: FileNotFoundException
Replication error: UnsupportedOperationException
Replication error: StackOverflowError
Replication error: NoSuchElementException
Replication error: ArithmeticException
Replication error: ConcurrentModificationException
Replication error: InputMismatchException
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
--> delete repository test-repo-2
noop (seq# [2])
noop (seq# [3])
noop (seq# [4])
noop (seq# [5])
noop (seq# [6])
noop (seq# [7])
noop (seq# [8])
noop (seq# [9])
noop (seq# [10])
noop (seq# [11])
noop (seq# [12])
noop (seq# [13])
noop (seq# [14])
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> delete repository test-repo-1
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
--> check that trying to create a repository with the same settings repeatedly does not update cluster state
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
-->  deleting a repository is allowed when the cluster is not read only
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
--> check that both repositories can be retrieved by getRepositories query
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
-->  deleting a repository is blocked when the cluster is read only
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
--> check that both repositories are in cluster state
Sending off 5 operations
Sending off 2 operations
Sending off 6 operations
Sending off 4 operations
Sending off 1 operations
Sending off 7 operations
Sending off 9 operations
Sending off 8 operations
Sending off 10 operations
Sending off 12 operations
Sending off 11 operations
Sending off 15 operations
Sending off 13 operations
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is allowed when the cluster is not read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
-->  registering a repository is blocked when the cluster is read only
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
--> check that repository is really there
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
check that it was written successfully
File document.docx was not deleted and is not pending delete, attempting delete again...
File image.jpg was not deleted and is not pending delete, attempting delete again...
File video.mp4 was not deleted and is not pending delete, attempting delete again...
File report.pdf was not deleted and is not pending delete, attempting delete again...
File presentation.pptx was not deleted and is not pending delete, attempting delete again...
File data.csv was not deleted and is not pending delete, attempting delete again...
File code.js was not deleted and is not pending delete, attempting delete again...
File style.css was not deleted and is not pending delete, attempting delete again...
File template.html was not deleted and is not pending delete, attempting delete again...
File audio.wav was not deleted and is not pending delete, attempting delete again...
File configuration.ini was not deleted and is not pending delete, attempting delete again...
File log.txt was not deleted and is not pending delete, attempting delete again...
File database.db was not deleted and is not pending delete, attempting delete again...
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
--> verify that we didn't leave any files as a result of verification
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
wait for the task to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
--> wait for snapshot to finish
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
verify that the task has started and is still running
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
shard was relocated successfully
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
--> unblock all data nodes
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
start a task that will store its results
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
shard relocation was cancelled
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
--> wait for data nodes to get blocked
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
unblock the write executor
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
timed out waiting for relocation hand-off to complete
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
unblocked the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
blocking the write executor
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
--> create two remote index shallow snapshots
block the write executor
block the write executor
block the write executor
block the write executor
block the write executor
block the write executor
block the write executor
block the write executor
block the write executor
block the write executor
block the write executor
block the write executor
block the write executor
block the write executor
block the write executor
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
delete index during snapshot creation
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> checking that test tasks are not running
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> create snapshot before index deletion during above snapshot deletion
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> cancelling the main test task
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
--> create snapshot to be deleted and then delete
error notifying global checkpoint listener of closed shard NullPointerException
error notifying global checkpoint listener of closed shard InvalidArgument
error notifying global checkpoint listener of closed shard AccessDenied
error notifying global checkpoint listener of closed shard OutOfMemoryError
error notifying global checkpoint listener of closed shard RuntimeError
error notifying global checkpoint listener of closed shard BadGatewayError
error notifying global checkpoint listener of closed shard ServiceUnavailable
error notifying global checkpoint listener of closed shard DatabaseConnectionError
error notifying global checkpoint listener of closed shard PermissionDenied
error notifying global checkpoint listener of closed shard NetworkError
error notifying global checkpoint listener of closed shard SchemaValidationError
error notifying global checkpoint listener of closed shard IndexOutOfRange
error notifying global checkpoint listener of closed shard AssertionError
error notifying global checkpoint listener of closed shard DivisionByZero
-->  close index products_index
-->  close index orders_index
-->  close index reviews_index
-->  close index categories_index
-->  close index customers_index
-->  close index suppliers_index
-->  close index employees_index
-->  close index inventory_index
-->  close index transactions_index
-->  close index shipments_index
-->  close index warehouse_index
-->  close index payment_index
-->  close index taxes_index
--> indexing 250 extra docs into product_index
--> indexing 50 extra docs into order_index
--> indexing 500 extra docs into review_index
--> indexing 300 extra docs into blog_index
--> indexing 150 extra docs into user_index
--> indexing 400 extra docs into category_index
--> indexing 200 extra docs into post_index
--> indexing 50 extra docs into job_index
--> indexing 350 extra docs into notification_index
--> indexing 100 extra docs into message_index
--> indexing 150 extra docs into event_index
--> indexing 200 extra docs into activity_index
--> indexing 300 extra docs into log_index
--> will run [5] threads, maxOps [50], unfinished seq no [2]
--> will run [3] threads, maxOps [30], unfinished seq no [1]
--> will run [8] threads, maxOps [80], unfinished seq no [3]
--> will run [7] threads, maxOps [70], unfinished seq no [2]
--> will run [2] threads, maxOps [20], unfinished seq no [2]
--> will run [6] threads, maxOps [60], unfinished seq no [1]
--> will run [4] threads, maxOps [40], unfinished seq no [3]
--> will run [9] threads, maxOps [90], unfinished seq no [1]
--> will run [1] threads, maxOps [10], unfinished seq no [2]
--> will run [5] threads, maxOps [50], unfinished seq no [4]
--> will run [3] threads, maxOps [30], unfinished seq no [3]
--> will run [7] threads, maxOps [70], unfinished seq no [1]
--> will run [2] threads, maxOps [20], unfinished seq no [3]
--> recovery continues from stage [3]
--> recovery continues from stage [5]
--> recovery continues from stage [7]
--> recovery continues from stage [9]
--> recovery continues from stage [11]
--> recovery continues from stage [13]
--> recovery continues from stage [15]
--> recovery continues from stage [17]
--> recovery continues from stage [19]
--> recovery continues from stage [21]
--> recovery continues from stage [23]
--> recovery continues from stage [25]
--> recovery continues from stage [27]
Scheduled retry with didRefresh=false
Scheduled retry with didRefresh=false
Scheduled retry with didRefresh=true
Scheduled retry with didRefresh=true
Scheduled retry with didRefresh=false
Scheduled retry with didRefresh=true
Scheduled retry with didRefresh=false
Scheduled retry with didRefresh=false
Scheduled retry with didRefresh=true
Scheduled retry with didRefresh=true
Scheduled retry with didRefresh=true
Scheduled retry with didRefresh=false
Scheduled retry with didRefresh=true
--> blocking recovery on stage [2]
--> blocking recovery on stage [3]
--> blocking recovery on stage [4]
--> blocking recovery on stage [5]
--> blocking recovery on stage [6]
--> blocking recovery on stage [7]
--> blocking recovery on stage [8]
--> blocking recovery on stage [9]
--> blocking recovery on stage [10]
--> blocking recovery on stage [11]
--> blocking recovery on stage [12]
--> blocking recovery on stage [13]
--> blocking recovery on stage [14]
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  restarting second data node, which should cause the primary shard on it to be failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
-->  wait for shard snapshot of first primary to show as failed
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
createMissingPeerRecoveryRetentionLeases: nothing to do
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
-->  restarting first data node, which should cause the primary shard on it to be failed
indexed [50] docs
indexed [100] docs
indexed [200] docs
indexed [500] docs
indexed [1000] docs
indexed [2000] docs
indexed [5000] docs
indexed [10000] docs
indexed [20000] docs
indexed [50000] docs
indexed [100000] docs
indexed [200000] docs
indexed [500000] docs
main events 20
main events 30
main events 40
main events 50
main events 60
main events 70
main events 80
main events 90
main events 100
main events 110
main events 120
main events 130
main events 140
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  wait for shard snapshots to show as failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  restarting data node, which should cause primary shards to be failed
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
-->  starting a cluster-manager node and two data nodes
updated local checkpoint of [08120394] from [150] to [300]
updated local checkpoint of [04301928] from [200] to [400]
updated local checkpoint of [05281234] from [250] to [500]
updated local checkpoint of [09231756] from [300] to [600]
updated local checkpoint of [06250698] from [350] to [700]
updated local checkpoint of [01230495] from [400] to [800]
updated local checkpoint of [07230981] from [450] to [900]
updated local checkpoint of [08311276] from [500] to [1000]
updated local checkpoint of [03251538] from [550] to [1100]
updated local checkpoint of [04301746] from [600] to [1200]
updated local checkpoint of [07190928] from [650] to [1300]
updated local checkpoint of [09061027] from [700] to [1400]
updated local checkpoint of [05190510] from [750] to [1500]
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> restart random data node and add new data node to change index allocation
--> creating a degraded index with 1 primary, 1 replicas
--> creating a failed index with 0 primary, 3 replicas
--> creating a stable index with 2 primary, 1 replicas
--> creating a active index with 3 primary, 3 replicas
--> creating a inactive index with 0 primary, 0 replicas
--> creating a responsive index with 1 primary, 2 replicas
--> creating a unresponsive index with 2 primary, 0 replicas
--> creating a optimized index with 3 primary, 1 replicas
--> creating a uninitialized index with 0 primary, 2 replicas
--> creating a available index with 2 primary, 3 replicas
--> creating a completed index with 1 primary, 0 replicas
--> creating a pending index with 3 primary, 3 replicas
--> creating a configured index with 2 primary, 1 replicas
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
-->  creating date math snapshot
--> indexing 25 extra docs to be trimmed
--> indexing 50 extra docs to be trimmed
--> indexing 100 extra docs to be trimmed
--> indexing 200 extra docs to be trimmed
--> indexing 500 extra docs to be trimmed
--> indexing 1000 extra docs to be trimmed
--> indexing 2000 extra docs to be trimmed
--> indexing 5000 extra docs to be trimmed
--> indexing 10000 extra docs to be trimmed
--> indexing 20000 extra docs to be trimmed
--> indexing 50000 extra docs to be trimmed
--> indexing 100000 extra docs to be trimmed
--> indexing 200000 extra docs to be trimmed
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restore the shrunk index and ensure all shards are allocated
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> restart the node with the stale replica
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> start a new data node
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> stop the node with the primary
--> indexing 50 extra docs
--> indexing 200 extra docs
--> indexing 75 extra docs
--> indexing 150 extra docs
--> indexing 300 extra docs
--> indexing 125 extra docs
--> indexing 250 extra docs
--> indexing 400 extra docs
--> indexing 175 extra docs
--> indexing 350 extra docs
--> indexing 450 extra docs
--> indexing 225 extra docs
--> indexing 500 extra docs
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> delete index and stop the data node
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
--> index more data, now the replica is stale
marked [58390] as in-sync
marked [75643] as in-sync
marked [23480] as in-sync
marked [87951] as in-sync
marked [16732] as in-sync
marked [42857] as in-sync
marked [76239] as in-sync
marked [31529] as in-sync
marked [64892] as in-sync
marked [82178] as in-sync
marked [50939] as in-sync
marked [09341] as in-sync
marked [68905] as in-sync
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> snapshot the shrunk index
--> indexing 5000 stale docs
--> indexing 200 stale docs
--> indexing 8000 stale docs
--> indexing 300 stale docs
--> indexing 6000 stale docs
--> indexing 1500 stale docs
--> indexing 4000 stale docs
--> indexing 900 stale docs
--> indexing 7000 stale docs
--> indexing 2500 stale docs
--> indexing 100 stale docs
--> indexing 4500 stale docs
--> indexing 1200 stale docs
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> close the index, now the replica is stale
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
--> stop node with the replica shard
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
-->  starting a cluster-manager node and a data node
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> starting another node, with filtering not allowing allocation to the new node, it should not get any shards
--> indexing 2000 rollback docs
--> indexing 3000 rollback docs
--> indexing 4000 rollback docs
--> indexing 5000 rollback docs
--> indexing 6000 rollback docs
--> indexing 7000 rollback docs
--> indexing 8000 rollback docs
--> indexing 9000 rollback docs
--> indexing 10000 rollback docs
--> indexing 11000 rollback docs
--> indexing 12000 rollback docs
--> indexing 13000 rollback docs
--> indexing 14000 rollback docs
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> verify that snapshot was partial
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> setting up allocation filtering to only allow allocation to the current node
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> Recover replica3 from replica2
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> starting another node, with the rebalance threshold so high, it should not get any shards
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> Promote replica2 as the primary
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> setting balancing threshold really high, so it won't be met
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> Promote replica1 as the primary
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> starting another node, with rebalancing disabled, it should get no shards
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
--> disabling rebalancing on the index
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
-->  starting three cluster-manager nodes and two data nodes
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> starting a single node
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> verify that snapshot was successful
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> setting up allocation filtering to prevent allocation to both nodes
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> wait until the snapshot is done
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> creating an index with 1 primary, 0 replicas, with allocation filtering so the primary can't be assigned
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> stopping cluster-manager node
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
--> restarting the stopped nodes
number of shards: 8
number of shards: 12
number of shards: 15
number of shards: 20
number of shards: 25
number of shards: 30
number of shards: 35
number of shards: 40
number of shards: 45
number of shards: 50
number of shards: 55
number of shards: 60
number of shards: 65
Rethrottled [2] times
Rethrottled [3] times
Rethrottled [4] times
Rethrottled [5] times
Rethrottled [6] times
Rethrottled [7] times
Rethrottled [8] times
Rethrottled [9] times
Rethrottled [10] times
Rethrottled [11] times
Rethrottled [12] times
Rethrottled [13] times
Rethrottled [14] times
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
--> setting allocation filtering to only allow allocation on the currently running node
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
-->  starting two cluster-manager nodes and two data nodes
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> shutting down all nodes except the one that holds the primary
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> make sure that properly setup repository can be registered on all nodes
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
--> stopping the node with the replica
Reading [image.jpg]
Reading [data.json]
Reading [config.xml]
Reading [log.txt]
Reading [README.md]
Reading [index.html]
Reading [script.js]
Reading [style.css]
Reading [user.txt]
Reading [output.pdf]
Reading [database.sql]
Reading [input.txt]
Reading [settings.properties]
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
--> stopping the node with the primary
exception caught: ArrayIndexOutOfBoundsException
exception caught: FileNotFoundException
exception caught: IllegalArgumentException
exception caught: RuntimeException
exception caught: IndexOutOfBoundsException
exception caught: NoSuchElementException
exception caught: ClassCastException
exception caught: IOException
exception caught: ArithmeticException
exception caught: UnsupportedOperationException
exception caught: SecurityException
exception caught: NullPointerException
exception caught: ArrayIndexOutOfBoundsException
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
--> shutdown one of the nodes that should make half of the shards unavailable
try with update
try with delete
try with select
try with create
try with drop
try with join
try with merge
try with truncate
try with alter
try with commit
try with rollback
try with grant
try with revoke
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> force merging down to a single segment to get a deterministic set of files
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the closed index that was snapshotted completely
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
--> restore snapshot for the index that didn't have any shards snapshotted successfully
exception on open RuntimeException
exception on open IOException
exception on open NullPointerException
exception on open ArrayIndexOutOfBoundsException
exception on open IllegalArgumentException
exception on open NumberFormatException
exception on open IndexOutOfBoundsException
exception on open SecurityException
exception on open IllegalStateException
exception on open ClassCastException
exception on open ArithmeticException
exception on open NoSuchElementException
exception on open StringIndexOutOfBoundsException
The plugin blocked on 2 out of 5 shards
The plugin blocked on 3 out of 5 shards
The plugin blocked on 4 out of 5 shards
The plugin blocked on 5 out of 5 shards
The plugin blocked on 6 out of 5 shards
The plugin blocked on 7 out of 5 shards
The plugin blocked on 8 out of 5 shards
The plugin blocked on 9 out of 5 shards
The plugin blocked on 10 out of 5 shards
The plugin blocked on 11 out of 5 shards
The plugin blocked on 12 out of 5 shards
The plugin blocked on 13 out of 5 shards
The plugin blocked on 14 out of 5 shards
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> restore snapshot for the partial index
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> setting shard routing weights for weighted round robin
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> restore snapshot for the index that was snapshotted completely
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> start 3 data nodes on zones 'a' & 'b' & 'c'
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
--> restore incomplete snapshot - should fail
searching for [banana]
searching for [orange]
searching for [grape]
searching for [melon]
searching for [kiwi]
searching for [strawberry]
searching for [pineapple]
searching for [peach]
searching for [pear]
searching for [plum]
searching for [mango]
searching for [cherry]
searching for [blueberry]
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
--> start 3 cluster manager nodes on zones 'a' & 'b' & 'c'
current snapshot status [IN PROGRESS]
current snapshot status [FAILED]
current snapshot status [CANCELLED]
current snapshot status [UNKNOWN]
current snapshot status [COMPLETED]
current snapshot status [PENDING]
current snapshot status [PAUSED]
current snapshot status [RESUMED]
current snapshot status [EXPIRED]
current snapshot status [CREATED]
current snapshot status [DELETED]
current snapshot status [ARCHIVED]
current snapshot status [RESTORED]
total [20] reused [10]
total [15] reused [7]
total [8] reused [3]
total [12] reused [6]
total [25] reused [12]
total [18] reused [9]
total [30] reused [15]
total [22] reused [11]
total [17] reused [8]
total [14] reused [7]
total [27] reused [13]
total [16] reused [8]
total [23] reused [11]
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using status
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
checking snapshot completion using wait_for_completion flag
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> Delete previously added doc and verify doc count
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> start snapshot with default settings without a closed index - should fail
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
--> Index one doc (to be deleted next) and verify doc count
Failed to send remote shard failure ArrayIndexOutOfBoundsException
Failed to send remote shard failure ClassCastException
Failed to send remote shard failure IllegalArgumentException
Failed to send remote shard failure ArithmeticException
Failed to send remote shard failure FileNotFoundException
Failed to send remote shard failure NullPointerException
Failed to send remote shard failure ArrayIndexOutOfBoundsException
Failed to send remote shard failure ClassCastException
Failed to send remote shard failure IllegalArgumentException
Failed to send remote shard failure ArithmeticException
Failed to send remote shard failure FileNotFoundException
Failed to send remote shard failure NullPointerException
Failed to send remote shard failure ArrayIndexOutOfBoundsException
Failed to send remote shard failure ClassCastException
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will have no allocated shards
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
--> create an index that will be closed
Successfully failed remote shardId [207] allocation id [b86ef99]
Successfully failed remote shardId [315] allocation id [f3471cd]
Successfully failed remote shardId [412] allocation id [e0db4a0]
Successfully failed remote shardId [527] allocation id [d80f9bc]
Successfully failed remote shardId [638] allocation id [c6785ad]
Successfully failed remote shardId [710] allocation id [b4c2fae]
Successfully failed remote shardId [819] allocation id [a9e1d02]
Successfully failed remote shardId [921] allocation id [fa6d7e7]
Successfully failed remote shardId [1012] allocation id [eae04b4]
Successfully failed remote shardId [1125] allocation id [de1af6f]
Successfully failed remote shardId [1239] allocation id [c0e7f32]
Successfully failed remote shardId [1345] allocation id [bb5b8e3]
Successfully failed remote shardId [1447] allocation id [bd4ecb2]
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> create an index that will have all allocated shards
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> shutdown one of the nodes
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> create an index that will have some unallocated shards
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> Go through a loop of creating and deleting a snapshot to trigger repository cleanup
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
--> making sure that snapshot no longer exists
unexpected failure RuntimeException
unexpected failure NullPointerException
unexpected failure IOException
unexpected failure ArrayIndexOutOfBoundsException
unexpected failure IllegalArgumentException
unexpected failure OutOfMemoryError
unexpected failure StackOverflowError
unexpected failure IllegalStateException
unexpected failure NoSuchElementException
unexpected failure ClassCastException
unexpected failure ArithmeticException
unexpected failure IndexOutOfBoundsException
unexpected failure NumberFormatException
Number of failed shards [0]
Number of failed shards [2]
Number of failed shards [5]
Number of failed shards [1]
Number of failed shards [4]
Number of failed shards [6]
Number of failed shards [2]
Number of failed shards [1]
Number of failed shards [0]
Number of failed shards [3]
Number of failed shards [5]
Number of failed shards [4]
Number of failed shards [2]
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload time moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
upload bytes moving average is not ready
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> waiting for block to kick in
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
--> check that gateway-persistent custom metadata survived full cluster restart
onFoundPeersUpdated(17 peers)
onFoundPeersUpdated(29 peers)
onFoundPeersUpdated(15 peers)
onFoundPeersUpdated(21 peers)
onFoundPeersUpdated(28 peers)
onFoundPeersUpdated(19 peers)
onFoundPeersUpdated(24 peers)
onFoundPeersUpdated(30 peers)
onFoundPeersUpdated(16 peers)
onFoundPeersUpdated(27 peers)
onFoundPeersUpdated(20 peers)
onFoundPeersUpdated(18 peers)
onFoundPeersUpdated(26 peers)
Configuring remote cluster [10.0.0.2]
Configuring remote cluster [172.16.0.3]
Configuring remote cluster [192.168.1.4]
Configuring remote cluster [10.0.0.5]
Configuring remote cluster [172.16.1.6]
Configuring remote cluster [192.168.2.7]
Configuring remote cluster [10.0.0.8]
Configuring remote cluster [172.16.2.9]
Configuring remote cluster [192.168.3.10]
Configuring remote cluster [10.0.0.11]
Configuring remote cluster [172.16.3.12]
Configuring remote cluster [192.168.4.13]
Configuring remote cluster [10.0.0.14]
Cluster state: standby
Cluster state: error
Cluster state: initializing
Cluster state: paused
Cluster state: maintenance
Cluster state: degraded
Cluster state: syncing
Cluster state: updating
Cluster state: resizing
Cluster state: failed
Cluster state: idle
Cluster state: unavailable
Cluster state: recovering
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> check that custom persistent metadata was restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> make sure old repository wasn't restored
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
--> change custom persistent metadata
500 docs indexed at 5 docs/s required 500000 bytes of disk space, or 1000 bytes per document. Took: 10s.
2000 docs indexed at 15 docs/s required 1500000 bytes of disk space, or 750 bytes per document. Took: 8s.
800 docs indexed at 8 docs/s required 640000 bytes of disk space, or 800 bytes per document. Took: 4s.
1500 docs indexed at 12 docs/s required 1800000 bytes of disk space, or 1200 bytes per document. Took: 6s.
2500 docs indexed at 20 docs/s required 2500000 bytes of disk space, or 1000 bytes per document. Took: 12s.
3000 docs indexed at 25 docs/s required 3000000 bytes of disk space, or 1000 bytes per document. Took: 10s.
400 docs indexed at 4 docs/s required 160000 bytes of disk space, or 400 bytes per document. Took: 16s.
600 docs indexed at 6 docs/s required 360000 bytes of disk space, or 600 bytes per document. Took: 15s.
700 docs indexed at 7 docs/s required 490000 bytes of disk space, or 700 bytes per document. Took: 13s.
1800 docs indexed at 18 docs/s required 1620000 bytes of disk space, or 900 bytes per document. Took: 9s.
1200 docs indexed at 12 docs/s required 1200000 bytes of disk space, or 1000 bytes per document. Took: 7s.
900 docs indexed at 9 docs/s required 810000 bytes of disk space, or 900 bytes per document. Took: 14s.
2200 docs indexed at 22 docs/s required 2420000 bytes of disk space, or 1100 bytes per document. Took: 5s.
2700 docs indexed at 27 docs/s required 2700000 bytes of disk space, or 1000 bytes per document. Took: 9s.
Cleanup of output files failed: FileNotFoundException
Cleanup of output files failed: IOException
Cleanup of output files failed: ArrayIndexOutOfBoundsException
Cleanup of output files failed: ClassCastException
Cleanup of output files failed: IllegalArgumentException
Cleanup of output files failed: NoSuchMethodException
Cleanup of output files failed: InterruptedException
Cleanup of output files failed: StackOverflowError
Cleanup of output files failed: OutOfMemoryError
Cleanup of output files failed: ArithmeticException
Cleanup of output files failed: UnsupportedOperationException
Cleanup of output files failed: IndexOutOfBoundsException
Cleanup of output files failed: SecurityException
Cleanup of output files failed: NoSuchFieldException
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
--> add custom persistent metadata
Saturated at: 45
Saturated at: 55
Saturated at: 20
Saturated at: 10
Saturated at: 70
Saturated at: 50
Saturated at: 25
Saturated at: 60
Saturated at: 5
Saturated at: 15
Saturated at: 35
Saturated at: 65
Saturated at: 40
Running command with env: production
Running command with env: testing
Running command with env: staging
Running command with env: integration
Running command with env: demo
Running command with env: local
Running command with env: sandbox
Running command with env: preview
Running command with env: release
Running command with env: master
Running command with env: backup
Running command with env: live
Running command with env: debug
Package type: tar
Package type: deb
Package type: rpm
Package type: jar
Package type: war
Package type: exe
Package type: dmg
Package type: app
Package type: apk
Package type: msi
Package type: pkg
Package type: dmg
Package type: app
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> change the test persistent setting and break it
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> set test persistent setting
--> executing a task [2] times
--> executing a task [3] times
--> executing a task [4] times
--> executing a task [5] times
--> executing a task [6] times
--> executing a task [7] times
--> executing a task [8] times
--> executing a task [9] times
--> executing a task [10] times
--> executing a task [11] times
--> executing a task [12] times
--> executing a task [13] times
--> executing a task [14] times
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
--> try to create snapshot
Can't show contents NullReference
Can't show contents AccessDenied
Can't show contents FileNotFound
Can't show contents InvalidArgument
Can't show contents PermissionDenied
Can't show contents OutOfMemory
Can't show contents DivideByZero
Can't show contents StackOverflow
Can't show contents NetworkError
Can't show contents DatabaseError
Can't show contents TimeOut
Can't show contents SyntaxError
Can't show contents IllegalState
Can't show contents AssertionError
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> try to delete snapshot
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> restoring the first snapshot, the repository should not have lost any shard data despite deleting index-N, because it uses snap-*.data files and not the index-N to determine what files to restore
--> auto-queue with a measurement window of 8 tasks
--> auto-queue with a measurement window of 12 tasks
--> auto-queue with a measurement window of 3 tasks
--> auto-queue with a measurement window of 10 tasks
--> auto-queue with a measurement window of 6 tasks
--> auto-queue with a measurement window of 9 tasks
--> auto-queue with a measurement window of 7 tasks
--> auto-queue with a measurement window of 2 tasks
--> auto-queue with a measurement window of 4 tasks
--> auto-queue with a measurement window of 11 tasks
--> auto-queue with a measurement window of 15 tasks
--> auto-queue with a measurement window of 1 tasks
--> auto-queue with a measurement window of 14 tasks
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> deleting shard level index file
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
--> make sure that we can create the snapshot again
Freed [7] contexts
Freed [2] contexts
Freed [9] contexts
Freed [5] contexts
Freed [3] contexts
Freed [6] contexts
Freed [1] contexts
Freed [8] contexts
Freed [10] contexts
Freed [12] contexts
Freed [15] contexts
Freed [11] contexts
Freed [14] contexts
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
--> truncate snapshot file to make it unreadable
completing the future after sleeping 200ms
completing the future after sleeping 300ms
completing the future after sleeping 400ms
completing the future after sleeping 500ms
completing the future after sleeping 600ms
completing the future after sleeping 700ms
completing the future after sleeping 800ms
completing the future after sleeping 900ms
completing the future after sleeping 1000ms
completing the future after sleeping 1100ms
completing the future after sleeping 1200ms
completing the future after sleeping 1300ms
completing the future after sleeping 1400ms
Showing contents of directory: data/ (C:/data)
Showing contents of directory: images/ (C:/images)
Showing contents of directory: documents/ (C:/documents)
Showing contents of directory: files/ (C:/files)
Showing contents of directory: backups/ (C:/backups)
Showing contents of directory: reports/ (C:/reports)
Showing contents of directory: temp/ (C:/temp)
Showing contents of directory: archives/ (C:/archives)
Showing contents of directory: resources/ (C:/resources)
Showing contents of directory: scripts/ (C:/scripts)
Showing contents of directory: projects/ (C:/projects)
Showing contents of directory: downloads/ (C:/downloads)
Showing contents of directory: media/ (C:/media)
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
--> delete global state metadata
listener 2 added
listener 3 added
listener 4 added
listener 5 added
listener 6 added
listener 7 added
listener 8 added
listener 9 added
listener 10 added
listener 11 added
listener 12 added
listener 13 added
listener 14 added
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
--> delete index metadata and shard metadata
Can't show logs from directory /var/log/system as it doesn't exists
Can't show logs from directory /var/log/security as it doesn't exists
Can't show logs from directory /var/log/database as it doesn't exists
Can't show logs from directory /var/log/debug as it doesn't exists
Can't show logs from directory /var/log/error as it doesn't exists
Can't show logs from directory /var/log/access as it doesn't exists
Can't show logs from directory /var/log/audit as it doesn't exists
Can't show logs from directory /var/log/event as it doesn't exists
Can't show logs from directory /var/log/traffic as it doesn't exists
Can't show logs from directory /var/log/authentication as it doesn't exists
Can't show logs from directory /var/log/application1 as it doesn't exists
Can't show logs from directory /var/log/system1 as it doesn't exists
Can't show logs from directory /var/log/security1 as it doesn't exists
Remote store is not enabled for index: products
Remote store is not enabled for index: orders
Remote store is not enabled for index: categories
Remote store is not enabled for index: reviews
Remote store is not enabled for index: customers
Remote store is not enabled for index: employees
Remote store is not enabled for index: suppliers
Remote store is not enabled for index: inventory
Remote store is not enabled for index: transactions
Remote store is not enabled for index: locations
Remote store is not enabled for index: warehouses
Remote store is not enabled for index: assets
Remote store is not enabled for index: expenses
listener 2 received value orange
listener 3 received value banana
listener 4 received value strawberry
listener 5 received value watermelon
listener 6 received value mango
listener 7 received value pineapple
listener 8 received value grape
listener 9 received value lemon
listener 10 received value peach
listener 11 received value cherry
listener 12 received value kiwi
listener 13 received value pear
listener 14 received value plum
-->  indexing [500] more documents into [products]
-->  indexing [1000] more documents into [orders]
-->  indexing [200] more documents into [invoices]
-->  indexing [50] more documents into [customers]
-->  indexing [300] more documents into [reviews]
-->  indexing [150] more documents into [categories]
-->  indexing [250] more documents into [logs]
-->  indexing [400] more documents into [notifications]
-->  indexing [800] more documents into [messages]
-->  indexing [600] more documents into [contacts]
-->  indexing [350] more documents into [settings]
-->  indexing [750] more documents into [archives]
-->  indexing [900] more documents into [favorites]
Can't list log files FileNotFoundException
Can't list log files PermissionDeniedException
Can't list log files IOException
Can't list log files NoSuchFileException
Can't list log files AccessDeniedException
Can't list log files InvalidPathException
Can't list log files NullPointerException
Can't list log files FileNotFoundException
Can't list log files NoSuchElementException
Can't list log files IOException
Can't list log files PermissionDeniedException
Can't list log files OutOfMemoryError
Can't list log files IllegalArgumentException
failed to restore from remote store NullPointerException
failed to restore from remote store SocketTimeoutException
failed to restore from remote store FileNotFoundException
failed to restore from remote store AccessDeniedException
failed to restore from remote store InvalidCredentialsException
failed to restore from remote store ConnectionTimeoutException
failed to restore from remote store DatabaseException
failed to restore from remote store OutOfMemoryError
failed to restore from remote store ClassCastException
failed to restore from remote store IllegalArgumentException
failed to restore from remote store NoSuchElementException
failed to restore from remote store ConcurrentModificationException
failed to restore from remote store ArrayIndexOutOfBoundsException
Checking whether file /etc/config.ini exists in container
Checking whether file /home/user/data.txt exists in container
Checking whether file /usr/bin/app.exe exists in container
Checking whether file /opt/logs/error.log exists in container
Checking whether file /var/www/index.html exists in container
Checking whether file /tmp/output.txt exists in container
Checking whether file /root/script.sh exists in container
Checking whether file /var/log/system.log exists in container
Checking whether file /etc/hosts exists in container
Checking whether file /home/user/image.jpg exists in container
Checking whether file /usr/bin/config.xml exists in container
Checking whether file /opt/logs/app.log exists in container
Checking whether file /var/www/file.txt exists in container
using [tiered] merge mergePolicy with expunge_deletes_allowed[10%], floor_segment[3], max_merge_at_once[20], max_merged_segment[100], segments_per_tier[20.0], deletes_pct_allowed[30%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[15%], floor_segment[4], max_merge_at_once[30], max_merged_segment[150], segments_per_tier[30.0], deletes_pct_allowed[40%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[20%], floor_segment[5], max_merge_at_once[40], max_merged_segment[200], segments_per_tier[40.0], deletes_pct_allowed[50%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[25%], floor_segment[6], max_merge_at_once[50], max_merged_segment[250], segments_per_tier[50.0], deletes_pct_allowed[60%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[30%], floor_segment[7], max_merge_at_once[60], max_merged_segment[300], segments_per_tier[60.0], deletes_pct_allowed[70%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[35%], floor_segment[8], max_merge_at_once[70], max_merged_segment[350], segments_per_tier[70.0], deletes_pct_allowed[80%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[40%], floor_segment[9], max_merge_at_once[80], max_merged_segment[400], segments_per_tier[80.0], deletes_pct_allowed[90%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[45%], floor_segment[10], max_merge_at_once[90], max_merged_segment[450], segments_per_tier[90.0], deletes_pct_allowed[100%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[50%], floor_segment[11], max_merge_at_once[100], max_merged_segment[500], segments_per_tier[100.0], deletes_pct_allowed[110%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[55%], floor_segment[12], max_merge_at_once[110], max_merged_segment[550], segments_per_tier[110.0], deletes_pct_allowed[120%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[60%], floor_segment[13], max_merge_at_once[120], max_merged_segment[600], segments_per_tier[120.0], deletes_pct_allowed[130%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[65%], floor_segment[14], max_merge_at_once[130], max_merged_segment[650], segments_per_tier[130.0], deletes_pct_allowed[140%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[70%], floor_segment[15], max_merge_at_once[140], max_merged_segment[700], segments_per_tier[140.0], deletes_pct_allowed[150%]
using [tiered] merge mergePolicy with expunge_deletes_allowed[75%], floor_segment[16], max_merge_at_once[150], max_merged_segment[750], segments_per_tier[150.0], deletes_pct_allowed[160%]
-->  creating index [products] with [500] documents in it
-->  creating index [orders] with [250] documents in it
-->  creating index [messages] with [1000] documents in it
-->  creating index [invoices] with [200] documents in it
-->  creating index [customers] with [300] documents in it
-->  creating index [categories] with [150] documents in it
-->  creating index [reviews] with [800] documents in it
-->  creating index [employees] with [400] documents in it
-->  creating index [suppliers] with [200] documents in it
-->  creating index [transactions] with [600] documents in it
-->  creating index [logs] with [50] documents in it
-->  creating index [settings] with [20] documents in it
-->  creating index [notifications] with [80] documents in it
Caught exception while waiting for ES to exit TimeoutException
Caught exception while waiting for ES to exit IOException
Caught exception while waiting for ES to exit DatabaseException
Caught exception while waiting for ES to exit IllegalArgumentException
Caught exception while waiting for ES to exit NullPointerException
Caught exception while waiting for ES to exit OutOfMemoryException
Caught exception while waiting for ES to exit IndexOutOfBoundsException
Caught exception while waiting for ES to exit StackOverflowException
Caught exception while waiting for ES to exit NoSuchElementException
Caught exception while waiting for ES to exit ClassCastException
Caught exception while waiting for ES to exit ArithmeticException
Caught exception while waiting for ES to exit InvalidParameterException
Caught exception while waiting for ES to exit FileNotFoundException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data from newly mounted repository throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
--> verify loading repository data throws RepositoryException
Caught exception while waiting for ES to start ConnectionException
Caught exception while waiting for ES to start IllegalArgumentException
Caught exception while waiting for ES to start NullPointerException
Caught exception while waiting for ES to start IllegalStateException
Caught exception while waiting for ES to start FileNotFoundException
Caught exception while waiting for ES to start SocketTimeoutException
Caught exception while waiting for ES to start EOFException
Caught exception while waiting for ES to start ClassCastException
Caught exception while waiting for ES to start ArrayIndexOutOfBoundsException
Caught exception while waiting for ES to start NumberFormatException
Caught exception while waiting for ES to start NoSuchElementException
Caught exception while waiting for ES to start AssertionError
Caught exception while waiting for ES to start UnsupportedOperationException
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> set next generation as pending in the cluster state
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> verify index-N blob is found at the expected location
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
--> wait for all listeners on snapshots service to be resolved to avoid snapshot task batching causing a conflict
Installing file: package.zip
Installing file: driver.msi
Installing file: readme.txt
Installing file: script.sh
Installing file: plugin.jar
Installing file: config.ini
Installing file: library.dll
Installing file: patch.patch
Installing file: data.csv
Installing file: style.css
Installing file: image.png
Installing file: font.ttf
Installing file: document.docx
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> verify index-N blob is found at the new location
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> make sure snapshot doesn't exist
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
--> verify repository remains blocked
warmed global ordinals for [numericField], took [2454ms]
warmed global ordinals for [dateField], took [864ms]
warmed global ordinals for [booleanField], took [1955ms]
warmed global ordinals for [objectField], took [3010ms]
warmed global ordinals for [arrayField], took [3857ms]
warmed global ordinals for [geoField], took [1468ms]
warmed global ordinals for [nestedField], took [2772ms]
warmed global ordinals for [byteField], took [925ms]
warmed global ordinals for [shortField], took [1811ms]
warmed global ordinals for [intField], took [2365ms]
warmed global ordinals for [longField], took [2987ms]
warmed global ordinals for [floatField], took [1782ms]
warmed global ordinals for [doubleField], took [2246ms]
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob back to initial generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
--> move index-N blob to next generation
top warming took [20]
top warming took [30]
top warming took [40]
top warming took [50]
top warming took [60]
top warming took [70]
top warming took [80]
top warming took [90]
top warming took [100]
top warming took [110]
top warming took [120]
top warming took [130]
top warming took [140]
script: bar.sh stdout: Command executed successfully. stderr: None
script: baz.py stdout: Process finished with exit code 0. stderr: None
script: script.sh stdout: Output generated. stderr: None
script: test.py stdout: File not found. stderr: None
script: program.c stdout: Compilation error. stderr: None
script: script.py stdout: Error: Invalid syntax. stderr: None
script: main.java stdout: Build success. stderr: None
script: script.sh stdout: Permission denied. stderr: None
script: foo.py stdout: SyntaxError: invalid syntax. stderr: None
script: script.py stdout: Import error. stderr: None
script: script.sh stdout: Error: File not found. stderr: None
script: bar.sh stdout: Command not found. stderr: None
script: script.py stdout: NameError: name 'x' is not defined. stderr: None
top warming has been interrupted RuntimeException
top warming has been interrupted NullPointerException
top warming has been interrupted ArrayIndexOutOfBoundsException
top warming has been interrupted IllegalArgumentException
top warming has been interrupted ClassCastException
top warming has been interrupted OutOfMemoryError
top warming has been interrupted StackOverflowError
top warming has been interrupted SQLException
top warming has been interrupted IOException
top warming has been interrupted NoSuchElementException
top warming has been interrupted ArithmeticException
top warming has been interrupted TimeoutException
top warming has been interrupted InterruptedException
--> wait for [2] deletions to show up in the cluster state
--> wait for [9] deletions to show up in the cluster state
--> wait for [7] deletions to show up in the cluster state
--> wait for [1] deletions to show up in the cluster state
--> wait for [8] deletions to show up in the cluster state
--> wait for [3] deletions to show up in the cluster state
--> wait for [6] deletions to show up in the cluster state
--> wait for [4] deletions to show up in the cluster state
--> wait for [10] deletions to show up in the cluster state
--> wait for [15] deletions to show up in the cluster state
--> wait for [12] deletions to show up in the cluster state
--> wait for [14] deletions to show up in the cluster state
--> wait for [11] deletions to show up in the cluster state
Error while trying to sleep ArithmeticException
Error while trying to sleep ArrayIndexOutOfBoundsException
Error while trying to sleep IllegalArgumentException
Error while trying to sleep NoSuchElementException
Error while trying to sleep NumberFormatException
Error while trying to sleep FileNotFoundException
Error while trying to sleep ClassCastException
Error while trying to sleep RuntimeException
Error while trying to sleep IndexOutOfBoundsException
Error while trying to sleep ConcurrentModificationException
Error while trying to sleep AssertionError
Error while trying to sleep StackOverflowError
Error while trying to sleep OutOfMemoryError
Using /usr/lib/jvm/java-11-openjdk
Using /opt/java/jdk-8
Using /usr/local/jdk1.8.0_181
Using /usr/java/jdk-11
Using /usr/lib/jvm/java-1.8.0-openjdk
Using /usr/java/jdk1.7.0_181
Using /usr/lib/jvm/java-11
Using /Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home
Using /usr/java/jdk1.8.0_202
Using /usr/lib/jvm/java-8-openjdk
Using /usr/java/jdk1.8.0_231
Using /Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home
Using /usr/java/jdk1.8.0_112
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> wait for snapshot to complete
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> start two snapshots
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> wait for relocations to start
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> make sure all failing requests get a response
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> verify that all snapshots are gone and no more work is left in the cluster state
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> stopping current cluster-manager node
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> waiting for second snapshot to finish and the other two snapshots to become aborted
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
--> wait for delete to be enqueued in cluster state
indexing [50] docs after setting number of replicas to 0
indexing [100] docs after setting number of replicas to 0
indexing [200] docs after setting number of replicas to 0
indexing [500] docs after setting number of replicas to 0
indexing [1000] docs after setting number of replicas to 0
indexing [2000] docs after setting number of replicas to 0
indexing [5000] docs after setting number of replicas to 0
indexing [10000] docs after setting number of replicas to 0
indexing [20000] docs after setting number of replicas to 0
indexing [50000] docs after setting number of replicas to 0
indexing [100000] docs after setting number of replicas to 0
indexing [200000] docs after setting number of replicas to 0
indexing [500000] docs after setting number of replicas to 0
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify that all snapshots are gone
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
--> verify both deletes have completed
indexing [1000] docs after moving primary
indexing [1500] docs after moving primary
indexing [2000] docs after moving primary
indexing [2500] docs after moving primary
indexing [3000] docs after moving primary
indexing [3500] docs after moving primary
indexing [4000] docs after moving primary
indexing [4500] docs after moving primary
indexing [5000] docs after moving primary
indexing [5500] docs after moving primary
indexing [6000] docs after moving primary
indexing [6500] docs after moving primary
indexing [7000] docs after moving primary
indexing [7500] docs after moving primary
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> verify all snapshots were aborted
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
--> waiting for second and third snapshot to finish
indexing [50] docs after allowing shards on all nodes
indexing [100] docs after allowing shards on all nodes
indexing [200] docs after allowing shards on all nodes
indexing [500] docs after allowing shards on all nodes
indexing [1000] docs after allowing shards on all nodes
indexing [2000] docs after allowing shards on all nodes
indexing [5000] docs after allowing shards on all nodes
indexing [10000] docs after allowing shards on all nodes
indexing [20000] docs after allowing shards on all nodes
indexing [50000] docs after allowing shards on all nodes
indexing [100000] docs after allowing shards on all nodes
indexing [200000] docs after allowing shards on all nodes
indexing [500000] docs after allowing shards on all nodes
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> waiting for all three snapshots to show up as in-progress
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
--> verify that the first snapshot is gone
indexing [500] docs initially
indexing [200] docs initially
indexing [1500] docs initially
indexing [800] docs initially
indexing [300] docs initially
indexing [700] docs initially
indexing [1200] docs initially
indexing [400] docs initially
indexing [900] docs initially
indexing [600] docs initially
indexing [1100] docs initially
indexing [100] docs initially
indexing [1400] docs initially
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
Search idle is not supported for indices with replicas using 'replication.type: SEGMENT'
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
--> wait for snapshot on second data node to finish
indexing doc with [5] concurrent updates after setting number of replicas to 1
indexing doc with [8] concurrent updates after setting number of replicas to 1
indexing doc with [3] concurrent updates after setting number of replicas to 1
indexing doc with [9] concurrent updates after setting number of replicas to 1
indexing doc with [1] concurrent updates after setting number of replicas to 1
indexing doc with [7] concurrent updates after setting number of replicas to 1
indexing doc with [6] concurrent updates after setting number of replicas to 1
indexing doc with [4] concurrent updates after setting number of replicas to 1
indexing doc with [12] concurrent updates after setting number of replicas to 1
indexing doc with [10] concurrent updates after setting number of replicas to 1
indexing doc with [15] concurrent updates after setting number of replicas to 1
indexing doc with [11] concurrent updates after setting number of replicas to 1
indexing doc with [14] concurrent updates after setting number of replicas to 1
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
--> waiting for concurrent snapshot(s) to finish
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
setting number of replicas to 1
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> waiting for batched deletes to finish
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
--> wait for clone to start fully with shards assigned in the cluster state
indexing doc with [10] concurrent updates after setting number of replicas to 0
indexing doc with [15] concurrent updates after setting number of replicas to 0
indexing doc with [20] concurrent updates after setting number of replicas to 0
indexing doc with [25] concurrent updates after setting number of replicas to 0
indexing doc with [30] concurrent updates after setting number of replicas to 0
indexing doc with [35] concurrent updates after setting number of replicas to 0
indexing doc with [40] concurrent updates after setting number of replicas to 0
indexing doc with [45] concurrent updates after setting number of replicas to 0
indexing doc with [50] concurrent updates after setting number of replicas to 0
indexing doc with [55] concurrent updates after setting number of replicas to 0
indexing doc with [60] concurrent updates after setting number of replicas to 0
indexing doc with [65] concurrent updates after setting number of replicas to 0
indexing doc with [70] concurrent updates after setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
setting number of replicas to 0
Lock files count: 5
Lock files count: 7
Lock files count: 3
Lock files count: 12
Lock files count: 8
Lock files count: 6
Lock files count: 2
Lock files count: 9
Lock files count: 4
Lock files count: 11
Lock files count: 13
Lock files count: 15
Lock files count: 1
indexing docs with [8] concurrent updates after moving primary
indexing docs with [2] concurrent updates after moving primary
indexing docs with [5] concurrent updates after moving primary
indexing docs with [6] concurrent updates after moving primary
indexing docs with [1] concurrent updates after moving primary
indexing docs with [4] concurrent updates after moving primary
indexing docs with [9] concurrent updates after moving primary
indexing docs with [7] concurrent updates after moving primary
indexing docs with [10] concurrent updates after moving primary
indexing docs with [11] concurrent updates after moving primary
indexing docs with [15] concurrent updates after moving primary
indexing docs with [12] concurrent updates after moving primary
indexing docs with [14] concurrent updates after moving primary
indexing docs with [20] concurrent updates after allowing shards on all nodes
indexing docs with [30] concurrent updates after allowing shards on all nodes
indexing docs with [40] concurrent updates after allowing shards on all nodes
indexing docs with [50] concurrent updates after allowing shards on all nodes
indexing docs with [60] concurrent updates after allowing shards on all nodes
indexing docs with [70] concurrent updates after allowing shards on all nodes
indexing docs with [80] concurrent updates after allowing shards on all nodes
indexing docs with [90] concurrent updates after allowing shards on all nodes
indexing docs with [100] concurrent updates after allowing shards on all nodes
indexing docs with [110] concurrent updates after allowing shards on all nodes
indexing docs with [120] concurrent updates after allowing shards on all nodes
indexing docs with [130] concurrent updates after allowing shards on all nodes
indexing docs with [140] concurrent updates after allowing shards on all nodes
--> deleting index [products]
--> deleting index [orders]
--> deleting index [invoices]
--> deleting index [logs]
--> deleting index [categories]
--> deleting index [messages]
--> deleting index [notifications]
--> deleting index [reviews]
--> deleting index [settings]
--> deleting index [profiles]
--> deleting index [tags]
--> deleting index [followers]
--> deleting index [likes]
primary resolved to: attribute
primary resolved to: textNode
primary resolved to: commentNode
primary resolved to: processingInstructionNode
primary resolved to: documentNode
primary resolved to: documentTypeNode
primary resolved to: documentFragmentNode
primary resolved to: entityReferenceNode
primary resolved to: entityNode
primary resolved to: notationNode
primary resolved to: cdataSectionNode
primary resolved to: element
primary resolved to: attribute
primary resolved to: textNode
--> asserting that index [orders] contains [50] documents
--> asserting that index [products] contains [200] documents
--> asserting that index [customers] contains [150] documents
--> asserting that index [inventory] contains [75] documents
--> asserting that index [categories] contains [30] documents
--> asserting that index [reviews] contains [80] documents
--> asserting that index [transactions] contains [90] documents
--> asserting that index [logs] contains [40] documents
--> asserting that index [comments] contains [120] documents
--> asserting that index [invoices] contains [60] documents
--> asserting that index [cart] contains [20] documents
--> asserting that index [messages] contains [70] documents
--> asserting that index [notifications] contains [110] documents
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
allowing shards on all nodes
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> asserting that the two snapshots refer to different files in the repository
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
--> force merging down to a single segment
indexing docs with [5] concurrent updates initially
indexing docs with [15] concurrent updates initially
indexing docs with [2] concurrent updates initially
indexing docs with [8] concurrent updates initially
indexing docs with [12] concurrent updates initially
indexing docs with [6] concurrent updates initially
indexing docs with [20] concurrent updates initially
indexing docs with [4] concurrent updates initially
indexing docs with [18] concurrent updates initially
indexing docs with [7] concurrent updates initially
indexing docs with [13] concurrent updates initially
indexing docs with [9] concurrent updates initially
indexing docs with [3] concurrent updates initially
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
--> adding some documents to test index and flush in between to get at least two segments
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
allowing replica shards assignment on bwc nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
Remove allocation include settings so that shards can be allocated on current version nodes
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> delete some documents from test index
--> Skip test for version 8.2.3 where segment replication feature is not available
--> Skip test for version 10.1.5 where segment replication feature is not available
--> Skip test for version 8.0.9 where segment replication feature is not available
--> Skip test for version 11.2.6 where segment replication feature is not available
--> Skip test for version 9.1.2 where segment replication feature is not available
--> Skip test for version 7.3.4 where segment replication feature is not available
--> Skip test for version 10.0.7 where segment replication feature is not available
--> Skip test for version 11.0.3 where segment replication feature is not available
--> Skip test for version 8.1.0 where segment replication feature is not available
--> Skip test for version 9.2.4 where segment replication feature is not available
--> Skip test for version 10.2.1 where segment replication feature is not available
--> Skip test for version 7.4.6 where segment replication feature is not available
--> Skip test for version 11.1.8 where segment replication feature is not available
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> adding some documents to test index
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> waiting for snapshot thread pool to be empty
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
--> restore should have failed
cluster discovered: cluster-manager id='cm-5678'
cluster discovered: cluster-manager id='cm-9101'
cluster discovered: cluster-manager id='cm-1121'
cluster discovered: cluster-manager id='cm-3141'
cluster discovered: cluster-manager id='cm-5161'
cluster discovered: cluster-manager id='cm-7181'
cluster discovered: cluster-manager id='cm-9202'
cluster discovered: cluster-manager id='cm-1222'
cluster discovered: cluster-manager id='cm-3242'
cluster discovered: cluster-manager id='cm-5262'
cluster discovered: cluster-manager id='cm-7282'
cluster discovered: cluster-manager id='cm-9303'
cluster discovered: cluster-manager id='cm-1343'
node: 10.0.0.1
node: 172.16.0.1
node: 192.168.1.1
node: 10.0.0.2
node: 172.16.0.2
node: 192.168.0.2
node: 10.0.0.3
node: 172.16.0.3
node: 192.168.1.2
node: 10.0.0.4
node: 172.16.0.4
node: 192.168.0.3
node: 10.0.0.5
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
--> aborting restore by deleting the index
cluster nodes: inactive
cluster nodes: pending
cluster nodes: standby
cluster nodes: error
cluster nodes: ready
cluster nodes: halted
cluster nodes: initializing
cluster nodes: running
cluster nodes: stopped
cluster nodes: paused
cluster nodes: restarting
cluster nodes: upgrading
cluster nodes: maintenance
--> waiting for snapshot thread [max=20] pool to be full
--> waiting for snapshot thread [max=30] pool to be full
--> waiting for snapshot thread [max=40] pool to be full
--> waiting for snapshot thread [max=50] pool to be full
--> waiting for snapshot thread [max=60] pool to be full
--> waiting for snapshot thread [max=70] pool to be full
--> waiting for snapshot thread [max=80] pool to be full
--> waiting for snapshot thread [max=90] pool to be full
--> waiting for snapshot thread [max=100] pool to be full
--> waiting for snapshot thread [max=110] pool to be full
--> waiting for snapshot thread [max=120] pool to be full
--> waiting for snapshot thread [max=130] pool to be full
--> waiting for snapshot thread [max=140] pool to be full
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a prefix
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
This is an info message with a shardId
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with four indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with three indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
--> run suggestions with two indices
health api response: 404 Not Found
health api response: 500 Internal Server Error
health api response: 403 Forbidden
health api response: 302 Found
health api response: 401 Unauthorized
health api response: 503 Service Unavailable
health api response: 400 Bad Request
health api response: 204 No Content
health api response: 201 Created
health api response: 301 Moved Permanently
health api response: 409 Conflict
health api response: 502 Bad Gateway
health api response: 412 Precondition Failed
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
--> run suggestions with one index
###### indices search stats: 500
###### indices search stats: 1500
###### indices search stats: 800
###### indices search stats: 1200
###### indices search stats: 300
###### indices search stats: 2000
###### indices search stats: 900
###### indices search stats: 600
###### indices search stats: 1800
###### indices search stats: 700
###### indices search stats: 1100
###### indices search stats: 400
###### indices search stats: 1400
###### indices search stats: 100
Flushing [2]
Flushing [3]
Flushing [4]
Flushing [5]
Flushing [6]
Flushing [7]
Flushing [8]
Flushing [9]
Flushing [10]
Flushing [11]
Flushing [12]
Flushing [13]
Flushing [14]
-> Unable to find shard location
-> Failed to retrieve shard data
-> Shard search query returned no results
-> Shard search request timed out
-> Invalid shard identifier
-> Shard search operation failed
-> Shard not available for search
-> Unexpected error during shard search
-> Shard search limit exceeded
-> Shard search request rejected
-> Shard search authentication failed
-> Shard search connection lost
-> Inconsistent shard data
Indexing document [2]
Indexing document [3]
Indexing document [4]
Indexing document [5]
Indexing document [6]
Indexing document [7]
Indexing document [8]
Indexing document [9]
Indexing document [10]
Indexing document [11]
Indexing document [12]
Indexing document [13]
Indexing document [14]
Indexing 500 random documents
Indexing 250 random documents
Indexing 100 random documents
Indexing 50 random documents
Indexing 25 random documents
Indexing 10 random documents
Indexing 5 random documents
Indexing 2 random documents
Indexing 1 random documents
Indexing 10000 random documents
Indexing 5000 random documents
Indexing 2500 random documents
Indexing 10000 random documents
expected: failure actual:success
expected: timeout actual:failure
expected: error actual:error
expected: empty actual:empty
expected: not found actual:not found
expected: invalid actual:invalid
expected: incorrect actual:correct
expected: incomplete actual:complete
expected: mismatch actual:match
expected: outdated actual:updated
expected: unauthorized actual:authorized
expected: forbidden actual:allowed
expected: duplicate actual:unique
expected: null actual:not null
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with an unmapped field, verify it fails
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing b
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _first
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> sort with missing _last
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> testing field with dots in the name
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
--> sort with no missing (same as missing _last)
search type is image
search type is video
search type is news
search type is blog
search type is social media
search type is forum
search type is shopping
search type is music
search type is podcast
search type is document
search type is email
search type is chat
search type is map
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> testing basic search with sort
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
--> shards should fail due to network disruption
Found 50 in old index
Found 200 in old index
Found 75 in old index
Found 150 in old index
Found 300 in old index
Found 125 in old index
Found 250 in old index
Found 175 in old index
Found 350 in old index
Found 225 in old index
Found 400 in old index
Found 275 in old index
Found 450 in old index
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> creating network partition disruption
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
--> data nodes in zone a and b are stopped
Refreshing [2]
Refreshing [3]
Refreshing [4]
Refreshing [5]
Refreshing [6]
Refreshing [7]
Refreshing [8]
Refreshing [9]
Refreshing [10]
Refreshing [11]
Refreshing [12]
Refreshing [13]
Refreshing [14]
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> deleted shard routing weights for weighted round robin
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> creating indices for test
--> index [1] is green, took [492] ms
--> index [2] is green, took [672] ms
--> index [3] is green, took [523] ms
--> index [4] is green, took [788] ms
--> index [5] is green, took [351] ms
--> index [6] is green, took [623] ms
--> index [7] is green, took [462] ms
--> index [8] is green, took [582] ms
--> index [9] is green, took [441] ms
--> index [10] is green, took [682] ms
--> index [11] is green, took [553] ms
--> index [12] is green, took [747] ms
--> index [13] is green, took [412] ms
Cleaning scroll with id r4jk23f
Cleaning scroll with id 63sg732
Cleaning scroll with id e45nru7
Cleaning scroll with id 75f8era
Cleaning scroll with id ab72kq6
Cleaning scroll with id 8f43w56
Cleaning scroll with id 23sdjw9
Cleaning scroll with id 6ndkf45
Cleaning scroll with id x38jr2h
Cleaning scroll with id 2j5asak
Cleaning scroll with id q26f5k6
Cleaning scroll with id 4jrnm84
Cleaning scroll with id 9a84ndw
--> failed request count is [8]
--> failed request count is [5]
--> failed request count is [2]
--> failed request count is [9]
--> failed request count is [1]
--> failed request count is [6]
--> failed request count is [4]
--> failed request count is [7]
--> failed request count is [10]
--> failed request count is [12]
--> failed request count is [11]
--> failed request count is [15]
--> failed request count is [13]
Using lowLevelCancellation: false
Using lowLevelCancellation: true
Using lowLevelCancellation: false
Using lowLevelCancellation: true
Using lowLevelCancellation: false
Using lowLevelCancellation: true
Using lowLevelCancellation: false
Using lowLevelCancellation: true
Using lowLevelCancellation: false
Using lowLevelCancellation: true
Using lowLevelCancellation: false
Using lowLevelCancellation: true
Using lowLevelCancellation: false
Scroll size=200, from=100: Failed to scroll
Scroll size=50, from=250: Scrolled successfully
Scroll size=150, from=300: Failed to scroll
Scroll size=80, from=450: Scrolled successfully
Scroll size=120, from=530: Scrolled successfully
Scroll size=70, from=650: Failed to scroll
Scroll size=180, from=720: Scrolled successfully
Scroll size=90, from=900: Scrolled successfully
Scroll size=30, from=990: Failed to scroll
Scroll size=250, from=1020: Scrolled successfully
Scroll size=60, from=1270: Scrolled successfully
Scroll size=200, from=1330: Failed to scroll
Scroll size=110, from=1530: Scrolled successfully
Control: stop
Control: pause
Control: resume
Control: restart
Control: shutdown
Control: enable
Control: disable
Control: configure
Control: execute
Control: cancel
Control: initialize
Control: terminate
Control: activate
numDocs=500, scrollRequestSize=50, sort=desc, searchType=fuzzy
numDocs=2000, scrollRequestSize=200, sort=asc, searchType=phrase
numDocs=1500, scrollRequestSize=150, sort=desc, searchType=exact
numDocs=800, scrollRequestSize=80, sort=asc, searchType=fuzzy
numDocs=300, scrollRequestSize=30, sort=desc, searchType=phrase
numDocs=1200, scrollRequestSize=120, sort=asc, searchType=exact
numDocs=700, scrollRequestSize=70, sort=desc, searchType=fuzzy
numDocs=2500, scrollRequestSize=250, sort=asc, searchType=phrase
numDocs=1800, scrollRequestSize=180, sort=desc, searchType=exact
numDocs=900, scrollRequestSize=90, sort=asc, searchType=fuzzy
numDocs=350, scrollRequestSize=35, sort=desc, searchType=phrase
numDocs=1400, scrollRequestSize=140, sort=asc, searchType=exact
numDocs=600, scrollRequestSize=60, sort=desc, searchType=fuzzy
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > param1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
running doc['num1'].value > 1
--> creating [5] replicas for index [1]
--> creating [2] replicas for index [2]
--> creating [4] replicas for index [3]
--> creating [6] replicas for index [4]
--> creating [1] replicas for index [5]
--> creating [8] replicas for index [6]
--> creating [9] replicas for index [7]
--> creating [7] replicas for index [8]
--> creating [5] replicas for index [9]
--> creating [2] replicas for index [10]
--> creating [4] replicas for index [11]
--> creating [3] replicas for index [12]
--> creating [1] replicas for index [13]
--> Using time_zone [Europe/London], now is [2022-06-15 15:30:45]
--> Using time_zone [Asia/Tokyo], now is [2022-06-15 22:30:45]
--> Using time_zone [Australia/Sydney], now is [2022-06-16 00:30:45]
--> Using time_zone [America/Los_Angeles], now is [2022-06-15 07:30:45]
--> Using time_zone [Europe/Paris], now is [2022-06-15 16:30:45]
--> Using time_zone [Asia/Shanghai], now is [2022-06-15 22:30:45]
--> Using time_zone [Australia/Melbourne], now is [2022-06-16 00:30:45]
--> Using time_zone [America/Chicago], now is [2022-06-15 08:30:45]
--> Using time_zone [Europe/Berlin], now is [2022-06-15 16:30:45]
--> Using time_zone [Asia/Dubai], now is [2022-06-15 19:30:45]
--> Using time_zone [Australia/Brisbane], now is [2022-06-16 00:30:45]
--> Using time_zone [America/Toronto], now is [2022-06-15 10:30:45]
--> Using time_zone [Europe/Madrid], now is [2022-06-15 16:30:45]
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item with routing attribute and two items without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Running moreLikeThis with one item without routing attribute
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Creating index test with routing required for type1
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
Now check like this doc, but ignore one doc in the index, then two and so on...
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
First check the document matches all indexed docs.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Indexing each field value of this document as a single document.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Create a document that has all the fields.
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking the document matches otherwise ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with an empty document ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Checking with a malformed field value ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Creating an index with a single document ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Checking the document matches ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
Indexing a single document ...
--> consuming settings hashmap
--> consuming settings treemap
--> consuming settings hashtable
--> consuming settings linkedhashmap
--> consuming settings concurrentmap
--> consuming settings weakhashmap
--> consuming settings identityhashmap
--> consuming settings sortedmap
--> consuming settings navigablemap
--> consuming settings concurrentskiplistmap
--> consuming settings enummap
--> consuming settings copyonwritearraymap
--> consuming settings linkedhashmap
--> consuming settings concurrenthashmap
Testing with minimum_should_match = 1
Testing with minimum_should_match = 2
Testing with minimum_should_match = 3
Testing with minimum_should_match = 4
Testing with minimum_should_match = 5
Testing with minimum_should_match = 6
Testing with minimum_should_match = 7
Testing with minimum_should_match = 8
Testing with minimum_should_match = 9
Testing with minimum_should_match = 10
Testing with minimum_should_match = 11
Testing with minimum_should_match = 12
Testing with minimum_should_match = 13
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Indexing with each doc having one less term ...
Running More Like This with max_query_terms = 10
Running More Like This with max_query_terms = 15
Running More Like This with max_query_terms = 20
Running More Like This with max_query_terms = 25
Running More Like This with max_query_terms = 30
Running More Like This with max_query_terms = 35
Running More Like This with max_query_terms = 40
Running More Like This with max_query_terms = 45
Running More Like This with max_query_terms = 50
Running More Like This with max_query_terms = 55
Running More Like This with max_query_terms = 60
Running More Like This with max_query_terms = 65
Running More Like This with max_query_terms = 70
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include false
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running More Like This with include true
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on alias with node client
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on release shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on beta shard
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Running moreLikeThis on index
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
Creating aliases alias release
mean: 2.8
mean: 4.1
mean: 2.2
mean: 3.9
mean: 4.7
mean: 2.1
mean: 3.3
mean: 3.2
mean: 4.5
mean: 2.6
mean: 3.8
mean: 4.0
mean: 2.9
median: 10
median: 3
median: 7
median: 12
median: 8
median: 4
median: 11
median: 6
median: 9
median: 2
median: 14
median: 1
median: 13
percentile_25: 25
percentile_25: 50
percentile_25: 35
percentile_25: 80
percentile_25: 60
percentile_25: 15
percentile_25: 30
percentile_25: 40
percentile_25: 75
percentile_25: 20
percentile_25: 90
percentile_25: 65
percentile_25: 85
percentile_75: 0.932
percentile_75: 0.756
percentile_75: 0.904
percentile_75: 0.689
percentile_75: 0.756
percentile_75: 0.926
percentile_75: 0.811
percentile_75: 0.785
percentile_75: 0.911
percentile_75: 0.719
percentile_75: 0.899
percentile_75: 0.834
percentile_75: 0.802
percentile_75: 0.694
distribution: 0.8
distribution: 0.3
distribution: 0.1
distribution: 0.6
distribution: 0.7
distribution: 0.9
distribution: 0.2
distribution: 0.4
distribution: 0.65
distribution: 0.25
distribution: 0.85
distribution: 0.35
distribution: 0.15
avg repeat: 3.7
avg repeat: 4.2
avg repeat: 1.8
avg repeat: 2.9
avg repeat: 3.5
avg repeat: 4.1
avg repeat: 2.3
avg repeat: 3.9
avg repeat: 4.7
avg repeat: 2.1
avg repeat: 3.4
avg repeat: 4.5
avg repeat: 1.9
max repeat: 8
max repeat: 3
max repeat: 10
max repeat: 6
max repeat: 2
max repeat: 7
max repeat: 4
max repeat: 9
max repeat: 1
max repeat: 12
max repeat: 11
max repeat: 15
max repeat: 13
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value * factor
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
running doc['unsigned_num1'].value
This is a trace message
This is a trace message
This is a trace message
This is a trace message
This is a trace message
This is a trace message
This is a trace message
This is a trace message
This is a trace message
This is a trace message
This is a trace message
This is a trace message
This is a trace message
This is a trace message
This is a trace message
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
running doc['num1'].value * factor
This is a debug message
This is a debug message
This is a debug message
This is a debug message
This is a debug message
This is a debug message
This is a debug message
This is a debug message
This is a debug message
This is a debug message
This is a debug message
This is a debug message
This is a debug message
This is a debug message
This is a debug message
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
running doc['num1'].value
This is an info message
This is an info message
This is an info message
This is an info message
This is an info message
This is an info message
This is an info message
This is an info message
This is an info message
This is an info message
This is an info message
This is an info message
This is an info message
This is an info message
This is an info message
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
--> highlighting and searching on field2
This is a warning message
This is a warning message
This is a warning message
This is a warning message
This is a warning message
This is a warning message
This is a warning message
This is a warning message
This is a warning message
This is a warning message
This is a warning message
This is a warning message
This is a warning message
This is a warning message
This is a warning message
failed to sync translog TimeoutException
failed to sync translog NullPointerException
failed to sync translog IndexOutOfBoundsException
failed to sync translog ParseException
failed to sync translog IllegalArgumentException
failed to sync translog IllegalStateException
failed to sync translog OutOfMemoryError
failed to sync translog StackOverflowError
failed to sync translog SecurityException
failed to sync translog ArrayIndexOutOfBoundsException
failed to sync translog NoSuchElementException
failed to sync translog ClassCastException
failed to sync translog ArithmeticException
failed to sync translog AssertionError
This is an error message
This is an error message
This is an error message
This is an error message
This is an error message
This is an error message
This is an error message
This is an error message
This is an error message
This is an error message
This is an error message
This is an error message
This is an error message
This is an error message
This is an error message
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
--> searching on field2, highlighting on field2, falling back to the plain highlighter
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
explicitly enforcing bootstrap checks
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field2, highlighting on field2
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
--> searching on field1, highlighting on field1
Eastern Standard Time from 2021-02-15T12:00:00 to 2021-02-15T13:00:00
Central European Time from 2021-03-31T03:30:00 to 2021-03-31T04:30:00
Japan Standard Time from 2021-05-20T19:45:00 to 2021-05-20T20:45:00
Mountain Standard Time from 2021-07-05T08:15:00 to 2021-07-05T09:15:00
Australian Eastern Standard Time from 2021-09-10T23:30:00 to 2021-09-11T00:30:00
Greenwich Mean Time from 2021-10-25T16:00:00 to 2021-10-25T17:00:00
Central Standard Time from 2021-12-15T06:45:00 to 2021-12-15T07:45:00
Mountain Daylight Time from 2022-02-02T11:30:00 to 2022-02-02T12:30:00
British Summer Time from 2022-03-17T22:15:00 to 2022-03-17T23:15:00
Central Daylight Time from 2022-05-06T02:00:00 to 2022-05-06T03:00:00
Pacific Daylight Time from 2022-06-30T15:45:00 to 2022-06-30T16:45:00
Eastern European Time from 2022-08-20T10:30:00 to 2022-08-20T11:30:00
Indian Standard Time from 2022-11-11T03:15:00 to 2022-11-11T04:15:00
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> searching explicitly on field1 and highlighting on it
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with large phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on field1 with default phrase limit
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with word boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> highlighting and searching on 'field' with sentence boundary_scanner
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters on the field
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> searching with boundary characters
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field*
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
--> highlighting and searching on field1 and field2 produces different tags
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed multi search with a wrong query
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Start Testing failed search with wrong from
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Done Testing failed search
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
Start Testing failed search with wrong query
SearchPhaseException: Error executing search request
SearchPhaseException: Invalid search syntax
SearchPhaseException: Exception occurred while processing query
SearchPhaseException: Error executing search request
SearchPhaseException: Invalid search syntax
SearchPhaseException: Exception occurred while processing query
SearchPhaseException: Error executing search request
SearchPhaseException: Invalid search syntax
SearchPhaseException: Exception occurred while processing query
SearchPhaseException: Error executing search request
SearchPhaseException: Invalid search syntax
SearchPhaseException: Exception occurred while processing query
SearchPhaseException: Error executing search request
SearchPhaseException: Invalid search syntax
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
ClusterHealth timed out - only index one doc and expect searches to fail
Match all Successful shards: [8]  numShards: [4]
Match all Successful shards: [10]  numShards: [7]
Match all Successful shards: [6]  numShards: [3]
Match all Successful shards: [15]  numShards: [9]
Match all Successful shards: [5]  numShards: [2]
Match all Successful shards: [11]  numShards: [6]
Match all Successful shards: [7]  numShards: [4]
Match all Successful shards: [9]  numShards: [6]
Match all Successful shards: [13]  numShards: [8]
Match all Successful shards: [8]  numShards: [5]
Match all Successful shards: [14]  numShards: [7]
Match all Successful shards: [4]  numShards: [2]
Match all Successful shards: [12]  numShards: [7]
Successful shards: [8]  numShards: [10]
Successful shards: [10]  numShards: [15]
Successful shards: [2]  numShards: [3]
Successful shards: [6]  numShards: [9]
Successful shards: [1]  numShards: [2]
Successful shards: [9]  numShards: [12]
Successful shards: [5]  numShards: [8]
Successful shards: [7]  numShards: [11]
Successful shards: [3]  numShards: [4]
Successful shards: [12]  numShards: [18]
Successful shards: [15]  numShards: [20]
Successful shards: [11]  numShards: [16]
Successful shards: [14]  numShards: [21]
non-critical exceptions: IndexOutOfBoundsException
non-critical exceptions: IllegalArgumentException
non-critical exceptions: ArrayIndexOutOfBoundsException
non-critical exceptions: ClassCastException
non-critical exceptions: UnsupportedOperationException
non-critical exceptions: FileNotFoundException
non-critical exceptions: NoSuchElementException
non-critical exceptions: IllegalStateException
non-critical exceptions: NumberFormatException
non-critical exceptions: ClassNotFoundException
non-critical exceptions: UnsupportedOperationException
non-critical exceptions: IllegalArgumentException
non-critical exceptions: ArithmeticException
hits count mismatch on any shard search failed, post explicit wait for green hits are 500
hits count mismatch on any shard search failed, post explicit wait for green hits are 1000
hits count mismatch on any shard search failed, post explicit wait for green hits are 2000
hits count mismatch on any shard search failed, post explicit wait for green hits are 5000
hits count mismatch on any shard search failed, post explicit wait for green hits are 10000
hits count mismatch on any shard search failed, post explicit wait for green hits are 20000
hits count mismatch on any shard search failed, post explicit wait for green hits are 50000
hits count mismatch on any shard search failed, post explicit wait for green hits are 100000
hits count mismatch on any shard search failed, post explicit wait for green hits are 200000
hits count mismatch on any shard search failed, post explicit wait for green hits are 500000
hits count mismatch on any shard search failed, post explicit wait for green hits are 1000000
hits count mismatch on any shard search failed, post explicit wait for green hits are 2000000
hits count mismatch on any shard search failed, post explicit wait for green hits are 5000000
forced refresh failed after interval change: IllegalArgumentException
forced refresh failed after interval change: IndexOutOfBoundsException
forced refresh failed after interval change: ArrayIndexOutOfBoundsException
forced refresh failed after interval change: ClassCastException
forced refresh failed after interval change: OutOfMemoryError
forced refresh failed after interval change: StackOverflowError
forced refresh failed after interval change: UnsupportedOperationException
forced refresh failed after interval change: AssertionError
forced refresh failed after interval change: ConcurrentModificationException
forced refresh failed after interval change: NoClassDefFoundError
forced refresh failed after interval change: NoSuchFieldError
forced refresh failed after interval change: NoSuchMethodError
forced refresh failed after interval change: UnsatisfiedLinkError
hits count mismatch on any shard search failed, post explicit refresh hits are 200
hits count mismatch on any shard search failed, post explicit refresh hits are 300
hits count mismatch on any shard search failed, post explicit refresh hits are 400
hits count mismatch on any shard search failed, post explicit refresh hits are 500
hits count mismatch on any shard search failed, post explicit refresh hits are 600
hits count mismatch on any shard search failed, post explicit refresh hits are 700
hits count mismatch on any shard search failed, post explicit refresh hits are 800
hits count mismatch on any shard search failed, post explicit refresh hits are 900
hits count mismatch on any shard search failed, post explicit refresh hits are 1000
hits count mismatch on any shard search failed, post explicit refresh hits are 1100
hits count mismatch on any shard search failed, post explicit refresh hits are 1200
hits count mismatch on any shard search failed, post explicit refresh hits are 1300
hits count mismatch on any shard search failed, post explicit refresh hits are 1400
Track score=92
Track score=78
Track score=90
Track score=80
Track score=88
Track score=82
Track score=95
Track score=75
Track score=87
Track score=83
Track score=91
Track score=79
Track score=93
Using percentiles=[0.1, 0.2, 0.9]
Using percentiles=[0.05, 0.5, 0.95]
Using percentiles=[0.3, 0.6, 0.8]
Using percentiles=[0.15, 0.25, 0.35]
Using percentiles=[0.4, 0.5, 0.6]
Using percentiles=[0.7, 0.8, 0.9]
Using percentiles=[0.2, 0.4, 0.6]
Using percentiles=[0.1, 0.3, 0.5]
Using percentiles=[0.05, 0.15, 0.25]
Using percentiles=[0.35, 0.45, 0.55]
Using percentiles=[0.65, 0.75, 0.85]
Using percentiles=[0.5, 0.7, 0.9]
Using percentiles=[0.3, 0.5, 0.7]
Using values=[0.2, 0.3, 0.4]
Using values=[0.3, 0.4, 0.5]
Using values=[0.4, 0.5, 0.6]
Using values=[0.5, 0.6, 0.7]
Using values=[0.6, 0.7, 0.8]
Using values=[0.7, 0.8, 0.9]
Using values=[0.8, 0.9, 1.0]
Using values=[0.9, 1.0, 1.1]
Using values=[1.0, 1.1, 1.2]
Using values=[1.1, 1.2, 1.3]
Using values=[1.2, 1.3, 1.4]
Using values=[1.3, 1.4, 1.5]
Using values=[1.4, 1.5, 1.6]
Indexing [200] docs
Indexing [300] docs
Indexing [400] docs
Indexing [500] docs
Indexing [600] docs
Indexing [700] docs
Indexing [800] docs
Indexing [900] docs
Indexing [1000] docs
Indexing [1100] docs
Indexing [1200] docs
Indexing [1300] docs
Indexing [1400] docs
Checking results for bucket my-bucket
Checking results for bucket test-bucket
Checking results for bucket data-bucket
Checking results for bucket log-bucket
Checking results for bucket image-bucket
Checking results for bucket backup-bucket
Checking results for bucket production-bucket
Checking results for bucket development-bucket
Checking results for bucket staging-bucket
Checking results for bucket demo-bucket
Checking results for bucket temp-bucket
Checking results for bucket archive-bucket
Checking results for bucket logs-bucket
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
--> verifying mget with ids [1,2], with no routing, should fail
AGG COLLECTION MODE: parallel
AGG COLLECTION MODE: disabled
AGG COLLECTION MODE: concurrent
AGG COLLECTION MODE: sequential
AGG COLLECTION MODE: adaptive
AGG COLLECTION MODE: batched
AGG COLLECTION MODE: atomic
AGG COLLECTION MODE: exclusive
AGG COLLECTION MODE: synchronized
AGG COLLECTION MODE: lazy
AGG COLLECTION MODE: eager
AGG COLLECTION MODE: buffered
AGG COLLECTION MODE: independent
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying mget with ids [1,2], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying term vector with id [1], with routing [0], should succeed
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with no routing, should fail
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying explain with id [2], with routing [0], should succeed
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1], with no routing, should fail
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> verifying get with id [1] with routing [0], should succeed
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> deleting with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> indexing with id [1], with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
--> verifying get with no routing, should fail
failed to close resource IOException
failed to close resource SQLException
failed to close resource NullPointerException
failed to close resource IllegalStateException
failed to close resource ArrayIndexOutOfBoundsException
failed to close resource ArithmeticException
failed to close resource ClassCastException
failed to close resource OutOfMemoryError
failed to close resource IllegalArgumentException
failed to close resource NoSuchElementException
failed to close resource SecurityException
failed to close resource RuntimeException
failed to close resource IndexOutOfBoundsException
failed to close resource ConcurrentModificationException
checking abstract runnable exception for BikeRunner
checking abstract runnable exception for TrainRunner
checking abstract runnable exception for ShipRunner
checking abstract runnable exception for PlaneRunner
checking abstract runnable exception for BusRunner
checking abstract runnable exception for TruckRunner
checking abstract runnable exception for MotorcycleRunner
checking abstract runnable exception for ScooterRunner
checking abstract runnable exception for TaxiRunner
checking abstract runnable exception for BoatRunner
checking abstract runnable exception for BicycleRunner
checking abstract runnable exception for TramRunner
checking abstract runnable exception for ElectricScooterRunner
unexpected exception while stopping nio group ArrayIndexOutOfBoundsException
unexpected exception while stopping nio group IllegalArgumentException
unexpected exception while stopping nio group RuntimeException
unexpected exception while stopping nio group IOException
unexpected exception while stopping nio group ClassNotFoundException
unexpected exception while stopping nio group NoSuchElementException
unexpected exception while stopping nio group IllegalStateException
unexpected exception while stopping nio group ConcurrentModificationException
unexpected exception while stopping nio group NullPointerException
unexpected exception while stopping nio group ArrayIndexOutOfBoundsException
unexpected exception while stopping nio group IllegalArgumentException
unexpected exception while stopping nio group RuntimeException
unexpected exception while stopping nio group IOException
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> indexing with id [1], and routing [0]
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
--> deleting with routing, should delete
[15] closing... (reason: [Error])
[8] closing... (reason: [Timeout])
[3] closing... (reason: [Full])
[6] closing... (reason: [Overload])
[12] closing... (reason: [Invalid])
[1] closing... (reason: [Shutdown])
[5] closing... (reason: [Unknown])
[9] closing... (reason: [Suspended])
[13] closing... (reason: [Restart])
[7] closing... (reason: [Failure])
[2] closing... (reason: [Blocked])
[11] closing... (reason: [Resource Exhaustion])
[4] closing... (reason: [Crash])
numberOfEntries: 200
numberOfEntries: 300
numberOfEntries: 400
numberOfEntries: 500
numberOfEntries: 600
numberOfEntries: 700
numberOfEntries: 800
numberOfEntries: 900
numberOfEntries: 1000
numberOfEntries: 1100
numberOfEntries: 1200
numberOfEntries: 1300
numberOfEntries: 1400
partSize: 2048, lastPartSize: 1024, partCount: 5
partSize: 4096, lastPartSize: 2048, partCount: 3
partSize: 8192, lastPartSize: 4096, partCount: 2
partSize: 16384, lastPartSize: 8192, partCount: 1
partSize: 32768, lastPartSize: 16384, partCount: 1
partSize: 65536, lastPartSize: 32768, partCount: 1
partSize: 131072, lastPartSize: 65536, partCount: 1
partSize: 262144, lastPartSize: 131072, partCount: 1
partSize: 524288, lastPartSize: 262144, partCount: 1
partSize: 1048576, lastPartSize: 524288, partCount: 1
partSize: 2097152, lastPartSize: 1048576, partCount: 1
partSize: 4194304, lastPartSize: 2097152, partCount: 1
partSize: 8388608, lastPartSize: 4194304, partCount: 1
partSize: 16777216, lastPartSize: 8388608, partCount: 1
using max_chunk_size[250], max_header_size[512], max_initial_line_length[128], max_content_length[8192], pipelining_max_events[20]
using max_chunk_size[500], max_header_size[2048], max_initial_line_length[512], max_content_length[16384], pipelining_max_events[30]
using max_chunk_size[1000], max_header_size[4096], max_initial_line_length[1024], max_content_length[32768], pipelining_max_events[40]
using max_chunk_size[2000], max_header_size[8192], max_initial_line_length[2048], max_content_length[65536], pipelining_max_events[50]
using max_chunk_size[5000], max_header_size[16384], max_initial_line_length[4096], max_content_length[131072], pipelining_max_events[60]
using max_chunk_size[10000], max_header_size[32768], max_initial_line_length[8192], max_content_length[262144], pipelining_max_events[70]
using max_chunk_size[15000], max_header_size[65536], max_initial_line_length[16384], max_content_length[524288], pipelining_max_events[80]
using max_chunk_size[20000], max_header_size[131072], max_initial_line_length[32768], max_content_length[1048576], pipelining_max_events[90]
using max_chunk_size[30000], max_header_size[262144], max_initial_line_length[65536], max_content_length[2097152], pipelining_max_events[100]
using max_chunk_size[50000], max_header_size[524288], max_initial_line_length[131072], max_content_length[4194304], pipelining_max_events[110]
using max_chunk_size[80000], max_header_size[1048576], max_initial_line_length[262144], max_content_length[8388608], pipelining_max_events[120]
using max_chunk_size[100000], max_header_size[2097152], max_initial_line_length[524288], max_content_length[16777216], pipelining_max_events[130]
using max_chunk_size[150000], max_header_size[4194304], max_initial_line_length[1048576], max_content_length[33554432], pipelining_max_events[140]
using max_chunk_size[200000], max_header_size[8388608], max_initial_line_length[2097152], max_content_length[67108864], pipelining_max_events[150]
Keys to override: password
Keys to override: email
Keys to override: access_token
Keys to override: session_id
Keys to override: api_key
Keys to override: country
Keys to override: language
Keys to override: currency
Keys to override: timezone
Keys to override: theme
Keys to override: font_size
Keys to override: background_color
Keys to override: notification_sound
Error while closing Opentelemetry TimeoutException
Error while closing Opentelemetry NullPointerException
Error while closing Opentelemetry IOException
Error while closing Opentelemetry AuthorizationException
Error while closing Opentelemetry SecurityException
Error while closing Opentelemetry DatabaseException
Error while closing Opentelemetry InvalidParameterException
Error while closing Opentelemetry NetworkException
Error while closing Opentelemetry OutOfMemoryException
Error while closing Opentelemetry InvalidStateException
Error while closing Opentelemetry UnknownException
Error while closing Opentelemetry IllegalStateException
Error while closing Opentelemetry FormatException
--> shrinking index [products] to [prds]
--> shrinking index [user] to [usr]
--> shrinking index [orders] to [ords]
--> shrinking index [messages] to [msgs]
--> shrinking index [categories] to [cats]
--> shrinking index [reviews] to [rvws]
--> shrinking index [settings] to [stgs]
--> shrinking index [payments] to [pmts]
--> shrinking index [logs] to [lgs]
--> shrinking index [images] to [imgs]
--> shrinking index [publications] to [pubs]
--> shrinking index [events] to [evts]
--> shrinking index [tags] to [tgs]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> indexing with id [1], and routing [4]
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> creating alias with search routing [3,4] and index routing 4
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> verifying search with wrong routing should not find
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> creating alias with routing [4]
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> verifying get and search with routing, should find
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> indexing with id [0], and routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> creating alias with routing [3]
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> search all on index_* should find two
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_2 which is a concrete index
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> indexing on index_1 which is an alias for index with routing [1]
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-a0,alias-b1 should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-ab, should find two
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> search with alias-a1,alias-b0, should not find
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [0], and routing [1] using alias to test-b
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> indexing with id [1], and routing [0] using alias to test-a
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with test, alias0 and alias1, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with alias0, alias1 and alias01, should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with two routing aliases , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 0,1 indexRoutings , should find two
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 1 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with 0 routing, should find one
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> search with no routing, should fine two
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> indexing with id [2], and routing [1] using alias
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with correct routing, should find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with wrong routing, should not find
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> search with no routing, should fine one
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with routing alias, should delete
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> deleting with no routing, should not delete anything
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> updating with id [1] and routing through alias
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing alias, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with routing, should find
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> verifying get with no routing, should not find anything
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> indexing with id [1], and routing [0] using alias
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
--> write two outdated index-N blobs
Exception from http client ConnectException
Exception from http client IOException
Exception from http client UnknownHostException
Exception from http client SSLHandshakeException
Exception from http client SocketException
Exception from http client NoSuchAlgorithmException
Exception from http client FileNotFoundException
Exception from http client MalformedURLException
Exception from http client SSLException
Exception from http client InvalidKeyException
Exception from http client KeyStoreException
Exception from http client NoSuchProviderException
Exception from http client InvalidKeySpecException
Successfully instantiated the SpanExporter class JaegerExporter
Successfully instantiated the SpanExporter class ZipkinExporter
Successfully instantiated the SpanExporter class SimpleExporter
Successfully instantiated the SpanExporter class LoggingExporter
Successfully instantiated the SpanExporter class FileExporter
Successfully instantiated the SpanExporter class KafkaExporter
Successfully instantiated the SpanExporter class PrometheusExporter
Successfully instantiated the SpanExporter class SplunkExporter
Successfully instantiated the SpanExporter class DatadogExporter
Successfully instantiated the SpanExporter class HoneycombExporter
Successfully instantiated the SpanExporter class WavefrontExporter
Successfully instantiated the SpanExporter class DynatraceExporter
Successfully instantiated the SpanExporter class NewRelicExporter
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
Error closing input stream
creating shard_id 2
creating shard_id 3
creating shard_id 4
creating shard_id 5
creating shard_id 6
creating shard_id 7
creating shard_id 8
creating shard_id 9
creating shard_id 10
creating shard_id 11
creating shard_id 12
creating shard_id 13
creating shard_id 14
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
--> creating a garbage data blob
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  starting two cluster-manager nodes and one data node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  unblocking cluster-manager node
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  ensure cleanup is still in progress
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  wait for cleanup to finish and disappear from cluster state
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
-->  stopping cluster-manager node
num of docs in iter 50 2
num of docs in iter 100 3
num of docs in iter 200 4
num of docs in iter 500 5
num of docs in iter 1000 6
num of docs in iter 2000 7
num of docs in iter 5000 8
num of docs in iter 10000 9
num of docs in iter 20000 10
num of docs in iter 50000 11
num of docs in iter 100000 12
num of docs in iter 200000 13
num of docs in iter 500000 14
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
--> Verify that the segment files are same on local and repository eventually
failed to close shard ResourceNotFoundException
failed to close shard ConnectionTimeoutException
failed to close shard ConstraintViolationException
failed to close shard NullPointerException
failed to close shard IllegalArgumentException
failed to close shard IOException
failed to close shard OutOfMemoryError
failed to close shard IndexOutOfBoundsException
failed to close shard ArithmeticException
failed to close shard NoSuchElementException
failed to close shard ArrayIndexOutOfBoundsException
failed to close shard ClassCastException
failed to close shard UnsupportedOperationException
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index with the same name, different UUID
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
--> Create index and ingest 50 docs
failed to close reader IOException
failed to close reader FileNotFoundException
failed to close reader NullPointerException
failed to close reader EOFException
failed to close reader SocketException
failed to close reader SQLException
failed to close reader ArrayIndexOutOfBoundsException
failed to close reader ArithmeticException
failed to close reader ClassCastException
failed to close reader RuntimeException
failed to close reader NoSuchMethodException
failed to close reader NumberFormatException
failed to close reader IllegalArgumentException
failed to close reader IndexOutOfBoundsException
exception error from blob container for file document.docx
exception error from blob container for file video.mp4
exception error from blob container for file data.csv
exception error from blob container for file code.py
exception error from blob container for file music.mp3
exception error from blob container for file presentation.pptx
exception error from blob container for file report.pdf
exception error from blob container for file backup.bak
exception error from blob container for file archive.zip
exception error from blob container for file spreadsheet.xlsx
exception error from blob container for file readme.txt
exception error from blob container for file config.ini
exception error from blob container for file script.js
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
Using instance profile credentials
adding [10] nodes
adding [3] nodes
adding [7] nodes
adding [2] nodes
adding [8] nodes
adding [6] nodes
adding [1] nodes
adding [9] nodes
adding [4] nodes
adding [12] nodes
adding [15] nodes
adding [11] nodes
adding [13] nodes
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore one index after deletion
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
--> restore all indices from the snapshot
failing primary shards 4,5,6 for index [products]
failing primary shards 7,8,9 for index [orders]
failing primary shards 10,11,12 for index [invoices]
failing primary shards 13,14,15 for index [customers]
failing primary shards 16,17,18 for index [payments]
failing primary shards 19,20,21 for index [reviews]
failing primary shards 22,23,24 for index [transactions]
failing primary shards 25,26,27 for index [messages]
failing primary shards 28,29,30 for index [notifications]
failing primary shards 31,32,33 for index [settings]
failing primary shards 34,35,36 for index [logs]
failing primary shards 37,38,39 for index [analytics]
failing primary shards 40,41,42 for index [campaigns]
Keytab Length: 1024
Keytab Length: 512
Keytab Length: 2048
Keytab Length: 4096
Keytab Length: 128
Keytab Length: 256
Keytab Length: 768
Keytab Length: 1536
Keytab Length: 3072
Keytab Length: 64
Keytab Length: 32
Keytab Length: 16
Keytab Length: 8
applied reroute. active shards: p [64], t [128], init shards: [5], relocating: [2]
applied reroute. active shards: p [256], t [512], init shards: [20], relocating: [10]
applied reroute. active shards: p [32], t [64], init shards: [2], relocating: [1]
applied reroute. active shards: p [16], t [32], init shards: [1], relocating: [0]
applied reroute. active shards: p [512], t [1024], init shards: [40], relocating: [20]
applied reroute. active shards: p [8], t [16], init shards: [0], relocating: [0]
applied reroute. active shards: p [4], t [8], init shards: [0], relocating: [0]
applied reroute. active shards: p [2], t [4], init shards: [0], relocating: [0]
applied reroute. active shards: p [1], t [2], init shards: [0], relocating: [0]
applied reroute. active shards: p [256], t [512], init shards: [20], relocating: [10]
applied reroute. active shards: p [128], t [256], init shards: [10], relocating: [5]
applied reroute. active shards: p [64], t [128], init shards: [5], relocating: [2]
applied reroute. active shards: p [32], t [64], init shards: [2], relocating: [1]
Path 2 [C:/Program Files/Folder1/file2.jpg]
Path 2 [D:/Projects/Folder2/file3.py]
Path 2 [E:/Pictures/image.png]
Path 2 [F:/Music/song.mp3]
Path 2 [G:/Videos/movie.avi]
Path 2 [H:/Documents/file4.docx]
Path 2 [I:/Downloads/file5.pdf]
Path 2 [J:/Pictures/image2.jpg]
Path 2 [K:/Program Files/Folder3/file6.exe]
Path 2 [L:/Music/song2.mp3]
Path 2 [M:/Videos/movie2.avi]
Path 2 [N:/Projects/Folder4/file7.py]
Path 2 [O:/Documents/file8.docx]
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.
Adding configuration to HDFS Client Configuration : dfs.replication = 3
Adding configuration to HDFS Client Configuration : dfs.blocksize = 134217728
Adding configuration to HDFS Client Configuration : dfs.namenode.rpc-bind-host = 0.0.0.0
Adding configuration to HDFS Client Configuration : dfs.data.transfer.client.read.timeout = 60000
Adding configuration to HDFS Client Configuration : dfs.client.block.write.replace-datanode-on-failure.best-effort = false
Adding configuration to HDFS Client Configuration : dfs.client.block.write.retries = 3
Adding configuration to HDFS Client Configuration : dfs.client.block.write.locateFollowingBlock.retries = 3
Adding configuration to HDFS Client Configuration : dfs.client.max.block.acquire.failures = 3
Adding configuration to HDFS Client Configuration : dfs.client.failover.max.attempts = 15
Adding configuration to HDFS Client Configuration : dfs.client.failover.sleep.base.millis = 500
Adding configuration to HDFS Client Configuration : dfs.client.failover.connection.retries = 3
Adding configuration to HDFS Client Configuration : dfs.client.failover.proxy.provider = org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
Adding configuration to HDFS Client Configuration : dfs.client.socket-timeout = 5000
Setup test with 5 shards and 3 replicas.
Setup test with 8 shards and 4 replicas.
Setup test with 15 shards and 1 replicas.
Setup test with 12 shards and 3 replicas.
Setup test with 6 shards and 2 replicas.
Setup test with 9 shards and 4 replicas.
Setup test with 3 shards and 1 replicas.
Setup test with 7 shards and 2 replicas.
Setup test with 14 shards and 3 replicas.
Setup test with 11 shards and 4 replicas.
Setup test with 2 shards and 1 replicas.
Setup test with 4 shards and 2 replicas.
Setup test with 13 shards and 3 replicas.
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
do a reroute, should remain the same
now remove a replica
now remove a replica
now remove a replica
now remove a replica
now remove a replica
now remove a replica
now remove a replica
now remove a replica
now remove a replica
now remove a replica
now remove a replica
now remove a replica
now remove a replica
now remove a replica
now remove a replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Add another node and start the added replica
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Start all the replica shards
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Apply started shards for new index
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Start primary on node4. Now all replicas for that primary start getting accounted for from node4.
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Exclude node1 and add node4. After this, primary shard on node1 moves to RELOCATING state and only non initial replica recoveries are impacted
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
Add a new node for all replica assignment. 4 replicas move to INIT after reroute.
merge failure action rejected NullReferenceException
merge failure action rejected FileLoadException
merge failure action rejected ArgumentException
merge failure action rejected IndexOutOfRangeException
merge failure action rejected DivideByZeroException
merge failure action rejected FileNotFoundException
merge failure action rejected StackOverflowException
merge failure action rejected InvalidOperationException
merge failure action rejected OutOfMemoryException
merge failure action rejected FormatException
merge failure action rejected UnauthorizedAccessException
merge failure action rejected ArrayTypeMismatchException
merge failure action rejected KeyNotFoundException
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
create a new index and start all primaries
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
failed to flush after merge has finished
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
1 replica should be initializing now for the existing indices (we throttle to 1) on each node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
move started non-primary to new node
start one more node
start one more node
start one more node
start one more node
start one more node
start one more node
start one more node
start one more node
start one more node
start one more node
start one more node
start one more node
start one more node
start one more node
start one more node
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start one more node, initializing second non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start initializing non-primary
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
start one more node, first non-primary should start being allocated
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
with one node, do reroute, only 1 should initialize
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start the relocating shards, one more shard should relocate away from node1
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
start another 2 nodes, 5 shards should be relocating - at most 5 are allowed per node
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
with one node, do reroute, only 5 should initialize
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start initializing replicas, all should be started
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start another node, replicas should start being allocated
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
start initializing, another 2 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
with one node, do reroute, only 3 should initialize
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, all primaries should be started
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 1 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start initializing, another 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
start one node, do reroute, only 3 should initialize
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Start the shards on node 3
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
Add another node and perform rerouting
stop throttling indexing: numMergesInFlight=6, maxNumMerges=10
stop throttling indexing: numMergesInFlight=2, maxNumMerges=8
stop throttling indexing: numMergesInFlight=4, maxNumMerges=9
stop throttling indexing: numMergesInFlight=1, maxNumMerges=7
stop throttling indexing: numMergesInFlight=5, maxNumMerges=12
stop throttling indexing: numMergesInFlight=7, maxNumMerges=14
stop throttling indexing: numMergesInFlight=9, maxNumMerges=13
stop throttling indexing: numMergesInFlight=11, maxNumMerges=16
stop throttling indexing: numMergesInFlight=8, maxNumMerges=11
stop throttling indexing: numMergesInFlight=10, maxNumMerges=18
stop throttling indexing: numMergesInFlight=13, maxNumMerges=20
stop throttling indexing: numMergesInFlight=15, maxNumMerges=19
stop throttling indexing: numMergesInFlight=12, maxNumMerges=22
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard together with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> test starting of relocating primary shard with initializing / relocating replica
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> testing starting of relocating shards
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> test starting of shard
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
--> building initial cluster state
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Start another node, backup shard should start initializing
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Kill node1, backup shard should become primary
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Add another node and perform rerouting, nothing will happen since primary shards not started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
Now, mark the relocated as started
now throttling indexing: numMergesInFlight=2, maxNumMerges=7
now throttling indexing: numMergesInFlight=4, maxNumMerges=6
now throttling indexing: numMergesInFlight=1, maxNumMerges=8
now throttling indexing: numMergesInFlight=6, maxNumMerges=4
now throttling indexing: numMergesInFlight=5, maxNumMerges=3
now throttling indexing: numMergesInFlight=7, maxNumMerges=2
now throttling indexing: numMergesInFlight=8, maxNumMerges=1
now throttling indexing: numMergesInFlight=9, maxNumMerges=15
now throttling indexing: numMergesInFlight=10, maxNumMerges=12
now throttling indexing: numMergesInFlight=11, maxNumMerges=10
now throttling indexing: numMergesInFlight=14, maxNumMerges=9
now throttling indexing: numMergesInFlight=13, maxNumMerges=11
now throttling indexing: numMergesInFlight=16, maxNumMerges=17
Adding 7 nodes
Adding 10 nodes
Adding 2 nodes
Adding 8 nodes
Adding 3 nodes
Adding 4 nodes
Adding 1 nodes
Adding 6 nodes
Adding 9 nodes
Adding 12 nodes
Adding 11 nodes
Adding 13 nodes
Adding 14 nodes
failed to close engineUnknown
failed to close engineException
failed to close engineConnection
failed to close engineInvalidOperation
failed to close engineTimeout
failed to close enginePermission
failed to close engineResource
failed to close engineAssertion
failed to close engineConfiguration
failed to close engineDatabase
failed to close engineAuthentication
failed to close engineConcurrency
failed to close engineSerialization
Exception while closing AwsCredentialsProviderIOException
Exception while closing AwsCredentialsProviderTimeoutException
Exception while closing AwsCredentialsProviderIllegalArgumentException
Exception while closing AwsCredentialsProviderIllegalStateException
Exception while closing AwsCredentialsProviderAuthorizationException
Exception while closing AwsCredentialsProviderConnectionException
Exception while closing AwsCredentialsProviderSecurityException
Exception while closing AwsCredentialsProviderParseException
Exception while closing AwsCredentialsProviderIllegalArgumentException
Exception while closing AwsCredentialsProviderInterruptedException
Exception while closing AwsCredentialsProviderInvalidValueException
Exception while closing AwsCredentialsProviderNullPointerException
Exception while closing AwsCredentialsProviderSocketException
--> Indexing 20 operations in iteration #2
--> Indexing 30 operations in iteration #3
--> Indexing 40 operations in iteration #4
--> Indexing 50 operations in iteration #5
--> Indexing 60 operations in iteration #6
--> Indexing 70 operations in iteration #7
--> Indexing 80 operations in iteration #8
--> Indexing 90 operations in iteration #9
--> Indexing 100 operations in iteration #10
--> Indexing 110 operations in iteration #11
--> Indexing 120 operations in iteration #12
--> Indexing 130 operations in iteration #13
--> Indexing 140 operations in iteration #14
--> Indexing data for 10 iterations with flush=false
--> Indexing data for 20 iterations with flush=true
--> Indexing data for 20 iterations with flush=false
--> Indexing data for 30 iterations with flush=true
--> Indexing data for 30 iterations with flush=false
--> Indexing data for 40 iterations with flush=true
--> Indexing data for 40 iterations with flush=false
--> Indexing data for 50 iterations with flush=true
--> Indexing data for 50 iterations with flush=false
--> Indexing data for 60 iterations with flush=true
--> Indexing data for 60 iterations with flush=false
--> Indexing data for 70 iterations with flush=true
--> using storage_class [HDD]
--> using storage_class [Tape]
--> using storage_class [Cloud]
--> using storage_class [Flash]
--> using storage_class [Optical]
--> using storage_class [NAS]
--> using storage_class [SAN]
--> using storage_class [Hybrid]
--> using storage_class [RAID]
--> using storage_class [Object]
--> using storage_class [Disk]
--> using storage_class [Block]
--> using storage_class [Cache]
failed to prepare/warm ArrayIndexOutOfBoundsException
failed to prepare/warm FileNotFoundException
failed to prepare/warm NumberFormatException
failed to prepare/warm ClassCastException
failed to prepare/warm IllegalArgumentException
failed to prepare/warm ArithmeticException
failed to prepare/warm IOException
failed to prepare/warm InterruptedException
failed to prepare/warm NoSuchElementException
failed to prepare/warm OutOfMemoryError
failed to prepare/warm StackOverflowError
failed to prepare/warm NoSuchMethodError
failed to prepare/warm AssertionError
starting with resumable upload id [5b6e18f3a9]
starting with resumable upload id [e9c273ba01]
starting with resumable upload id [3f728a5ce0]
starting with resumable upload id [8d16b9f4a7]
starting with resumable upload id [bf4c8d102e]
starting with resumable upload id [2eacb3f65d]
starting with resumable upload id [fa6b829015]
starting with resumable upload id [64798eacb1]
starting with resumable upload id [1b3a9c86d4]
starting with resumable upload id [c6d90e27a4]
starting with resumable upload id [a0f4156bc3]
starting with resumable upload id [578d1ebcf1]
starting with resumable upload id [95e4d3b17f]
Building initial routing table with 20 indices
Building initial routing table with 30 indices
Building initial routing table with 40 indices
Building initial routing table with 50 indices
Building initial routing table with 60 indices
Building initial routing table with 70 indices
Building initial routing table with 80 indices
Building initial routing table with 90 indices
Building initial routing table with 100 indices
Building initial routing table with 110 indices
Building initial routing table with 120 indices
Building initial routing table with 130 indices
Building initial routing table with 140 indices
Done Balancing after 3 iterations. State: Warning
Done Balancing after 8 iterations. State: Error
Done Balancing after 5 iterations. State: OK
Done Balancing after 9 iterations. State: OK
Done Balancing after 6 iterations. State: Error
Done Balancing after 1 iterations. State: Warning
Done Balancing after 10 iterations. State: OK
Done Balancing after 7 iterations. State: OK
Done Balancing after 2 iterations. State: Error
Done Balancing after 4 iterations. State: Warning
Done Balancing after 11 iterations. State: OK
Done Balancing after 15 iterations. State: OK
Done Balancing after 13 iterations. State: Warning
removing node [node2]
removing node [node3]
removing node [node4]
removing node [node5]
removing node [node6]
removing node [node7]
removing node [node8]
removing node [node9]
removing node [node10]
removing node [node11]
removing node [node12]
removing node [node13]
removing node [node14]
resumable upload is composed of 5 total chunks (3 chunks of length 1024 and last chunk of length 768)
resumable upload is composed of 8 total chunks (6 chunks of length 512 and last chunk of length 384)
resumable upload is composed of 12 total chunks (9 chunks of length 256 and last chunk of length 192)
resumable upload is composed of 6 total chunks (4 chunks of length 512 and last chunk of length 384)
resumable upload is composed of 9 total chunks (7 chunks of length 256 and last chunk of length 192)
resumable upload is composed of 11 total chunks (8 chunks of length 128 and last chunk of length 96)
resumable upload is composed of 7 total chunks (5 chunks of length 256 and last chunk of length 192)
resumable upload is composed of 10 total chunks (7 chunks of length 128 and last chunk of length 96)
resumable upload is composed of 13 total chunks (10 chunks of length 128 and last chunk of length 96)
resumable upload is composed of 9 total chunks (6 chunks of length 256 and last chunk of length 192)
resumable upload is composed of 12 total chunks (9 chunks of length 128 and last chunk of length 96)
resumable upload is composed of 14 total chunks (11 chunks of length 128 and last chunk of length 96)
resumable upload is composed of 8 total chunks (5 chunks of length 512 and last chunk of length 384)
Exception occurred while getting segment files: FileNotFoundException
Exception occurred while getting segment files: IndexOutOfBoundsException
Exception occurred while getting segment files: IllegalArgumentException
Exception occurred while getting segment files: ArrayIndexOutOfBoundsException
Exception occurred while getting segment files: ClassCastException
Exception occurred while getting segment files: IOException
Exception occurred while getting segment files: UnsupportedOperationException
Exception occurred while getting segment files: NoSuchMethodException
Exception occurred while getting segment files: SecurityException
Exception occurred while getting segment files: InterruptedException
Exception occurred while getting segment files: OutOfMemoryError
Exception occurred while getting segment files: StackOverflowError
Exception occurred while getting segment files: IllegalStateException
Failed to close translog ArrayIndexOutOfBoundsException
Failed to close translog NullPointerException
Failed to close translog IllegalArgumentException
Failed to close translog IllegalStateException
Failed to close translog FileNotFoundException
Failed to close translog OutOfMemoryError
Failed to close translog StackOverflowError
Failed to close translog NoSuchMethodError
Failed to close translog ClassNotFoundException
Failed to close translog NumberFormatException
Failed to close translog IndexOutOfBoundsException
Failed to close translog UnsupportedOperationException
Failed to close translog AssertionError
using bucket [images], base_path [/mnt], chunk_size [2048], compress [false]
using bucket [logs], base_path [/var], chunk_size [4096], compress [true]
using bucket [documents], base_path [/home], chunk_size [8192], compress [false]
using bucket [videos], base_path [/media], chunk_size [16384], compress [true]
using bucket [temp], base_path [/tmp], chunk_size [32768], compress [false]
using bucket [backup], base_path [/backup], chunk_size [65536], compress [true]
using bucket [archives], base_path [/archives], chunk_size [131072], compress [false]
using bucket [exports], base_path [/exports], chunk_size [262144], compress [true]
using bucket [cache], base_path [/cache], chunk_size [524288], compress [false]
using bucket [media], base_path [/media], chunk_size [1048576], compress [true]
using bucket [temp], base_path [/tmp], chunk_size [2097152], compress [false]
using bucket [backup], base_path [/backup], chunk_size [4194304], compress [true]
using bucket [archives], base_path [/archives], chunk_size [8388608], compress [false]
--> Created index=products
--> Created index=orders
--> Created index=categories
--> Created index=inventory
--> Created index=customers
--> Created index=reviews
--> Created index=transactions
--> Created index=employees
--> Created index=suppliers
--> Created index=logs
--> Created index=messages
--> Created index=notifications
--> Created index=invoices
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
update ShardsLimitAllocationDecider.INDEX_TOTAL_SHARDS_PER_NODE_SETTING.getKey() for test, see that things move
engine closed [Out of memory]
engine closed [Connection lost]
engine closed [Invalid input]
engine closed [File not found]
engine closed [Database corruption]
engine closed [Network failure]
engine closed [Disk full]
engine closed [Unexpected shutdown]
engine closed [Authentication failure]
engine closed [Invalid request]
engine closed [Timeout]
engine closed [Resource exhaustion]
engine closed [Configuration error]
engine closed [Server overload]
--> Deleting the repository=repo2
--> Deleting the repository=repo3
--> Deleting the repository=repo4
--> Deleting the repository=repo5
--> Deleting the repository=repo6
--> Deleting the repository=repo7
--> Deleting the repository=repo8
--> Deleting the repository=repo9
--> Deleting the repository=repo10
--> Deleting the repository=repo11
--> Deleting the repository=repo12
--> Deleting the repository=repo13
--> Deleting the repository=repo14
not removing node [123] as it holds a primary with no replacement
not removing node [789] as it holds a primary with no replacement
not removing node [456] as it holds a primary with no replacement
not removing node [890] as it holds a primary with no replacement
not removing node [234] as it holds a primary with no replacement
not removing node [901] as it holds a primary with no replacement
not removing node [345] as it holds a primary with no replacement
not removing node [678] as it holds a primary with no replacement
not removing node [912] as it holds a primary with no replacement
not removing node [567] as it holds a primary with no replacement
not removing node [123] as it holds a primary with no replacement
not removing node [789] as it holds a primary with no replacement
not removing node [456] as it holds a primary with no replacement
listBlobsByPrefix(documents/)
listBlobsByPrefix(videos/)
listBlobsByPrefix(archives/)
listBlobsByPrefix(audio/)
listBlobsByPrefix(temp/)
listBlobsByPrefix(public/)
listBlobsByPrefix(private/)
listBlobsByPrefix(thumbnails/)
listBlobsByPrefix(files/)
listBlobsByPrefix(logs/)
listBlobsByPrefix(backup/)
listBlobsByPrefix(configs/)
listBlobsByPrefix(data/)
corrupting [copy] to /tmp/test. file name: [data.txt]
corrupting [move] to ~/backup. file name: [document.docx]
corrupting [rename] to /var/log/archive. file name: [log.txt]
corrupting [encrypt] to /home/user/encrypted. file name: [secret.pdf]
corrupting [compress] to /tmp/archive.zip. file name: [folder]
corrupting [delete] to /dev/null. file name: [image2.jpg]
corrupting [copy] to /tmp/test. file name: [data2.txt]
corrupting [move] to ~/backup. file name: [document2.docx]
corrupting [rename] to /var/log/archive. file name: [log2.txt]
corrupting [encrypt] to /home/user/encrypted. file name: [secret2.pdf]
corrupting [compress] to /tmp/archive.zip. file name: [folder2]
corrupting [delete] to /dev/null. file name: [image3.jpg]
corrupting [copy] to /tmp/test. file name: [data3.txt]
corrupting [move] to ~/backup. file name: [document3.docx]
Start iteration 2
Start iteration 3
Start iteration 4
Start iteration 5
Start iteration 6
Start iteration 7
Start iteration 8
Start iteration 9
Start iteration 10
Start iteration 11
Start iteration 12
Start iteration 13
Start iteration 14
Using Hadoop authentication method: KERBEROS
Using Hadoop authentication method: TOKEN
Using Hadoop authentication method: CUSTOM
Using Hadoop authentication method: PAM
Using Hadoop authentication method: LDAP
Using Hadoop authentication method: NOSASL
Using Hadoop authentication method: KERBEROS_SSL
Using Hadoop authentication method: DIGEST
Using Hadoop authentication method: SPNEGO
Using Hadoop authentication method: CUSTOM
Using Hadoop authentication method: SIMPLE
Using Hadoop authentication method: TOKEN
Using Hadoop authentication method: NOSASL
local initializations: [x, y, z], relocating: [a, b], need to initialize: false
local initializations: [q, r, s], relocating: [m, n, o], need to initialize: true
local initializations: [p], relocating: [q, r, s], need to initialize: false
local initializations: [t, u, v], relocating: [w], need to initialize: true
local initializations: [t, u, v], relocating: [l, m], need to initialize: false
local initializations: [e, f, g], relocating: [h, i, j, k], need to initialize: true
local initializations: [l, m], relocating: [n], need to initialize: false
local initializations: [o, p, q, r], relocating: [s, t], need to initialize: true
local initializations: [u, v, w], relocating: [a, b, c], need to initialize: false
local initializations: [x, y, z], relocating: [a, b, c], need to initialize: true
local initializations: [d, e, f, g], relocating: [h, i], need to initialize: false
local initializations: [h, i], relocating: [j, k], need to initialize: true
local initializations: [l, m, n], relocating: [j, k], need to initialize: false
local initializations: [l, m, n], relocating: [o, p, q], need to initialize: true
Hadoop security enabled: [false]
Hadoop security enabled: [true]
Hadoop security enabled: [false]
Hadoop security enabled: [true]
Hadoop security enabled: [false]
Hadoop security enabled: [true]
Hadoop security enabled: [false]
Hadoop security enabled: [true]
Hadoop security enabled: [false]
Hadoop security enabled: [true]
Hadoop security enabled: [false]
Hadoop security enabled: [true]
Hadoop security enabled: [false]
failed to rollback writer on close IOException
failed to rollback writer on close SQLException
failed to rollback writer on close FileNotFoundException
failed to rollback writer on close ArrayIndexOutOfBoundsException
failed to rollback writer on close NoSuchElementException
failed to rollback writer on close ClassNotFoundException
failed to rollback writer on close NumberFormatException
failed to rollback writer on close TimeoutException
failed to rollback writer on close InterruptedException
failed to rollback writer on close IllegalArgumentException
failed to rollback writer on close AssertionError
failed to rollback writer on close IllegalStateException
failed to rollback writer on close SecurityException
Engine is already closed.DatabaseException
Engine is already closed.IllegalStateException
Engine is already closed.ClosedEngineException
Engine is already closed.RuntimeException
Engine is already closed.ConnectionException
Engine is already closed.InvalidStateException
Engine is already closed.OperationFailedException
Engine is already closed.SecurityException
Engine is already closed.TimeoutException
Engine is already closed.IOError
Engine is already closed.ConfigurationException
Engine is already closed.NetworkException
Engine is already closed.UnexpectedException
Engine is already closed.AuthenticationException
[5] primaries should be still started but [5] other primaries should be unassigned
[7] primaries should be still started but [7] other primaries should be unassigned
[2] primaries should be still started but [2] other primaries should be unassigned
[6] primaries should be still started but [6] other primaries should be unassigned
[4] primaries should be still started but [4] other primaries should be unassigned
[1] primaries should be still started but [1] other primaries should be unassigned
[8] primaries should be still started but [8] other primaries should be unassigned
[9] primaries should be still started but [9] other primaries should be unassigned
[10] primaries should be still started but [10] other primaries should be unassigned
[11] primaries should be still started but [11] other primaries should be unassigned
[12] primaries should be still started but [12] other primaries should be unassigned
[13] primaries should be still started but [13] other primaries should be unassigned
[14] primaries should be still started but [14] other primaries should be unassigned
--> indexing [200] more docs
--> indexing [300] more docs
--> indexing [400] more docs
--> indexing [500] more docs
--> indexing [600] more docs
--> indexing [700] more docs
--> indexing [800] more docs
--> indexing [900] more docs
--> indexing [1000] more docs
--> indexing [1100] more docs
--> indexing [1200] more docs
--> indexing [1300] more docs
--> indexing [1400] more docs
starting segment upgrade upgradeOnlyAncientSegments=false
starting segment upgrade upgradeOnlyAncientSegments=1
starting segment upgrade upgradeOnlyAncientSegments=0
starting segment upgrade upgradeOnlyAncientSegments=on
starting segment upgrade upgradeOnlyAncientSegments=off
starting segment upgrade upgradeOnlyAncientSegments=yes
starting segment upgrade upgradeOnlyAncientSegments=no
starting segment upgrade upgradeOnlyAncientSegments=enabled
starting segment upgrade upgradeOnlyAncientSegments=disabled
starting segment upgrade upgradeOnlyAncientSegments=exclusive
starting segment upgrade upgradeOnlyAncientSegments=inclusive
starting segment upgrade upgradeOnlyAncientSegments=required
starting segment upgrade upgradeOnlyAncientSegments=optional
readBlob(file.txt) from position [100] with length [unlimited]
readBlob(socket.jpg) from position [50] with length [unlimited]
readBlob(data.bin) from position [200] with length [unlimited]
readBlob(video.mp4) from position [300] with length [unlimited]
readBlob(audio.wav) from position [150] with length [unlimited]
readBlob(presentation.pptx) from position [80] with length [unlimited]
readBlob(sheet.xlsx) from position [250] with length [unlimited]
readBlob(document.doc) from position [120] with length [unlimited]
readBlob(script.js) from position [30] with length [unlimited]
readBlob(style.css) from position [70] with length [unlimited]
readBlob(database.db) from position [180] with length [unlimited]
readBlob(code.java) from position [220] with length [unlimited]
readBlob(config.json) from position [270] with length [unlimited]
create 2 indices with [5] no replicas, and wait till all are allocated
create 2 indices with [7] no replicas, and wait till all are allocated
create 2 indices with [2] no replicas, and wait till all are allocated
create 2 indices with [4] no replicas, and wait till all are allocated
create 2 indices with [6] no replicas, and wait till all are allocated
create 2 indices with [1] no replicas, and wait till all are allocated
create 2 indices with [8] no replicas, and wait till all are allocated
create 2 indices with [9] no replicas, and wait till all are allocated
create 2 indices with [10] no replicas, and wait till all are allocated
create 2 indices with [12] no replicas, and wait till all are allocated
create 2 indices with [14] no replicas, and wait till all are allocated
create 2 indices with [11] no replicas, and wait till all are allocated
create 2 indices with [15] no replicas, and wait till all are allocated
--> indexing [200] docs
--> indexing [300] docs
--> indexing [400] docs
--> indexing [500] docs
--> indexing [600] docs
--> indexing [700] docs
--> indexing [800] docs
--> indexing [900] docs
--> indexing [1000] docs
--> indexing [1100] docs
--> indexing [1200] docs
--> indexing [1300] docs
--> indexing [1400] docs
session id [987b541e] is gone
session id [d394b3f8] is gone
session id [ef956df4] is gone
session id [27f431e9] is gone
session id [8df4c291] is gone
session id [146ce7b2] is gone
session id [c93f8a7d] is gone
session id [732efa64] is gone
session id [b448dc6c] is gone
session id [fe1a8d15] is gone
session id [609ca41b] is gone
session id [a4d68e03] is gone
session id [1b56cf89] is gone
Failed to close ReaderManager NullPointerException
Failed to close ReaderManager FileNotFoundException
Failed to close ReaderManager ArrayIndexOutOfBoundsException
Failed to close ReaderManager NoSuchElementException
Failed to close ReaderManager IllegalArgumentException
Failed to close ReaderManager IllegalStateException
Failed to close ReaderManager OutOfMemoryError
Failed to close ReaderManager StackOverflowError
Failed to close ReaderManager ClassNotFoundException
Failed to close ReaderManager IndexOutOfBoundsException
Failed to close ReaderManager ArithmeticException
Failed to close ReaderManager IllegalArgumentException
Failed to close ReaderManager IllegalStateException
blue nodes: yellowNodes
blue nodes: greenNodes
blue nodes: purpleNodes
blue nodes: orangeNodes
blue nodes: pinkNodes
blue nodes: brownNodes
blue nodes: grayNodes
blue nodes: whiteNodes
blue nodes: blackNodes
blue nodes: cyanNodes
blue nodes: magentaNodes
blue nodes: limeNodes
blue nodes: silverNodes
new commit on flush, hasUncommittedChanges:false, force:true, shouldPeriodicallyFlush:false
new commit on flush, hasUncommittedChanges:true, force:true, shouldPeriodicallyFlush:false
new commit on flush, hasUncommittedChanges:false, force:false, shouldPeriodicallyFlush:true
new commit on flush, hasUncommittedChanges:true, force:true, shouldPeriodicallyFlush:true
new commit on flush, hasUncommittedChanges:false, force:false, shouldPeriodicallyFlush:false
new commit on flush, hasUncommittedChanges:true, force:false, shouldPeriodicallyFlush:true
new commit on flush, hasUncommittedChanges:false, force:true, shouldPeriodicallyFlush:false
new commit on flush, hasUncommittedChanges:true, force:true, shouldPeriodicallyFlush:false
new commit on flush, hasUncommittedChanges:false, force:false, shouldPeriodicallyFlush:true
new commit on flush, hasUncommittedChanges:true, force:true, shouldPeriodicallyFlush:true
new commit on flush, hasUncommittedChanges:false, force:false, shouldPeriodicallyFlush:false
new commit on flush, hasUncommittedChanges:true, force:false, shouldPeriodicallyFlush:true
new commit on flush, hasUncommittedChanges:false, force:true, shouldPeriodicallyFlush:false
--> blocking recoveries from primary (allowed failures: [network connection])
--> blocking recoveries from primary (allowed failures: [hardware failure])
--> blocking recoveries from primary (allowed failures: [timeout])
--> blocking recoveries from primary (allowed failures: [insufficient resources])
--> blocking recoveries from primary (allowed failures: [authentication failure])
--> blocking recoveries from primary (allowed failures: [database error])
--> blocking recoveries from primary (allowed failures: [invalid input])
--> blocking recoveries from primary (allowed failures: [memory leak])
--> blocking recoveries from primary (allowed failures: [permission denied])
--> blocking recoveries from primary (allowed failures: [disk full])
--> blocking recoveries from primary (allowed failures: [file not found])
--> blocking recoveries from primary (allowed failures: [service not available])
--> blocking recoveries from primary (allowed failures: [server crash])
blobExists(image.jpg)
blobExists(document.docx)
blobExists(video.mp4)
blobExists(audio.wav)
blobExists(folder1/)
blobExists(folder2/)
blobExists(folder3/)
blobExists(data.csv)
blobExists(script.js)
blobExists(style.css)
blobExists(config.xml)
blobExists(database.sql)
blobExists(icon.ico)
--> index [25] documents
--> index [3] documents
--> index [8] documents
--> index [16] documents
--> index [5] documents
--> index [20] documents
--> index [14] documents
--> index [7] documents
--> index [12] documents
--> index [2] documents
--> index [9] documents
--> index [18] documents
--> index [6] documents
--> index [11] documents
From: DEF456 with Version: 2.5 to: GHI789 with Version: 3.8
From: JKL012 with Version: 3.2 to: MNO345 with Version: 4.1
From: PQR678 with Version: 4.5 to: STU901 with Version: 5.3
From: VWX234 with Version: 5.6 to: YZA567 with Version: 6.2
From: BCD890 with Version: 6.7 to: EFG123 with Version: 7.4
From: HIJ456 with Version: 7.9 to: KLM789 with Version: 8.6
From: NOP012 with Version: 8.1 to: QRS345 with Version: 9.0
From: TUV678 with Version: 9.3 to: WXY901 with Version: 10.2
From: ZAB234 with Version: 10.5 to: CDE567 with Version: 11.1
From: FGH890 with Version: 11.4 to: IJK123 with Version: 12.7
From: LMN456 with Version: 12.9 to: OPQ789 with Version: 13.4
From: RST012 with Version: 13.6 to: UVW345 with Version: 14.0
From: XYZ678 with Version: 14.3 to: YZA901 with Version: 15.2
From: BCD234 with Version: 15.5 to: EFG567 with Version: 16.1
Couldn't mark store corrupted: NullPointerException
Couldn't mark store corrupted: IndexOutOfBoundsException
Couldn't mark store corrupted: FileNotFoundException
Couldn't mark store corrupted: ClassCastException
Couldn't mark store corrupted: StackOverflowError
Couldn't mark store corrupted: IllegalArgumentException
Couldn't mark store corrupted: UnsupportedOperationException
Couldn't mark store corrupted: ConcurrentModificationException
Couldn't mark store corrupted: NumberFormatException
Couldn't mark store corrupted: OutOfMemoryError
Couldn't mark store corrupted: NoClassDefFoundError
Couldn't mark store corrupted: NoSuchMethodError
Couldn't mark store corrupted: ArrayIndexOutOfBoundsException
extracted content: text_2
extracted content: text_3
extracted content: text_4
extracted content: text_5
extracted content: text_6
extracted content: text_7
extracted content: text_8
extracted content: text_9
extracted content: text_10
extracted content: text_11
extracted content: text_12
extracted content: text_13
extracted content: text_14
failEngine threw exception ArrayIndexOutOfBoundsException
failEngine threw exception ClassCastException
failEngine threw exception IllegalArgumentException
failEngine threw exception IllegalStateException
failEngine threw exception IndexOutOfBoundsException
failEngine threw exception NoSuchElementException
failEngine threw exception NumberFormatException
failEngine threw exception NullPointerException
failEngine threw exception StringIndexOutOfBoundsException
failEngine threw exception UnsupportedOperationException
failEngine threw exception ConcurrentModificationException
failEngine threw exception FileNotFoundException
failEngine threw exception IOException
failed to access searcher manager IOException
failed to access searcher manager NullPointerException
failed to access searcher manager FileNotFoundException
failed to access searcher manager ArrayIndexOutOfBoundsException
failed to access searcher manager SQLException
failed to access searcher manager ClassNotFoundException
failed to access searcher manager OutOfMemoryError
failed to access searcher manager StackOverflowError
failed to access searcher manager IllegalArgumentException
failed to access searcher manager NumberFormatException
failed to access searcher manager ClassCastException
failed to access searcher manager NoSuchElementException
failed to access searcher manager IndexOutOfBoundsException
Failing NullPointerException
Failing ArrayIndexOutOfBoundsException
Failing IllegalArgumentException
Failing UnsupportedOperationException
Failing ClassNotFoundException
Failing ArithmeticException
Failing ClassCastException
Failing OutOfMemoryError
Failing StackOverflowError
Failing NoClassDefFoundError
Failing FileNotFoundException
Failing IOException
Failing InterruptedException
Missing id [abc]
Missing id [XYZ]
Missing id [456]
Missing id [def]
Missing id [789]
Missing id [ghi]
Missing id [012]
Missing id [jkl]
Missing id [345]
Missing id [mno]
Missing id [678]
Missing id [pqr]
Missing id [901]
Missing id [stu]
Safe commit [Add new feature for user registration], last commit [Update UI styling]
Safe commit [Optimize performance of search algorithm], last commit [Resolve merge conflicts]
Safe commit [Implement new authentication method], last commit [Fix issue with data validation]
Safe commit [Integrate third-party API], last commit [Improve error handling mechanism]
Safe commit [Add unit tests for key functionalities], last commit [Update documentation]
Safe commit [Fix security vulnerability], last commit [Implement caching system]
Safe commit [Improve logging mechanism], last commit [Refactor code structure]
Safe commit [Update dependencies], last commit [Remove deprecated code]
Safe commit [Enhance user experience], last commit [Optimize database queries]
Safe commit [Add error handling for edge cases], last commit [Update configuration settings]
Safe commit [Implement new feature], last commit [Fix issue with data storage]
Safe commit [Modify user permissions], last commit [Improve error messages]
Safe commit [Refactor code for better readability], last commit [Resolve compatibility issues]
Safe commit [Update user interface elements], last commit [Implement pagination mechanism]
Delete index commit [Fix bug #1234]
Delete index commit [Add new feature]
Delete index commit [Refactor code]
Delete index commit [Update dependencies]
Delete index commit [Merge branch 'develop']
Delete index commit [Implement user authentication]
Delete index commit [Optimize database queries]
Delete index commit [Fix security vulnerability]
Delete index commit [Update README.md]
Delete index commit [Remove deprecated code]
Delete index commit [Add unit tests]
Delete index commit [Improve error handling]
Delete index commit [Fix broken link]
failed to invoke on store closed ArrayIndexOutOfBoundsException
failed to invoke on store closed FileNotFoundException
failed to invoke on store closed IllegalArgumentException
failed to invoke on store closed IOException
failed to invoke on store closed NoSuchElementException
failed to invoke on store closed NumberFormatException
failed to invoke on store closed ClassCastException
failed to invoke on store closed OutOfMemoryError
failed to invoke on store closed StackOverflowError
failed to invoke on store closed NoSuchMethodError
failed to invoke on store closed IllegalAccessException
failed to invoke on store closed IllegalStateException
failed to invoke on store closed IndexOutOfBoundsException
failed to read latest segment infos on flush E_pK6Y75q1
failed to read latest segment infos on flush E_6MGg8In3
failed to read latest segment infos on flush E_qJ1ArOs8
failed to read latest segment infos on flush E_ur9MsRz4
failed to read latest segment infos on flush E_yS2CiNj9
failed to read latest segment infos on flush E_tKq4JsN5
failed to read latest segment infos on flush E_zH7GvVk2
failed to read latest segment infos on flush E_kOp9HqJ1
failed to read latest segment infos on flush E_rY5ItYm3
failed to read latest segment infos on flush E_cOp9HqJ1
failed to read latest segment infos on flush E_bY5ItYm3
failed to read latest segment infos on flush E_iOp9HqJ1
failed to read latest segment infos on flush E_aY5ItYm3
--> all shards allocated, replica that should be promoted: replica2
--> all shards allocated, replica that should be promoted: replica3
--> all shards allocated, replica that should be promoted: replica4
--> all shards allocated, replica that should be promoted: replica5
--> all shards allocated, replica that should be promoted: replica6
--> all shards allocated, replica that should be promoted: replica7
--> all shards allocated, replica that should be promoted: replica8
--> all shards allocated, replica that should be promoted: replica9
--> all shards allocated, replica that should be promoted: replica10
--> all shards allocated, replica that should be promoted: replica11
--> all shards allocated, replica that should be promoted: replica12
--> all shards allocated, replica that should be promoted: replica13
--> all shards allocated, replica that should be promoted: replica14
Generated password: x3M6k7P2
Generated password: s9RtY5nW
Generated password: q6PzS1vF
Generated password: e2HnR7dL
Generated password: b5XrM3sV
Generated password: j7NtB4eG
Generated password: p1VyQ6zA
Generated password: w9LmF2tP
Generated password: h3GsX8nB
Generated password: u5DjW7xR
Generated password: o9VpK3bH
Generated password: r7SdZ5cN
Generated password: y3FtH6vP
--> START search test round 2
--> START search test round 3
--> START search test round 4
--> START search test round 5
--> START search test round 6
--> START search test round 7
--> START search test round 8
--> START search test round 9
--> START search test round 10
--> START search test round 11
--> START search test round 12
--> START search test round 13
--> START search test round 14
recovered maximum sequence number [789] and local checkpoint [234]
recovered maximum sequence number [567] and local checkpoint [890]
recovered maximum sequence number [432] and local checkpoint [678]
recovered maximum sequence number [901] and local checkpoint [345]
recovered maximum sequence number [678] and local checkpoint [012]
recovered maximum sequence number [345] and local checkpoint [789]
recovered maximum sequence number [890] and local checkpoint [567]
recovered maximum sequence number [654] and local checkpoint [901]
recovered maximum sequence number [321] and local checkpoint [678]
recovered maximum sequence number [098] and local checkpoint [345]
recovered maximum sequence number [876] and local checkpoint [890]
recovered maximum sequence number [543] and local checkpoint [012]
recovered maximum sequence number [210] and local checkpoint [789]
failing shard on node [node2]
failing shard on node [node3]
failing shard on node [node4]
failing shard on node [node5]
failing shard on node [node6]
failing shard on node [node7]
failing shard on node [node8]
failing shard on node [node9]
failing shard on node [node10]
failing shard on node [node11]
failing shard on node [node12]
failing shard on node [node13]
failing shard on node [node14]
failed to invoke before index added to cluster callback AssertionError
failed to invoke before index added to cluster callback NullPointerException
failed to invoke before index added to cluster callback IllegalArgumentException
failed to invoke before index added to cluster callback ArrayIndexOutOfBoundsException
failed to invoke before index added to cluster callback ClassCastException
failed to invoke before index added to cluster callback ArithmeticException
failed to invoke before index added to cluster callback IndexOutOfBoundsException
failed to invoke before index added to cluster callback IOException
failed to invoke before index added to cluster callback FileNotFoundException
failed to invoke before index added to cluster callback NoSuchElementException
failed to invoke before index added to cluster callback NumberFormatException
failed to invoke before index added to cluster callback OutOfMemoryError
failed to invoke before index added to cluster callback StackOverflowError
--> DONE relocate the shard from node3 to node4
--> DONE relocate the shard from node5 to node6
--> DONE relocate the shard from node7 to node8
--> DONE relocate the shard from node9 to node10
--> DONE relocate the shard from node11 to node12
--> DONE relocate the shard from node13 to node14
--> DONE relocate the shard from node15 to node16
--> DONE relocate the shard from node17 to node18
--> DONE relocate the shard from node19 to node20
--> DONE relocate the shard from node21 to node22
--> DONE relocate the shard from node23 to node24
--> DONE relocate the shard from node25 to node26
--> DONE relocate the shard from node27 to node28
--> START relocate the shard from Node3 to Node4
--> START relocate the shard from Node5 to Node6
--> START relocate the shard from Node7 to Node8
--> START relocate the shard from Node9 to Node10
--> START relocate the shard from Node11 to Node12
--> START relocate the shard from Node13 to Node14
--> START relocate the shard from Node15 to Node16
--> START relocate the shard from Node17 to Node18
--> START relocate the shard from Node19 to Node20
--> START relocate the shard from Node21 to Node22
--> START relocate the shard from Node23 to Node24
--> START relocate the shard from Node25 to Node26
--> START relocate the shard from Node27 to Node28
--> new primary is on version 2.6.0: 192.168.0.2
--> new primary is on version 3.0.0: 192.168.0.3
--> new primary is on version 3.2.1: 192.168.0.4
--> new primary is on version 4.1.2: 192.168.0.5
--> new primary is on version 4.5.6: 192.168.0.6
--> new primary is on version 5.0.0: 192.168.0.7
--> new primary is on version 5.4.3: 192.168.0.8
--> new primary is on version 6.2.1: 192.168.0.9
--> new primary is on version 7.0.0: 192.168.0.10
--> new primary is on version 7.3.2: 192.168.0.11
--> new primary is on version 8.1.4: 192.168.0.12
--> new primary is on version 8.5.0: 192.168.0.13
--> new primary is on version 9.0.2: 192.168.0.14
--> Simulate GCE Auth/Metadata response for [https://api.example.com]
--> Simulate GCE Auth/Metadata response for [https://dev.example.com]
--> Simulate GCE Auth/Metadata response for [https://test.example.com]
--> Simulate GCE Auth/Metadata response for [https://staging.example.com]
--> Simulate GCE Auth/Metadata response for [https://prod.example.com]
--> Simulate GCE Auth/Metadata response for [https://sandbox.example.com]
--> Simulate GCE Auth/Metadata response for [https://uat.example.com]
--> Simulate GCE Auth/Metadata response for [https://demo.example.com]
--> Simulate GCE Auth/Metadata response for [https://stg.example.com]
--> Simulate GCE Auth/Metadata response for [https://localhost:8080]
--> Simulate GCE Auth/Metadata response for [https://internal.example.com]
--> Simulate GCE Auth/Metadata response for [https://qa.example.com]
--> Simulate GCE Auth/Metadata response for [https://preprod.example.com]
failed to invoke after index removed callback RuntimeException
failed to invoke after index removed callback NullPointerException
failed to invoke after index removed callback IndexOutOfBoundsException
failed to invoke after index removed callback ArrayIndexOutOfBoundsException
failed to invoke after index removed callback ClassCastException
failed to invoke after index removed callback IllegalArgumentException
failed to invoke after index removed callback IllegalStateException
failed to invoke after index removed callback UnsupportedOperationException
failed to invoke after index removed callback ConcurrentModificationException
failed to invoke after index removed callback NoSuchElementException
failed to invoke after index removed callback NumberFormatException
failed to invoke after index removed callback ArithmeticException
failed to invoke after index removed callback OutOfMemoryError
--> Allow indexer to index [200] documents
--> Allow indexer to index [300] documents
--> Allow indexer to index [400] documents
--> Allow indexer to index [500] documents
--> Allow indexer to index [600] documents
--> Allow indexer to index [700] documents
--> Allow indexer to index [800] documents
--> Allow indexer to index [900] documents
--> Allow indexer to index [1000] documents
--> Allow indexer to index [1100] documents
--> Allow indexer to index [1200] documents
--> Allow indexer to index [1300] documents
--> Allow indexer to index [1400] documents
--> Simulate GCE API response for [https://www.example.com]
--> Simulate GCE API response for [https://www.yahoo.com]
--> Simulate GCE API response for [https://www.bing.com]
--> Simulate GCE API response for [https://www.amazon.com]
--> Simulate GCE API response for [https://www.facebook.com]
--> Simulate GCE API response for [https://www.apple.com]
--> Simulate GCE API response for [https://www.microsoft.com]
--> Simulate GCE API response for [https://www.netflix.com]
--> Simulate GCE API response for [https://www.spotify.com]
--> Simulate GCE API response for [https://www.twitter.com]
--> Simulate GCE API response for [https://www.instagram.com]
--> Simulate GCE API response for [https://www.linkedin.com]
--> Simulate GCE API response for [https://www.reddit.com]
failed to invoke after index created callback Error
failed to invoke after index created callback Warning
failed to invoke after index created callback NullPointer
failed to invoke after index created callback IllegalArgument
failed to invoke after index created callback ClassNotFound
failed to invoke after index created callback RuntimeException
failed to invoke after index created callback ArrayIndexOutOfBounds
failed to invoke after index created callback NoSuchMethod
failed to invoke after index created callback OutOfMemory
failed to invoke after index created callback StackOverflow
failed to invoke after index created callback InterruptedException
failed to invoke after index created callback AssertionFailed
failed to invoke after index created callback NoClassDefFound
--> node [207] has version [5.7]
--> node [512] has version [1.9]
--> node [415] has version [3.2]
--> node [309] has version [4.6]
--> node [621] has version [2.1]
--> node [714] has version [6.5]
--> node [918] has version [3.9]
--> node [826] has version [1.7]
--> node [127] has version [5.4]
--> node [431] has version [2.9]
--> node [934] has version [4.2]
--> node [239] has version [3.6]
--> node [542] has version [7.1]
kill the node [node2] of the primary shard for the relocating replica
kill the node [node3] of the primary shard for the relocating replica
kill the node [node4] of the primary shard for the relocating replica
kill the node [node5] of the primary shard for the relocating replica
kill the node [node6] of the primary shard for the relocating replica
kill the node [node7] of the primary shard for the relocating replica
kill the node [node8] of the primary shard for the relocating replica
kill the node [node9] of the primary shard for the relocating replica
kill the node [node10] of the primary shard for the relocating replica
kill the node [node11] of the primary shard for the relocating replica
kill the node [node12] of the primary shard for the relocating replica
kill the node [node13] of the primary shard for the relocating replica
kill the node [node14] of the primary shard for the relocating replica
--> candidate on 2 node; shard routing: replica
--> candidate on 3 node; shard routing: primary
--> candidate on 4 node; shard routing: replica
--> candidate on 5 node; shard routing: primary
--> candidate on 6 node; shard routing: replica
--> candidate on 7 node; shard routing: primary
--> candidate on 8 node; shard routing: replica
--> candidate on 9 node; shard routing: primary
--> candidate on 10 node; shard routing: replica
--> candidate on 11 node; shard routing: primary
--> candidate on 12 node; shard routing: replica
--> candidate on 13 node; shard routing: primary
--> candidate on 14 node; shard routing: replica
time: [9:15 AM]
time: [12:45 PM]
time: [7:27 PM]
time: [3:50 AM]
time: [6:18 PM]
time: [10:11 AM]
time: [2:37 PM]
time: [8:59 AM]
time: [1:20 PM]
time: [5:45 PM]
time: [11:23 AM]
time: [6:51 PM]
time: [3:13 AM]
--> starting node2 ...
--> starting node3 ...
--> starting node4 ...
--> starting node5 ...
--> starting node6 ...
--> starting node7 ...
--> starting node8 ...
--> starting node9 ...
--> starting node10 ...
--> starting node11 ...
--> starting node12 ...
--> starting node13 ...
--> starting node14 ...
full cache clear, reason out of memory
full cache clear, reason configuration update
full cache clear, reason data corruption
full cache clear, reason server restart
full cache clear, reason security breach
full cache clear, reason application crash
full cache clear, reason database connection failure
full cache clear, reason disk failure
full cache clear, reason unauthorized access
full cache clear, reason software update
full cache clear, reason performance optimization
full cache clear, reason data inconsistency
full cache clear, reason cache overflow
current node found. Ignoring node_2 - 192.168.0.2
current node found. Ignoring node_3 - 192.168.0.3
current node found. Ignoring node_4 - 192.168.0.4
current node found. Ignoring node_5 - 192.168.0.5
current node found. Ignoring node_6 - 192.168.0.6
current node found. Ignoring node_7 - 192.168.0.7
current node found. Ignoring node_8 - 192.168.0.8
current node found. Ignoring node_9 - 192.168.0.9
current node found. Ignoring node_10 - 192.168.0.10
current node found. Ignoring node_11 - 192.168.0.11
current node found. Ignoring node_12 - 192.168.0.12
current node found. Ignoring node_13 - 192.168.0.13
current node found. Ignoring node_14 - 192.168.0.14
adding server2, type database, address 192.168.1.20, transport_address 192.168.1.20:3306, status offline
adding server3, type server, address 192.168.1.30, transport_address 192.168.1.30:22, status online
adding server4, type web, address 192.168.1.40, transport_address 192.168.1.40:8080, status online
adding server5, type database, address 192.168.1.50, transport_address 192.168.1.50:3306, status offline
adding server6, type server, address 192.168.1.60, transport_address 192.168.1.60:22, status online
adding server7, type web, address 192.168.1.70, transport_address 192.168.1.70:8080, status online
adding server8, type database, address 192.168.1.80, transport_address 192.168.1.80:3306, status offline
adding server9, type server, address 192.168.1.90, transport_address 192.168.1.90:22, status online
adding server10, type web, address 192.168.1.100, transport_address 192.168.1.100:8080, status online
adding server11, type database, address 192.168.1.110, transport_address 192.168.1.110:3306, status offline
adding server12, type server, address 192.168.1.120, transport_address 192.168.1.120:22, status online
adding server13, type web, address 192.168.1.130, transport_address 192.168.1.130:8080, status online
adding server14, type database, address 192.168.1.140, transport_address 192.168.1.140:3306, status offline
using transport addresses 10.0.0.1
using transport addresses 192.168.1.1
using transport addresses 172.16.0.1
using transport addresses 10.1.1.1
using transport addresses 192.168.0.1
using transport addresses 172.17.0.1
using transport addresses 10.2.2.2
using transport addresses 192.168.2.2
using transport addresses 172.18.0.1
using transport addresses 10.3.3.3
using transport addresses 192.168.3.3
using transport addresses 172.19.0.1
using transport addresses 10.4.4.4
iteration 2 - returned documents: 85 (expected 150)
iteration 3 - returned documents: 120 (expected 150)
iteration 4 - returned documents: 135 (expected 150)
iteration 5 - returned documents: 140 (expected 150)
iteration 6 - returned documents: 155 (expected 150)
iteration 7 - returned documents: 110 (expected 150)
iteration 8 - returned documents: 125 (expected 150)
iteration 9 - returned documents: 95 (expected 150)
iteration 10 - returned documents: 105 (expected 150)
iteration 11 - returned documents: 145 (expected 150)
iteration 12 - returned documents: 130 (expected 150)
iteration 13 - returned documents: 90 (expected 150)
iteration 14 - returned documents: 115 (expected 150)
clearing all bitsets because new data arrived
clearing all bitsets because memory is low
clearing all bitsets because timeout occurred
clearing all bitsets because invalid data received
clearing all bitsets because system shutdown
clearing all bitsets because error in processing
clearing all bitsets because out of disk space
clearing all bitsets because data corruption
clearing all bitsets because overload occurred
clearing all bitsets because connection lost
clearing all bitsets because invalid configuration
clearing all bitsets because file not found
clearing all bitsets because network failure
--> state before failing shards: inactive
--> state before failing shards: degraded
--> state before failing shards: error
--> state before failing shards: standby
--> state before failing shards: offline
--> state before failing shards: maintenance
--> state before failing shards: unknown
--> state before failing shards: pending
--> state before failing shards: paused
--> state before failing shards: blocked
--> state before failing shards: initializing
--> state before failing shards: resyncing
--> state before failing shards: deleting
testRelocationWhileIndexingRandom(numRelocations=5, numberOfReplicas=2, numberOfNodes=7)
testRelocationWhileIndexingRandom(numRelocations=8, numberOfReplicas=4, numberOfNodes=3)
testRelocationWhileIndexingRandom(numRelocations=7, numberOfReplicas=5, numberOfNodes=2)
testRelocationWhileIndexingRandom(numRelocations=3, numberOfReplicas=6, numberOfNodes=4)
testRelocationWhileIndexingRandom(numRelocations=6, numberOfReplicas=3, numberOfNodes=5)
testRelocationWhileIndexingRandom(numRelocations=5, numberOfReplicas=7, numberOfNodes=2)
testRelocationWhileIndexingRandom(numRelocations=4, numberOfReplicas=2, numberOfNodes=8)
testRelocationWhileIndexingRandom(numRelocations=9, numberOfReplicas=5, numberOfNodes=1)
testRelocationWhileIndexingRandom(numRelocations=2, numberOfReplicas=7, numberOfNodes=3)
testRelocationWhileIndexingRandom(numRelocations=6, numberOfReplicas=4, numberOfNodes=2)
testRelocationWhileIndexingRandom(numRelocations=4, numberOfReplicas=1, numberOfNodes=9)
testRelocationWhileIndexingRandom(numRelocations=8, numberOfReplicas=6, numberOfNodes=3)
testRelocationWhileIndexingRandom(numRelocations=3, numberOfReplicas=2, numberOfNodes=7)
--> counts: total: 150, unassigned: 15, initializing: 25, relocating: 8, started: 102
--> counts: total: 200, unassigned: 20, initializing: 35, relocating: 10, started: 135
--> counts: total: 110, unassigned: 12, initializing: 18, relocating: 4, started: 76
--> counts: total: 80, unassigned: 8, initializing: 15, relocating: 3, started: 54
--> counts: total: 120, unassigned: 11, initializing: 17, relocating: 5, started: 87
--> counts: total: 160, unassigned: 15, initializing: 22, relocating: 7, started: 114
--> counts: total: 90, unassigned: 9, initializing: 14, relocating: 3, started: 64
--> counts: total: 130, unassigned: 13, initializing: 20, relocating: 5, started: 91
--> counts: total: 180, unassigned: 17, initializing: 28, relocating: 8, started: 123
--> counts: total: 70, unassigned: 7, initializing: 12, relocating: 2, started: 49
--> counts: total: 140, unassigned: 14, initializing: 19, relocating: 6, started: 98
--> counts: total: 100, unassigned: 10, initializing: 20, relocating: 5, started: 65
--> counts: total: 150, unassigned: 15, initializing: 25, relocating: 8, started: 102
opensearch_port is instance of java.lang.String. Ignoring...
opensearch_port is instance of java.util.List. Ignoring...
opensearch_port is instance of java.util.Map. Ignoring...
opensearch_port is instance of java.util.Set. Ignoring...
opensearch_port is instance of java.io.File. Ignoring...
opensearch_port is instance of java.net.Socket. Ignoring...
opensearch_port is instance of java.util.Date. Ignoring...
opensearch_port is instance of java.util.ArrayList. Ignoring...
opensearch_port is instance of java.lang.Double. Ignoring...
opensearch_port is instance of java.util.HashMap. Ignoring...
opensearch_port is instance of java.lang.Boolean. Ignoring...
opensearch_port is instance of java.util.HashSet. Ignoring...
opensearch_port is instance of java.lang.Float. Ignoring...
iteration [2] - failed shards: 0 (expected 0)
iteration [3] - failed shards: 1 (expected 0)
iteration [4] - failed shards: 2 (expected 0)
iteration [5] - failed shards: 0 (expected 0)
iteration [6] - failed shards: 4 (expected 0)
iteration [7] - failed shards: 0 (expected 0)
iteration [8] - failed shards: 2 (expected 0)
iteration [9] - failed shards: 1 (expected 0)
iteration [10] - failed shards: 0 (expected 0)
iteration [11] - failed shards: 0 (expected 0)
iteration [12] - failed shards: 3 (expected 0)
iteration [13] - failed shards: 0 (expected 0)
iteration [14] - failed shards: 2 (expected 0)
--> using shard size [2048]
--> using shard size [4096]
--> using shard size [8192]
--> using shard size [16384]
--> using shard size [32768]
--> using shard size [65536]
--> using shard size [131072]
--> using shard size [262144]
--> using shard size [524288]
--> using shard size [1048576]
--> using shard size [2097152]
--> using shard size [4194304]
--> using shard size [8388608]
--> using shard size [16777216]
filtering out instance resource-2 based tags ['tag3', 'tag4'], not part of {'tag3': 'value3', 'tag4': 'value4'}
filtering out instance resource-3 based tags ['tag5', 'tag6'], not part of {'tag5': 'value5', 'tag6': 'value6'}
filtering out instance resource-4 based tags [], not part of {}
filtering out instance resource-5 based tags [], not part of {}
filtering out instance resource-6 based tags [], not part of {}
filtering out instance resource-7 based tags [], not part of {}
filtering out instance resource-8 based tags [], not part of {}
filtering out instance resource-9 based tags [], not part of {}
filtering out instance resource-10 based tags [], not part of {}
filtering out instance resource-11 based tags [], not part of {}
filtering out instance resource-12 based tags [], not part of {}
filtering out instance resource-13 based tags [], not part of {}
filtering out instance resource-14 based tags [], not part of {}
opensearch_port is defined with 9300
opensearch_port is defined with 5601
opensearch_port is defined with 8080
opensearch_port is defined with 9201
opensearch_port is defined with 5602
opensearch_port is defined with 9301
opensearch_port is defined with 8081
opensearch_port is defined with 9202
opensearch_port is defined with 5603
opensearch_port is defined with 9302
opensearch_port is defined with 8082
opensearch_port is defined with 9203
opensearch_port is defined with 5604
failed to invoke before index created callback RuntimeException
failed to invoke before index created callback IOException
failed to invoke before index created callback NullPointerException
failed to invoke before index created callback ArrayIndexOutOfBoundsException
failed to invoke before index created callback IllegalArgumentException
failed to invoke before index created callback SQLException
failed to invoke before index created callback FileNotFoundException
failed to invoke before index created callback NoSuchElementException
failed to invoke before index created callback ClassCastException
failed to invoke before index created callback OutOfMemoryError
failed to invoke before index created callback StackOverflowError
failed to invoke before index created callback UnsupportedOperationException
failed to invoke before index created callback AssertionError
--> nodeWithoutPrimary: node2
--> nodeWithoutPrimary: node3
--> nodeWithoutPrimary: node4
--> nodeWithoutPrimary: node5
--> nodeWithoutPrimary: node6
--> nodeWithoutPrimary: node7
--> nodeWithoutPrimary: node8
--> nodeWithoutPrimary: node9
--> nodeWithoutPrimary: node10
--> nodeWithoutPrimary: node11
--> nodeWithoutPrimary: node12
--> nodeWithoutPrimary: node13
--> nodeWithoutPrimary: node14
iteration [2] - successful shards: 4 (expected 6)
iteration [3] - successful shards: 6 (expected 6)
iteration [4] - successful shards: 6 (expected 6)
iteration [5] - successful shards: 4 (expected 6)
iteration [6] - successful shards: 6 (expected 6)
iteration [7] - successful shards: 5 (expected 6)
iteration [8] - successful shards: 5 (expected 6)
iteration [9] - successful shards: 6 (expected 6)
iteration [10] - successful shards: 6 (expected 6)
iteration [11] - successful shards: 4 (expected 6)
iteration [12] - successful shards: 6 (expected 6)
iteration [13] - successful shards: 5 (expected 6)
iteration [14] - successful shards: 4 (expected 6)
instance server002 with tags development, app-server is added to discovery
instance server003 with tags testing, web-server is added to discovery
instance server004 with tags production, web-server is added to discovery
instance server005 with tags development, database is added to discovery
instance server006 with tags testing, app-server is added to discovery
instance server007 with tags production, database is added to discovery
instance server008 with tags development, web-server is added to discovery
instance server009 with tags testing, app-server is added to discovery
instance server010 with tags production, app-server is added to discovery
instance server011 with tags development, web-server is added to discovery
instance server012 with tags testing, database is added to discovery
instance server013 with tags production, web-server is added to discovery
instance server014 with tags development, database is added to discovery
no tags for this instance but we asked for tags. test won't be part of the cluster.
no tags for this instance but we asked for tags. production won't be part of the cluster.
no tags for this instance but we asked for tags. dev won't be part of the cluster.
no tags for this instance but we asked for tags. staging won't be part of the cluster.
no tags for this instance but we asked for tags. qa won't be part of the cluster.
no tags for this instance but we asked for tags. backup won't be part of the cluster.
no tags for this instance but we asked for tags. database won't be part of the cluster.
no tags for this instance but we asked for tags. server won't be part of the cluster.
no tags for this instance but we asked for tags. loadbalancer won't be part of the cluster.
no tags for this instance but we asked for tags. app won't be part of the cluster.
no tags for this instance but we asked for tags. web won't be part of the cluster.
no tags for this instance but we asked for tags. worker won't be part of the cluster.
no tags for this instance but we asked for tags. gateway won't be part of the cluster.
Setting up tests for src node B and target node 2
Setting up tests for src node C and target node 3
Setting up tests for src node D and target node 4
Setting up tests for src node E and target node 5
Setting up tests for src node F and target node 6
Setting up tests for src node G and target node 7
Setting up tests for src node H and target node 8
Setting up tests for src node I and target node 9
Setting up tests for src node J and target node 10
Setting up tests for src node K and target node 11
Setting up tests for src node L and target node 12
Setting up tests for src node M and target node 13
Setting up tests for src node N and target node 14
shard [7] - count 250, primary false
shard [9] - count 500, primary true
shard [1] - count 150, primary true
shard [5] - count 300, primary false
shard [12] - count 400, primary true
shard [8] - count 200, primary false
shard [6] - count 450, primary true
shard [2] - count 175, primary true
shard [4] - count 275, primary false
shard [11] - count 350, primary true
shard [10] - count 225, primary false
shard [14] - count 600, primary true
shard [13] - count 400, primary true
Invalid format, from file: data.csv, exception is: FormatException
Access denied, from file: secret.docx, exception is: PermissionDeniedException
Connection timeout, from file: server.log, exception is: TimeoutException
Corrupted data, from file: backup.bak, exception is: DataCorruptionException
Invalid input, from file: input.txt, exception is: InputValidationException
Server error, from file: error.log, exception is: ServerErrorException
Invalid credentials, from file: credentials.json, exception is: AuthenticationException
File locked, from file: locked.docx, exception is: FileLockedException
Disk full, from file: data.bin, exception is: DiskFullException
File size exceeds limit, from file: large_file.pdf, exception is: FileSizeLimitException
File not writable, from file: config.ini, exception is: FileNotWritableException
Invalid permission, from file: secure.txt, exception is: PermissionException
File already exists, from file: new_file.txt, exception is: FileAlreadyExistsException
Network error, from file: network.log, exception is: NetworkErrorException
--> num relocations to get balance: 5
--> num relocations to get balance: 2
--> num relocations to get balance: 8
--> num relocations to get balance: 1
--> num relocations to get balance: 6
--> num relocations to get balance: 4
--> num relocations to get balance: 7
--> num relocations to get balance: 9
--> num relocations to get balance: 10
--> num relocations to get balance: 12
--> num relocations to get balance: 11
--> num relocations to get balance: 15
--> num relocations to get balance: 13
start filtering instance example2 with tags tag2.
start filtering instance example3 with tags tag3.
start filtering instance example4 with tags tag4.
start filtering instance example5 with tags tag5.
start filtering instance example6 with tags tag6.
start filtering instance example7 with tags tag7.
start filtering instance example8 with tags tag8.
start filtering instance example9 with tags tag9.
start filtering instance example10 with tags tag10.
start filtering instance example11 with tags tag11.
start filtering instance example12 with tags tag12.
start filtering instance example13 with tags tag13.
start filtering instance example14 with tags tag14.
unexpected exception while closing http channels: IOException
unexpected exception while closing http channels: SocketTimeoutException
unexpected exception while closing http channels: SSLHandshakeException
unexpected exception while closing http channels: ConnectionResetException
unexpected exception while closing http channels: FileNotFoundException
unexpected exception while closing http channels: ParseException
unexpected exception while closing http channels: UnknownHostException
unexpected exception while closing http channels: SocketException
unexpected exception while closing http channels: JSONException
unexpected exception while closing http channels: OutOfMemoryError
unexpected exception while closing http channels: NoSuchMethodException
unexpected exception while closing http channels: ArrayIndexOutOfBoundsException
unexpected exception while closing http channels: StackOverflowError
unexpected exception while closing http channels: ClassCastException
Add routing externalRouting
Add routing internalRouting
Add routing customRouting
Add routing backupRouting
Add routing secondaryRouting
Add routing defaultRouting
Add routing dynamicRouting
Add routing staticRouting
Add routing primaryRouting
Add routing specificRouting
Add routing routeOne
Add routing routeTwo
Add routing routeThree
Add routing routeFour
node B is TERMINATED. Ignoring
node C is TERMINATED. Ignoring
node D is TERMINATED. Ignoring
node E is TERMINATED. Ignoring
node F is TERMINATED. Ignoring
node G is TERMINATED. Ignoring
node H is TERMINATED. Ignoring
node I is TERMINATED. Ignoring
node J is TERMINATED. Ignoring
node K is TERMINATED. Ignoring
node L is TERMINATED. Ignoring
node M is TERMINATED. Ignoring
node N is TERMINATED. Ignoring
gce instance my-instance-2 with status terminated found.
gce instance my-instance-3 with status stopped found.
gce instance my-instance-4 with status pending found.
gce instance my-instance-5 with status initializing found.
gce instance my-instance-6 with status error found.
gce instance my-instance-7 with status suspended found.
gce instance my-instance-8 with status migrating found.
gce instance my-instance-9 with status maintenance found.
gce instance my-instance-10 with status unknown found.
gce instance my-instance-11 with status starting found.
gce instance my-instance-12 with status stopping found.
gce instance my-instance-13 with status pausing found.
gce instance my-instance-14 with status resuming found.
Removing half the nodes (10)
Removing half the nodes (15)
Removing half the nodes (20)
Removing half the nodes (25)
Removing half the nodes (30)
Removing half the nodes (35)
Removing half the nodes (40)
Removing half the nodes (45)
Removing half the nodes (50)
Removing half the nodes (55)
Removing half the nodes (60)
Removing half the nodes (65)
Removing half the nodes (70)
shard02 no local shard info found
shard03 no local shard info found
shard04 no local shard info found
shard05 no local shard info found
shard06 no local shard info found
shard07 no local shard info found
shard08 no local shard info found
shard09 no local shard info found
shard10 no local shard info found
shard11 no local shard info found
shard12 no local shard info found
shard13 no local shard info found
shard14 no local shard info found
using tags cooking
using tags technology
using tags fashion
using tags music
using tags art
using tags fitness
using tags travel
using tags photography
using tags gaming
using tags books
using tags movies
using tags education
using tags business
ServiceB loading local shard state info
ServiceC loading local shard state info
ServiceD loading local shard state info
ServiceE loading local shard state info
ServiceF loading local shard state info
ServiceG loading local shard state info
ServiceH loading local shard state info
ServiceI loading local shard state info
ServiceJ loading local shard state info
ServiceK loading local shard state info
ServiceL loading local shard state info
ServiceM loading local shard state info
ServiceN loading local shard state info
unable to shutdown GCE Http Transport IOException
unable to shutdown GCE Http Transport TimeoutException
unable to shutdown GCE Http Transport ConnectionException
unable to shutdown GCE Http Transport UnknownHostException
unable to shutdown GCE Http Transport SocketException
unable to shutdown GCE Http Transport SSLHandshakeException
unable to shutdown GCE Http Transport FileNotFoundException
unable to shutdown GCE Http Transport ParseException
unable to shutdown GCE Http Transport ClassNotFoundException
unable to shutdown GCE Http Transport UnauthorizedException
unable to shutdown GCE Http Transport InternalServerError
unable to shutdown GCE Http Transport BadRequestException
unable to shutdown GCE Http Transport ConflictException
--> 25 docs indexed
--> 5 docs indexed
--> 15 docs indexed
--> 30 docs indexed
--> 8 docs indexed
--> 20 docs indexed
--> 12 docs indexed
--> 35 docs indexed
--> 3 docs indexed
--> 18 docs indexed
--> 7 docs indexed
--> 22 docs indexed
--> 14 docs indexed
--> waiting for 50 docs to be indexed ...
--> waiting for 100 docs to be indexed ...
--> waiting for 200 docs to be indexed ...
--> waiting for 500 docs to be indexed ...
--> waiting for 1000 docs to be indexed ...
--> waiting for 2000 docs to be indexed ...
--> waiting for 5000 docs to be indexed ...
--> waiting for 10000 docs to be indexed ...
--> waiting for 20000 docs to be indexed ...
--> waiting for 50000 docs to be indexed ...
--> waiting for 100000 docs to be indexed ...
--> waiting for 200000 docs to be indexed ...
--> waiting for 500000 docs to be indexed ...
cluster health request timed out: yellow
cluster health request timed out: green
cluster health request timed out: orange
cluster health request timed out: blue
cluster health request timed out: purple
cluster health request timed out: gray
cluster health request timed out: black
cluster health request timed out: white
cluster health request timed out: brown
cluster health request timed out: pink
cluster health request timed out: cyan
cluster health request timed out: magenta
cluster health request timed out: silver
token [12bd23] will expire in [7200] s
token [ac54d2] will expire in [1800] s
token [78a9c1] will expire in [14400] s
token [d98ba4] will expire in [900] s
token [f12b9c] will expire in [7200] s
token [524a79] will expire in [3600] s
token [bc86d1] will expire in [900] s
token [a0b129] will expire in [1800] s
token [d536b2] will expire in [3600] s
token [fe23c1] will expire in [28800] s
token [4ab32e] will expire in [900] s
token [ff4a23] will expire in [7200] s
token [9c23d4] will expire in [1800] s
--> complete initializing round: [1]
--> complete initializing round: [2]
--> complete initializing round: [3]
--> complete initializing round: [4]
--> complete initializing round: [5]
--> complete initializing round: [6]
--> complete initializing round: [7]
--> complete initializing round: [8]
--> complete initializing round: [9]
--> complete initializing round: [10]
--> complete initializing round: [11]
--> complete initializing round: [12]
--> complete initializing round: [13]
unable to start GCE discovery service FileNotFoundException
unable to start GCE discovery service ConnectionTimeoutException
unable to start GCE discovery service NoSuchElementException
unable to start GCE discovery service NullPointerException
unable to start GCE discovery service SocketTimeoutException
unable to start GCE discovery service IOException
unable to start GCE discovery service SecurityException
unable to start GCE discovery service IllegalArgumentException
unable to start GCE discovery service ClassNotFoundException
unable to start GCE discovery service UnsupportedOperationException
unable to start GCE discovery service IndexOutOfBoundsException
unable to start GCE discovery service ArrayIndexOutOfBoundsException
unable to start GCE discovery service OutOfMemoryError
Waiting for persistent task with id 67890 to disappear
Waiting for persistent task with id 54321 to disappear
Waiting for persistent task with id 98760 to disappear
Waiting for persistent task with id 23451 to disappear
Waiting for persistent task with id 09876 to disappear
Waiting for persistent task with id 76543 to disappear
Waiting for persistent task with id 21098 to disappear
Waiting for persistent task with id 45678 to disappear
Waiting for persistent task with id 78903 to disappear
Waiting for persistent task with id 34512 to disappear
Waiting for persistent task with id 60897 to disappear
Waiting for persistent task with id 90123 to disappear
Waiting for persistent task with id 45678 to disappear
cancelling allocation of replica on [node2], can perform a noop recovery on node [node4]
cancelling allocation of replica on [node3], can perform a noop recovery on node [node5]
cancelling allocation of replica on [node4], can perform a noop recovery on node [node6]
cancelling allocation of replica on [node5], can perform a noop recovery on node [node7]
cancelling allocation of replica on [node6], can perform a noop recovery on node [node8]
cancelling allocation of replica on [node7], can perform a noop recovery on node [node9]
cancelling allocation of replica on [node8], can perform a noop recovery on node [node10]
cancelling allocation of replica on [node9], can perform a noop recovery on node [node11]
cancelling allocation of replica on [node10], can perform a noop recovery on node [node12]
cancelling allocation of replica on [node11], can perform a noop recovery on node [node13]
cancelling allocation of replica on [node12], can perform a noop recovery on node [node14]
cancelling allocation of replica on [node13], can perform a noop recovery on node [node15]
cancelling allocation of replica on [node14], can perform a noop recovery on node [node16]
Found running task with id 2675 and parent 4128
Found running task with id 3798 and parent 6437
Found running task with id 8132 and parent 2951
Found running task with id 9461 and parent 7182
Found running task with id 5247 and parent 2693
Found running task with id 7316 and parent 1558
Found running task with id 8936 and parent 6294
Found running task with id 4628 and parent 1116
Found running task with id 5871 and parent 7614
Found running task with id 2365 and parent 4127
Found running task with id 9349 and parent 7981
Found running task with id 3905 and parent 1563
Found running task with id 6224 and parent 4609
Unassigned shards: shard2
Unassigned shards: shard3
Unassigned shards: shard4
Unassigned shards: shard5
Unassigned shards: shard6
Unassigned shards: shard7
Unassigned shards: shard8
Unassigned shards: shard9
Unassigned shards: shard10
Unassigned shards: shard11
Unassigned shards: shard12
Unassigned shards: shard13
Unassigned shards: shard14
Waiting for 5 tasks to start
Waiting for 3 tasks to start
Waiting for 8 tasks to start
Waiting for 15 tasks to start
Waiting for 2 tasks to start
Waiting for 7 tasks to start
Waiting for 12 tasks to start
Waiting for 4 tasks to start
Waiting for 6 tasks to start
Waiting for 9 tasks to start
Waiting for 1 tasks to start
Waiting for 20 tasks to start
Waiting for 13 tasks to start
Relocating shards: shard2
Relocating shards: shard3
Relocating shards: shard4
Relocating shards: shard5
Relocating shards: shard6
Relocating shards: shard7
Relocating shards: shard8
Relocating shards: shard9
Relocating shards: shard10
Relocating shards: shard11
Relocating shards: shard12
Relocating shards: shard13
Relocating shards: shard14
Started shards: shard2
Started shards: shard3
Started shards: shard4
Started shards: shard5
Started shards: shard6
Started shards: shard7
Started shards: shard8
Started shards: shard9
Started shards: shard10
Started shards: shard11
Started shards: shard12
Started shards: shard13
Started shards: shard14
Initializing shards: [shard2]
Initializing shards: [shard3]
Initializing shards: [shard4]
Initializing shards: [shard5]
Initializing shards: [shard6]
Initializing shards: [shard7]
Initializing shards: [shard8]
Initializing shards: [shard9]
Initializing shards: [shard10]
Initializing shards: [shard11]
Initializing shards: [shard12]
Initializing shards: [shard13]
Initializing shards: [shard14]
Error while deleting stale Remote Cluster Metadata files NullPointerException
Error while deleting stale Remote Cluster Metadata files FileNotFoundException
Error while deleting stale Remote Cluster Metadata files ClassNotFoundException
Error while deleting stale Remote Cluster Metadata files ArrayIndexOutOfBoundsException
Error while deleting stale Remote Cluster Metadata files NumberFormatException
Error while deleting stale Remote Cluster Metadata files IllegalArgumentException
Error while deleting stale Remote Cluster Metadata files UnsupportedOperationException
Error while deleting stale Remote Cluster Metadata files AssertionError
Error while deleting stale Remote Cluster Metadata files StackOverflowError
Error while deleting stale Remote Cluster Metadata files OutOfMemoryError
Error while deleting stale Remote Cluster Metadata files NoClassDefFoundError
Error while deleting stale Remote Cluster Metadata files IndexOutOfBoundsException
Error while deleting stale Remote Cluster Metadata files ArithmeticException
creating 20 persistent tasks
creating 30 persistent tasks
creating 40 persistent tasks
creating 50 persistent tasks
creating 60 persistent tasks
creating 70 persistent tasks
creating 80 persistent tasks
creating 90 persistent tasks
creating 100 persistent tasks
creating 110 persistent tasks
creating 120 persistent tasks
creating 130 persistent tasks
creating 140 persistent tasks
Error while fetching Remote Cluster Metadata manifests NullPointerException
Error while fetching Remote Cluster Metadata manifests IOException
Error while fetching Remote Cluster Metadata manifests ArrayIndexOutOfBoundsException
Error while fetching Remote Cluster Metadata manifests ClassCastException
Error while fetching Remote Cluster Metadata manifests IllegalArgumentException
Error while fetching Remote Cluster Metadata manifests OutOfMemoryError
Error while fetching Remote Cluster Metadata manifests StackOverflowError
Error while fetching Remote Cluster Metadata manifests FileNotFoundException
Error while fetching Remote Cluster Metadata manifests TimeoutException
Error while fetching Remote Cluster Metadata manifests NumberFormatException
Error while fetching Remote Cluster Metadata manifests InvalidParameterException
Error while fetching Remote Cluster Metadata manifests IllegalStateException
Error while fetching Remote Cluster Metadata manifests NoSuchElementException
started [10] instances
started [2] instances
started [7] instances
started [3] instances
started [1] instances
started [6] instances
started [4] instances
started [8] instances
started [9] instances
started [12] instances
started [15] instances
started [11] instances
started [13] instances
started [8] instances with [7] stage=prod tag
started [12] instances with [3] stage=prod tag
started [6] instances with [5] stage=prod tag
started [2] instances with [9] stage=prod tag
started [7] instances with [6] stage=prod tag
started [3] instances with [12] stage=prod tag
started [9] instances with [2] stage=prod tag
started [5] instances with [6] stage=prod tag
started [10] instances with [4] stage=prod tag
started [8] instances with [7] stage=prod tag
started [4] instances with [10] stage=prod tag
started [6] instances with [5] stage=prod tag
started [2] instances with [9] stage=prod tag
Deleted all remote cluster metadata for cluster UUID - b1f36e74-e613-4dc8-8b25-3a24688208b7
Deleted all remote cluster metadata for cluster UUID - f7a66f19-5a48-4cd8-8338-f5dab718986f
Deleted all remote cluster metadata for cluster UUID - 9c7641fe-6cea-4326-848c-10a527b5ce47
Deleted all remote cluster metadata for cluster UUID - ed64752e-d646-432f-bc61-c68c641a7818
Deleted all remote cluster metadata for cluster UUID - 519f7b71-8f95-4f82-bc3c-aa5f0f73f0b4
Deleted all remote cluster metadata for cluster UUID - d2916d87-bc6d-46a2-955d-10563cd13e7f
Deleted all remote cluster metadata for cluster UUID - 06b25f8d-1090-4a38-9b07-90e46cc0dbcc
Deleted all remote cluster metadata for cluster UUID - bf731074-5650-42b1-85a4-ff01b8e8a8ae
Deleted all remote cluster metadata for cluster UUID - b375d7b4-4b78-4a51-ab30-fc1ed8851242
Deleted all remote cluster metadata for cluster UUID - 40fc5b55-d917-4a6f-8af4-078b734502f5
Deleted all remote cluster metadata for cluster UUID - 2594f800-bfa4-4d1e-967f-9911a38975b3
Deleted all remote cluster metadata for cluster UUID - 5dcf0386-68b0-4534-8bda-6a720c05df6c
Deleted all remote cluster metadata for cluster UUID - 73bc23b2-6134-4ae6-bd68-cf47b553e366
--> addresses found: 192.168.1.2
--> addresses found: 172.18.0.3
--> addresses found: 10.10.10.4
--> addresses found: 192.168.0.5
--> addresses found: 172.16.1.6
--> addresses found: 10.20.30.7
--> addresses found: 192.168.2.8
--> addresses found: 172.17.0.9
--> addresses found: 10.50.100.10
--> addresses found: 192.168.3.11
--> addresses found: 172.16.2.12
--> addresses found: 10.30.40.13
--> addresses found: 192.168.4.14
No manifest file present in remote store for cluster name: cluster2, cluster UUID: uuid2
No manifest file present in remote store for cluster name: cluster3, cluster UUID: uuid3
No manifest file present in remote store for cluster name: cluster4, cluster UUID: uuid4
No manifest file present in remote store for cluster name: cluster5, cluster UUID: uuid5
No manifest file present in remote store for cluster name: cluster6, cluster UUID: uuid6
No manifest file present in remote store for cluster name: cluster7, cluster UUID: uuid7
No manifest file present in remote store for cluster name: cluster8, cluster UUID: uuid8
No manifest file present in remote store for cluster name: cluster9, cluster UUID: uuid9
No manifest file present in remote store for cluster name: cluster10, cluster UUID: uuid10
No manifest file present in remote store for cluster name: cluster11, cluster UUID: uuid11
No manifest file present in remote store for cluster name: cluster12, cluster UUID: uuid12
No manifest file present in remote store for cluster name: cluster13, cluster UUID: uuid13
No manifest file present in remote store for cluster name: cluster14, cluster UUID: uuid14
obtaining ec2 hostname from ec2 meta-data url https://example2.com
obtaining ec2 hostname from ec2 meta-data url https://example3.com
obtaining ec2 hostname from ec2 meta-data url https://example4.com
obtaining ec2 hostname from ec2 meta-data url https://example5.com
obtaining ec2 hostname from ec2 meta-data url https://example6.com
obtaining ec2 hostname from ec2 meta-data url https://example7.com
obtaining ec2 hostname from ec2 meta-data url https://example8.com
obtaining ec2 hostname from ec2 meta-data url https://example9.com
obtaining ec2 hostname from ec2 meta-data url https://example10.com
obtaining ec2 hostname from ec2 meta-data url https://example11.com
obtaining ec2 hostname from ec2 meta-data url https://example12.com
obtaining ec2 hostname from ec2 meta-data url https://example13.com
obtaining ec2 hostname from ec2 meta-data url https://example14.com
writing cluster state took [624ms] which is above the warn threshold of [500]; wrote  metadata for [7] indices and skipped [1] unchanged indices
writing cluster state took [437ms] which is above the warn threshold of [500]; wrote  metadata for [3] indices and skipped [4] unchanged indices
writing cluster state took [686ms] which is above the warn threshold of [500]; wrote  metadata for [10] indices and skipped [0] unchanged indices
writing cluster state took [328ms] which is above the warn threshold of [500]; wrote  metadata for [2] indices and skipped [4] unchanged indices
writing cluster state took [762ms] which is above the warn threshold of [500]; wrote  metadata for [12] indices and skipped [0] unchanged indices
writing cluster state took [513ms] which is above the warn threshold of [500]; wrote  metadata for [6] indices and skipped [1] unchanged indices
writing cluster state took [468ms] which is above the warn threshold of [500]; wrote  metadata for [4] indices and skipped [3] unchanged indices
writing cluster state took [562ms] which is above the warn threshold of [500]; wrote  metadata for [9] indices and skipped [0] unchanged indices
writing cluster state took [624ms] which is above the warn threshold of [500]; wrote  metadata for [11] indices and skipped [1] unchanged indices
writing cluster state took [390ms] which is above the warn threshold of [500]; wrote  metadata for [3] indices and skipped [5] unchanged indices
writing cluster state took [624ms] which is above the warn threshold of [500]; wrote  metadata for [8] indices and skipped [0] unchanged indices
writing cluster state took [546ms] which is above the warn threshold of [500]; wrote  metadata for [5] indices and skipped [2] unchanged indices
writing cluster state took [437ms] which is above the warn threshold of [500]; wrote  metadata for [3] indices and skipped [3] unchanged indices
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/67890
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/54321
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/09876
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/98765
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/67890
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/54321
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/09876
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/98765
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/67890
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/54321
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/09876
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/98765
obtaining ec2 [placement/availability-zone] from ec2 meta-data url http://example.com/ec2/meta-data/67890
using explicit ec2 region [us-west-2]
using explicit ec2 region [eu-west-1]
using explicit ec2 region [ap-southeast-2]
using explicit ec2 region [sa-east-1]
using explicit ec2 region [ap-northeast-1]
using explicit ec2 region [ap-southeast-1]
using explicit ec2 region [eu-central-1]
using explicit ec2 region [us-west-1]
using explicit ec2 region [ap-northeast-2]
using explicit ec2 region [ca-central-1]
using explicit ec2 region [eu-west-2]
using explicit ec2 region [ap-south-1]
using explicit ec2 region [eu-west-3]
using dynamic transport addresses 10.0.0.1
using dynamic transport addresses 172.16.0.1
using dynamic transport addresses 192.168.0.101
using dynamic transport addresses 10.0.1.1
using dynamic transport addresses 172.16.1.1
using dynamic transport addresses 192.168.2.100
using dynamic transport addresses 10.1.0.1
using dynamic transport addresses 172.16.0.2
using dynamic transport addresses 192.168.1.102
using dynamic transport addresses 10.0.0.2
using dynamic transport addresses 172.16.0.3
using dynamic transport addresses 192.168.0.103
using dynamic transport addresses 10.0.1.2
adding instance2, address 192.168.1.2, transport_address 10.0.0.2
adding instance3, address 192.168.1.3, transport_address 10.0.0.3
adding instance4, address 192.168.1.4, transport_address 10.0.0.4
adding instance5, address 192.168.1.5, transport_address 10.0.0.5
adding instance6, address 192.168.1.6, transport_address 10.0.0.6
adding instance7, address 192.168.1.7, transport_address 10.0.0.7
adding instance8, address 192.168.1.8, transport_address 10.0.0.8
adding instance9, address 192.168.1.9, transport_address 10.0.0.9
adding instance10, address 192.168.1.10, transport_address 10.0.0.10
adding instance11, address 192.168.1.11, transport_address 10.0.0.11
adding instance12, address 192.168.1.12, transport_address 10.0.0.12
adding instance13, address 192.168.1.13, transport_address 10.0.0.13
adding instance14, address 192.168.1.14, transport_address 10.0.0.14
not adding i-98765432, address is null, host_type database
not adding i-56789012, address is null, host_type appserver
not adding i-24681357, address is null, host_type proxy
not adding i-97531864, address is null, host_type cache
not adding i-74185296, address is null, host_type loadbalancer
not adding i-34567890, address is null, host_type storage
not adding i-90123456, address is null, host_type messagebroker
not adding i-65432109, address is null, host_type queuemanager
not adding i-13579246, address is null, host_type indexserver
not adding i-86420975, address is null, host_type namenode
not adding i-26948276, address is null, host_type datanode
not adding i-50694281, address is null, host_type kafka
not adding i-72503468, address is null, host_type elasticsearch
using [10.0.0.1] as the instance address
using [172.16.0.1] as the instance address
using [192.168.0.254] as the instance address
using [192.168.10.100] as the instance address
using [10.1.1.1] as the instance address
using [172.20.0.1] as the instance address
using [192.168.1.10] as the instance address
using [10.0.1.1] as the instance address
using [172.16.10.1] as the instance address
using [192.168.0.1] as the instance address
using [192.168.0.2] as the instance address
using [10.0.0.10] as the instance address
using [172.16.0.10] as the instance address
reading hostname from [dev] instance tag
reading hostname from [staging] instance tag
reading hostname from [uat] instance tag
reading hostname from [test] instance tag
reading hostname from [prod-1] instance tag
reading hostname from [prod-2] instance tag
reading hostname from [prod-3] instance tag
reading hostname from [dev-1] instance tag
reading hostname from [dev-2] instance tag
reading hostname from [staging-1] instance tag
reading hostname from [staging-2] instance tag
reading hostname from [uat-1] instance tag
reading hostname from [uat-2] instance tag
--> stopping node node_3
--> stopping node node_4
--> stopping node node_5
--> stopping node node_6
--> stopping node node_7
--> stopping node node_8
--> stopping node node_9
--> stopping node node_10
--> stopping node node_11
--> stopping node node_12
--> stopping node node_13
--> stopping node node_14
--> stopping node node_15
filtering out instance i-67890 based on groups group4,group5,group6, does not include all of security-group
filtering out instance i-24680 based on groups group7,group8,group9, does not include all of security-group
filtering out instance i-13579 based on groups group10,group11,group12, does not include all of security-group
filtering out instance i-10293 based on groups group13,group14,group15, does not include all of security-group
filtering out instance i-47583 based on groups group16,group17,group18, does not include all of security-group
filtering out instance i-67543 based on groups group19,group20,group21, does not include all of security-group
filtering out instance i-38475 based on groups group22,group23,group24, does not include all of security-group
filtering out instance i-16483 based on groups group25,group26,group27, does not include all of security-group
filtering out instance i-78653 based on groups group28,group29,group30, does not include all of security-group
filtering out instance i-72948 based on groups group31,group32,group33, does not include all of security-group
filtering out instance i-28475 based on groups group34,group35,group36, does not include all of security-group
filtering out instance i-47383 based on groups group37,group38,group39, does not include all of security-group
filtering out instance i-94736 based on groups group40,group41,group42, does not include all of security-group
error retrieving instance list from IMDS RuntimeException
error retrieving instance list from IMDS NullPointerException
error retrieving instance list from IMDS SecurityException
error retrieving instance list from IMDS SocketException
error retrieving instance list from IMDS IOException
error retrieving instance list from IMDS ClassCastException
error retrieving instance list from IMDS IllegalArgumentException
error retrieving instance list from IMDS EncryptionException
error retrieving instance list from IMDS InvalidFormatException
error retrieving instance list from IMDS TimeoutException
error retrieving instance list from IMDS ConnectionException
error retrieving instance list from IMDS InvalidResponseException
error retrieving instance list from IMDS ServiceUnavailableException
error retrieving instance list from IMDS ServiceNotFoundException
received: stop, relocation starts
received: pause, relocation starts
received: resume, relocation starts
received: restart, relocation starts
received: backup, relocation starts
received: restore, relocation starts
received: deploy, relocation starts
received: update, relocation starts
received: monitor, relocation starts
received: shutdown, relocation starts
received: initialize, relocation starts
received: validate, relocation starts
received: configure, relocation starts
using host_type development, tags [db, backend], groups [group3, group4] with any_group true, availability_zones us-west-2
using host_type staging, tags [web], groups [group5] with any_group false, availability_zones eu-west-1
using host_type test, tags [web], groups [group6] with any_group true, availability_zones ap-northeast-1
using host_type production, tags [web], groups [group1] with any_group true, availability_zones us-west-1
using host_type development, tags [db, backend], groups [group2, group3] with any_group false, availability_zones us-east-2
using host_type staging, tags [db, frontend], groups [group4, group5] with any_group true, availability_zones ap-southeast-1
using host_type test, tags [web, backend], groups [group6, group7] with any_group false, availability_zones eu-central-1
using host_type production, tags [frontend], groups [group1] with any_group false, availability_zones us-west-2
using host_type development, tags [db], groups [group2] with any_group true, availability_zones ap-northeast-2
using host_type staging, tags [web, backend], groups [group3, group4] with any_group false, availability_zones eu-west-2
using host_type test, tags [db, frontend], groups [group5, group6] with any_group true, availability_zones us-east-1
using host_type production, tags [web, frontend], groups [group1, group2] with any_group true, availability_zones us-east-2
using host_type development, tags [db, backend], groups [group3, group4] with any_group false, availability_zones ap-southeast-1
growing document buffer from [500] to [1000]
growing document buffer from [50] to [100]
growing document buffer from [300] to [600]
growing document buffer from [150] to [300]
growing document buffer from [800] to [1600]
growing document buffer from [70] to [140]
growing document buffer from [200] to [400]
growing document buffer from [1000] to [2000]
growing document buffer from [20] to [40]
growing document buffer from [80] to [160]
growing document buffer from [400] to [800]
growing document buffer from [60] to [120]
growing document buffer from [250] to [500]
received: copy, relocation done
received: delete, relocation done
received: rename, relocation done
received: create, relocation done
received: update, relocation done
received: read, relocation done
received: execute, relocation done
received: archive, relocation done
received: restore, relocation done
received: import, relocation done
received: export, relocation done
received: synchronize, relocation done
received: encrypt, relocation done
Removing 20 nodes
Removing 30 nodes
Removing 40 nodes
Removing 50 nodes
Removing 60 nodes
Removing 70 nodes
Removing 80 nodes
Removing 90 nodes
Removing 100 nodes
Removing 110 nodes
Removing 120 nodes
Removing 130 nodes
Removing 140 nodes
updating metadata for index2, changing version from 2.1 to 3.0
updating metadata for index3, changing version from 1.2 to 1.5
updating metadata for index4, changing version from 2.5 to 3.6
updating metadata for index5, changing version from 3.0 to 4.0
updating metadata for index6, changing version from 2.0 to 2.2
updating metadata for index7, changing version from 1.1 to 1.3
updating metadata for index8, changing version from 2.2 to 2.5
updating metadata for index9, changing version from 1.8 to 2.0
updating metadata for index10, changing version from 3.5 to 4.0
updating metadata for index11, changing version from 2.1 to 2.5
updating metadata for index12, changing version from 1.6 to 2.0
updating metadata for index13, changing version from 3.2 to 3.5
updating metadata for index14, changing version from 2.0 to 2.3
ignoring endpoint endpoint2 as different than publicEndpoint2
ignoring endpoint endpoint3 as different than publicEndpoint3
ignoring endpoint endpoint4 as different than publicEndpoint4
ignoring endpoint endpoint5 as different than publicEndpoint5
ignoring endpoint endpoint6 as different than publicEndpoint6
ignoring endpoint endpoint7 as different than publicEndpoint7
ignoring endpoint endpoint8 as different than publicEndpoint8
ignoring endpoint endpoint9 as different than publicEndpoint9
ignoring endpoint endpoint10 as different than publicEndpoint10
ignoring endpoint endpoint11 as different than publicEndpoint11
ignoring endpoint endpoint12 as different than publicEndpoint12
ignoring endpoint endpoint13 as different than publicEndpoint13
ignoring endpoint endpoint14 as different than publicEndpoint14
start 15 nodes
start 20 nodes
start 25 nodes
start 30 nodes
start 35 nodes
start 40 nodes
start 45 nodes
start 50 nodes
start 55 nodes
start 60 nodes
start 65 nodes
start 70 nodes
start 75 nodes
7 addresses added
2 addresses added
5 addresses added
1 addresses added
3 addresses added
6 addresses added
8 addresses added
9 addresses added
12 addresses added
10 addresses added
11 addresses added
15 addresses added
13 addresses added
currentTerm [7] matches previous currentTerm, writing changes only
currentTerm [2] matches previous currentTerm, writing changes only
currentTerm [9] matches previous currentTerm, writing changes only
currentTerm [3] matches previous currentTerm, writing changes only
currentTerm [4] matches previous currentTerm, writing changes only
currentTerm [8] matches previous currentTerm, writing changes only
currentTerm [1] matches previous currentTerm, writing changes only
currentTerm [6] matches previous currentTerm, writing changes only
currentTerm [10] matches previous currentTerm, writing changes only
currentTerm [12] matches previous currentTerm, writing changes only
currentTerm [11] matches previous currentTerm, writing changes only
currentTerm [14] matches previous currentTerm, writing changes only
currentTerm [13] matches previous currentTerm, writing changes only
currentTerm [16] matches previous currentTerm, writing changes only
now, start [2] more node, check that rebalancing will happen because we set it to always
now, start [3] more node, check that rebalancing will happen because we set it to always
now, start [4] more node, check that rebalancing will happen because we set it to always
now, start [5] more node, check that rebalancing will happen because we set it to always
now, start [6] more node, check that rebalancing will happen because we set it to always
now, start [7] more node, check that rebalancing will happen because we set it to always
now, start [8] more node, check that rebalancing will happen because we set it to always
now, start [9] more node, check that rebalancing will happen because we set it to always
now, start [10] more node, check that rebalancing will happen because we set it to always
now, start [11] more node, check that rebalancing will happen because we set it to always
now, start [12] more node, check that rebalancing will happen because we set it to always
now, start [13] more node, check that rebalancing will happen because we set it to always
now, start [14] more node, check that rebalancing will happen because we set it to always
writing cluster state took [162ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [3] indices and skipped [0] unchanged indices
writing cluster state took [220ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [4] indices and skipped [0] unchanged indices
writing cluster state took [183ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [2] indices and skipped [0] unchanged indices
writing cluster state took [195ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [1] indices and skipped [0] unchanged indices
writing cluster state took [215ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [6] indices and skipped [0] unchanged indices
writing cluster state took [242ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [5] indices and skipped [0] unchanged indices
writing cluster state took [173ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [3] indices and skipped [0] unchanged indices
writing cluster state took [198ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [2] indices and skipped [0] unchanged indices
writing cluster state took [189ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [4] indices and skipped [0] unchanged indices
writing cluster state took [207ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [1] indices and skipped [0] unchanged indices
writing cluster state took [166ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [3] indices and skipped [0] unchanged indices
writing cluster state took [192ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [6] indices and skipped [0] unchanged indices
writing cluster state took [203ms] which is above the warn threshold of [200]; wrote global metadata [true] and metadata for [5] indices and skipped [0] unchanged indices
nodes B: node2
nodes B: node3
nodes B: node4
nodes B: node5
nodes B: node6
nodes B: node7
nodes B: node8
nodes B: node9
nodes B: node10
nodes B: node11
nodes B: node12
nodes B: node13
nodes B: node14
writing cluster state took [387ms]; wrote global metadata [false] and metadata for [3] indices and skipped [1] unchanged indices
writing cluster state took [521ms]; wrote global metadata [true] and metadata for [6] indices and skipped [2] unchanged indices
writing cluster state took [159ms]; wrote global metadata [false] and metadata for [2] indices and skipped [0] unchanged indices
writing cluster state took [426ms]; wrote global metadata [true] and metadata for [4] indices and skipped [1] unchanged indices
writing cluster state took [294ms]; wrote global metadata [true] and metadata for [5] indices and skipped [0] unchanged indices
writing cluster state took [218ms]; wrote global metadata [false] and metadata for [3] indices and skipped [2] unchanged indices
writing cluster state took [478ms]; wrote global metadata [true] and metadata for [7] indices and skipped [0] unchanged indices
writing cluster state took [334ms]; wrote global metadata [true] and metadata for [6] indices and skipped [1] unchanged indices
writing cluster state took [192ms]; wrote global metadata [false] and metadata for [4] indices and skipped [0] unchanged indices
writing cluster state took [568ms]; wrote global metadata [true] and metadata for [7] indices and skipped [1] unchanged indices
writing cluster state took [401ms]; wrote global metadata [false] and metadata for [2] indices and skipped [0] unchanged indices
writing cluster state took [248ms]; wrote global metadata [true] and metadata for [3] indices and skipped [1] unchanged indices
writing cluster state took [545ms]; wrote global metadata [true] and metadata for [5] indices and skipped [0] unchanged indices
nodes A: Abc7eB156F932
nodes A: 923E71fFCB15dA
nodes A: Bc8Ff4328891aB
nodes A: DfE95aFdCbE28D
nodes A: E87213cF95a1D6
nodes A: 9873fAeC6dD4f5
nodes A: Cb6cD9D5ba7KB6
nodes A: fAeBfD9f7afA15
nodes A: bAaAeE96f12cdF
nodes A: cBaDef47FA718"),
nodes A: Ffdbe5D7f7l318
nodes A: Abc7eB156F932
nodes A: 923E71fFCB15dA
nodes A: Bc8Ff4328891aB
current deployment name [Deployment C] different from [Deployment D]. skipping...
current deployment name [Deployment E] different from [Deployment F]. skipping...
current deployment name [Deployment G] different from [Deployment H]. skipping...
current deployment name [Deployment I] different from [Deployment J]. skipping...
current deployment name [Deployment K] different from [Deployment L]. skipping...
current deployment name [Deployment M] different from [Deployment N]. skipping...
current deployment name [Deployment O] different from [Deployment P]. skipping...
current deployment name [Deployment Q] different from [Deployment R]. skipping...
current deployment name [Deployment S] different from [Deployment T]. skipping...
current deployment name [Deployment U] different from [Deployment V]. skipping...
current deployment name [Deployment W] different from [Deployment X]. skipping...
current deployment name [Deployment Y] different from [Deployment Z]. skipping...
current deployment name [Deployment AA] different from [Deployment AB]. skipping...
current deployment name [Deployment AC] different from [Deployment AD]. skipping...
request 5678 released for index 2
request 9123 released for index 3
request 4567 released for index 4
request 8901 released for index 5
request 2345 released for index 6
request 6789 released for index 7
request 3210 released for index 8
request 7654 released for index 9
request 1098 released for index 10
request 5432 released for index 11
request 9876 released for index 12
request 3210 released for index 13
request 7654 released for index 14
writing cluster state took [187ms] which is above the warn threshold of [200]; wrote full state with [15] indices
writing cluster state took [312ms] which is above the warn threshold of [200]; wrote full state with [28] indices
writing cluster state took [150ms] which is above the warn threshold of [200]; wrote full state with [12] indices
writing cluster state took [294ms] which is above the warn threshold of [200]; wrote full state with [34] indices
writing cluster state took [201ms] which is above the warn threshold of [200]; wrote full state with [21] indices
writing cluster state took [275ms] which is above the warn threshold of [200]; wrote full state with [30] indices
writing cluster state took [190ms] which is above the warn threshold of [200]; wrote full state with [17] indices
writing cluster state took [330ms] which is above the warn threshold of [200]; wrote full state with [40] indices
writing cluster state took [280ms] which is above the warn threshold of [200]; wrote full state with [32] indices
writing cluster state took [210ms] which is above the warn threshold of [200]; wrote full state with [23] indices
writing cluster state took [275ms] which is above the warn threshold of [200]; wrote full state with [31] indices
writing cluster state took [160ms] which is above the warn threshold of [200]; wrote full state with [14] indices
writing cluster state took [305ms] which is above the warn threshold of [200]; wrote full state with [36] indices
timezone: [GMT-5], now [2022-09-02 15:45:00], name: [Emily]
timezone: [GMT+3], now [2022-09-03 08:15:00], name: [Michael]
timezone: [GMT-8], now [2022-09-04 19:00:00], name: [Sophia]
timezone: [GMT+2], now [2022-09-05 12:00:00], name: [Andrew]
timezone: [GMT-4], now [2022-09-06 14:30:00], name: [Olivia]
timezone: [GMT+5], now [2022-09-07 05:45:00], name: [William]
timezone: [GMT-7], now [2022-09-08 20:15:00], name: [Ava]
timezone: [GMT+4], now [2022-09-09 09:30:00], name: [Liam]
timezone: [GMT-6], now [2022-09-10 17:55:00], name: [Isabella]
timezone: [GMT+6], now [2022-09-11 06:20:00], name: [Benjamin]
timezone: [GMT-3], now [2022-09-12 16:10:00], name: [Mia]
timezone: [GMT+7], now [2022-09-13 03:40:00], name: [Ethan]
timezone: [GMT-2], now [2022-09-14 17:30:00], name: [Charlotte]
current deployment slot [slot2] for [app2] is different from [staging]. skipping...
current deployment slot [slot3] for [app3] is different from [development]. skipping...
current deployment slot [slot4] for [app4] is different from [testing]. skipping...
current deployment slot [slot5] for [app5] is different from [sandbox]. skipping...
current deployment slot [slot6] for [app6] is different from [uat]. skipping...
current deployment slot [slot7] for [app7] is different from [preprod]. skipping...
current deployment slot [slot8] for [app8] is different from [demo]. skipping...
current deployment slot [slot9] for [app9] is different from [qa]. skipping...
current deployment slot [slot10] for [app10] is different from [performance]. skipping...
current deployment slot [slot11] for [app11] is different from [loadtest]. skipping...
current deployment slot [slot12] for [app12] is different from [backup]. skipping...
current deployment slot [slot13] for [app13] is different from [maintenance]. skipping...
current deployment slot [slot14] for [app14] is different from [release]. skipping...
request 456 intercepted for index 2
request 789 intercepted for index 3
request abc intercepted for index 4
request def intercepted for index 5
request ghi intercepted for index 6
request jkl intercepted for index 7
request mno intercepted for index 8
request pqr intercepted for index 9
request stu intercepted for index 10
request vwx intercepted for index 11
request yza intercepted for index 12
request bcd intercepted for index 13
request efg intercepted for index 14
writing cluster state took [2100ms]; wrote full state with [2] indices
writing cluster state took [980ms]; wrote full state with [7] indices
writing cluster state took [1780ms]; wrote full state with [3] indices
writing cluster state took [1420ms]; wrote full state with [4] indices
writing cluster state took [1920ms]; wrote full state with [6] indices
writing cluster state took [1250ms]; wrote full state with [3] indices
writing cluster state took [1370ms]; wrote full state with [2] indices
writing cluster state took [1970ms]; wrote full state with [5] indices
writing cluster state took [1120ms]; wrote full state with [6] indices
writing cluster state took [1650ms]; wrote full state with [4] indices
writing cluster state took [1890ms]; wrote full state with [7] indices
writing cluster state took [1230ms]; wrote full state with [2] indices
writing cluster state took [1570ms]; wrote full state with [7] indices
cluster status: AVAILABLE, expected UNAVAILABLE
cluster status: DEGRADED, expected DEGRADED
cluster status: UNAVAILABLE, expected UNKNOWN
cluster status: AVAILABLE, expected AVAILABLE
cluster status: DEGRADED, expected AVAILABLE
cluster status: UNKNOWN, expected DEGRADED
cluster status: UNAVAILABLE, expected UNAVAILABLE
cluster status: AVAILABLE, expected DEGRADED
cluster status: DEGRADED, expected UNKNOWN
cluster status: UNAVAILABLE, expected DEGRADED
cluster status: UNKNOWN, expected UNAVAILABLE
cluster status: DEGRADED, expected DEGRADED
cluster status: UNAVAILABLE, expected AVAILABLE
failed on closing cluster state writer RuntimeException
failed on closing cluster state writer IOException
failed on closing cluster state writer NullPointerException
failed on closing cluster state writer IllegalArgumentException
failed on closing cluster state writer ArrayIndexOutOfBoundsException
failed on closing cluster state writer ClassCastException
failed on closing cluster state writer SecurityException
failed on closing cluster state writer NoSuchElementException
failed on closing cluster state writer AssertionError
failed on closing cluster state writer OutOfMemoryError
failed on closing cluster state writer StackOverflowError
failed on closing cluster state writer IndexOutOfBoundsException
failed on closing cluster state writer ArithmeticException
removing metadata for [78902b5]
removing metadata for [cde971a]
removing metadata for [2e15fdb]
removing metadata for [9f1d827]
removing metadata for [68ed34c]
removing metadata for [3a1788e]
removing metadata for [b6b4f56]
removing metadata for [d56e2a7]
removing metadata for [7c90309]
removing metadata for [e895a2f]
removing metadata for [105876d]
removing metadata for [46cdfe9]
removing metadata for [83a5fcd]
exception while finding ip Exception2
exception while finding ip Exception3
exception while finding ip Exception4
exception while finding ip Exception5
exception while finding ip Exception6
exception while finding ip Exception7
exception while finding ip Exception8
exception while finding ip Exception9
exception while finding ip Exception10
exception while finding ip Exception11
exception while finding ip Exception12
exception while finding ip Exception13
exception while finding ip Exception14
interrupted IOException
interrupted SQLException
interrupted NullPointerException
interrupted ArrayIndexOutOfBoundsException
interrupted IllegalArgumentException
interrupted FileNotFoundException
interrupted ArithmeticException
interrupted ClassNotFoundException
interrupted NoSuchElementException
interrupted NumberFormatException
interrupted RuntimeException
interrupted AssertionError
interrupted IllegalStateException
AzureServiceRemoteException caught AuthenticationFailedException
AzureServiceRemoteException caught TimeoutException
AzureServiceRemoteException caught ResourceNotFoundException
AzureServiceRemoteException caught ConnectionRefusedException
AzureServiceRemoteException caught NullPointerException
AzureServiceRemoteException caught InternalServerException
AzureServiceRemoteException caught UnauthorizedAccessException
AzureServiceRemoteException caught InvalidRequestException
AzureServiceRemoteException caught PermissionDeniedException
AzureServiceRemoteException caught FileNotFoundException
AzureServiceRemoteException caught OverflowException
AzureServiceRemoteException caught OperationCanceledException
AzureServiceRemoteException caught OutOfMemoryException
AzureServiceRemoteException caught NetworkErrorException
updating metadata for [2]
updating metadata for [3]
updating metadata for [4]
updating metadata for [5]
updating metadata for [6]
updating metadata for [7]
updating metadata for [8]
updating metadata for [9]
updating metadata for [10]
updating metadata for [11]
updating metadata for [12]
updating metadata for [13]
updating metadata for [14]
creating index index2 with 2500 documents
creating index index3 with 5000 documents
creating index index4 with 7500 documents
creating index index5 with 10000 documents
creating index index6 with 12500 documents
creating index index7 with 15000 documents
creating index index8 with 17500 documents
creating index index9 with 20000 documents
creating index index10 with 22500 documents
creating index index11 with 25000 documents
creating index index12 with 27500 documents
creating index index13 with 30000 documents
creating index index14 with 32500 documents
creating empty index index2
creating empty index index3
creating empty index index4
creating empty index index5
creating empty index index6
creating empty index index7
creating empty index index8
creating empty index index9
creating empty index index10
creating empty index index11
creating empty index index12
creating empty index index13
creating empty index index14
can not get list of azure nodes: [Connection failure]. Returning empty list of nodes.
can not get list of azure nodes: [Network error]. Returning empty list of nodes.
can not get list of azure nodes: [Authentication failure]. Returning empty list of nodes.
can not get list of azure nodes: [Invalid credentials]. Returning empty list of nodes.
can not get list of azure nodes: [Timeout exceeded]. Returning empty list of nodes.
can not get list of azure nodes: [API error]. Returning empty list of nodes.
can not get list of azure nodes: [Invalid request]. Returning empty list of nodes.
can not get list of azure nodes: [Server error]. Returning empty list of nodes.
can not get list of azure nodes: [Resource not found]. Returning empty list of nodes.
can not get list of azure nodes: [Data corruption]. Returning empty list of nodes.
can not get list of azure nodes: [Insufficient permissions]. Returning empty list of nodes.
can not get list of azure nodes: [Invalid response]. Returning empty list of nodes.
can not get list of azure nodes: [Invalid input]. Returning empty list of nodes.
new leafReaderContext: context2
new leafReaderContext: context3
new leafReaderContext: context4
new leafReaderContext: context5
new leafReaderContext: context6
new leafReaderContext: context7
new leafReaderContext: context8
new leafReaderContext: context9
new leafReaderContext: context10
new leafReaderContext: context11
new leafReaderContext: context12
new leafReaderContext: context13
new leafReaderContext: context14
running query [DELETE FROM products WHERE id = 100]
running query [UPDATE customers SET address = '123 Main St' WHERE id = 50]
running query [INSERT INTO orders (customer_id, product_id) VALUES (10, 200)]
running query [SELECT COUNT(*) FROM orders]
running query [UPDATE products SET price = 9.99 WHERE category = 'electronics']
running query [DELETE FROM users WHERE last_login < '2021-01-01']
running query [INSERT INTO orders (customer_id, product_id) SELECT id, 500 FROM customers WHERE city = 'New York']
running query [SELECT * FROM products WHERE price BETWEEN 10 AND 50]
running query [UPDATE users SET status = 'inactive' WHERE last_login < NOW() - INTERVAL 30 DAYS]
running query [INSERT INTO customers (first_name, last_name) VALUES ('John', 'Doe')]
running query [DELETE FROM orders WHERE order_date < '2021-05-01']
running query [SELECT AVG(price) FROM products WHERE category = 'clothing']
running query [UPDATE users SET password = 'new_password' WHERE id = 100]
Non-committed nodes: 5
Non-committed nodes: 3
Non-committed nodes: 7
Non-committed nodes: 1
Non-committed nodes: 2
Non-committed nodes: 8
Non-committed nodes: 4
Non-committed nodes: 6
Non-committed nodes: 9
Non-committed nodes: 12
Non-committed nodes: 15
Non-committed nodes: 11
Non-committed nodes: 13
creating new Azure client for [789012], [compute]
creating new Azure client for [345678], [network]
creating new Azure client for [901234], [database]
creating new Azure client for [567890], [container]
creating new Azure client for [123789], [monitoring]
creating new Azure client for [890123], [analytics]
creating new Azure client for [456789], [security]
creating new Azure client for [012345], [iot]
creating new Azure client for [678901], [machine learning]
creating new Azure client for [234567], [cognitive services]
creating new Azure client for [890123], [api management]
creating new Azure client for [345678], [application insights]
creating new Azure client for [012345], [event grid]
Committing nodes: node2
Committing nodes: node3
Committing nodes: node4
Committing nodes: node5
Committing nodes: node6
Committing nodes: node7
Committing nodes: node8
Committing nodes: node9
Committing nodes: node10
Committing nodes: node11
Committing nodes: node12
Committing nodes: node13
Committing nodes: node14
found index metadata for indexB
found index metadata for indexC
found index metadata for indexD
found index metadata for indexE
found index metadata for indexF
found index metadata for indexG
found index metadata for indexH
found index metadata for indexI
found index metadata for indexJ
found index metadata for indexK
found index metadata for indexL
found index metadata for indexM
found index metadata for indexN
Injecting fault at: 192.168.0.2, publicationDidNotMakeItToNode2: false
Injecting fault at: 172.16.0.3, publicationDidNotMakeItToNode2: true
Injecting fault at: 10.0.0.4, publicationDidNotMakeItToNode2: false
Injecting fault at: 192.168.0.5, publicationDidNotMakeItToNode2: true
Injecting fault at: 172.16.0.6, publicationDidNotMakeItToNode2: false
Injecting fault at: 10.0.0.7, publicationDidNotMakeItToNode2: true
Injecting fault at: 192.168.0.8, publicationDidNotMakeItToNode2: false
Injecting fault at: 172.16.0.9, publicationDidNotMakeItToNode2: true
Injecting fault at: 10.0.0.10, publicationDidNotMakeItToNode2: false
Injecting fault at: 192.168.0.11, publicationDidNotMakeItToNode2: true
Injecting fault at: 172.16.0.12, publicationDidNotMakeItToNode2: false
Injecting fault at: 10.0.0.13, publicationDidNotMakeItToNode2: true
Injecting fault at: 192.168.0.14, publicationDidNotMakeItToNode2: false
--> using azure host type Standard_B2ms
--> using azure host type Standard_DS3_v2
--> using azure host type Standard_E4s_v3
--> using azure host type Standard_F2s_v2
--> using azure host type Standard_G5
--> using azure host type Standard_H16r
--> using azure host type Standard_L8s_v2
--> using azure host type Standard_M32ms
--> done cluster health, status YELLOW
--> done cluster health, status RED
--> done cluster health, status GRAY
--> done cluster health, status BLUE
--> done cluster health, status ORANGE
--> done cluster health, status PURPLE
--> done cluster health, status BLACK
--> done cluster health, status WHITE
--> done cluster health, status PINK
--> done cluster health, status BROWN
--> done cluster health, status CYAN
--> done cluster health, status SILVER
--> done cluster health, status GOLD
Injecting fault at: module B
Injecting fault at: module C
Injecting fault at: module D
Injecting fault at: module E
Injecting fault at: module F
Injecting fault at: module G
Injecting fault at: module H
Injecting fault at: module I
Injecting fault at: module J
Injecting fault at: module K
Injecting fault at: module L
Injecting fault at: module M
Injecting fault at: module N
Failed serializing XML ParseException
Failed serializing XML NullPointerException
Failed serializing XML TransformerException
Failed serializing XML SAXException
Failed serializing XML InvalidFormatException
Failed serializing XML ArrayIndexOutOfBoundsException
Failed serializing XML ClassNotFoundException
Failed serializing XML RuntimeException
Failed serializing XML OutOfMemoryError
Failed serializing XML IllegalArgumentException
Failed serializing XML IllegalStateException
Failed serializing XML IndexOutOfBoundsException
Failed serializing XML SecurityException
found global metadata with last-accepted term [45]
found global metadata with last-accepted term [23]
found global metadata with last-accepted term [9]
found global metadata with last-accepted term [31]
found global metadata with last-accepted term [17]
found global metadata with last-accepted term [28]
found global metadata with last-accepted term [6]
found global metadata with last-accepted term [39]
found global metadata with last-accepted term [14]
found global metadata with last-accepted term [37]
found global metadata with last-accepted term [20]
found global metadata with last-accepted term [4]
found global metadata with last-accepted term [26]
Possibly unsuccessful voting nodes: NodeB
Possibly unsuccessful voting nodes: NodeC
Possibly unsuccessful voting nodes: NodeD
Possibly unsuccessful voting nodes: NodeE
Possibly unsuccessful voting nodes: NodeF
Possibly unsuccessful voting nodes: NodeG
Possibly unsuccessful voting nodes: NodeH
Possibly unsuccessful voting nodes: NodeI
Possibly unsuccessful voting nodes: NodeJ
Possibly unsuccessful voting nodes: NodeK
Possibly unsuccessful voting nodes: NodeL
Possibly unsuccessful voting nodes: NodeM
Possibly unsuccessful voting nodes: NodeN
[_global] writing state, reason [insufficient disk space]
[_global] writing state, reason [network connection lost]
[_global] writing state, reason [permission denied]
[_global] writing state, reason [database error]
[_global] writing state, reason [invalid input]
[_global] writing state, reason [out of memory]
[_global] writing state, reason [timeout]
[_global] writing state, reason [configuration error]
[_global] writing state, reason [authentication failed]
[_global] writing state, reason [data corruption]
[_global] writing state, reason [server overload]
[_global] writing state, reason [file already exists]
[_global] writing state, reason [unexpected error]
Successful voting nodes: node2
Successful voting nodes: node3
Successful voting nodes: node4
Successful voting nodes: node5
Successful voting nodes: node6
Successful voting nodes: node7
Successful voting nodes: node8
Successful voting nodes: node9
Successful voting nodes: node10
Successful voting nodes: node11
Successful voting nodes: node12
Successful voting nodes: node13
Successful voting nodes: node14
[1] state written
[2] state written
[3] state written
[4] state written
[5] state written
[6] state written
[7] state written
[8] state written
[9] state written
[10] state written
[11] state written
[12] state written
[13] state written
using explicit kms region [eu-central-1]
using explicit kms region [ap-northeast-1]
using explicit kms region [sa-east-1]
using explicit kms region [us-east-1]
using explicit kms region [ap-southeast-2]
using explicit kms region [eu-west-1]
using explicit kms region [ap-south-1]
using explicit kms region [us-west-1]
using explicit kms region [ca-central-1]
using explicit kms region [eu-west-2]
using explicit kms region [ap-southeast-1]
using explicit kms region [us-east-2]
using explicit kms region [eu-west-3]
Voting configuration: ranked-choice
Voting configuration: approval-voting
Voting configuration: proportional-representation
Voting configuration: plurality
Voting configuration: cumulative-voting
Voting configuration: limited-vote
Voting configuration: single-transferable-vote
Voting configuration: borda-count
Voting configuration: range-voting
Voting configuration: majority-judgment
Voting configuration: open-list
Voting configuration: closed-list
Voting configuration: direct-recall
[2] writing state, reason [Permission denied]
[3] writing state, reason [Memory full]
[4] writing state, reason [Connection lost]
[5] writing state, reason [Invalid input]
[6] writing state, reason [Timeout]
[7] writing state, reason [Server error]
[8] writing state, reason [Disk space low]
[9] writing state, reason [Data corruption]
[10] writing state, reason [Invalid configuration]
[11] writing state, reason [Network unreachable]
[12] writing state, reason [Undefined variable]
[13] writing state, reason [Database query failed]
[14] writing state, reason [Authentication failed]
using explicit kms endpoint [kms.us-west-1.amazonaws.com]
using explicit kms endpoint [kms.eu-central-1.amazonaws.com]
using explicit kms endpoint [kms.ap-northeast-2.amazonaws.com]
using explicit kms endpoint [kms.ap-southeast-1.amazonaws.com]
using explicit kms endpoint [kms.sa-east-1.amazonaws.com]
using explicit kms endpoint [kms.ca-central-1.amazonaws.com]
using explicit kms endpoint [kms.eu-west-2.amazonaws.com]
using explicit kms endpoint [kms.ap-southeast-2.amazonaws.com]
using explicit kms endpoint [kms.us-east-2.amazonaws.com]
using explicit kms endpoint [kms.eu-west-1.amazonaws.com]
using explicit kms endpoint [kms.cn-north-1.amazonaws.com.cn]
using explicit kms endpoint [kms.us-west-2.amazonaws.com]
using explicit kms endpoint [kms.ap-northeast-1.amazonaws.com]
project completed
task completed
operation completed
experiment completed
milestone completed
assignment completed
goal completed
challenge completed
objective completed
mission completed
test completed
request completed
survey completed
[_meta] state written (generation: 2)
[_meta] state written (generation: 3)
[_meta] state written (generation: 4)
[_meta] state written (generation: 5)
[_meta] state written (generation: 6)
[_meta] state written (generation: 7)
[_meta] state written (generation: 8)
[_meta] state written (generation: 9)
[_meta] state written (generation: 10)
[_meta] state written (generation: 11)
[_meta] state written (generation: 12)
[_meta] state written (generation: 13)
[_meta] state written (generation: 14)
--> failing at 220ms
--> failing at 180ms
--> failing at 300ms
--> failing at 250ms
--> failing at 290ms
--> failing at 210ms
--> failing at 280ms
--> failing at 240ms
--> failing at 170ms
--> failing at 230ms
--> failing at 190ms
--> failing at 260ms
--> failing at 200ms
--> checking again that no failure is detected in 200 checks
--> checking again that no failure is detected in 300 checks
--> checking again that no failure is detected in 400 checks
--> checking again that no failure is detected in 500 checks
--> checking again that no failure is detected in 600 checks
--> checking again that no failure is detected in 700 checks
--> checking again that no failure is detected in 800 checks
--> checking again that no failure is detected in 900 checks
--> checking again that no failure is detected in 1000 checks
--> checking again that no failure is detected in 1100 checks
--> checking again that no failure is detected in 1200 checks
--> checking again that no failure is detected in 1300 checks
--> checking again that no failure is detected in 1400 checks
Failed to load kuromoji user dictionary NullPointerException
Failed to load kuromoji user dictionary FileNotFoundException
Failed to load kuromoji user dictionary IOException
Failed to load kuromoji user dictionary OutOfMemoryError
Failed to load kuromoji user dictionary ArrayIndexOutOfBoundsException
Failed to load kuromoji user dictionary ClassCastException
Failed to load kuromoji user dictionary NoSuchElementException
Failed to load kuromoji user dictionary IllegalStateException
Failed to load kuromoji user dictionary IllegalArgumentException
Failed to load kuromoji user dictionary AssertionError
Failed to load kuromoji user dictionary ArithmeticException
Failed to load kuromoji user dictionary NumberFormatException
Failed to load kuromoji user dictionary DateTimeParseException
generation id [2] read from [state2.txt]
generation id [3] read from [state3.txt]
generation id [4] read from [state4.txt]
generation id [5] read from [state5.txt]
generation id [6] read from [state6.txt]
generation id [7] read from [state7.txt]
generation id [8] read from [state8.txt]
generation id [9] read from [state9.txt]
generation id [10] read from [state10.txt]
generation id [11] read from [state11.txt]
generation id [12] read from [state12.txt]
generation id [13] read from [state13.txt]
generation id [14] read from [state14.txt]
--> checking that no failure is detected in 200 checks
--> checking that no failure is detected in 300 checks
--> checking that no failure is detected in 400 checks
--> checking that no failure is detected in 500 checks
--> checking that no failure is detected in 600 checks
--> checking that no failure is detected in 700 checks
--> checking that no failure is detected in 800 checks
--> checking that no failure is detected in 900 checks
--> checking that no failure is detected in 1000 checks
--> checking that no failure is detected in 1100 checks
--> checking that no failure is detected in 1200 checks
--> checking that no failure is detected in 1300 checks
--> checking that no failure is detected in 1400 checks
Failed to resolve collation rules location /file2
Failed to resolve collation rules location /file3
Failed to resolve collation rules location /file4
Failed to resolve collation rules location /file5
Failed to resolve collation rules location /file6
Failed to resolve collation rules location /file7
Failed to resolve collation rules location /file8
Failed to resolve collation rules location /file9
Failed to resolve collation rules location /file10
Failed to resolve collation rules location /file11
Failed to resolve collation rules location /file12
Failed to resolve collation rules location /file13
Failed to resolve collation rules location /file14
found state file: /home/user/state2.bin
found state file: /data/app/state3.bin
found state file: /tmp/cache/state4.bin
found state file: /var/logs/state5.bin
found state file: /home/user/Documents/state6.bin
found state file: /data/app/config/state7.bin
found state file: /tmp/temp/state8.bin
found state file: /var/logs/data/state9.bin
found state file: /home/user/Downloads/state10.bin
found state file: /data/app/cache/state11.bin
found state file: /tmp/logs/state12.bin
found state file: /var/data/config/state13.bin
found state file: /home/user/Pictures/state14.bin
Failed to parse collation rules: ParsingException
Failed to parse collation rules: InvalidInputException
Failed to parse collation rules: OutOfMemoryError
Failed to parse collation rules: StackOverflowError
Failed to parse collation rules: FileNotFoundException
Failed to parse collation rules: IllegalArgumentException
Failed to parse collation rules: NoSuchMethodException
Failed to parse collation rules: IndexOutOfBoundsException
Failed to parse collation rules: ClassCastException
Failed to parse collation rules: ArrayIndexOutOfBoundsException
Failed to parse collation rules: IllegalStateException
Failed to parse collation rules: UnsupportedOperationException
Failed to parse collation rules: NullPointerException
--> using settings2
--> using settings3
--> using settings4
--> using settings5
--> using settings6
--> using settings7
--> using settings8
--> using settings9
--> using settings10
--> using settings11
--> using settings12
--> using settings13
--> using settings14
cleanupOldFiles: cleaning up folder2
cleanupOldFiles: cleaning up folder3
cleanupOldFiles: cleaning up folder4
cleanupOldFiles: cleaning up folder5
cleanupOldFiles: cleaning up folder6
cleanupOldFiles: cleaning up folder7
cleanupOldFiles: cleaning up folder8
cleanupOldFiles: cleaning up folder9
cleanupOldFiles: cleaning up folder10
cleanupOldFiles: cleaning up folder11
cleanupOldFiles: cleaning up folder12
cleanupOldFiles: cleaning up folder13
cleanupOldFiles: cleaning up folder14
--> verify count again 2000
--> verify count again 3000
--> verify count again 4000
--> verify count again 5000
--> verify count again 6000
--> verify count again 7000
--> verify count again 8000
--> verify count again 9000
--> verify count again 10000
--> verify count again 11000
--> verify count again 12000
--> verify count again 13000
--> verify count again 14000
--> restarting node2
--> restarting node3
--> restarting node4
--> restarting node5
--> restarting node6
--> restarting node7
--> restarting node8
--> restarting node9
--> restarting node10
--> restarting node11
--> restarting node12
--> restarting node13
--> restarting node14
Caught exception ArrayIndexOutOfBoundsException
Caught exception FileNotFoundException
Caught exception NumberFormatException
Caught exception ClassNotFoundException
Caught exception ArithmeticException
Caught exception IllegalArgumentException
Caught exception NoSuchElementException
Caught exception IndexOutOfBoundsException
Caught exception ConcurrentModificationException
Caught exception UnsupportedOperationException
Caught exception NullPointerException
Caught exception ArrayIndexOutOfBoundsException
Caught exception FileNotFoundException
--> restarting [node2] as a cluster-manager-ineligible node
--> restarting [node3] as a cluster-manager-ineligible node
--> restarting [node4] as a cluster-manager-ineligible node
--> restarting [node5] as a cluster-manager-ineligible node
--> restarting [node6] as a cluster-manager-ineligible node
--> restarting [node7] as a cluster-manager-ineligible node
--> restarting [node8] as a cluster-manager-ineligible node
--> restarting [node9] as a cluster-manager-ineligible node
--> restarting [node10] as a cluster-manager-ineligible node
--> restarting [node11] as a cluster-manager-ineligible node
--> restarting [node12] as a cluster-manager-ineligible node
--> restarting [node13] as a cluster-manager-ineligible node
--> restarting [node14] as a cluster-manager-ineligible node
--> temporaryFilesPostClear : file2.txt
--> temporaryFilesPostClear : file3.txt
--> temporaryFilesPostClear : file4.txt
--> temporaryFilesPostClear : file5.txt
--> temporaryFilesPostClear : file6.txt
--> temporaryFilesPostClear : file7.txt
--> temporaryFilesPostClear : file8.txt
--> temporaryFilesPostClear : file9.txt
--> temporaryFilesPostClear : file10.txt
--> temporaryFilesPostClear : file11.txt
--> temporaryFilesPostClear : file12.txt
--> temporaryFilesPostClear : file13.txt
--> temporaryFilesPostClear : file14.txt
cleaned up /path/to/file2.txt
cleaned up /path/to/file3.txt
cleaned up /path/to/file4.txt
cleaned up /path/to/file5.txt
cleaned up /path/to/file6.txt
cleaned up /path/to/file7.txt
cleaned up /path/to/file8.txt
cleaned up /path/to/file9.txt
cleaned up /path/to/file10.txt
cleaned up /path/to/file11.txt
cleaned up /path/to/file12.txt
cleaned up /path/to/file13.txt
cleaned up /path/to/file14.txt
Error closing netty event loop group connection closed
Error closing netty event loop group null cause
Error closing netty event loop group timeout error
Error closing netty event loop group unknown error
Error closing netty event loop group unexpected exception
Error closing netty event loop group file not found
Error closing netty event loop group database error
Error closing netty event loop group event loop terminated
Error closing netty event loop group network failure
Error closing netty event loop group memory leak detected
Error closing netty event loop group invalid parameter
Error closing netty event loop group invalid operation
Error closing netty event loop group unauthorized access
--> temporaryFiles log2
--> temporaryFiles log3
--> temporaryFiles log4
--> temporaryFiles log5
--> temporaryFiles log6
--> temporaryFiles log7
--> temporaryFiles log8
--> temporaryFiles log9
--> temporaryFiles log10
--> temporaryFiles log11
--> temporaryFiles log12
--> temporaryFiles log13
--> temporaryFiles log14
--> emitting warnings every [1000ms]
--> emitting warnings every [2000ms]
--> emitting warnings every [4000ms]
--> emitting warnings every [8000ms]
--> emitting warnings every [16000ms]
--> emitting warnings every [32000ms]
--> emitting warnings every [64000ms]
--> emitting warnings every [128000ms]
--> emitting warnings every [256000ms]
--> emitting warnings every [512000ms]
--> emitting warnings every [1024000ms]
--> emitting warnings every [2048000ms]
--> emitting warnings every [4096000ms]
--> emitting warnings every [8192000ms]
rebooting [15]
rebooting [19]
rebooting [23]
rebooting [28]
rebooting [30]
rebooting [34]
rebooting [37]
rebooting [41]
rebooting [43]
rebooting [47]
rebooting [51]
rebooting [54]
rebooting [59]
ignoring dangled index [idx2] on node [node2] due to an existing alias with the same name
ignoring dangled index [idx3] on node [node3] due to an existing alias with the same name
ignoring dangled index [idx4] on node [node4] due to an existing alias with the same name
ignoring dangled index [idx5] on node [node5] due to an existing alias with the same name
ignoring dangled index [idx6] on node [node6] due to an existing alias with the same name
ignoring dangled index [idx7] on node [node7] due to an existing alias with the same name
ignoring dangled index [idx8] on node [node8] due to an existing alias with the same name
ignoring dangled index [idx9] on node [node9] due to an existing alias with the same name
ignoring dangled index [idx10] on node [node10] due to an existing alias with the same name
ignoring dangled index [idx11] on node [node11] due to an existing alias with the same name
ignoring dangled index [idx12] on node [node12] due to an existing alias with the same name
ignoring dangled index [idx13] on node [node13] due to an existing alias with the same name
ignoring dangled index [idx14] on node [node14] due to an existing alias with the same name
Failed to close a socket. connection
Failed to close a socket. stream
Failed to close a socket. port
Failed to close a socket. connection timeout
Failed to close a socket. handshake
Failed to close a socket. TCP
Failed to close a socket. SSL
Failed to close a socket. UDP
Failed to close a socket. connection reset
Failed to close a socket. timeout
Failed to close a socket. remote host
Failed to close a socket. local address
Failed to close a socket. remote address
file chunk [2] lastChunk: true
file chunk [3] lastChunk: false
file chunk [4] lastChunk: true
file chunk [5] lastChunk: false
file chunk [6] lastChunk: true
file chunk [7] lastChunk: false
file chunk [8] lastChunk: true
file chunk [9] lastChunk: false
file chunk [10] lastChunk: true
file chunk [11] lastChunk: false
file chunk [12] lastChunk: true
file chunk [13] lastChunk: false
file chunk [14] lastChunk: true
Failed to create a new channel from an accepted socket.connection refused
Failed to create a new channel from an accepted socket.unknown error
Failed to create a new channel from an accepted socket.invalid argument
Failed to create a new channel from an accepted socket.connection timeout
Failed to create a new channel from an accepted socket.permission denied
Failed to create a new channel from an accepted socket.invalid address
Failed to create a new channel from an accepted socket.unsupported protocol
Failed to create a new channel from an accepted socket.not enough memory
Failed to create a new channel from an accepted socket.network unreachable
Failed to create a new channel from an accepted socket.invalid socket type
Failed to create a new channel from an accepted socket.address already in use
Failed to create a new channel from an accepted socket.connection reset
Failed to create a new channel from an accepted socket.invalid host
--> submitting second value to Sarah
--> submitting second value to Michael
--> submitting second value to Emily
--> submitting second value to David
--> submitting second value to Jessica
--> submitting second value to James
--> submitting second value to Olivia
--> submitting second value to Benjamin
--> submitting second value to Sophia
--> submitting second value to Joseph
--> submitting second value to Ava
--> submitting second value to Samuel
--> submitting second value to Isabella
--> submitting second value to Daniel
--> submitting first value to Bob
--> submitting first value to Charlie
--> submitting first value to David
--> submitting first value to Emily
--> submitting first value to Frank
--> submitting first value to Grace
--> submitting first value to Hannah
--> submitting first value to Isaac
--> submitting first value to Jack
--> submitting first value to Kate
--> submitting first value to Liam
--> submitting first value to Mia
--> submitting first value to Noah
writing cluster state took [187ms] which is above the warn threshold of [200]; wrote metadata for [7] indices and skipped [1] unchanged indices
writing cluster state took [312ms] which is above the warn threshold of [200]; wrote metadata for [4] indices and skipped [3] unchanged indices
writing cluster state took [175ms] which is above the warn threshold of [200]; wrote metadata for [6] indices and skipped [0] unchanged indices
writing cluster state took [245ms] which is above the warn threshold of [200]; wrote metadata for [3] indices and skipped [2] unchanged indices
writing cluster state took [198ms] which is above the warn threshold of [200]; wrote metadata for [4] indices and skipped [1] unchanged indices
writing cluster state took [287ms] which is above the warn threshold of [200]; wrote metadata for [2] indices and skipped [2] unchanged indices
writing cluster state took [221ms] which is above the warn threshold of [200]; wrote metadata for [5] indices and skipped [1] unchanged indices
writing cluster state took [263ms] which is above the warn threshold of [200]; wrote metadata for [3] indices and skipped [2] unchanged indices
writing cluster state took [303ms] which is above the warn threshold of [200]; wrote metadata for [4] indices and skipped [0] unchanged indices
writing cluster state took [212ms] which is above the warn threshold of [200]; wrote metadata for [6] indices and skipped [2] unchanged indices
writing cluster state took [195ms] which is above the warn threshold of [200]; wrote metadata for [5] indices and skipped [1] unchanged indices
writing cluster state took [282ms] which is above the warn threshold of [200]; wrote metadata for [4] indices and skipped [3] unchanged indices
writing cluster state took [231ms] which is above the warn threshold of [200]; wrote metadata for [3] indices and skipped [0] unchanged indices
--> blackholing userB
--> blackholing userC
--> blackholing userD
--> blackholing userE
--> blackholing userF
--> blackholing userG
--> blackholing userH
--> blackholing userI
--> blackholing userJ
--> blackholing userK
--> blackholing userL
--> blackholing userM
--> blackholing userN
--> Cluster state post nodes stop success
--> Cluster state post nodes stop warning
--> Cluster state post nodes stop failure
--> Cluster state post nodes stop terminated
--> Cluster state post nodes stop complete
--> Cluster state post nodes stop partial
--> Cluster state post nodes stop interrupted
--> Cluster state post nodes stop paused
--> Cluster state post nodes stop pending
--> Cluster state post nodes stop running
--> Cluster state post nodes stop cancelled
--> Cluster state post nodes stop unknown
--> Cluster state post nodes stop internal_error
--> Cluster state post nodes stop busy
using max_chunk_size[512], max_header_size[2048], max_initial_line_length[2048], max_content_length[32768], receive_predictor[1], max_composite_buffer_components[32], pipelining_max_events[64]
using max_chunk_size[1024], max_header_size[4096], max_initial_line_length[4096], max_content_length[65536], receive_predictor[2], max_composite_buffer_components[64], pipelining_max_events[128]
using max_chunk_size[2048], max_header_size[8192], max_initial_line_length[8192], max_content_length[131072], receive_predictor[3], max_composite_buffer_components[128], pipelining_max_events[256]
using max_chunk_size[4096], max_header_size[16384], max_initial_line_length[16384], max_content_length[262144], receive_predictor[4], max_composite_buffer_components[256], pipelining_max_events[512]
using max_chunk_size[8192], max_header_size[32768], max_initial_line_length[32768], max_content_length[524288], receive_predictor[5], max_composite_buffer_components[512], pipelining_max_events[1024]
using max_chunk_size[16384], max_header_size[65536], max_initial_line_length[65536], max_content_length[1048576], receive_predictor[6], max_composite_buffer_components[1024], pipelining_max_events[2048]
using max_chunk_size[32768], max_header_size[131072], max_initial_line_length[131072], max_content_length[2097152], receive_predictor[7], max_composite_buffer_components[2048], pipelining_max_events[4096]
using max_chunk_size[65536], max_header_size[262144], max_initial_line_length[262144], max_content_length[4194304], receive_predictor[8], max_composite_buffer_components[4096], pipelining_max_events[8192]
using max_chunk_size[131072], max_header_size[524288], max_initial_line_length[524288], max_content_length[8388608], receive_predictor[9], max_composite_buffer_components[8192], pipelining_max_events[16384]
using max_chunk_size[262144], max_header_size[1048576], max_initial_line_length[1048576], max_content_length[16777216], receive_predictor[10], max_composite_buffer_components[16384], pipelining_max_events[32768]
using max_chunk_size[524288], max_header_size[2097152], max_initial_line_length[2097152], max_content_length[33554432], receive_predictor[11], max_composite_buffer_components[32768], pipelining_max_events[65536]
using max_chunk_size[1048576], max_header_size[4194304], max_initial_line_length[4194304], max_content_length[67108864], receive_predictor[12], max_composite_buffer_components[65536], pipelining_max_events[131072]
using max_chunk_size[2097152], max_header_size[8388608], max_initial_line_length[8388608], max_content_length[134217728], receive_predictor[13], max_composite_buffer_components[131072], pipelining_max_events[262144]
using max_chunk_size[4194304], max_header_size[16777216], max_initial_line_length[16777216], max_content_length[268435456], receive_predictor[14], max_composite_buffer_components[262144], pipelining_max_events[524288]
writing cluster state took [187ms]; wrote metadata for [8] indices and skipped [0] unchanged indices
writing cluster state took [312ms]; wrote metadata for [3] indices and skipped [1] unchanged indices
writing cluster state took [410ms]; wrote metadata for [12] indices and skipped [3] unchanged indices
writing cluster state took [145ms]; wrote metadata for [7] indices and skipped [4] unchanged indices
writing cluster state took [275ms]; wrote metadata for [10] indices and skipped [6] unchanged indices
writing cluster state took [198ms]; wrote metadata for [2] indices and skipped [0] unchanged indices
writing cluster state took [320ms]; wrote metadata for [6] indices and skipped [1] unchanged indices
writing cluster state took [265ms]; wrote metadata for [9] indices and skipped [2] unchanged indices
writing cluster state took [196ms]; wrote metadata for [4] indices and skipped [3] unchanged indices
writing cluster state took [183ms]; wrote metadata for [3] indices and skipped [0] unchanged indices
writing cluster state took [345ms]; wrote metadata for [11] indices and skipped [5] unchanged indices
writing cluster state took [231ms]; wrote metadata for [8] indices and skipped [1] unchanged indices
writing cluster state took [279ms]; wrote metadata for [9] indices and skipped [3] unchanged indices
--> Adding 5 nodes
--> Adding 20 nodes
--> Adding 8 nodes
--> Adding 15 nodes
--> Adding 3 nodes
--> Adding 12 nodes
--> Adding 7 nodes
--> Adding 6 nodes
--> Adding 18 nodes
--> Adding 9 nodes
--> Adding 4 nodes
--> Adding 14 nodes
--> Adding 11 nodes
--> blocking cluster state application on leader1
--> blocking cluster state application on node2
--> blocking cluster state application on replica3
--> blocking cluster state application on master4
--> blocking cluster state application on slave5
--> blocking cluster state application on server6
--> blocking cluster state application on worker7
--> blocking cluster state application on agent8
--> blocking cluster state application on client9
--> blocking cluster state application on edge10
--> blocking cluster state application on proxy11
--> blocking cluster state application on coordinator12
--> blocking cluster state application on scheduler13
--> blocking cluster state application on dispatcher14
--> blackholing follower JaneSmith
--> blackholing follower MarkJohnson
--> blackholing follower EmilyBrown
--> blackholing follower MichaelDavis
--> blackholing follower SarahWilson
--> blackholing follower JamesMiller
--> blackholing follower JessicaAnderson
--> blackholing follower DavidTaylor
--> blackholing follower OliviaThomas
--> blackholing follower DanielClark
--> blackholing follower SophiaLee
--> blackholing follower ChristopherHall
--> blackholing follower AvaMartin
--> Creating index test2 with primary shardCount2 and replica replicaCount2
--> Creating index test3 with primary shardCount3 and replica replicaCount3
--> Creating index test4 with primary shardCount4 and replica replicaCount4
--> Creating index test5 with primary shardCount5 and replica replicaCount5
--> Creating index test6 with primary shardCount6 and replica replicaCount6
--> Creating index test7 with primary shardCount7 and replica replicaCount7
--> Creating index test8 with primary shardCount8 and replica replicaCount8
--> Creating index test9 with primary shardCount9 and replica replicaCount9
--> Creating index test10 with primary shardCount10 and replica replicaCount10
--> Creating index test11 with primary shardCount11 and replica replicaCount11
--> Creating index test12 with primary shardCount12 and replica replicaCount12
--> Creating index test13 with primary shardCount13 and replica replicaCount13
--> Creating index test14 with primary shardCount14 and replica replicaCount14
--> leader2 and follower2 get disconnect event
--> leader3 and follower3 get disconnect event
--> leader4 and follower4 get disconnect event
--> leader5 and follower5 get disconnect event
--> leader6 and follower6 get disconnect event
--> leader7 and follower7 get disconnect event
--> leader8 and follower8 get disconnect event
--> leader9 and follower9 get disconnect event
--> leader10 and follower10 get disconnect event
--> leader11 and follower11 get disconnect event
--> leader12 and follower12 get disconnect event
--> leader13 and follower13 get disconnect event
--> leader14 and follower14 get disconnect event
stepped down as cluster-manager before recovering state [source2]
stepped down as cluster-manager before recovering state [source3]
stepped down as cluster-manager before recovering state [source4]
stepped down as cluster-manager before recovering state [source5]
stepped down as cluster-manager before recovering state [source6]
stepped down as cluster-manager before recovering state [source7]
stepped down as cluster-manager before recovering state [source8]
stepped down as cluster-manager before recovering state [source9]
stepped down as cluster-manager before recovering state [source10]
stepped down as cluster-manager before recovering state [source11]
stepped down as cluster-manager before recovering state [source12]
stepped down as cluster-manager before recovering state [source13]
stepped down as cluster-manager before recovering state [source14]
--> Creating index 2 with shard count 4 and replica count 6test2
--> Creating index 3 with shard count 8 and replica count 9test3
--> Creating index 4 with shard count 5 and replica count 7test4
--> Creating index 5 with shard count 1 and replica count 2test5
--> Creating index 6 with shard count 3 and replica count 4test6
--> Creating index 7 with shard count 6 and replica count 8test7
--> Creating index 8 with shard count 9 and replica count 5test8
--> Creating index 9 with shard count 7 and replica count 1test9
--> Creating index 10 with shard count 2 and replica count 3test10
--> Creating index 11 with shard count 4 and replica count 6test11
--> Creating index 12 with shard count 8 and replica count 9test12
--> Creating index 13 with shard count 5 and replica count 7test13
--> Creating index 14 with shard count 1 and replica count 2test14
--> disconnecting follower Bob
--> disconnecting follower Charlie
--> disconnecting follower Dave
--> disconnecting follower Eve
--> disconnecting follower Frank
--> disconnecting follower Grace
--> disconnecting follower Helen
--> disconnecting follower Ivan
--> disconnecting follower Jack
--> disconnecting follower Kelly
--> disconnecting follower Lily
--> disconnecting follower Mike
--> disconnecting follower Nancy
sd_notify returned error [2]
sd_notify returned error [3]
sd_notify returned error [4]
sd_notify returned error [5]
sd_notify returned error [6]
sd_notify returned error [7]
sd_notify returned error [8]
sd_notify returned error [9]
sd_notify returned error [10]
sd_notify returned error [11]
sd_notify returned error [12]
sd_notify returned error [13]
sd_notify returned error [14]
--> Creating 20 nodes
--> Creating 30 nodes
--> Creating 40 nodes
--> Creating 50 nodes
--> Creating 60 nodes
--> Creating 70 nodes
--> Creating 80 nodes
--> Creating 90 nodes
--> Creating 100 nodes
--> Creating 110 nodes
--> Creating 120 nodes
--> Creating 130 nodes
--> Creating 140 nodes
recovered [10] indices into cluster_state
recovered [2] indices into cluster_state
recovered [8] indices into cluster_state
recovered [3] indices into cluster_state
recovered [7] indices into cluster_state
recovered [1] indices into cluster_state
recovered [6] indices into cluster_state
recovered [9] indices into cluster_state
recovered [4] indices into cluster_state
recovered [11] indices into cluster_state
recovered [15] indices into cluster_state
recovered [12] indices into cluster_state
recovered [14] indices into cluster_state
--> changing health status of leader B to unhealthy
--> changing health status of leader C to unhealthy
--> changing health status of leader D to unhealthy
--> changing health status of leader E to unhealthy
--> changing health status of leader F to unhealthy
--> changing health status of leader G to unhealthy
--> changing health status of leader H to unhealthy
--> changing health status of leader I to unhealthy
--> changing health status of leader J to unhealthy
--> changing health status of leader K to unhealthy
--> changing health status of leader L to unhealthy
--> changing health status of leader M to unhealthy
--> changing health status of leader N to unhealthy
recover_after_time [200ms] elapsed. performing state recovery...
recover_after_time [300ms] elapsed. performing state recovery...
recover_after_time [400ms] elapsed. performing state recovery...
recover_after_time [500ms] elapsed. performing state recovery...
recover_after_time [600ms] elapsed. performing state recovery...
recover_after_time [700ms] elapsed. performing state recovery...
recover_after_time [800ms] elapsed. performing state recovery...
recover_after_time [900ms] elapsed. performing state recovery...
recover_after_time [1000ms] elapsed. performing state recovery...
recover_after_time [1100ms] elapsed. performing state recovery...
recover_after_time [1200ms] elapsed. performing state recovery...
recover_after_time [1300ms] elapsed. performing state recovery...
recover_after_time [1400ms] elapsed. performing state recovery...
--> blackholing leader node2
--> blackholing leader node3
--> blackholing leader node4
--> blackholing leader node5
--> blackholing leader node6
--> blackholing leader node7
--> blackholing leader node8
--> blackholing leader node9
--> blackholing leader node10
--> blackholing leader node11
--> blackholing leader node12
--> blackholing leader node13
--> blackholing leader node14
extending startup timeout via sd_notify failed with [1]
extending startup timeout via sd_notify failed with [2]
extending startup timeout via sd_notify failed with [3]
extending startup timeout via sd_notify failed with [4]
extending startup timeout via sd_notify failed with [5]
extending startup timeout via sd_notify failed with [6]
extending startup timeout via sd_notify failed with [7]
extending startup timeout via sd_notify failed with [8]
extending startup timeout via sd_notify failed with [9]
extending startup timeout via sd_notify failed with [10]
extending startup timeout via sd_notify failed with [11]
extending startup timeout via sd_notify failed with [12]
extending startup timeout via sd_notify failed with [13]
delayed state recovery failed Unknown error occurred
delayed state recovery failed Data corruption detected
delayed state recovery failed Failed to retrieve data
delayed state recovery failed Internal server error
delayed state recovery failed Connection timed out
delayed state recovery failed Invalid input
delayed state recovery failed Failed to load configuration
delayed state recovery failed Resource allocation failed
delayed state recovery failed Database connection lost
delayed state recovery failed Unexpected termination
delayed state recovery failed Insufficient memory
delayed state recovery failed File not found
delayed state recovery failed Invalid request received
OPENSEARCH_SD_NOTIFY is set to [false]
OPENSEARCH_SD_NOTIFY is set to [0]
OPENSEARCH_SD_NOTIFY is set to [1]
OPENSEARCH_SD_NOTIFY is set to [enabled]
OPENSEARCH_SD_NOTIFY is set to [disabled]
OPENSEARCH_SD_NOTIFY is set to [on]
OPENSEARCH_SD_NOTIFY is set to [off]
OPENSEARCH_SD_NOTIFY is set to [yes]
OPENSEARCH_SD_NOTIFY is set to [no]
OPENSEARCH_SD_NOTIFY is set to [active]
OPENSEARCH_SD_NOTIFY is set to [inactive]
OPENSEARCH_SD_NOTIFY is set to [enabled]
OPENSEARCH_SD_NOTIFY is set to [disabled]
OPENSEARCH_SD_NOTIFY is set to [1]
--> performing ops-based recoveries up to [82.0%] of docs
--> performing ops-based recoveries up to [63.5%] of docs
--> performing ops-based recoveries up to [91.2%] of docs
--> performing ops-based recoveries up to [70.8%] of docs
--> performing ops-based recoveries up to [88.1%] of docs
--> performing ops-based recoveries up to [77.3%] of docs
--> performing ops-based recoveries up to [95.4%] of docs
--> performing ops-based recoveries up to [60.6%] of docs
--> performing ops-based recoveries up to [85.7%] of docs
--> performing ops-based recoveries up to [72.9%] of docs
--> performing ops-based recoveries up to [93.8%] of docs
--> performing ops-based recoveries up to [68.1%] of docs
--> performing ops-based recoveries up to [80.2%] of docs
--> disconnecting leader node-2
--> disconnecting leader node-3
--> disconnecting leader node-4
--> disconnecting leader node-5
--> disconnecting leader node-6
--> disconnecting leader node-7
--> disconnecting leader node-8
--> disconnecting leader node-9
--> disconnecting leader node-10
--> disconnecting leader node-11
--> disconnecting leader node-12
--> disconnecting leader node-13
--> disconnecting leader node-14
delaying initial state recovery for 30 minutes. Server maintenance
delaying initial state recovery for 1 hour. Network congestion
delaying initial state recovery for 45 minutes. Database backup
delaying initial state recovery for 20 minutes. Hardware upgrade
delaying initial state recovery for 10 minutes. Software update
delaying initial state recovery for 50 minutes. Power outage
delaying initial state recovery for 25 minutes. Database migration
delaying initial state recovery for 35 minutes. Data corruption
delaying initial state recovery for 55 minutes. Server overload
delaying initial state recovery for 40 minutes. Security breach
delaying initial state recovery for 5 minutes. Configuration error
delaying initial state recovery for 3 hours. Memory leak
delaying initial state recovery for 1.5 hours. Disk failure
Failed to resolve inet address for allowed URL [google.com], skipping
Failed to resolve inet address for allowed URL [facebook.com], skipping
Failed to resolve inet address for allowed URL [stackoverflow.com], skipping
Failed to resolve inet address for allowed URL [github.com], skipping
Failed to resolve inet address for allowed URL [amazon.com], skipping
Failed to resolve inet address for allowed URL [baidu.com], skipping
Failed to resolve inet address for allowed URL [twitter.com], skipping
Failed to resolve inet address for allowed URL [youtube.com], skipping
Failed to resolve inet address for allowed URL [linkedin.com], skipping
Failed to resolve inet address for allowed URL [netflix.com], skipping
Failed to resolve inet address for allowed URL [instagram.com], skipping
Failed to resolve inet address for allowed URL [pinterest.com], skipping
Failed to resolve inet address for allowed URL [yahoo.com], skipping
--> start recovery request: starting seq_no 2, commit userData2
--> start recovery request: starting seq_no 3, commit userData3
--> start recovery request: starting seq_no 4, commit userData4
--> start recovery request: starting seq_no 5, commit userData5
--> start recovery request: starting seq_no 6, commit userData6
--> start recovery request: starting seq_no 7, commit userData7
--> start recovery request: starting seq_no 8, commit userData8
--> start recovery request: starting seq_no 9, commit userData9
--> start recovery request: starting seq_no 10, commit userData10
--> start recovery request: starting seq_no 11, commit userData11
--> start recovery request: starting seq_no 12, commit userData12
--> start recovery request: starting seq_no 13, commit userData13
--> start recovery request: starting seq_no 14, commit userData14
state recovery failed: IndexOutOfBoundsException
state recovery failed: IllegalArgumentException
state recovery failed: ArrayIndexOutOfBoundsException
state recovery failed: ConcurrentModificationException
state recovery failed: UnsupportedOperationException
state recovery failed: ClassCastException
state recovery failed: NoSuchElementException
state recovery failed: ArithmeticException
state recovery failed: StackOverflowError
state recovery failed: OutOfMemoryError
state recovery failed: SecurityException
state recovery failed: FileNotFoundException
state recovery failed: IOException
--> healing broken bones
--> healing illnesses
--> healing burns
--> healing cuts
--> healing infections
--> healing bruises
--> healing sprains
--> healing allergies
--> healing rashes
--> healing headaches
--> healing stomachaches
--> healing sore throats
--> healing back pain
not recovering from gateway, nodes_size (data+master) [15] < recover_after_nodes [7]
not recovering from gateway, nodes_size (data+master) [8] < recover_after_nodes [3]
not recovering from gateway, nodes_size (data+master) [12] < recover_after_nodes [6]
not recovering from gateway, nodes_size (data+master) [9] < recover_after_nodes [4]
not recovering from gateway, nodes_size (data+master) [14] < recover_after_nodes [7]
not recovering from gateway, nodes_size (data+master) [11] < recover_after_nodes [5]
not recovering from gateway, nodes_size (data+master) [7] < recover_after_nodes [2]
not recovering from gateway, nodes_size (data+master) [13] < recover_after_nodes [6]
not recovering from gateway, nodes_size (data+master) [10] < recover_after_nodes [5]
not recovering from gateway, nodes_size (data+master) [16] < recover_after_nodes [8]
not recovering from gateway, nodes_size (data+master) [9] < recover_after_nodes [4]
not recovering from gateway, nodes_size (data+master) [15] < recover_after_nodes [7]
not recovering from gateway, nodes_size (data+master) [12] < recover_after_nodes [6]
--> healing disconnect3 and disconnect4
--> healing disconnect5 and disconnect6
--> healing disconnect7 and disconnect8
--> healing disconnect9 and disconnect10
--> healing disconnect11 and disconnect12
--> healing disconnect13 and disconnect14
--> healing disconnect15 and disconnect16
--> healing disconnect17 and disconnect18
--> healing disconnect19 and disconnect20
--> healing disconnect21 and disconnect22
--> healing disconnect23 and disconnect24
--> healing disconnect25 and disconnect26
--> healing disconnect27 and disconnect28
--> preventing POST request by dropping request
--> preventing DELETE request by dropping request
--> preventing PUT request by dropping request
--> preventing HEAD request by dropping request
--> preventing OPTIONS request by dropping request
--> preventing PATCH request by dropping request
--> preventing TRACE request by dropping request
--> preventing CONNECT request by dropping request
--> preventing SEARCH request by dropping request
--> preventing UPDATE request by dropping request
--> preventing CREATE request by dropping request
--> preventing READ request by dropping request
--> preventing WRITE request by dropping request
--> preventing EXECUTE request by dropping request
not recovering from gateway, nodes_size (data) [15] < recover_after_data_nodes [3]
not recovering from gateway, nodes_size (data) [8] < recover_after_data_nodes [7]
not recovering from gateway, nodes_size (data) [12] < recover_after_data_nodes [2]
not recovering from gateway, nodes_size (data) [20] < recover_after_data_nodes [4]
not recovering from gateway, nodes_size (data) [6] < recover_after_data_nodes [5]
not recovering from gateway, nodes_size (data) [14] < recover_after_data_nodes [1]
not recovering from gateway, nodes_size (data) [9] < recover_after_data_nodes [6]
not recovering from gateway, nodes_size (data) [18] < recover_after_data_nodes [3]
not recovering from gateway, nodes_size (data) [7] < recover_after_data_nodes [1]
not recovering from gateway, nodes_size (data) [16] < recover_after_data_nodes [7]
not recovering from gateway, nodes_size (data) [11] < recover_after_data_nodes [4]
not recovering from gateway, nodes_size (data) [13] < recover_after_data_nodes [2]
not recovering from gateway, nodes_size (data) [19] < recover_after_data_nodes [6]
--> preventing POST request by throwing ConnectTransportException
--> preventing DELETE request by throwing ConnectTransportException
--> preventing PUT request by throwing ConnectTransportException
--> preventing HEAD request by throwing ConnectTransportException
--> preventing OPTIONS request by throwing ConnectTransportException
--> preventing PATCH request by throwing ConnectTransportException
--> preventing TRACE request by throwing ConnectTransportException
--> preventing CONNECT request by throwing ConnectTransportException
--> preventing FETCH request by throwing ConnectTransportException
--> preventing SEARCH request by throwing ConnectTransportException
--> preventing UPDATE request by throwing ConnectTransportException
--> preventing CREATE request by throwing ConnectTransportException
--> preventing READ request by throwing ConnectTransportException
--> preventing WRITE request by throwing ConnectTransportException
not recovering from gateway, nodes_size (master) [15] < recover_after_master_nodes [8]
not recovering from gateway, nodes_size (master) [22] < recover_after_master_nodes [12]
not recovering from gateway, nodes_size (master) [9] < recover_after_master_nodes [3]
not recovering from gateway, nodes_size (master) [17] < recover_after_master_nodes [9]
not recovering from gateway, nodes_size (master) [5] < recover_after_master_nodes [2]
not recovering from gateway, nodes_size (master) [12] < recover_after_master_nodes [6]
not recovering from gateway, nodes_size (master) [8] < recover_after_master_nodes [4]
not recovering from gateway, nodes_size (master) [13] < recover_after_master_nodes [7]
not recovering from gateway, nodes_size (master) [7] < recover_after_master_nodes [3]
not recovering from gateway, nodes_size (master) [20] < recover_after_master_nodes [9]
not recovering from gateway, nodes_size (master) [11] < recover_after_master_nodes [5]
not recovering from gateway, nodes_size (master) [16] < recover_after_master_nodes [8]
not recovering from gateway, nodes_size (master) [6] < recover_after_master_nodes [2]
Latest manifest is not present in remote store for cluster UUID: cluster_2
Latest manifest is not present in remote store for cluster UUID: cluster_3
Latest manifest is not present in remote store for cluster UUID: cluster_4
Latest manifest is not present in remote store for cluster UUID: cluster_5
Latest manifest is not present in remote store for cluster UUID: cluster_6
Latest manifest is not present in remote store for cluster UUID: cluster_7
Latest manifest is not present in remote store for cluster UUID: cluster_8
Latest manifest is not present in remote store for cluster UUID: cluster_9
Latest manifest is not present in remote store for cluster UUID: cluster_10
Latest manifest is not present in remote store for cluster UUID: cluster_11
Latest manifest is not present in remote store for cluster UUID: cluster_12
Latest manifest is not present in remote store for cluster UUID: cluster_13
Latest manifest is not present in remote store for cluster UUID: cluster_14
--> will drop requests between blue & red on [Tuesday]
--> will drop requests between blue & red on [Wednesday]
--> will drop requests between blue & red on [Thursday]
--> will drop requests between blue & red on [Friday]
--> will drop requests between blue & red on [Saturday]
--> will drop requests between blue & red on [Sunday]
--> will break connection between blue & red on [Monday]
--> will break connection between blue & red on [Tuesday]
--> will break connection between blue & red on [Wednesday]
--> will break connection between blue & red on [Thursday]
--> will break connection between blue & red on [Friday]
--> will break connection between blue & red on [Saturday]
--> will break connection between blue & red on [Sunday]
--> will drop requests between blue & red on [Summer]
Caught expected version conflict trying to perform mutation number [2] with version [v2] on attempt [2]. Retrying.
Caught expected version conflict trying to perform mutation number [3] with version [v3] on attempt [3]. Retrying.
Caught expected version conflict trying to perform mutation number [4] with version [v4] on attempt [4]. Retrying.
Caught expected version conflict trying to perform mutation number [5] with version [v5] on attempt [5]. Retrying.
Caught expected version conflict trying to perform mutation number [6] with version [v6] on attempt [6]. Retrying.
Caught expected version conflict trying to perform mutation number [7] with version [v7] on attempt [7]. Retrying.
Caught expected version conflict trying to perform mutation number [8] with version [v8] on attempt [8]. Retrying.
Caught expected version conflict trying to perform mutation number [9] with version [v9] on attempt [9]. Retrying.
Caught expected version conflict trying to perform mutation number [10] with version [v10] on attempt [10]. Retrying.
Caught expected version conflict trying to perform mutation number [11] with version [v11] on attempt [11]. Retrying.
Caught expected version conflict trying to perform mutation number [12] with version [v12] on attempt [12]. Retrying.
Caught expected version conflict trying to perform mutation number [13] with version [v13] on attempt [13]. Retrying.
Caught expected version conflict trying to perform mutation number [14] with version [v14] on attempt [14]. Retrying.
--> submitting value [456] to [Bob]
--> submitting value [789] to [Charlie]
--> submitting value [abc] to [David]
--> submitting value [def] to [Eve]
--> submitting value [ghi] to [Frank]
--> submitting value [xyz] to [Grace]
--> submitting value [123] to [Hank]
--> submitting value [456] to [Ivy]
--> submitting value [999] to [Jack]
--> submitting value [000] to [Karen]
--> submitting value [111] to [Liam]
--> submitting value [222] to [Mary]
--> submitting value [333] to [Nina]
--> attempting to send start_recovery request for shard: 2
--> attempting to send start_recovery request for shard: 3
--> attempting to send start_recovery request for shard: 4
--> attempting to send start_recovery request for shard: 5
--> attempting to send start_recovery request for shard: 6
--> attempting to send start_recovery request for shard: 7
--> attempting to send start_recovery request for shard: 8
--> attempting to send start_recovery request for shard: 9
--> attempting to send start_recovery request for shard: 10
--> attempting to send start_recovery request for shard: 11
--> attempting to send start_recovery request for shard: 12
--> attempting to send start_recovery request for shard: 13
--> attempting to send start_recovery request for shard: 14
Unblocking the [Task] executor
Unblocking the [Cache] executor
Unblocking the [Event] executor
Unblocking the [IO] executor
Unblocking the [Network] executor
Unblocking the [File] executor
Unblocking the [Database] executor
Unblocking the [Thread] executor
Unblocking the [Memory] executor
Unblocking the [UI] executor
Unblocking the [Job] executor
Unblocking the [Log] executor
Unblocking the [Security] executor
Unblocking the [Scheduler] executor
Settings: true
Settings: 'hello'
Settings: 2.5
Settings: [1, 2, 3]
Settings: 'admin'
Settings: false
Settings: 'world'
Settings: 100
Settings: [4, 5, 6]
Settings: 'guest'
Settings: 3.14
Settings: null
Settings: [7, 8, 9]
--> preventing registration response by throwing exception
--> preventing logout response by throwing exception
--> preventing search response by throwing exception
--> preventing purchase response by throwing exception
--> preventing add to cart response by throwing exception
--> preventing delete account response by throwing exception
--> preventing update profile response by throwing exception
--> preventing reset password response by throwing exception
--> preventing submit form response by throwing exception
--> preventing checkout response by throwing exception
--> preventing view cart response by throwing exception
--> preventing cancel order response by throwing exception
--> preventing contact support response by throwing exception
--> preventing remove item response by throwing exception
Blocked the [thread] executor
Blocked the [job] executor
Blocked the [process] executor
Blocked the [worker] executor
Blocked the [request] executor
Blocked the [command] executor
Blocked the [operation] executor
Blocked the [handler] executor
Blocked the [service] executor
Blocked the [scheduler] executor
Blocked the [agent] executor
Blocked the [event] executor
Blocked the [task2] executor
cluster state update already queued (setting cluster state to 2.0)
cluster state update already queued (setting cluster state to 3.0)
cluster state update already queued (setting cluster state to 4.0)
cluster state update already queued (setting cluster state to 5.0)
cluster state update already queued (setting cluster state to 6.0)
cluster state update already queued (setting cluster state to 7.0)
cluster state update already queued (setting cluster state to 8.0)
cluster state update already queued (setting cluster state to 9.0)
cluster state update already queued (setting cluster state to 10.0)
cluster state update already queued (setting cluster state to 11.0)
cluster state update already queued (setting cluster state to 12.0)
cluster state update already queued (setting cluster state to 13.0)
cluster state update already queued (setting cluster state to 14.0)
Arguments: [arg4, arg5, arg6]
Arguments: [arg7, arg8, arg9]
Arguments: [arg10, arg11, arg12]
Arguments: [arg13, arg14, arg15]
Arguments: [arg16, arg17, arg18]
Arguments: [arg19, arg20, arg21]
Arguments: [arg22, arg23, arg24]
Arguments: [arg25, arg26, arg27]
Arguments: [arg28, arg29, arg30]
Arguments: [arg31, arg32, arg33]
Arguments: [arg34, arg35, arg36]
Arguments: [arg37, arg38, arg39]
Arguments: [arg40, arg41, arg42]
--> preventing logout response by breaking connection
--> preventing register response by breaking connection
--> preventing payment response by breaking connection
--> preventing search response by breaking connection
--> preventing add to cart response by breaking connection
--> preventing checkout response by breaking connection
--> preventing update profile response by breaking connection
--> preventing add to wishlist response by breaking connection
--> preventing remove from cart response by breaking connection
--> preventing recommend response by breaking connection
--> preventing view product response by breaking connection
--> preventing view order response by breaking connection
--> preventing reset password response by breaking connection
Blocking the [worker] executor
Blocking the [background] executor
Blocking the [scheduler] executor
Blocking the [event] executor
Blocking the [io] executor
Blocking the [network] executor
Blocking the [disk] executor
Blocking the [render] executor
Blocking the [cache] executor
Blocking the [download] executor
Blocking the [update] executor
Blocking the [database] executor
Blocking the [query] executor
queuing cluster state update (setting cluster state to 5)
queuing cluster state update (setting cluster state to 10)
queuing cluster state update (setting cluster state to 3)
queuing cluster state update (setting cluster state to 7)
queuing cluster state update (setting cluster state to 1)
queuing cluster state update (setting cluster state to 9)
queuing cluster state update (setting cluster state to 6)
queuing cluster state update (setting cluster state to 4)
queuing cluster state update (setting cluster state to 8)
queuing cluster state update (setting cluster state to 12)
queuing cluster state update (setting cluster state to 18)
queuing cluster state update (setting cluster state to 14)
queuing cluster state update (setting cluster state to 11)
queuing term update: (setting term to 1)
queuing term update: (setting term to 2)
queuing term update: (setting term to 3)
queuing term update: (setting term to 4)
queuing term update: (setting term to 5)
queuing term update: (setting term to 6)
queuing term update: (setting term to 7)
queuing term update: (setting term to 8)
queuing term update: (setting term to 9)
queuing term update: (setting term to 10)
queuing term update: (setting term to 11)
queuing term update: (setting term to 12)
queuing term update: (setting term to 13)
expected IllegalStateException  but got ArrayIndexOutOfBoundsException
expected IllegalStateException  but got IllegalArgumentException
expected IllegalStateException  but got IndexOutOfBoundsException
expected IllegalStateException  but got ClassCastException
expected IllegalStateException  but got UnsupportedOperationException
expected IllegalStateException  but got RuntimeException
expected IllegalStateException  but got NumberFormatException
expected IllegalStateException  but got NoSuchElementException
expected IllegalStateException  but got ConcurrentModificationException
expected IllegalStateException  but got FileNotFoundException
expected IllegalStateException  but got IllegalArgumentException
expected IllegalStateException  but got NullPointerException
expected IllegalStateException  but got IllegalAccessError
--> creating test index: index2
--> creating test index: index3
--> creating test index: index4
--> creating test index: index5
--> creating test index: index6
--> creating test index: index7
--> creating test index: index8
--> creating test index: index9
--> creating test index: index10
--> creating test index: index11
--> creating test index: index12
--> creating test index: index13
--> creating test index: index14
shard2 scheduling reroute for Shard Relocation
shard3 scheduling reroute for Resource Balancing
shard4 scheduling reroute for Index Optimization
shard5 scheduling reroute for Network Upgrade
shard6 scheduling reroute for Disk Full
shard7 scheduling reroute for Memory Leak
shard8 scheduling reroute for Query Timeout
shard9 scheduling reroute for CPU Overload
shard10 scheduling reroute for Replication Lag
shard11 scheduling reroute for Data Corruption
shard12 scheduling reroute for Power Outage
shard13 scheduling reroute for Hardware Failure
shard14 scheduling reroute for Version Upgrade
expected ConnectTransportException  but got IOException
expected ConnectTransportException  but got ConnectionRefusedException
expected ConnectTransportException  but got SSLHandshakeException
expected ConnectTransportException  but got NoRouteToHostException
expected ConnectTransportException  but got ConnectException
expected ConnectTransportException  but got UnknownHostException
expected ConnectTransportException  but got SocketTimeoutException
expected ConnectTransportException  but got EOFException
expected ConnectTransportException  but got IllegalArgumentException
expected ConnectTransportException  but got ClassCastException
expected ConnectTransportException  but got NullPointerException
expected ConnectTransportException  but got IndexOutOfBoundsException
expected ConnectTransportException  but got AssertionError
expected TransportException  but got TimeoutException
expected TransportException  but got ConnectException
expected TransportException  but got RemoteException
expected TransportException  but got SSLHandshakeException
expected TransportException  but got NullPointerException
expected TransportException  but got ClassCastException
expected TransportException  but got IllegalArgumentException
expected TransportException  but got NoSuchElementException
expected TransportException  but got IndexOutOfBoundsException
expected TransportException  but got UnsupportedOperationException
expected TransportException  but got ArrayIndexOutOfBoundsException
expected TransportException  but got IllegalStateException
expected TransportException  but got SecurityException
Client did not provide certificates UnknownHostException
Client did not provide certificates SSLException
Client did not provide certificates SocketTimeoutException
Client did not provide certificates FileNotFoundException
Client did not provide certificates IOException
Client did not provide certificates NullPointerException
Client did not provide certificates IllegalArgumentException
Client did not provide certificates InvalidKeyException
Client did not provide certificates IndexOutOfBoundsException
Client did not provide certificates SecurityException
Client did not provide certificates NoSuchAlgorithmException
Client did not provide certificates ClassCastException
Client did not provide certificates ArrayIndexOutOfBoundsException
failed to fetch state from nodeB
failed to fetch state from nodeC
failed to fetch state from nodeD
failed to fetch state from nodeE
failed to fetch state from nodeF
failed to fetch state from nodeG
failed to fetch state from nodeH
failed to fetch state from nodeI
failed to fetch state from nodeJ
failed to fetch state from nodeK
failed to fetch state from nodeL
failed to fetch state from nodeM
failed to fetch state from nodeN
expected ClusterBlockException  but got IndexOutOfBoundsException
expected ClusterBlockException  but got IllegalArgumentException
expected ClusterBlockException  but got UnsupportedOperationException
expected ClusterBlockException  but got ClassCastException
expected ClusterBlockException  but got ArrayIndexOutOfBoundsException
expected ClusterBlockException  but got FileNotFoundException
expected ClusterBlockException  but got NoSuchMethodException
expected ClusterBlockException  but got NoSuchFieldException
expected ClusterBlockException  but got NumberFormatException
expected ClusterBlockException  but got ConcurrentModificationException
expected ClusterBlockException  but got NullPointerException
expected ClusterBlockException  but got IllegalArgumentException
expected ClusterBlockException  but got NoSuchElementException
Didn't trigger a reindex failure on the second attempt
Didn't trigger a reindex failure on the third attempt
Didn't trigger a reindex failure on the fourth attempt
Didn't trigger a reindex failure on the fifth attempt
Didn't trigger a reindex failure on the sixth attempt
Didn't trigger a reindex failure on the seventh attempt
Didn't trigger a reindex failure on the eighth attempt
Didn't trigger a reindex failure on the ninth attempt
Didn't trigger a reindex failure on the tenth attempt
Didn't trigger a reindex failure on the eleventh attempt
Didn't trigger a reindex failure on the twelfth attempt
Didn't trigger a reindex failure on the thirteenth attempt
Didn't trigger a reindex failure on the fourteenth attempt
performing state recovery from [node4, node5, node6]
performing state recovery from [node7, node8, node9]
performing state recovery from [node10, node11, node12]
performing state recovery from [node13, node14, node15]
performing state recovery from [node16, node17, node18]
performing state recovery from [node19, node20, node21]
performing state recovery from [node22, node23, node24]
performing state recovery from [node25, node26, node27]
performing state recovery from [node28, node29, node30]
performing state recovery from [node31, node32, node33]
performing state recovery from [node34, node35, node36]
performing state recovery from [node37, node38, node39]
performing state recovery from [node40, node41, node42]
adding test block to cluster state image.jpg
adding test block to cluster state socket.jpg
adding test block to cluster state data.bin
adding test block to cluster state config.xml
adding test block to cluster state log.txt
adding test block to cluster state report.csv
adding test block to cluster state video.mp4
adding test block to cluster state audio.wav
adding test block to cluster state temp.tmp
adding test block to cluster state document.docx
adding test block to cluster state code.java
adding test block to cluster state style.css
adding test block to cluster state script.js
--> delete all documents with routing [5678] with a delete-by-query
--> delete all documents with routing [abcd] with a delete-by-query
--> delete all documents with routing [efgh] with a delete-by-query
--> delete all documents with routing [ijkl] with a delete-by-query
--> delete all documents with routing [mnop] with a delete-by-query
--> delete all documents with routing [qrst] with a delete-by-query
--> delete all documents with routing [uvwx] with a delete-by-query
--> delete all documents with routing [yz12] with a delete-by-query
--> delete all documents with routing [34ab] with a delete-by-query
--> delete all documents with routing [56cd] with a delete-by-query
--> delete all documents with routing [78ef] with a delete-by-query
--> delete all documents with routing [ghij] with a delete-by-query
--> delete all documents with routing [klmn] with a delete-by-query
op [thread-2] has started and will resume execution once allPermitsAction is terminated
op [thread-3] has started and will resume execution once allPermitsAction is terminated
op [thread-4] has started and will resume execution once allPermitsAction is terminated
op [thread-5] has started and will resume execution once allPermitsAction is terminated
op [thread-6] has started and will resume execution once allPermitsAction is terminated
op [thread-7] has started and will resume execution once allPermitsAction is terminated
op [thread-8] has started and will resume execution once allPermitsAction is terminated
op [thread-9] has started and will resume execution once allPermitsAction is terminated
op [thread-10] has started and will resume execution once allPermitsAction is terminated
op [thread-11] has started and will resume execution once allPermitsAction is terminated
op [thread-12] has started and will resume execution once allPermitsAction is terminated
op [thread-13] has started and will resume execution once allPermitsAction is terminated
op [thread-14] has started and will resume execution once allPermitsAction is terminated
failed to send allocate dangled java.io.IOException
failed to send allocate dangled NullPointerException
failed to send allocate dangled ClassNotFoundException
failed to send allocate dangled ArrayIndexOutOfBoundsException
failed to send allocate dangled IllegalArgumentException
failed to send allocate dangled FileNotFoundException
failed to send allocate dangled OutOfMemoryError
failed to send allocate dangled ArithmeticException
failed to send allocate dangled NoSuchElementException
failed to send allocate dangled SocketTimeoutException
failed to send allocate dangled SQLException
failed to send allocate dangled IndexOutOfBoundsException
failed to send allocate dangled RuntimeException
--> counting documents with no routing, should be equal to [100]
--> counting documents with no routing, should be equal to [150]
--> counting documents with no routing, should be equal to [200]
--> counting documents with no routing, should be equal to [250]
--> counting documents with no routing, should be equal to [300]
--> counting documents with no routing, should be equal to [350]
--> counting documents with no routing, should be equal to [400]
--> counting documents with no routing, should be equal to [450]
--> counting documents with no routing, should be equal to [500]
--> counting documents with no routing, should be equal to [550]
--> counting documents with no routing, should be equal to [600]
--> counting documents with no routing, should be equal to [650]
--> counting documents with no routing, should be equal to [700]
starting [8] operations, among which the first [1] started ops should be blocked by [semaphore]
starting [5] operations, among which the first [2] started ops should be blocked by [mutex]
starting [15] operations, among which the first [7] started ops should be blocked by [condition variable]
starting [12] operations, among which the first [4] started ops should be blocked by [read-write lock]
starting [6] operations, among which the first [2] started ops should be blocked by [mutex]
starting [9] operations, among which the first [3] started ops should be blocked by [counter]
starting [7] operations, among which the first [2] started ops should be blocked by [mutex]
starting [13] operations, among which the first [5] started ops should be blocked by [semaphore]
starting [11] operations, among which the first [4] started ops should be blocked by [lock]
starting [4] operations, among which the first [1] started ops should be blocked by [condition variable]
starting [8] operations, among which the first [2] started ops should be blocked by [read-write lock]
starting [6] operations, among which the first [3] started ops should be blocked by [mutex]
starting [14] operations, among which the first [6] started ops should be blocked by [counter]
--> indexing [200] documents with routing
--> indexing [300] documents with routing
--> indexing [400] documents with routing
--> indexing [500] documents with routing
--> indexing [600] documents with routing
--> indexing [700] documents with routing
--> indexing [800] documents with routing
--> indexing [900] documents with routing
--> indexing [1000] documents with routing
--> indexing [1100] documents with routing
--> indexing [1200] documents with routing
--> indexing [1300] documents with routing
--> indexing [1400] documents with routing
got exception: ArrayIndexOutOfBoundsException
got exception: FileNotFoundException
got exception: NoSuchElementException
got exception: IllegalArgumentException
got exception: IllegalStateException
got exception: ClassNotFoundException
got exception: TimeoutException
got exception: ArithmeticException
got exception: IndexOutOfBoundsException
got exception: NoSuchMethodException
got exception: StackOverflowError
got exception: UnsupportedOperationException
got exception: NumberFormatException
--> create index on node: nodeB
--> create index on node: nodeC
--> create index on node: nodeD
--> create index on node: nodeE
--> create index on node: nodeF
--> create index on node: nodeG
--> create index on node: nodeH
--> create index on node: nodeI
--> create index on node: nodeJ
--> create index on node: nodeK
--> create index on node: nodeL
--> create index on node: nodeM
--> create index on node: nodeN
using state: executing
using state: paused
using state: complete
using state: error
using state: idle
using state: terminated
using state: waiting
using state: processing
using state: stopped
using state: active
using state: standby
using state: initializing
using state: sleeping
--> primary is assigned to [node2], checking request forwarded
--> primary is assigned to [node3], checking request forwarded
--> primary is assigned to [node4], checking request forwarded
--> primary is assigned to [node5], checking request forwarded
--> primary is assigned to [node6], checking request forwarded
--> primary is assigned to [node7], checking request forwarded
--> primary is assigned to [node8], checking request forwarded
--> primary is assigned to [node9], checking request forwarded
--> primary is assigned to [node10], checking request forwarded
--> primary is assigned to [node11], checking request forwarded
--> primary is assigned to [node12], checking request forwarded
--> primary is assigned to [node13], checking request forwarded
--> primary is assigned to [node14], checking request forwarded
using state: STARTED
using state: STOPPED
using state: RECOVERING
using state: SUSPENDED
using state: SHUTTING_DOWN
--> relocation complete state: STARTED
--> relocation complete state: IN_PROGRESS
--> relocation complete state: COMPLETED
--> relocation complete state: FAILED
--> relocation complete state: SUSPENDED
--> relocation complete state: ABORTED
--> relocation complete state: PENDING
--> relocation complete state: RETRY
--> relocation complete state: STOPPED
--> relocation complete state: PAUSED
--> relocation complete state: RESUMED
--> relocation complete state: CANCELLED
--> relocation complete state: SUCCESS
--> relocation complete state: ERROR
chose to modify 3 out of 15 docs
chose to modify 8 out of 20 docs
chose to modify 2 out of 8 docs
chose to modify 6 out of 12 docs
chose to modify 4 out of 9 docs
chose to modify 7 out of 14 docs
chose to modify 1 out of 6 docs
chose to modify 9 out of 18 docs
chose to modify 3 out of 7 docs
chose to modify 10 out of 25 docs
chose to modify 4 out of 11 docs
chose to modify 6 out of 13 docs
chose to modify 2 out of 5 docs
--> [iteration 2] relocation complete
--> [iteration 3] relocation complete
--> [iteration 4] relocation complete
--> [iteration 5] relocation complete
--> [iteration 6] relocation complete
--> [iteration 7] relocation complete
--> [iteration 8] relocation complete
--> [iteration 9] relocation complete
--> [iteration 10] relocation complete
--> [iteration 11] relocation complete
--> [iteration 12] relocation complete
--> [iteration 13] relocation complete
--> [iteration 14] relocation complete
failed to list dangling indices NullPointerException
failed to list dangling indices ArrayIndexOutOfBoundsException
failed to list dangling indices FileNotFoundException
failed to list dangling indices IllegalArgumentException
failed to list dangling indices ClassCastException
failed to list dangling indices ArithmeticException
failed to list dangling indices NoSuchElementException
failed to list dangling indices RuntimeException
failed to list dangling indices UnsupportedOperationException
failed to list dangling indices IndexOutOfBoundsException
failed to list dangling indices NumberFormatException
failed to list dangling indices IOException
failed to list dangling indices SecurityException
setting up [200] docs
setting up [300] docs
setting up [400] docs
setting up [500] docs
setting up [600] docs
setting up [700] docs
setting up [800] docs
setting up [900] docs
setting up [1000] docs
setting up [1100] docs
setting up [1200] docs
setting up [1300] docs
setting up [1400] docs
--> primary assigned state:STARTING
--> primary assigned state:IN_PROGRESS
--> primary assigned state:COMPLETED
--> primary assigned state:FAILED
--> primary assigned state:STOPPED
--> primary assigned state:RESTARTING
--> primary assigned state:TERMINATING
--> primary assigned state:FINISHED
--> primary assigned state:PAUSED
--> primary assigned state:WAITING
--> primary assigned state:UNKNOWN
--> primary assigned state:SUSPENDED
--> primary assigned state:RESUMING
timed out for waiting for relocation iteration [2] cluster state yellow hot threads CPU usage: 85%
timed out for waiting for relocation iteration [3] cluster state red hot threads CPU usage: 90%
timed out for waiting for relocation iteration [4] cluster state green hot threads CPU usage: 75%
timed out for waiting for relocation iteration [5] cluster state yellow hot threads CPU usage: 70%
timed out for waiting for relocation iteration [6] cluster state red hot threads CPU usage: 65%
timed out for waiting for relocation iteration [7] cluster state green hot threads CPU usage: 90%
timed out for waiting for relocation iteration [8] cluster state yellow hot threads CPU usage: 85%
timed out for waiting for relocation iteration [9] cluster state red hot threads CPU usage: 80%
timed out for waiting for relocation iteration [10] cluster state green hot threads CPU usage: 70%
timed out for waiting for relocation iteration [11] cluster state yellow hot threads CPU usage: 75%
timed out for waiting for relocation iteration [12] cluster state red hot threads CPU usage: 65%
timed out for waiting for relocation iteration [13] cluster state green hot threads CPU usage: 75%
timed out for waiting for relocation iteration [14] cluster state yellow hot threads CPU usage: 80%
rethrottling local task [456] to [100] requests per second
rethrottling local task [789] to [200] requests per second
rethrottling local task [321] to [75] requests per second
rethrottling local task [654] to [150] requests per second
rethrottling local task [987] to [250] requests per second
rethrottling local task [111] to [90] requests per second
rethrottling local task [222] to [180] requests per second
rethrottling local task [333] to [120] requests per second
rethrottling local task [444] to [240] requests per second
rethrottling local task [555] to [95] requests per second
rethrottling local task [666] to [190] requests per second
rethrottling local task [777] to [60] requests per second
rethrottling local task [888] to [30] requests per second
rethrottling children of task [456] to [50] requests per second
rethrottling children of task [789] to [200] requests per second
rethrottling children of task [234] to [75] requests per second
rethrottling children of task [567] to [150] requests per second
rethrottling children of task [890] to [80] requests per second
rethrottling children of task [345] to [120] requests per second
rethrottling children of task [678] to [250] requests per second
rethrottling children of task [901] to [60] requests per second
rethrottling children of task [432] to [180] requests per second
rethrottling children of task [765] to [90] requests per second
rethrottling children of task [098] to [300] requests per second
rethrottling children of task [321] to [70] requests per second
rethrottling children of task [654] to [130] requests per second
[1] no longer dangling (created), removing from dangling list
[2] no longer dangling (created), removing from dangling list
[3] no longer dangling (created), removing from dangling list
[4] no longer dangling (created), removing from dangling list
[5] no longer dangling (created), removing from dangling list
[6] no longer dangling (created), removing from dangling list
[7] no longer dangling (created), removing from dangling list
[8] no longer dangling (created), removing from dangling list
[9] no longer dangling (created), removing from dangling list
[10] no longer dangling (created), removing from dangling list
[11] no longer dangling (created), removing from dangling list
[12] no longer dangling (created), removing from dangling list
[13] no longer dangling (created), removing from dangling list
expected SearchPhaseException: [Invalid query]
expected SearchPhaseException: [Timeout exception]
expected SearchPhaseException: [Index not found]
expected SearchPhaseException: [Connection refused]
expected SearchPhaseException: [Authorization failure]
expected SearchPhaseException: [Syntax error]
expected SearchPhaseException: [Invalid parameter]
expected SearchPhaseException: [Resource exhausted]
expected SearchPhaseException: [Permission denied]
expected SearchPhaseException: [Invalid request]
expected SearchPhaseException: [Execution error]
expected SearchPhaseException: [Data corruption]
expected SearchPhaseException: [Network failure]
expected SearchPhaseException: [Disk full]
--> using initial replicationGroup: RG-002
--> using initial replicationGroup: RG-003
--> using initial replicationGroup: RG-004
--> using initial replicationGroup: RG-005
--> using initial replicationGroup: RG-006
--> using initial replicationGroup: RG-007
--> using initial replicationGroup: RG-008
--> using initial replicationGroup: RG-009
--> using initial replicationGroup: RG-010
--> using initial replicationGroup: RG-011
--> using initial replicationGroup: RG-012
--> using initial replicationGroup: RG-013
--> using initial replicationGroup: RG-014
ignoring unknown database setting: [username] with value [admin]; archiving
ignoring unknown security setting: [allowAccess] with value [false]; archiving
ignoring unknown logging setting: [logLevel] with value [DEBUG]; archiving
ignoring unknown authentication setting: [ldapURL] with value [ldap://localhost:389]; archiving
ignoring unknown cache setting: [maxSize] with value [1000]; archiving
ignoring unknown encryption setting: [algorithm] with value [AES]; archiving
ignoring unknown compression setting: [algorithm] with value [GZIP]; archiving
ignoring unknown messaging setting: [queueName] with value [myQueue]; archiving
ignoring unknown monitoring setting: [logInterval] with value [60]; archiving
ignoring unknown scheduling setting: [cronExpression] with value [0 0/5 * * * ?]; archiving
ignoring unknown mail setting: [smtpHost] with value [smtp.example.com]; archiving
ignoring unknown notification setting: [emailAddress] with value [info@example.com]; archiving
ignoring unknown performance setting: [maxThreads] with value [100]; archiving
Failed to shutdown the remote connection: SocketException
Failed to shutdown the remote connection: TimeoutException
Failed to shutdown the remote connection: ConnectionLostException
Failed to shutdown the remote connection: SSLHandshakeException
Failed to shutdown the remote connection: AuthorizationException
Failed to shutdown the remote connection: UnknownHostException
Failed to shutdown the remote connection: NullPointerException
Failed to shutdown the remote connection: SecurityException
Failed to shutdown the remote connection: ClassCastException
Failed to shutdown the remote connection: IllegalArgumentException
Failed to shutdown the remote connection: OutOfMemoryError
Failed to shutdown the remote connection: StackOverflowError
Failed to shutdown the remote connection: ArrayIndexOutOfBoundsException
total shards: 10
total shards: 3
total shards: 8
total shards: 2
total shards: 7
total shards: 4
total shards: 9
total shards: 6
total shards: 1
total shards: 12
total shards: 15
total shards: 20
total shards: 11
Successfully cleared [scrollId2]
Successfully cleared [scrollId3]
Successfully cleared [scrollId4]
Successfully cleared [scrollId5]
Successfully cleared [scrollId6]
Successfully cleared [scrollId7]
Successfully cleared [scrollId8]
Successfully cleared [scrollId9]
Successfully cleared [scrollId10]
Successfully cleared [scrollId11]
Successfully cleared [scrollId12]
Successfully cleared [scrollId13]
Successfully cleared [scrollId14]
--> using initial state: INITIALIZING
--> using initial state: CLOSED
--> using initial state: RECOVERING
--> using initial state: STOPPED
--> using initial state: SHUTTING_DOWN
--> using initial state: FAILED
--> using initial state: BLOCKED
--> using initial state: PAUSED
--> using initial state: INTERRUPTING
--> using initial state: RESTARTING
--> using initial state: COMPLETED
--> using initial state: DISCONNECTED
--> using initial state: SUSPENDED
--> using initial state: RESUMING
shard2 received failure for [doc_456] from node XYZ for an older fetching round (expected: 8 but was: 4)
shard3 received failure for [doc_789] from node PQR for an older fetching round (expected: 10 but was: 6)
shard4 received failure for [doc_012] from node DEF for an older fetching round (expected: 15 but was: 9)
shard5 received failure for [doc_345] from node GHI for an older fetching round (expected: 12 but was: 7)
shard6 received failure for [doc_678] from node MNO for an older fetching round (expected: 9 but was: 5)
shard7 received failure for [doc_901] from node JKL for an older fetching round (expected: 6 but was: 2)
shard8 received failure for [doc_234] from node STU for an older fetching round (expected: 11 but was: 8)
shard9 received failure for [doc_567] from node VWX for an older fetching round (expected: 7 but was: 3)
shard10 received failure for [doc_890] from node YZA for an older fetching round (expected: 14 but was: 10)
shard11 received failure for [doc_123] from node DEF for an older fetching round (expected: 17 but was: 11)
shard12 received failure for [doc_456] from node GHI for an older fetching round (expected: 20 but was: 12)
shard13 received failure for [doc_789] from node JKL for an older fetching round (expected: 9 but was: 5)
shard14 received failure for [doc_012] from node MNO for an older fetching round (expected: 12 but was: 6)
unexpected error NullPointerException
unexpected error ArrayIndexOutOfBoundsException
unexpected error FileNotFoundException
unexpected error NumberFormatException
unexpected error ClassNotFoundException
unexpected error IllegalArgumentException
unexpected error IllegalStateException
unexpected error IndexOutOfBoundsException
unexpected error ArithmeticException
unexpected error OutOfMemoryError
unexpected error StackOverflowError
unexpected error NoSuchElementException
unexpected error UnsupportedOperationException
unexpected error ConcurrentModificationException
exception(s) caught during test ArrayIndexOutOfBoundsException
exception(s) caught during test ArithmeticException
exception(s) caught during test FileNotFoundException
exception(s) caught during test IllegalArgumentException
exception(s) caught during test IllegalStateException
exception(s) caught during test ClassCastException
exception(s) caught during test NumberFormatException
exception(s) caught during test NoSuchElementException
exception(s) caught during test NullPointerException
exception(s) caught during test ArrayIndexOutOfBoundsException
exception(s) caught during test ArithmeticException
exception(s) caught during test FileNotFoundException
exception(s) caught during test IllegalArgumentException
More than one implementation found: ElasticsearchReindexExtension
More than one implementation found: LuceneReindexExtension
More than one implementation found: KafkaReindexExtension
More than one implementation found: RabbitMQReindexExtension
More than one implementation found: AWSReindexExtension
More than one implementation found: AzureReindexExtension
More than one implementation found: GoogleCloudReindexExtension
More than one implementation found: MongoDBReindexExtension
More than one implementation found: OracleReindexExtension
More than one implementation found: SQLServerReindexExtension
More than one implementation found: MySQLReindexExtension
More than one implementation found: PostgreSQLReindexExtension
More than one implementation found: RedisReindexExtension
More than one implementation found: MemcachedReindexExtension
INFO received response for [image.jpg] from node 5678 for an older fetching round (expected: 4 but was: 3)
INFO received response for [socket.jpg] from node 9101 for an older fetching round (expected: 6 but was: 5)
INFO received response for [video.mp4] from node 1121 for an older fetching round (expected: 8 but was: 7)
INFO received response for [document.docx] from node 3141 for an older fetching round (expected: 10 but was: 9)
INFO received response for [audio.wav] from node 5161 for an older fetching round (expected: 12 but was: 11)
INFO received response for [file.txt] from node 7181 for an older fetching round (expected: 14 but was: 13)
INFO received response for [picture.png] from node 9202 for an older fetching round (expected: 16 but was: 15)
INFO received response for [data.csv] from node 1223 for an older fetching round (expected: 18 but was: 17)
INFO received response for [document.pdf] from node 3243 for an older fetching round (expected: 20 but was: 19)
INFO received response for [image.jpeg] from node 5263 for an older fetching round (expected: 22 but was: 21)
INFO received response for [video.mov] from node 7283 for an older fetching round (expected: 24 but was: 23)
INFO received response for [audio.mp3] from node 9304 for an older fetching round (expected: 26 but was: 25)
INFO received response for [socket.txt] from node 1324 for an older fetching round (expected: 28 but was: 27)
Error: node 2 has failed for [network] (failure [Invalid Credentials])
Fatal: node 3 has failed for [server] (failure [Out of Memory])
Warning: node 4 has failed for [storage] (failure [Disk Full])
Error: node 5 has failed for [authentication] (failure [User Locked])
Fatal: node 6 has failed for [cache] (failure [Cache Overflow])
Warning: node 7 has failed for [security] (failure [Untrusted Certificate])
Error: node 8 has failed for [service] (failure [Internal Server Error])
Fatal: node 9 has failed for [processing] (failure [Null Pointer Exception])
Warning: node 10 has failed for [backup] (failure [Backup Corrupted])
Error: node 11 has failed for [communication] (failure [Connection Reset])
Fatal: node 12 has failed for [indexing] (failure [Index Out of Bounds])
Warning: node 13 has failed for [memory] (failure [Memory Leak])
Error: node 14 has failed for [monitoring] (failure [Timeout])
search for all docs of a specific type failed NullPointerException
search for all docs of a specific type failed ArrayIndexOutOfBoundsException
search for all docs of a specific type failed FileNotFoundException
search for all docs of a specific type failed IllegalArgumentException
search for all docs of a specific type failed NumberFormatException
search for all docs of a specific type failed ClassCastException
search for all docs of a specific type failed ConcurrentModificationException
search for all docs of a specific type failed NoSuchElementException
search for all docs of a specific type failed UnsupportedOperationException
search for all docs of a specific type failed IndexOutOfBoundsException
search for all docs of a specific type failed ArithmeticException
search for all docs of a specific type failed OutOfMemoryError
search for all docs of a specific type failed StackOverflowError
search for all docs of a specific type failed AssertionError
Failing on node 2
Failing on node 3
Failing on node 4
Failing on node 5
Failing on node 6
Failing on node 7
Failing on node 8
Failing on node 9
Failing on node 10
Failing on node 11
Failing on node 12
Failing on node 13
Failing on node 14
[456]: Finishing early because the task was cancelled
[789]: Finishing early because the task was cancelled
[234]: Finishing early because the task was cancelled
[567]: Finishing early because the task was cancelled
[890]: Finishing early because the task was cancelled
[345]: Finishing early because the task was cancelled
[678]: Finishing early because the task was cancelled
[901]: Finishing early because the task was cancelled
[432]: Finishing early because the task was cancelled
[765]: Finishing early because the task was cancelled
[098]: Finishing early because the task was cancelled
[543]: Finishing early because the task was cancelled
[876]: Finishing early because the task was cancelled
Task action on node 2
Task action on node 3
Task action on node 4
Task action on node 5
Task action on node 6
Task action on node 7
Task action on node 8
Task action on node 9
Task action on node 10
Task action on node 11
Task action on node 12
Task action on node 13
Task action on node 14
response 404
response 500
response 302
response 201
response 301
response 403
response 401
response 204
response 400
response 503
response 502
response 408
response 301
indexing [200] docs
indexing [300] docs
indexing [400] docs
indexing [500] docs
indexing [600] docs
indexing [700] docs
indexing [800] docs
indexing [900] docs
indexing [1000] docs
indexing [1100] docs
indexing [1200] docs
indexing [1300] docs
indexing [1400] docs
Listing currently running tasks using node [2]
Listing currently running tasks using node [3]
Listing currently running tasks using node [4]
Listing currently running tasks using node [5]
Listing currently running tasks using node [6]
Listing currently running tasks using node [7]
Listing currently running tasks using node [8]
Listing currently running tasks using node [9]
Listing currently running tasks using node [10]
Listing currently running tasks using node [11]
Listing currently running tasks using node [12]
Listing currently running tasks using node [13]
Listing currently running tasks using node [14]
iter 4, iter1 5, iter2 6, 150
iter 7, iter1 8, iter2 9, 200
iter 10, iter1 11, iter2 12, 250
iter 13, iter1 14, iter2 15, 300
iter 16, iter1 17, iter2 18, 350
iter 19, iter1 20, iter2 21, 400
iter 22, iter1 23, iter2 24, 450
iter 25, iter1 26, iter2 27, 500
iter 28, iter1 29, iter2 30, 550
iter 31, iter1 32, iter2 33, 600
iter 34, iter1 35, iter2 36, 650
iter 37, iter1 38, iter2 39, 700
iter 40, iter1 41, iter2 42, 750
[2022-06-02T10:15:45]: preparing bulk request
[2022-06-03T14:27:59]: preparing bulk request
[2022-06-04T16:42:33]: preparing bulk request
[2022-06-05T09:58:21]: preparing bulk request
[2022-06-06T11:20:05]: preparing bulk request
[2022-06-07T13:45:17]: preparing bulk request
[2022-06-08T15:55:39]: preparing bulk request
[2022-06-09T10:10:54]: preparing bulk request
[2022-06-10T09:22:07]: preparing bulk request
[2022-06-11T12:16:41]: preparing bulk request
[2022-06-12T14:33:25]: preparing bulk request
[2022-06-13T16:47:09]: preparing bulk request
[2022-06-14T08:51:36]: preparing bulk request
Doc 789012 was found on shard 3
Doc 345678 was found on shard 2
Doc 901234 was found on shard 4
Doc 567890 was found on shard 3
Doc 123456 was found on shard 2
Doc 789012 was found on shard 1
Doc 345678 was found on shard 4
Doc 901234 was found on shard 2
Doc 567890 was found on shard 1
Doc 123456 was found on shard 3
Doc 789012 was found on shard 2
Doc 345678 was found on shard 1
Doc 901234 was found on shard 3
Received response from extension: 404
Received response from extension: 500
Received response from extension: 302
Received response from extension: 401
Received response from extension: 403
Received response from extension: 204
Received response from extension: 301
Received response from extension: 201
Received response from extension: 503
Received response from extension: 400
Received response from extension: 408
Received response from extension: 504
Received response from extension: 409
unlucky node: B
unlucky node: C
unlucky node: D
unlucky node: E
unlucky node: F
unlucky node: G
unlucky node: H
unlucky node: I
unlucky node: J
unlucky node: K
unlucky node: L
unlucky node: M
unlucky node: N
Action on node B finished
Action on node C finished
Action on node D finished
Action on node E finished
Action on node F finished
Action on node G finished
Action on node H finished
Action on node I finished
Action on node J finished
Action on node K finished
Action on node L finished
Action on node M finished
Action on node N finished
[2]: starting
[3]: starting
[4]: starting
[5]: starting
[6]: starting
[7]: starting
[8]: starting
[9]: starting
[10]: starting
[11]: starting
[12]: starting
[13]: starting
[14]: starting
Action on node B
Action on node C
Action on node D
Action on node E
Action on node F
Action on node G
Action on node H
Action on node I
Action on node J
Action on node K
Action on node L
Action on node M
Action on node N
loading extension has been failed because of exception : Invalid input format
loading extension has been failed because of exception : File not found
loading extension has been failed because of exception : Connection timed out
loading extension has been failed because of exception : Null pointer exception
loading extension has been failed because of exception : Insufficient permissions
loading extension has been failed because of exception : Invalid configuration
loading extension has been failed because of exception : Out of memory error
loading extension has been failed because of exception : Invalid token
loading extension has been failed because of exception : Stack overflow
loading extension has been failed because of exception : Network error
loading extension has been failed because of exception : Disk full
loading extension has been failed because of exception : Access denied
loading extension has been failed because of exception : Invalid parameter
corrupting file /var/www/images/image.jpg on node beta
corrupting file /usr/local/bin/executable on node gamma
corrupting file /data/logs/logfile.log on node delta
corrupting file /tmp/tempfile.txt on node epsilon
corrupting file /home/user/documents/data.csv on node zeta
corrupting file /var/www/html/index.html on node eta
corrupting file /usr/local/bin/script.sh on node theta
corrupting file /var/log/system.log on node iota
corrupting file /tmp/tempfile2.txt on node kappa
corrupting file /home/user/documents/data.json on node lambda
corrupting file /var/www/html/style.css on node mu
corrupting file /usr/local/bin/executable2 on node nu
corrupting file /var/log/application.log on node xi
Test task finished on the node node2
Test task finished on the node node3
Test task finished on the node node4
Test task finished on the node node5
Test task finished on the node node6
Test task finished on the node node7
Test task finished on the node node8
Test task finished on the node node9
Test task finished on the node node10
Test task finished on the node node11
Test task finished on the node node12
Test task finished on the node node13
Test task finished on the node node14
No response from extension to request.IOException
No response from extension to request.NullPointerException
No response from extension to request.IndexOutOfBoundsException
No response from extension to request.UnsupportedOperationException
No response from extension to request.ClassCastException
No response from extension to request.FileNotFoundException
No response from extension to request.ConcurrentModificationException
No response from extension to request.NoSuchElementException
No response from extension to request.IllegalArgumentException
No response from extension to request.ArrayIndexOutOfBoundsException
No response from extension to request.OutOfMemoryError
No response from extension to request.NoClassDefFoundError
No response from extension to request.SecurityException
No response from extension to request.SQLSyntaxErrorException
controlTopDocs.scoreDocs[1].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[2].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[3].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[4].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[5].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[6].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[7].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[8].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[9].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[10].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[11].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[12].minimum_should_match_field=[NO_VALUE]
controlTopDocs.scoreDocs[13].minimum_should_match_field=[NO_VALUE]
Test task started on the node node-2
Test task started on the node node-3
Test task started on the node node-4
Test task started on the node node-5
Test task started on the node node-6
Test task started on the node node-7
Test task started on the node node-8
Test task started on the node node-9
Test task started on the node node-10
Test task started on the node node-11
Test task started on the node node-12
Test task started on the node node-13
Test task started on the node node-14
--> shard 2 has a corrupted file
--> shard 3 has a corrupted file
--> shard 4 has a corrupted file
--> shard 5 has a corrupted file
--> shard 6 has a corrupted file
--> shard 7 has a corrupted file
--> shard 8 has a corrupted file
--> shard 9 has a corrupted file
--> shard 10 has a corrupted file
--> shard 11 has a corrupted file
--> shard 12 has a corrupted file
--> shard 13 has a corrupted file
--> shard 14 has a corrupted file
Initialized extension: pluginB
Initialized extension: pluginC
Initialized extension: pluginD
Initialized extension: pluginE
Initialized extension: pluginF
Initialized extension: pluginG
Initialized extension: pluginH
Initialized extension: pluginI
Initialized extension: pluginJ
Initialized extension: pluginK
Initialized extension: pluginL
Initialized extension: pluginM
Initialized extension: pluginN
controlTopDocs.scoreDocs[1].query_to_string=queryTwo
controlTopDocs.scoreDocs[2].query_to_string=queryThree
controlTopDocs.scoreDocs[3].query_to_string=queryFour
controlTopDocs.scoreDocs[4].query_to_string=queryFive
controlTopDocs.scoreDocs[5].query_to_string=querySix
controlTopDocs.scoreDocs[6].query_to_string=querySeven
controlTopDocs.scoreDocs[7].query_to_string=queryEight
controlTopDocs.scoreDocs[8].query_to_string=queryNine
controlTopDocs.scoreDocs[9].query_to_string=queryTen
controlTopDocs.scoreDocs[10].query_to_string=queryEleven
controlTopDocs.scoreDocs[11].query_to_string=queryTwelve
controlTopDocs.scoreDocs[12].query_to_string=queryThirteen
controlTopDocs.scoreDocs[13].query_to_string=queryFourteen
Cluster turned red in busy loop: false
Cluster turned red in busy loop: true
Cluster turned red in busy loop: false
Cluster turned red in busy loop: true
Cluster turned red in busy loop: false
Cluster turned red in busy loop: true
Cluster turned red in busy loop: false
Cluster turned red in busy loop: true
Cluster turned red in busy loop: false
Cluster turned red in busy loop: true
Cluster turned red in busy loop: false
Cluster turned red in busy loop: true
Cluster turned red in busy loop: false
Cluster turned red in busy loop: true
check index [failure] main()
check index [failure] System.out.println()
check index [failure] Thread.sleep()
check index [failure] File.read()
check index [failure] Math.max()
check index [failure] ArrayList.add()
check index [failure] String.toLowerCase()
check index [failure] Integer.parseInt()
check index [failure] Boolean.valueOf()
check index [failure] Scanner.next()
check index [failure] Random.nextDouble()
check index [failure] Character.isDigit()
check index [failure] StringBuilder.append()
check index [failure] HashMap.put()
controlTopDocs.scoreDocs[1].score=0.6
controlTopDocs.scoreDocs[2].score=0.9
controlTopDocs.scoreDocs[3].score=0.7
controlTopDocs.scoreDocs[4].score=0.5
controlTopDocs.scoreDocs[5].score=0.4
controlTopDocs.scoreDocs[6].score=0.3
controlTopDocs.scoreDocs[7].score=0.2
controlTopDocs.scoreDocs[8].score=0.1
controlTopDocs.scoreDocs[9].score=0.5
controlTopDocs.scoreDocs[10].score=0.6
controlTopDocs.scoreDocs[11].score=0.7
controlTopDocs.scoreDocs[12].score=0.8
controlTopDocs.scoreDocs[13].score=0.9
controlTopDocs.scoreDocs[1].doc=5678
controlTopDocs.scoreDocs[2].doc=9101
controlTopDocs.scoreDocs[3].doc=1121
controlTopDocs.scoreDocs[4].doc=3141
controlTopDocs.scoreDocs[5].doc=5161
controlTopDocs.scoreDocs[6].doc=7181
controlTopDocs.scoreDocs[7].doc=9202
controlTopDocs.scoreDocs[8].doc=1223
controlTopDocs.scoreDocs[9].doc=1424
controlTopDocs.scoreDocs[10].doc=1625
controlTopDocs.scoreDocs[11].doc=1826
controlTopDocs.scoreDocs[12].doc=2027
controlTopDocs.scoreDocs[13].doc=2228
failed to check resource watcher NullPointerException
failed to check resource watcher IOException
failed to check resource watcher ArrayIndexOutOfBoundsException
failed to check resource watcher FileNotFoundException
failed to check resource watcher IllegalArgumentException
failed to check resource watcher NoSuchElementException
failed to check resource watcher ClassCastException
failed to check resource watcher NumberFormatException
failed to check resource watcher InterruptedException
failed to check resource watcher AssertionError
failed to check resource watcher OutOfMemoryError
failed to check resource watcher StackOverflowError
failed to check resource watcher NoClassDefFoundError
topDocs.scoreDocs[1].score=0.8
topDocs.scoreDocs[2].score=2.5
topDocs.scoreDocs[3].score=1.9
topDocs.scoreDocs[4].score=2.7
topDocs.scoreDocs[5].score=0.5
topDocs.scoreDocs[6].score=1.6
topDocs.scoreDocs[7].score=3.1
topDocs.scoreDocs[8].score=0.9
topDocs.scoreDocs[9].score=1.7
topDocs.scoreDocs[10].score=2.3
topDocs.scoreDocs[11].score=2.1
topDocs.scoreDocs[12].score=1.4
topDocs.scoreDocs[13].score=2.9
cannot notify file changes listener RuntimeException
cannot notify file changes listener IOException
cannot notify file changes listener NullPointerException
cannot notify file changes listener FileNotFoundException
cannot notify file changes listener IllegalArgumentException
cannot notify file changes listener ArrayIndexOutOfBoundsException
cannot notify file changes listener ClassCastException
cannot notify file changes listener ArithmeticException
cannot notify file changes listener OutOfMemoryError
cannot notify file changes listener NoClassDefFoundError
cannot notify file changes listener NoSuchMethodError
cannot notify file changes listener AssertionError
cannot notify file changes listener StackOverflowError
cannot notify file changes listener UnknownError
Could not register Transport Action: Action not found
Could not register Transport Action: Connection timed out
Could not register Transport Action: Invalid input
Could not register Transport Action: Unexpected response
Could not register Transport Action: Authentication failed
Could not register Transport Action: Invalid request
Could not register Transport Action: Action already exists
Could not register Transport Action: Request timeout
Could not register Transport Action: Network error
Could not register Transport Action: Database connection failed
Could not register Transport Action: Insufficient permissions
Could not register Transport Action: Resource not found
Could not register Transport Action: Internal server error
Could not register Transport Action: Invalid configuration
topDocs.scoreDocs[1].doc=5678
topDocs.scoreDocs[2].doc=91011
topDocs.scoreDocs[3].doc=121314
topDocs.scoreDocs[4].doc=151617
topDocs.scoreDocs[5].doc=181920
topDocs.scoreDocs[6].doc=212223
topDocs.scoreDocs[7].doc=242526
topDocs.scoreDocs[8].doc=272829
topDocs.scoreDocs[9].doc=303132
topDocs.scoreDocs[10].doc=333435
topDocs.scoreDocs[11].doc=363738
topDocs.scoreDocs[12].doc=394041
topDocs.scoreDocs[13].doc=424344
Rejected execution on onConnectionClosed: java.sql.SQLException
Rejected execution on onConnectionClosed: org.springframework.security.AccessDeniedException
Rejected execution on onConnectionClosed: javax.validation.ConstraintViolationException
Rejected execution on onConnectionClosed: org.apache.kafka.common.errors.TimeoutException
Rejected execution on onConnectionClosed: java.io.IOException
Rejected execution on onConnectionClosed: org.springframework.dao.DataIntegrityViolationException
Rejected execution on onConnectionClosed: java.net.SocketTimeoutException
Rejected execution on onConnectionClosed: org.hibernate.exception.SQLGrammarException
Rejected execution on onConnectionClosed: javax.naming.NameNotFoundException
Rejected execution on onConnectionClosed: org.apache.tomcat.util.http.fileupload.FileUploadBase$IOException
Rejected execution on onConnectionClosed: com.fasterxml.jackson.core.JsonParseException
Rejected execution on onConnectionClosed: org.quartz.JobExecutionException
Rejected execution on onConnectionClosed: java.util.NoSuchElementException
Rejected execution on onConnectionClosed: org.springframework.transaction.TransactionSystemException
--> B584D09B4FF630BA7A17D16CD6537A70 corrupted
--> 9F9E14C42C6283D66C98E88B20A8783D corrupted
--> 51BA4D066F56A288163F2DE078A7F05D corrupted
--> 42F8087CE1F1BEA6D65C3C46255DF026 corrupted
--> 7E746C045D9B7B708CE518B36568ABF2 corrupted
--> 5C74D1CBB8F6D0C4E5653227C0A72C5E corrupted
--> F1862CC55713D3764FE1A89C8962C8C3 corrupted
--> BA26B149E7B503929F98855C8D013666 corrupted
--> 2EF3A6A29CEA58887101B891EEAA58DA corrupted
--> 9484A3C54A3F091C1EDA23A0B167E4C1 corrupted
--> F274F7A6EC9B8E06239A45E84978E6E4 corrupted
--> 6FFE0D3C40C4A425B8C5CCFA2A9ACC87 corrupted
--> C5C8BC213CCC330DFA5CA33D9EDDC1C3 corrupted
56789 received response but can't resolve it to a request
98765 received response but can't resolve it to a request
24680 received response but can't resolve it to a request
13579 received response but can't resolve it to a request
54321 received response but can't resolve it to a request
86420 received response but can't resolve it to a request
11111 received response but can't resolve it to a request
22222 received response but can't resolve it to a request
33333 received response but can't resolve it to a request
44444 received response but can't resolve it to a request
55555 received response but can't resolve it to a request
66666 received response but can't resolve it to a request
77777 received response but can't resolve it to a request
-- stopped node2
-- stopped node3
-- stopped node4
-- stopped node5
-- stopped node6
-- stopped node7
-- stopped node8
-- stopped node9
-- stopped node10
-- stopped node11
-- stopped node12
-- stopped node13
-- stopped node14
topDocs.scoreDocs.length=5
topDocs.scoreDocs.length=15
topDocs.scoreDocs.length=8
topDocs.scoreDocs.length=12
topDocs.scoreDocs.length=3
topDocs.scoreDocs.length=7
topDocs.scoreDocs.length=9
topDocs.scoreDocs.length=4
topDocs.scoreDocs.length=6
topDocs.scoreDocs.length=2
topDocs.scoreDocs.length=11
topDocs.scoreDocs.length=14
topDocs.scoreDocs.length=13
Received response for a request that has timed out, sent [201ms] ago, timed out [65ms] ago, action [RECEIVE], node [Node2], id [5678]
Received response for a request that has timed out, sent [90ms] ago, timed out [20ms] ago, action [PROCESS], node [Node3], id [9876]
Received response for a request that has timed out, sent [135ms] ago, timed out [45ms] ago, action [SEND], node [Node4], id [2468]
Received response for a request that has timed out, sent [180ms] ago, timed out [60ms] ago, action [RECEIVE], node [Node5], id [1357]
Received response for a request that has timed out, sent [75ms] ago, timed out [15ms] ago, action [PROCESS], node [Node6], id [8642]
Received response for a request that has timed out, sent [211ms] ago, timed out [70ms] ago, action [SEND], node [Node7], id [7531]
Received response for a request that has timed out, sent [100ms] ago, timed out [30ms] ago, action [RECEIVE], node [Node8], id [9514]
Received response for a request that has timed out, sent [160ms] ago, timed out [55ms] ago, action [PROCESS], node [Node9], id [6483]
Received response for a request that has timed out, sent [125ms] ago, timed out [40ms] ago, action [SEND], node [Node10], id [2345]
Received response for a request that has timed out, sent [190ms] ago, timed out [65ms] ago, action [RECEIVE], node [Node11], id [7418]
Received response for a request that has timed out, sent [80ms] ago, timed out [25ms] ago, action [PROCESS], node [Node12], id [3197]
Received response for a request that has timed out, sent [145ms] ago, timed out [50ms] ago, action [SEND], node [Node13], id [8265]
Received response for a request that has timed out, sent [220ms] ago, timed out [75ms] ago, action [RECEIVE], node [Node14], id [5174]
Transport response handler not found of id [xyz789]
Transport response handler not found of id [123xyz]
Transport response handler not found of id [456abc]
Transport response handler not found of id [789def]
Transport response handler not found of id [uvw234]
Transport response handler not found of id [xyz987]
Transport response handler not found of id [345uvw]
Transport response handler not found of id [def456]
Transport response handler not found of id [234def]
Transport response handler not found of id [abc345]
Transport response handler not found of id [ghi678]
Transport response handler not found of id [567ghi]
Transport response handler not found of id [678jkl]
topDocs.totalHits=20
topDocs.totalHits=30
topDocs.totalHits=40
topDocs.totalHits=50
topDocs.totalHits=60
topDocs.totalHits=70
topDocs.totalHits=80
topDocs.totalHits=90
topDocs.totalHits=100
topDocs.totalHits=110
topDocs.totalHits=120
topDocs.totalHits=130
topDocs.totalHits=140
Test with document: report doc
Test with document: contract doc
Test with document: invoice doc
Test with document: presentation doc
Test with document: proposal doc
Test with document: agreement doc
Test with document: manual doc
Test with document: policy doc
Test with document: survey doc
Test with document: handbook doc
Test with document: checklist doc
Test with document: brochure doc
Test with document: script doc
[456][doAction] received response from [Node 2]
[789][doAction] received response from [Node 3]
[abc][doAction] received response from [Node 4]
[def][doAction] received response from [Node 5]
[ghi][doAction] received response from [Node 6]
[jkl][doAction] received response from [Node 7]
[mno][doAction] received response from [Node 8]
[pqr][doAction] received response from [Node 9]
[stu][doAction] received response from [Node 10]
[vwx][doAction] received response from [Node 11]
[yz1][doAction] received response from [Node 12]
[234][doAction] received response from [Node 13]
[567][doAction] received response from [Node 14]
--> failed acquiring lock for /var/data/index2
--> failed acquiring lock for /var/data/index3
--> failed acquiring lock for /var/data/index4
--> failed acquiring lock for /var/data/index5
--> failed acquiring lock for /var/data/index6
--> failed acquiring lock for /var/data/index7
--> failed acquiring lock for /var/data/index8
--> failed acquiring lock for /var/data/index9
--> failed acquiring lock for /var/data/index10
--> failed acquiring lock for /var/data/index11
--> failed acquiring lock for /var/data/index12
--> failed acquiring lock for /var/data/index13
--> failed acquiring lock for /var/data/index14
[1234][deleteUser] received request
[5678][updateUser] received request
[7890][getUser] received request
[2345][getUserInfo] received request
[4567][addProduct] received request
[8901][updateProduct] received request
[3456][deleteProduct] received request
[5678][getProduct] received request
[4321][getProductInfo] received request
[8765][addOrder] received request
[9012][updateOrder] received request
[6543][deleteOrder] received request
[4321][getOrder] received request
invalid action name [createProduct] must start with one of: CREATE, UPDATE
invalid action name [getOrders] must start with one of: GET, UPDATE
invalid action name [loginUser] must start with one of: LOGIN, UPDATE
invalid action name [addTask] must start with one of: ADD, UPDATE
invalid action name [deleteAccount] must start with one of: DELETE, UPDATE
invalid action name [registerUser] must start with one of: REGISTER, UPDATE
invalid action name [getCustomers] must start with one of: GET, UPDATE
invalid action name [updateProfile] must start with one of: UPDATE, MODIFY
invalid action name [searchProducts] must start with one of: SEARCH, FILTER
invalid action name [deleteTask] must start with one of: DELETE, UPDATE
invalid action name [checkoutOrder] must start with one of: CHECKOUT, UPDATE
invalid action name [addAccount] must start with one of: ADD, UPDATE
invalid action name [resetPassword] must start with one of: RESET, UPDATE
Testing with highlight type [italic]
Testing with highlight type [underline]
Testing with highlight type [color]
Testing with highlight type [background]
Testing with highlight type [shadow]
Testing with highlight type [size]
Testing with highlight type [border]
Testing with highlight type [blink]
Testing with highlight type [fade]
Testing with highlight type [wave]
Testing with highlight type [glow]
Testing with highlight type [outline]
Testing with highlight type [strikethrough]
--> corrupting translog on node node2
--> corrupting translog on node node3
--> corrupting translog on node node4
--> corrupting translog on node node5
--> corrupting translog on node node6
--> corrupting translog on node node7
--> corrupting translog on node node8
--> corrupting translog on node node9
--> corrupting translog on node node10
--> corrupting translog on node node11
--> corrupting translog on node node12
--> corrupting translog on node node13
--> corrupting translog on node node14
WARNING: Collecting file cache data paths
ERROR: Collecting file cache data paths
DEBUG: Collecting file cache data paths
LOG: Collecting file cache data paths
SUCCESS: Collecting file cache data paths
FAILURE: Collecting file cache data paths
IMPORTANT: Collecting file cache data paths
NOTICE: Collecting file cache data paths
VERBOSE: Collecting file cache data paths
CRITICAL: Collecting file cache data paths
ALERT: Collecting file cache data paths
EMERGENCY: Collecting file cache data paths
TRACE: Collecting file cache data paths
Round 2
Round 3
Round 4
Round 5
Round 6
Round 7
Round 8
Round 9
Round 10
Round 11
Round 12
Round 13
Round 14
hit= 12.6 world
hit= 99.8 example
hit= 78.1 test
hit= 34.9 log
hit= 45.3 message
hit= 67.2 code
hit= 24.7 output
hit= 89.5 result
hit= 10.2 error
hit= 56.4 data
hit= 87.3 value
hit= 23.8 request
hit= 91.6 response
hit= 39.1 request
Action: Closed the connection
Action: Updated the database
Action: Started the process
Action: Sent the email
Action: Reloaded the page
Action: Deleted the record
Action: Saved the document
Action: Executed the query
Action: Generated the report
Action: Processed the request
Action: Created the folder
Action: Logged in
Action: Accessed the website
--> indexing [100] more doc to be truncated
--> indexing [5] more doc to be truncated
--> indexing [50] more doc to be truncated
--> indexing [20] more doc to be truncated
--> indexing [200] more doc to be truncated
--> indexing [15] more doc to be truncated
--> indexing [150] more doc to be truncated
--> indexing [25] more doc to be truncated
--> indexing [250] more doc to be truncated
--> indexing [30] more doc to be truncated
--> indexing [300] more doc to be truncated
--> indexing [35] more doc to be truncated
--> indexing [350] more doc to be truncated
total_hits=10
total_hits=25
total_hits=50
total_hits=100
total_hits=250
total_hits=500
total_hits=1000
total_hits=2000
total_hits=5000
total_hits=10000
total_hits=20000
total_hits=50000
total_hits=100000
bucket=bucket2
bucket=bucket3
bucket=bucket4
bucket=bucket5
bucket=bucket6
bucket=bucket7
bucket=bucket8
bucket=bucket9
bucket=bucket10
bucket=bucket11
bucket=bucket12
bucket=bucket13
bucket=bucket14
--> indexing [500] docs to be kept
--> indexing [750] docs to be kept
--> indexing [1000] docs to be kept
--> indexing [1250] docs to be kept
--> indexing [1500] docs to be kept
--> indexing [1750] docs to be kept
--> indexing [2000] docs to be kept
--> indexing [2250] docs to be kept
--> indexing [2500] docs to be kept
--> indexing [2750] docs to be kept
--> indexing [3000] docs to be kept
--> indexing [3250] docs to be kept
--> indexing [3500] docs to be kept
--> output: Error: Invalid input
--> output: Welcome to the program
--> output: Command executed successfully
--> output: File not found
--> output: Database connection established
--> output: Processing complete
--> output: Output saved to file
--> output: Access denied
--> output: Invalid username or password
--> output: Transaction failed
--> output: Data successfully updated
--> output: Authentication successful
--> output: Request timeout
Remote clusters initialization failed partially: AccessDeniedException
Remote clusters initialization failed partially: ConnectionTimeoutException
Remote clusters initialization failed partially: OutOfMemoryException
Remote clusters initialization failed partially: InvalidCredentialsException
Remote clusters initialization failed partially: ResourceNotFoundException
Remote clusters initialization failed partially: ServerErrorException
Remote clusters initialization failed partially: DiskFullException
Remote clusters initialization failed partially: NetworkErrorException
Remote clusters initialization failed partially: AuthenticationFailedException
Remote clusters initialization failed partially: ConfigurationMismatchException
Remote clusters initialization failed partially: NotFoundException
Remote clusters initialization failed partially: PermissionDeniedException
Remote clusters initialization failed partially: DatabaseNotFoundException
Remote clusters initialization failed partially: TimeoutException
--> indexed 2000 docs
--> indexed 3000 docs
--> indexed 4000 docs
--> indexed 5000 docs
--> indexed 6000 docs
--> indexed 7000 docs
--> indexed 8000 docs
--> indexed 9000 docs
--> indexed 10000 docs
--> indexed 11000 docs
--> indexed 12000 docs
--> indexed 13000 docs
--> indexed 14000 docs
last shard lock wait decremented, removing lock for shard002
last shard lock wait decremented, removing lock for shard003
last shard lock wait decremented, removing lock for shard004
last shard lock wait decremented, removing lock for shard005
last shard lock wait decremented, removing lock for shard006
last shard lock wait decremented, removing lock for shard007
last shard lock wait decremented, removing lock for shard008
last shard lock wait decremented, removing lock for shard009
last shard lock wait decremented, removing lock for shard010
last shard lock wait decremented, removing lock for shard011
last shard lock wait decremented, removing lock for shard012
last shard lock wait decremented, removing lock for shard013
last shard lock wait decremented, removing lock for shard014
--> found file: [C:/documents/image.jpg]
--> found file: [C:/data/document.docx]
--> found file: [C:/folder2/image.png]
--> found file: [C:/documents/report.pdf]
--> found file: [C:/folder3/config.properties]
--> found file: [C:/data/file.csv]
--> found file: [C:/folder4/script.js]
--> found file: [C:/documents2/image.jpg]
--> found file: [C:/folder5/document.docx]
--> found file: [C:/data2/presentation.pptx]
--> found file: [C:/folder6/file.txt]
--> found file: [C:/documents3/script.js]
--> found file: [C:/folder7/image.png]
shard lock wait count for shard2 is now [8]
shard lock wait count for shard3 is now [3]
shard lock wait count for shard4 is now [6]
shard lock wait count for shard5 is now [2]
shard lock wait count for shard6 is now [10]
shard lock wait count for shard7 is now [7]
shard lock wait count for shard8 is now [4]
shard lock wait count for shard9 is now [9]
shard lock wait count for shard10 is now [1]
shard lock wait count for shard11 is now [12]
shard lock wait count for shard12 is now [13]
shard lock wait count for shard13 is now [17]
shard lock wait count for shard14 is now [11]
--> checking that [cache] has been cleared
--> checking that [logs] has been cleared
--> checking that [temp] has been cleared
--> checking that [data] has been cleared
--> checking that [backup] has been cleared
--> checking that [downloads] has been cleared
--> checking that [images] has been cleared
--> checking that [documents] has been cleared
--> checking that [config] has been cleared
--> checking that [plugins] has been cleared
--> checking that [themes] has been cleared
--> checking that [public] has been cleared
--> checking that [uploads] has been cleared
failed to send ping transport message IOException
failed to send ping transport message TimeoutException
failed to send ping transport message AuthenticationException
failed to send ping transport message ConnectionException
failed to send ping transport message SocketException
failed to send ping transport message InvalidRequestException
failed to send ping transport message MalformedPacketException
failed to send ping transport message UnknownHostException
failed to send ping transport message SSLHandshakeException
failed to send ping transport message UnexpectedResponseException
failed to send ping transport message ProtocolException
failed to send ping transport message NetworkErrorException
failed to send ping transport message ServerUnresponsiveException
released shard lock for [shard2]
released shard lock for [shard3]
released shard lock for [shard4]
released shard lock for [shard5]
released shard lock for [shard6]
released shard lock for [shard7]
released shard lock for [shard8]
released shard lock for [shard9]
released shard lock for [shard10]
released shard lock for [shard11]
released shard lock for [shard12]
released shard lock for [shard13]
released shard lock for [shard14]
closed transport connection [conn_2] to [node_3] with age [480ms]
closed transport connection [conn_3] to [node_2] with age [625ms]
closed transport connection [conn_4] to [node_1] with age [338ms]
closed transport connection [conn_5] to [node_4] with age [824ms]
closed transport connection [conn_6] to [node_2] with age [590ms]
closed transport connection [conn_7] to [node_3] with age [912ms]
closed transport connection [conn_8] to [node_4] with age [643ms]
closed transport connection [conn_9] to [node_1] with age [281ms]
closed transport connection [conn_10] to [node_3] with age [407ms]
closed transport connection [conn_11] to [node_2] with age [572ms]
closed transport connection [conn_12] to [node_4] with age [709ms]
closed transport connection [conn_13] to [node_1] with age [163ms]
closed transport connection [conn_14] to [node_2] with age [984ms]
--> translog size after delete: [512] num_ops [12] generation [2]
--> translog size after delete: [2048] num_ops [30] generation [3]
--> translog size after delete: [768] num_ops [18] generation [4]
--> translog size after delete: [1536] num_ops [24] generation [5]
--> translog size after delete: [2560] num_ops [42] generation [6]
--> translog size after delete: [1280] num_ops [36] generation [7]
--> translog size after delete: [1792] num_ops [15] generation [8]
--> translog size after delete: [3072] num_ops [27] generation [9]
--> translog size after delete: [896] num_ops [21] generation [10]
--> translog size after delete: [2304] num_ops [33] generation [11]
--> translog size after delete: [3328] num_ops [39] generation [12]
--> translog size after delete: [1920] num_ops [45] generation [13]
--> translog size after delete: [2816] num_ops [48] generation [14]
opened transport connection [456] to [server2] using channels [2]
opened transport connection [789] to [server3] using channels [3]
opened transport connection [abc] to [server4] using channels [4]
opened transport connection [def] to [server5] using channels [5]
opened transport connection [ghi] to [server6] using channels [6]
opened transport connection [jkl] to [server7] using channels [7]
opened transport connection [mno] to [server8] using channels [8]
opened transport connection [pqr] to [server9] using channels [9]
opened transport connection [stu] to [server10] using channels [10]
opened transport connection [vwx] to [server11] using channels [11]
opened transport connection [yz1] to [server12] using channels [12]
opened transport connection [234] to [server13] using channels [13]
opened transport connection [567] to [server14] using channels [14]
successfully acquired shardlock for [shard002]
successfully acquired shardlock for [shard003]
successfully acquired shardlock for [shard004]
successfully acquired shardlock for [shard005]
successfully acquired shardlock for [shard006]
successfully acquired shardlock for [shard007]
successfully acquired shardlock for [shard008]
successfully acquired shardlock for [shard009]
successfully acquired shardlock for [shard010]
successfully acquired shardlock for [shard011]
successfully acquired shardlock for [shard012]
successfully acquired shardlock for [shard013]
successfully acquired shardlock for [shard014]
include::CUSTOM_HEADER/index.asciidoc[]
include::PUBLIC_HEADER/index.asciidoc[]
include::PRIVATE_HEADER/index.asciidoc[]
include::USER_HEADER/index.asciidoc[]
include::ADMIN_HEADER/index.asciidoc[]
include::GUEST_HEADER/index.asciidoc[]
include::STAFF_HEADER/index.asciidoc[]
include::MANAGER_HEADER/index.asciidoc[]
include::MEMBER_HEADER/index.asciidoc[]
include::TEAM_HEADER/index.asciidoc[]
include::PROJECT_HEADER/index.asciidoc[]
include::PRODUCT_HEADER/index.asciidoc[]
include::SERVICE_HEADER/index.asciidoc[]
include::SUPPORT_HEADER/index.asciidoc[]
| <<Context2, Specialized API>>
| <<Context3, Specialized API>>
| <<Context4, Specialized API>>
| <<Context5, Specialized API>>
| <<Context6, Specialized API>>
| <<Context7, Specialized API>>
| <<Context8, Specialized API>>
| <<Context9, Specialized API>>
| <<Context10, Specialized API>>
| <<Context11, Specialized API>>
| <<Context12, Specialized API>>
| <<Context13, Specialized API>>
| <<Context14, Specialized API>>
locking all shards for index 1 - [3]
locking all shards for index 2 - [2]
locking all shards for index 3 - [4]
locking all shards for index 4 - [2]
locking all shards for index 5 - [1]
locking all shards for index 6 - [3]
locking all shards for index 7 - [2]
locking all shards for index 8 - [4]
locking all shards for index 9 - [2]
locking all shards for index 10 - [1]
locking all shards for index 11 - [3]
locking all shards for index 12 - [2]
locking all shards for index 13 - [4]
--> updating data_path to [/data/path2] for index [1]
--> updating data_path to [/data/path3] for index [2]
--> updating data_path to [/data/path4] for index [3]
--> updating data_path to [/data/path5] for index [4]
--> updating data_path to [/data/path6] for index [5]
--> updating data_path to [/data/path7] for index [6]
--> updating data_path to [/data/path8] for index [7]
--> updating data_path to [/data/path9] for index [8]
--> updating data_path to [/data/path10] for index [9]
--> updating data_path to [/data/path11] for index [10]
--> updating data_path to [/data/path12] for index [11]
--> updating data_path to [/data/path13] for index [12]
--> updating data_path to [/data/path14] for index [13]
[cluster2] opening managed connection to seed node: [node2] proxy address: [proxy2]
[cluster3] opening managed connection to seed node: [node3] proxy address: [proxy3]
[cluster4] opening managed connection to seed node: [node4] proxy address: [proxy4]
[cluster5] opening managed connection to seed node: [node5] proxy address: [proxy5]
[cluster6] opening managed connection to seed node: [node6] proxy address: [proxy6]
[cluster7] opening managed connection to seed node: [node7] proxy address: [proxy7]
[cluster8] opening managed connection to seed node: [node8] proxy address: [proxy8]
[cluster9] opening managed connection to seed node: [node9] proxy address: [proxy9]
[cluster10] opening managed connection to seed node: [node10] proxy address: [proxy10]
[cluster11] opening managed connection to seed node: [node11] proxy address: [proxy11]
[cluster12] opening managed connection to seed node: [node12] proxy address: [proxy12]
[cluster13] opening managed connection to seed node: [node13] proxy address: [proxy13]
[cluster14] opening managed connection to seed node: [node14] proxy address: [proxy14]
Failed to copy data path directory FileNotFoundException
Failed to copy data path directory AccessDeniedException
Failed to copy data path directory NoSuchFileException
Failed to copy data path directory SecurityException
Failed to copy data path directory NullPointerException
Failed to copy data path directory IllegalArgumentException
Failed to copy data path directory NoSuchElementException
Failed to copy data path directory SocketException
Failed to copy data path directory EOFException
Failed to copy data path directory SQLException
Failed to copy data path directory ArrayIndexOutOfBoundsException
Failed to copy data path directory ClassNotFoundException
Failed to copy data path directory AssertionError
deleting custom index 2 directory [location2]
deleting custom index 3 directory [location3]
deleting custom index 4 directory [location4]
deleting custom index 5 directory [location5]
deleting custom index 6 directory [location6]
deleting custom index 7 directory [location7]
deleting custom index 8 directory [location8]
deleting custom index 9 directory [location9]
deleting custom index 10 directory [location10]
deleting custom index 11 directory [location11]
deleting custom index 12 directory [location12]
deleting custom index 13 directory [location13]
deleting custom index 14 directory [location14]
[cluster-01] opening transient connection to seed node: [192.168.0.2]
[cluster-01] opening transient connection to seed node: [192.168.0.3]
[cluster-01] opening transient connection to seed node: [192.168.0.4]
[cluster-01] opening transient connection to seed node: [192.168.0.5]
[cluster-02] opening transient connection to seed node: [192.168.0.1]
[cluster-02] opening transient connection to seed node: [192.168.0.2]
[cluster-02] opening transient connection to seed node: [192.168.0.3]
[cluster-02] opening transient connection to seed node: [192.168.0.4]
[cluster-02] opening transient connection to seed node: [192.168.0.5]
[cluster-03] opening transient connection to seed node: [192.168.0.1]
[cluster-03] opening transient connection to seed node: [192.168.0.2]
[cluster-03] opening transient connection to seed node: [192.168.0.3]
[cluster-03] opening transient connection to seed node: [192.168.0.4]
deleting index 2 directory, paths(5): [path1, path2, path3, path4, path5]
deleting index 3 directory, paths(2): [path1, path2]
deleting index 4 directory, paths(4): [path1, path2, path3, path4]
deleting index 5 directory, paths(1): [path1]
deleting index 6 directory, paths(6): [path1, path2, path3, path4, path5, path6]
deleting index 7 directory, paths(3): [path1, path2, path3]
deleting index 8 directory, paths(2): [path1, path2]
deleting index 9 directory, paths(4): [path1, path2, path3, path4]
deleting index 10 directory, paths(1): [path1]
deleting index 11 directory, paths(2): [path1, path2]
deleting index 12 directory, paths(3): [path1, path2, path3]
deleting index 13 directory, paths(4): [path1, path2, path3, path4]
deleting index 14 directory, paths(2): [path1, path2]
[cluster2] successfully connected after disconnect of node2
[cluster3] successfully connected after disconnect of node3
[cluster4] successfully connected after disconnect of node4
[cluster5] successfully connected after disconnect of node5
[cluster6] successfully connected after disconnect of node6
[cluster7] successfully connected after disconnect of node7
[cluster8] successfully connected after disconnect of node8
[cluster9] successfully connected after disconnect of node9
[cluster10] successfully connected after disconnect of node10
[cluster11] successfully connected after disconnect of node11
[cluster12] successfully connected after disconnect of node12
[cluster13] successfully connected after disconnect of node13
[cluster14] successfully connected after disconnect of node14
See the <<Developer Guide, Installation API>> for a high-level overview of all packages and classes.
See the <<User Interface, Login API>> for a high-level overview of all packages and classes.
See the <<System Requirements, Configuration API>> for a high-level overview of all packages and classes.
See the <<Quick Start Guide, Setup API>> for a high-level overview of all packages and classes.
See the <<User Manual, Usage API>> for a high-level overview of all packages and classes.
See the <<Developer Guide, Configuration API>> for a high-level overview of all packages and classes.
See the <<User Interface, Dashboard API>> for a high-level overview of all packages and classes.
See the <<System Requirements, Installation API>> for a high-level overview of all packages and classes.
See the <<Quick Start Guide, Usage API>> for a high-level overview of all packages and classes.
See the <<User Manual, API Reference API>> for a high-level overview of all packages and classes.
See the <<Developer Guide, Development API>> for a high-level overview of all packages and classes.
See the <<User Interface, Profile API>> for a high-level overview of all packages and classes.
See the <<System Requirements, Deployment API>> for a high-level overview of all packages and classes.
See the <<Quick Start Guide, Configuration API>> for a high-level overview of all packages and classes.
deleted shard 2 directory, paths: [path2]
deleted shard 3 directory, paths: [path3]
deleted shard 4 directory, paths: [path4]
deleted shard 5 directory, paths: [path5]
deleted shard 6 directory, paths: [path6]
deleted shard 7 directory, paths: [path7]
deleted shard 8 directory, paths: [path8]
deleted shard 9 directory, paths: [path9]
deleted shard 10 directory, paths: [path10]
deleted shard 11 directory, paths: [path11]
deleted shard 12 directory, paths: [path12]
deleted shard 13 directory, paths: [path13]
deleted shard 14 directory, paths: [path14]
--> closing the index [product]
--> closing the index [order]
--> closing the index [invoice]
--> closing the index [review]
--> closing the index [category]
--> closing the index [employee]
--> closing the index [supplier]
--> closing the index [customer]
--> closing the index [transaction]
--> closing the index [log]
--> closing the index [settings]
--> closing the index [payment]
--> closing the index [inventory]
deleting custom shard 2 directory [D:/data/shard2]
deleting custom shard 3 directory [E:/data/shard3]
deleting custom shard 4 directory [F:/data/shard4]
deleting custom shard 5 directory [G:/data/shard5]
deleting custom shard 6 directory [H:/data/shard6]
deleting custom shard 7 directory [I:/data/shard7]
deleting custom shard 8 directory [J:/data/shard8]
deleting custom shard 9 directory [K:/data/shard9]
deleting custom shard 10 directory [L:/data/shard10]
deleting custom shard 11 directory [M:/data/shard11]
deleting custom shard 12 directory [N:/data/shard12]
deleting custom shard 13 directory [O:/data/shard13]
deleting custom shard 14 directory [P:/data/shard14]
--> creating index [products] with data_path [/data/products]
--> creating index [orders] with data_path [/data/orders]
--> creating index [categories] with data_path [/data/categories]
--> creating index [logs] with data_path [/data/logs]
--> creating index [customers] with data_path [/data/customers]
--> creating index [invoices] with data_path [/data/invoices]
--> creating index [reviews] with data_path [/data/reviews]
--> creating index [employees] with data_path [/data/employees]
--> creating index [suppliers] with data_path [/data/suppliers]
--> creating index [transactions] with data_path [/data/transactions]
--> creating index [messages] with data_path [/data/messages]
--> creating index [notifications] with data_path [/data/notifications]
--> creating index [dashboard] with data_path [/data/dashboard]
acquiring lock for shard_2, custom path: [path_2]
acquiring lock for shard_3, custom path: [path_3]
acquiring lock for shard_4, custom path: [path_4]
acquiring lock for shard_5, custom path: [path_5]
acquiring lock for shard_6, custom path: [path_6]
acquiring lock for shard_7, custom path: [path_7]
acquiring lock for shard_8, custom path: [path_8]
acquiring lock for shard_9, custom path: [path_9]
acquiring lock for shard_10, custom path: [path_10]
acquiring lock for shard_11, custom path: [path_11]
acquiring lock for shard_12, custom path: [path_12]
acquiring lock for shard_13, custom path: [path_13]
acquiring lock for shard_14, custom path: [path_14]
unable to open maximum number of connections [remote cluster: cluster2, opened: 15, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster3, opened: 20, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster4, opened: 25, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster5, opened: 30, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster6, opened: 35, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster7, opened: 40, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster8, opened: 45, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster9, opened: 50, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster10, opened: 55, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster11, opened: 60, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster12, opened: 65, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster13, opened: 70, maximum: 50]
unable to open maximum number of connections [remote cluster: cluster14, opened: 75, maximum: 50]
--> idxPath: [path2]
--> idxPath: [path3]
--> idxPath: [path4]
--> idxPath: [path5]
--> idxPath: [path6]
--> idxPath: [path7]
--> idxPath: [path8]
--> idxPath: [path9]
--> idxPath: [path10]
--> idxPath: [path11]
--> idxPath: [path12]
--> idxPath: [path13]
--> idxPath: [path14]
acquiring locks for shard-2, paths: [/data/file2.txt]
acquiring locks for shard-3, paths: [/data/file3.txt]
acquiring locks for shard-4, paths: [/data/file4.txt]
acquiring locks for shard-5, paths: [/data/file5.txt]
acquiring locks for shard-6, paths: [/data/file6.txt]
acquiring locks for shard-7, paths: [/data/file7.txt]
acquiring locks for shard-8, paths: [/data/file8.txt]
acquiring locks for shard-9, paths: [/data/file9.txt]
acquiring locks for shard-10, paths: [/data/file10.txt]
acquiring locks for shard-11, paths: [/data/file11.txt]
acquiring locks for shard-12, paths: [/data/file12.txt]
acquiring locks for shard-13, paths: [/data/file13.txt]
acquiring locks for shard-14, paths: [/data/file14.txt]
--> paths: C:/Program Files/MySQL/Data/
--> paths: /var/www/html/
--> paths: D:/Projects/ProjectA/src/
--> paths: E:/Documents/Reports/2022/
--> paths: ~/Downloads/
--> paths: C:/Users/User1/Documents/
--> paths: /home/user2/
--> paths: /usr/local/lib/
--> paths: D:/Photos/Vacation/2022/
--> paths: /var/log/nginx/
--> paths: /Users/User3/Desktop/
--> paths: C:/Program Files/Java/jdk1.8.0_271/bin/
--> paths: ~/Music/
handling inbound transport message [Error Message] took [350ms] which is above the warn threshold of [200ms]
handling inbound transport message [Warning Message] took [180ms] which is above the warn threshold of [150ms]
handling inbound transport message [Info Message] took [50ms] which is above the warn threshold of [40ms]
handling inbound transport message [Debug Message] took [95ms] which is above the warn threshold of [90ms]
handling inbound transport message [System Message] took [210ms] which is above the warn threshold of [180ms]
handling inbound transport message [User Message] took [320ms] which is above the warn threshold of [300ms]
handling inbound transport message [Network Message] took [75ms] which is above the warn threshold of [60ms]
handling inbound transport message [Security Message] took [180ms] which is above the warn threshold of [150ms]
handling inbound transport message [Business Message] took [420ms] which is above the warn threshold of [400ms]
handling inbound transport message [Performance Message] took [510ms] which is above the warn threshold of [500ms]
handling inbound transport message [Memory Message] took [185ms] which is above the warn threshold of [150ms]
handling inbound transport message [Database Message] took [290ms] which is above the warn threshold of [250ms]
handling inbound transport message [File Message] took [90ms] which is above the warn threshold of [80ms]
deleting shard 2 directory, paths: [dir2]
deleting shard 3 directory, paths: [dir3]
deleting shard 4 directory, paths: [dir4]
deleting shard 5 directory, paths: [dir5]
deleting shard 6 directory, paths: [dir6]
deleting shard 7 directory, paths: [dir7]
deleting shard 8 directory, paths: [dir8]
deleting shard 9 directory, paths: [dir9]
deleting shard 10 directory, paths: [dir10]
deleting shard 11 directory, paths: [dir11]
deleting shard 12 directory, paths: [dir12]
deleting shard 13 directory, paths: [dir13]
deleting shard 14 directory, paths: [dir14]
allow [2] replicas to allocate
allow [3] replicas to allocate
allow [4] replicas to allocate
allow [5] replicas to allocate
allow [6] replicas to allocate
allow [7] replicas to allocate
allow [8] replicas to allocate
allow [9] replicas to allocate
allow [10] replicas to allocate
allow [11] replicas to allocate
allow [12] replicas to allocate
allow [13] replicas to allocate
allow [14] replicas to allocate
existing connection to node node2, closing new redundant connection
existing connection to node node3, closing new redundant connection
existing connection to node node4, closing new redundant connection
existing connection to node node5, closing new redundant connection
existing connection to node node6, closing new redundant connection
existing connection to node node7, closing new redundant connection
existing connection to node node8, closing new redundant connection
existing connection to node node9, closing new redundant connection
existing connection to node node10, closing new redundant connection
existing connection to node node11, closing new redundant connection
existing connection to node node12, closing new redundant connection
existing connection to node node13, closing new redundant connection
existing connection to node node14, closing new redundant connection
heap size [8GB], compressed ordinary object pointers [false]
heap size [16GB], compressed ordinary object pointers [true]
heap size [32GB], compressed ordinary object pointers [false]
heap size [64GB], compressed ordinary object pointers [true]
heap size [128GB], compressed ordinary object pointers [false]
heap size [256GB], compressed ordinary object pointers [true]
heap size [512GB], compressed ordinary object pointers [false]
heap size [1TB], compressed ordinary object pointers [true]
heap size [2TB], compressed ordinary object pointers [false]
heap size [4TB], compressed ordinary object pointers [true]
heap size [8TB], compressed ordinary object pointers [false]
heap size [16TB], compressed ordinary object pointers [true]
heap size [32TB], compressed ordinary object pointers [false]
finished adding 10 retention leases
finished adding 15 retention leases
finished adding 20 retention leases
finished adding 25 retention leases
finished adding 30 retention leases
finished adding 35 retention leases
finished adding 40 retention leases
finished adding 45 retention leases
finished adding 50 retention leases
finished adding 55 retention leases
finished adding 60 retention leases
finished adding 65 retention leases
finished adding 70 retention leases
connected to node Node2
connected to node Node3
connected to node Node4
connected to node Node5
connected to node Node6
connected to node Node7
connected to node Node8
connected to node Node9
connected to node Node10
connected to node Node11
connected to node Node12
connected to node Node13
connected to node Node14
got 200
got 300
got 400
got 500
got 600
got 700
got 800
got 900
got 1000
got 1100
got 1200
got 1300
got 1400
using node location [C:/Program Files/Node], local_lock_id [892341]
using node location [/opt/nodejs], local_lock_id [128745]
using node location [D:/NodeInstallation], local_lock_id [763249]
using node location [/usr/local/node], local_lock_id [509231]
using node location [C:/Bin/Node], local_lock_id [638957]
using node location [/opt/node], local_lock_id [620831]
using node location [/usr/bin/nodejs], local_lock_id [473290]
using node location [C:/Program Files/Nodejs], local_lock_id [541382]
using node location [D:/node], local_lock_id [945281]
using node location [/usr/local/bin/node], local_lock_id [380295]
using node location [C:/NodeJS], local_lock_id [876213]
using node location [/opt/node/bin], local_lock_id [327941]
using node location [/usr/bin], local_lock_id [283750]
using node location [C:/Node], local_lock_id [604978]
The following specialized API is available in the createContext(contextInfo) context.
The following specialized API is available in the setContext(contextInfo) context.
The following specialized API is available in the deleteContext(contextInfo) context.
The following specialized API is available in the updateContext(contextInfo) context.
The following specialized API is available in the fetchContext(contextInfo) context.
The following specialized API is available in the validateContext(contextInfo) context.
The following specialized API is available in the listContexts(contextInfo) context.
The following specialized API is available in the searchContexts(contextInfo) context.
The following specialized API is available in the authorizeContext(contextInfo) context.
The following specialized API is available in the getContextInfo(contextInfo) context.
The following specialized API is available in the serializeContext(contextInfo) context.
The following specialized API is available in the deserializeContext(contextInfo) context.
The following specialized API is available in the cloneContext(contextInfo) context.
The following specialized API is available in the clearContext(contextInfo) context.
numDocs 200
numDocs 300
numDocs 400
numDocs 500
numDocs 600
numDocs 700
numDocs 800
numDocs 900
numDocs 1000
numDocs 1100
numDocs 1200
numDocs 1300
numDocs 1400
obtaining node lock on /var/log/file.log ...
obtaining node lock on /tmp/images/image.jpg ...
obtaining node lock on /opt/application/data.txt ...
obtaining node lock on /usr/local/bin/script.sh ...
obtaining node lock on /etc/config.ini ...
obtaining node lock on /var/www/index.html ...
obtaining node lock on /home/user/documents/document.docx ...
obtaining node lock on /opt/application/data.json ...
obtaining node lock on /usr/local/bin/program.bin ...
obtaining node lock on /tmp/files/file.txt ...
obtaining node lock on /var/log/syslog ...
obtaining node lock on /etc/hosts ...
obtaining node lock on /home/user/pictures/photo.png ...
using initial hosts host2
using initial hosts host3
using initial hosts host4
using initial hosts host5
using initial hosts host6
using initial hosts host7
using initial hosts host8
using initial hosts host9
using initial hosts host10
using initial hosts host11
using initial hosts host12
using initial hosts host13
using initial hosts host14
numshards 7, segments 35, total merges 15, current merge 8
numshards 3, segments 12, total merges 5, current merge 2
numshards 8, segments 22, total merges 7, current merge 4
numshards 4, segments 18, total merges 9, current merge 1
numshards 6, segments 25, total merges 12, current merge 5
numshards 9, segments 30, total merges 14, current merge 6
numshards 2, segments 9, total merges 4, current merge 0
numshards 10, segments 37, total merges 16, current merge 9
numshards 1, segments 5, total merges 2, current merge 1
numshards 3, segments 15, total merges 8, current merge 3
numshards 6, segments 24, total merges 11, current merge 4
numshards 9, segments 31, total merges 13, current merge 7
numshards 4, segments 19, total merges 10, current merge 2
loaded [/data/db2] geo-IP database
loaded [/data/db3] geo-IP database
loaded [/data/db4] geo-IP database
loaded [/data/db5] geo-IP database
loaded [/data/db6] geo-IP database
loaded [/data/db7] geo-IP database
loaded [/data/db8] geo-IP database
loaded [/data/db9] geo-IP database
loaded [/data/db10] geo-IP database
loaded [/data/db11] geo-IP database
loaded [/data/db12] geo-IP database
loaded [/data/db13] geo-IP database
loaded [/data/db14] geo-IP database
resolveConfiguredHosts.doRun: lifecycle is RUNNING, not proceeding
resolveConfiguredHosts.doRun: lifecycle is SHUTTING_DOWN, not proceeding
resolveConfiguredHosts.doRun: lifecycle is TERMINATED, not proceeding
resolveConfiguredHosts.doRun: lifecycle is STARTING, not proceeding
resolveConfiguredHosts.doRun: lifecycle is STOPPING, not proceeding
resolveConfiguredHosts.doRun: lifecycle is FAILED, not proceeding
resolveConfiguredHosts.doRun: lifecycle is UNKNOWN, not proceeding
resolveConfiguredHosts.doRun: lifecycle is PAUSED, not proceeding
resolveConfiguredHosts.doRun: lifecycle is RESUMING, not proceeding
resolveConfiguredHosts.doRun: lifecycle is SUCCEEDED, not proceeding
resolveConfiguredHosts.doRun: lifecycle is ABORTED, not proceeding
resolveConfiguredHosts.doRun: lifecycle is INTERRUPTED, not proceeding
resolveConfiguredHosts.doRun: lifecycle is WAITING, not proceeding
index round [2] - segments 12, total merges 3, current merge 2
index round [3] - segments 8, total merges 1, current merge 1
index round [4] - segments 15, total merges 4, current merge 3
index round [5] - segments 9, total merges 2, current merge 1
index round [6] - segments 11, total merges 3, current merge 2
index round [7] - segments 13, total merges 4, current merge 3
index round [8] - segments 7, total merges 1, current merge 1
index round [9] - segments 14, total merges 4, current merge 4
index round [10] - segments 10, total merges 2, current merge 1
index round [11] - segments 12, total merges 3, current merge 2
index round [12] - segments 8, total merges 1, current merge 1
index round [13] - segments 15, total merges 4, current merge 3
index round [14] - segments 9, total merges 2, current merge 1
Task execution finished on thread. Task: 5678, Thread: 9876
Task execution finished on thread. Task: 9876, Thread: 5432
Task execution finished on thread. Task: 3456, Thread: 8765
Task execution finished on thread. Task: 2345, Thread: 6789
Task execution finished on thread. Task: 8765, Thread: 4321
Task execution finished on thread. Task: 4321, Thread: 3456
Task execution finished on thread. Task: 6789, Thread: 2345
Task execution finished on thread. Task: 7890, Thread: 3456
Task execution finished on thread. Task: 5432, Thread: 4567
Task execution finished on thread. Task: 8765, Thread: 1111
Task execution finished on thread. Task: 3456, Thread: 2222
Task execution finished on thread. Task: 2222, Thread: 3333
Task execution finished on thread. Task: 3333, Thread: 4444
Task execution started on thread. Task: 002, Thread: 101
Task execution started on thread. Task: 003, Thread: 102
Task execution started on thread. Task: 004, Thread: 103
Task execution started on thread. Task: 005, Thread: 104
Task execution started on thread. Task: 006, Thread: 105
Task execution started on thread. Task: 007, Thread: 106
Task execution started on thread. Task: 008, Thread: 107
Task execution started on thread. Task: 009, Thread: 108
Task execution started on thread. Task: 010, Thread: 109
Task execution started on thread. Task: 011, Thread: 110
Task execution started on thread. Task: 012, Thread: 111
Task execution started on thread. Task: 013, Thread: 112
Task execution started on thread. Task: 014, Thread: 113
Random Geometry created for Indexing : polygon((0 0, 0 5, 5 5, 5 0, 0 0))
Random Geometry created for Indexing : linestring(1 2, 3 4, 5 6)
Random Geometry created for Indexing : multipoint((1 2), (3 4), (5 6))
Random Geometry created for Indexing : multipolygon(((0 0, 0 5, 5 5, 5 0, 0 0)), ((1 1, 1 2, 2 2, 2 1, 1 1)))
Random Geometry created for Indexing : geometrycollection(point(1 2), linestring(1 2, 3 4), polygon((0 0, 0 5, 5 5, 5 0, 0 0)))
Random Geometry created for Indexing : circularstring(0 0, 1 1, 2 2)
Random Geometry created for Indexing : compoundcurve(circularstring(0 0, 1 1, 2 2), linestring(1 2, 3 4))
Random Geometry created for Indexing : curvepolygon(comoundcurve(circularstring(0 0, 1 1, 2 2), linestring(1 2, 3 4)), circularstring(3 4, 5 6, 7 8))
Random Geometry created for Indexing : circularstring empty
Random Geometry created for Indexing : compoundcurve empty
Random Geometry created for Indexing : curvepolygon empty
Random Geometry created for Indexing : point empty
Random Geometry created for Indexing : line empty
Random Geometry created for Indexing : polygon empty
resolveConfiguredHosts: lifecycle is INITIALIZING, not proceeding
resolveConfiguredHosts: lifecycle is RUNNING, not proceeding
resolveConfiguredHosts: lifecycle is STOPPING, not proceeding
resolveConfiguredHosts: lifecycle is FAILED, not proceeding
resolveConfiguredHosts: lifecycle is PAUSED, not proceeding
resolveConfiguredHosts: lifecycle is RESTARTING, not proceeding
resolveConfiguredHosts: lifecycle is RESUMING, not proceeding
resolveConfiguredHosts: lifecycle is SUSPENDING, not proceeding
resolveConfiguredHosts: lifecycle is SHUTTING_DOWN, not proceeding
resolveConfiguredHosts: lifecycle is COMPLETED, not proceeding
resolveConfiguredHosts: lifecycle is EXPIRED, not proceeding
resolveConfiguredHosts: lifecycle is ABORTED, not proceeding
resolveConfiguredHosts: lifecycle is PENDING, not proceeding
resolveConfiguredHosts: lifecycle is TIMEOUT, not proceeding
Refreshing resource stats for Task: 789012
Refreshing resource stats for Task: 345678
Refreshing resource stats for Task: 901234
Refreshing resource stats for Task: 567890
Refreshing resource stats for Task: 123456
Refreshing resource stats for Task: 789012
Refreshing resource stats for Task: 345678
Refreshing resource stats for Task: 901234
Refreshing resource stats for Task: 567890
Refreshing resource stats for Task: 123456
Refreshing resource stats for Task: 789012
Refreshing resource stats for Task: 345678
Refreshing resource stats for Task: 901234
The bounding box was null for the Doc id abc
The bounding box was null for the Doc id xyz
The bounding box was null for the Doc id 456
The bounding box was null for the Doc id def
The bounding box was null for the Doc id uvw
The bounding box was null for the Doc id 789
The bounding box was null for the Doc id ghi
The bounding box was null for the Doc id pqr
The bounding box was null for the Doc id 012
The bounding box was null for the Doc id jkl
The bounding box was null for the Doc id mno
The bounding box was null for the Doc id 345
The bounding box was null for the Doc id stu
using max_concurrent_resolvers [5], resolver timeout [3000]
using max_concurrent_resolvers [8], resolver timeout [2000]
using max_concurrent_resolvers [15], resolver timeout [6000]
using max_concurrent_resolvers [12], resolver timeout [4000]
using max_concurrent_resolvers [7], resolver timeout [2500]
using max_concurrent_resolvers [20], resolver timeout [10000]
using max_concurrent_resolvers [3], resolver timeout [1500]
using max_concurrent_resolvers [9], resolver timeout [3500]
using max_concurrent_resolvers [6], resolver timeout [1800]
using max_concurrent_resolvers [11], resolver timeout [5500]
using max_concurrent_resolvers [14], resolver timeout [4500]
using max_concurrent_resolvers [17], resolver timeout [8000]
using max_concurrent_resolvers [4], resolver timeout [2200]
One of the X or Y list is empty or null. X.size : 7 Y.size : 0
One of the X or Y list is empty or null. X.size : 3 Y.size : 8
One of the X or Y list is empty or null. X.size : 0 Y.size : 12
One of the X or Y list is empty or null. X.size : 9 Y.size : 2
One of the X or Y list is empty or null. X.size : 6 Y.size : 9
One of the X or Y list is empty or null. X.size : 1 Y.size : 11
One of the X or Y list is empty or null. X.size : 4 Y.size : 4
One of the X or Y list is empty or null. X.size : 8 Y.size : 7
One of the X or Y list is empty or null. X.size : 2 Y.size : 3
One of the X or Y list is empty or null. X.size : 11 Y.size : 0
One of the X or Y list is empty or null. X.size : 5 Y.size : 1
One of the X or Y list is empty or null. X.size : 0 Y.size : 10
One of the X or Y list is empty or null. X.size : 12 Y.size : 6
Failed while trying to mark the task execution on current thread completed.FileNotFoundException
Failed while trying to mark the task execution on current thread completed.ArrayIndexOutOfBoundsException
Failed while trying to mark the task execution on current thread completed.IOException
Failed while trying to mark the task execution on current thread completed.IllegalArgumentException
Failed while trying to mark the task execution on current thread completed.InterruptedException
Failed while trying to mark the task execution on current thread completed.ClassCastException
Failed while trying to mark the task execution on current thread completed.NoSuchElementException
Failed while trying to mark the task execution on current thread completed.OutOfMemoryError
Failed while trying to mark the task execution on current thread completed.StackOverflowError
Failed while trying to mark the task execution on current thread completed.NumberFormatException
Failed while trying to mark the task execution on current thread completed.ArithmeticException
Failed while trying to mark the task execution on current thread completed.NullPointerException
Failed while trying to mark the task execution on current thread completed.FileNotFoundException
timed out after [10000] resolving host [google.com]
timed out after [3000] resolving host [stackoverflow.com]
timed out after [8000] resolving host [github.com]
timed out after [6000] resolving host [yahoo.com]
timed out after [2000] resolving host [bing.com]
timed out after [4000] resolving host [amazon.com]
timed out after [7000] resolving host [facebook.com]
timed out after [1500] resolving host [reddit.com]
timed out after [9000] resolving host [linkedin.com]
timed out after [2500] resolving host [twitter.com]
timed out after [3500] resolving host [instagram.com]
timed out after [12000] resolving host [youtube.com]
timed out after [4500] resolving host [netflix.com]
Stopping resource tracking for task: 456
Stopping resource tracking for task: 789
Stopping resource tracking for task: 101
Stopping resource tracking for task: 234
Stopping resource tracking for task: 567
Stopping resource tracking for task: 898
Stopping resource tracking for task: 333
Stopping resource tracking for task: 444
Stopping resource tracking for task: 555
Stopping resource tracking for task: 666
Stopping resource tracking for task: 777
Stopping resource tracking for task: 888
Stopping resource tracking for task: 999
Starting resource tracking for task: 456
Starting resource tracking for task: 789
Starting resource tracking for task: 098
Starting resource tracking for task: 765
Starting resource tracking for task: 432
Starting resource tracking for task: 321
Starting resource tracking for task: 654
Starting resource tracking for task: 987
Starting resource tracking for task: 234
Starting resource tracking for task: 567
Starting resource tracking for task: 890
Starting resource tracking for task: 109
Starting resource tracking for task: 876
failed to cancel tasks on channel closed IOException
failed to cancel tasks on channel closed NullPointerException
failed to cancel tasks on channel closed TimeoutException
failed to cancel tasks on channel closed RuntimeException
failed to cancel tasks on channel closed IllegalArgumentException
failed to cancel tasks on channel closed IllegalStateException
failed to cancel tasks on channel closed NoSuchElementException
failed to cancel tasks on channel closed IndexOutOfBoundsException
failed to cancel tasks on channel closed ClassNotFoundException
failed to cancel tasks on channel closed ArrayIndexOutOfBoundsException
failed to cancel tasks on channel closed ArithmeticException
failed to cancel tasks on channel closed AssertionError
failed to cancel tasks on channel closed OutOfMemoryError
--> highlighting (type=underline) and searching on field1
--> highlighting (type=italic) and searching on field1
--> highlighting (type=color) and searching on field1
--> highlighting (type=highlight) and searching on field1
--> highlighting (type=strikethrough) and searching on field1
--> highlighting (type=underline) and searching on field1
--> highlighting (type=bold) and searching on field1
--> highlighting (type=italic) and searching on field1
--> highlighting (type=underline) and searching on field1
--> highlighting (type=bold) and searching on field1
--> highlighting (type=italic) and searching on field1
--> highlighting (type=color) and searching on field1
--> highlighting (type=highlight) and searching on field1
Removing ban for the parent [456] on the node [node-2], reason: the parent node is gone
Removing ban for the parent [789] on the node [node-3], reason: the parent node is gone
Removing ban for the parent [987] on the node [node-4], reason: the parent node is gone
Removing ban for the parent [654] on the node [node-5], reason: the parent node is gone
Removing ban for the parent [321] on the node [node-6], reason: the parent node is gone
Removing ban for the parent [246] on the node [node-7], reason: the parent node is gone
Removing ban for the parent [135] on the node [node-8], reason: the parent node is gone
Removing ban for the parent [802] on the node [node-9], reason: the parent node is gone
Removing ban for the parent [579] on the node [node-10], reason: the parent node is gone
Removing ban for the parent [111] on the node [node-11], reason: the parent node is gone
Removing ban for the parent [222] on the node [node-12], reason: the parent node is gone
Removing ban for the parent [333] on the node [node-13], reason: the parent node is gone
Removing ban for the parent [444] on the node [node-14], reason: the parent node is gone
Failed to build synonyms: OutOfMemoryException
Failed to build synonyms: FileNotFoundException
Failed to build synonyms: InvalidOperationException
Failed to build synonyms: ArgumentException
Failed to build synonyms: StackOverflowException
Failed to build synonyms: IndexOutOfRangeException
Failed to build synonyms: AccessViolationException
Failed to build synonyms: DivideByZeroException
Failed to build synonyms: FormatException
Failed to build synonyms: KeyNotFoundException
Failed to build synonyms: NullReferenceException
Failed to build synonyms: OutOfMemoryException
Failed to build synonyms: FileNotFoundException
removing ban for the parent task 456
removing ban for the parent task 789
removing ban for the parent task 321
removing ban for the parent task 654
removing ban for the parent task 987
removing ban for the parent task 234
removing ban for the parent task 567
removing ban for the parent task 890
removing ban for the parent task 432
removing ban for the parent task 765
removing ban for the parent task 098
removing ban for the parent task 345
removing ban for the parent task 678
Synonym rule for banana was ignored
Synonym rule for orange was ignored
Synonym rule for grape was ignored
Synonym rule for kiwi was ignored
Synonym rule for pear was ignored
Synonym rule for watermelon was ignored
Synonym rule for strawberry was ignored
Synonym rule for pineapple was ignored
Synonym rule for mango was ignored
Synonym rule for cherry was ignored
Synonym rule for blueberry was ignored
Synonym rule for lemon was ignored
Synonym rule for peach was ignored
setting ban for the parent task 67890 due to security concerns
setting ban for the parent task 54321 due to inappropriate content
setting ban for the parent task 98765 due to fraudulent activity
setting ban for the parent task 24680 due to copyright infringement
setting ban for the parent task 13579 due to violation of community guidelines
setting ban for the parent task 86420 due to abusive behavior
setting ban for the parent task 55555 due to spamming activity
setting ban for the parent task 77777 due to harassment
setting ban for the parent task 88888 due to system vulnerability
setting ban for the parent task 99999 due to privacy violation
setting ban for the parent task 11111 due to illegal content
setting ban for the parent task 22222 due to inaccurate information
setting ban for the parent task 33333 due to disruptive behavior
couldn't store response data2, the node didn't join the cluster yet
couldn't store response data3, the node didn't join the cluster yet
couldn't store response data4, the node didn't join the cluster yet
couldn't store response data5, the node didn't join the cluster yet
couldn't store response data6, the node didn't join the cluster yet
couldn't store response data7, the node didn't join the cluster yet
couldn't store response data8, the node didn't join the cluster yet
couldn't store response data9, the node didn't join the cluster yet
couldn't store response data10, the node didn't join the cluster yet
couldn't store response data11, the node didn't join the cluster yet
couldn't store response data12, the node didn't join the cluster yet
couldn't store response data13, the node didn't join the cluster yet
couldn't store response data14, the node didn't join the cluster yet
--> testing with xcontent type: application/xml
--> testing with xcontent type: application/yaml
--> testing with xcontent type: text/plain
--> testing with xcontent type: text/html
--> testing with xcontent type: application/octet-stream
--> testing with xcontent type: application/pdf
--> testing with xcontent type: application/zip
--> testing with xcontent type: application/x-www-form-urlencoded
--> testing with xcontent type: multipart/form-data
--> testing with xcontent type: application/javascript
--> testing with xcontent type: application/ld+json
--> testing with xcontent type: application/rss+xml
--> testing with xcontent type: application/vnd.api+json
unregister child node node2 task task2
unregister child node node3 task task3
unregister child node node4 task task4
unregister child node node5 task task5
unregister child node node6 task task6
unregister child node node7 task task7
unregister child node node8 task task8
unregister child node node9 task task9
unregister child node node10 task task10
unregister child node node11 task task11
unregister child node node12 task task12
unregister child node node13 task task13
unregister child node node14 task task14
failure: IOException
failure: ArrayIndexOutOfBoundsException
failure: IllegalArgumentException
failure: FileNotFoundException
failure: ClassCastException
failure: NoSuchMethodException
failure: IndexOutOfBoundsException
failure: NumberFormatException
failure: AssertionError
failure: UnsupportedOperationException
failure: StackOverflowError
failure: FileNotFoundException
failure: OutOfMemoryError
- Jane Doe
- Alice Johnson
- Michael Brown
- Sarah Wilson
- Robert Lee
- David Davis
- Jennifer Miller
- Christopher Wilson
- Jessica Clark
- Matthew Thompson
- Emily Anderson
- Daniel Martinez
- Melissa Taylor
error encountered when updating the consumer RuntimeException
error encountered when updating the consumer NullPointerException
error encountered when updating the consumer IndexOutOfBoundsException
error encountered when updating the consumer IllegalArgumentException
error encountered when updating the consumer IllegalStateException
error encountered when updating the consumer NoSuchElementException
error encountered when updating the consumer ClassNotFoundException
error encountered when updating the consumer FileNotFoundException
error encountered when updating the consumer IOException
error encountered when updating the consumer SQLException
error encountered when updating the consumer SocketException
error encountered when updating the consumer HttpRequestException
error encountered when updating the consumer TimeoutException
unregister task for id: 5678
unregister task for id: 9876
unregister task for id: 4321
unregister task for id: 2468
unregister task for id: 1357
unregister task for id: 8642
unregister task for id: 9513
unregister task for id: 7890
unregister task for id: 0123
unregister task for id: 4567
unregister task for id: 8901
unregister task for id: 6543
unregister task for id: 3210
Failed to find issuer [amazon.com] in trust manager, but did find ...
Failed to find issuer [facebook.com] in trust manager, but did find ...
Failed to find issuer [microsoft.com] in trust manager, but did find ...
Failed to find issuer [github.com] in trust manager, but did find ...
Failed to find issuer [yahoo.com] in trust manager, but did find ...
Failed to find issuer [linkedin.com] in trust manager, but did find ...
Failed to find issuer [netflix.com] in trust manager, but did find ...
Failed to find issuer [instagram.com] in trust manager, but did find ...
Failed to find issuer [twitter.com] in trust manager, but did find ...
Failed to find issuer [apple.com] in trust manager, but did find ...
Failed to find issuer [stackoverflow.com] in trust manager, but did find ...
Failed to find issuer [spotify.com] in trust manager, but did find ...
Failed to find issuer [youtube.com] in trust manager, but did find ...
Failed to find issuer [uber.com] in trust manager, but did find ...
--> replica shard 2 recovered from node-3 to node-4, recovered 2048, reuse 1024
--> replica shard 3 recovered from node-2 to node-1, recovered 3072, reuse 1536
--> replica shard 4 recovered from node-4 to node-3, recovered 4096, reuse 2048
--> replica shard 5 recovered from node-3 to node-2, recovered 5120, reuse 2560
--> replica shard 6 recovered from node-1 to node-4, recovered 6144, reuse 3072
--> replica shard 7 recovered from node-2 to node-3, recovered 7168, reuse 3584
--> replica shard 8 recovered from node-4 to node-1, recovered 8192, reuse 4096
--> replica shard 9 recovered from node-1 to node-3, recovered 9216, reuse 4608
--> replica shard 10 recovered from node-3 to node-4, recovered 10240, reuse 5120
--> replica shard 11 recovered from node-4 to node-2, recovered 11264, reuse 5632
--> replica shard 12 recovered from node-2 to node-1, recovered 12288, reuse 6144
--> replica shard 13 recovered from node-4 to node-3, recovered 13312, reuse 6656
--> replica shard 14 recovered from node-1 to node-2, recovered 14336, reuse 7168
cancelling task with id 456
cancelling task with id 789
cancelling task with id 222
cancelling task with id 555
cancelling task with id 888
cancelling task with id 111
cancelling task with id 444
cancelling task with id 777
cancelling task with id 999
cancelling task with id 000
cancelling task with id 333
cancelling task with id 666
cancelling task with id 222
failed to register a completion listener as task resource tracking has already completed [taskId=456]
failed to register a completion listener as task resource tracking has already completed [taskId=789]
failed to register a completion listener as task resource tracking has already completed [taskId=987]
failed to register a completion listener as task resource tracking has already completed [taskId=654]
failed to register a completion listener as task resource tracking has already completed [taskId=321]
failed to register a completion listener as task resource tracking has already completed [taskId=987]
failed to register a completion listener as task resource tracking has already completed [taskId=654]
failed to register a completion listener as task resource tracking has already completed [taskId=123]
failed to register a completion listener as task resource tracking has already completed [taskId=789]
failed to register a completion listener as task resource tracking has already completed [taskId=456]
failed to register a completion listener as task resource tracking has already completed [taskId=321]
failed to register a completion listener as task resource tracking has already completed [taskId=789]
failed to register a completion listener as task resource tracking has already completed [taskId=654]
access: target thread=t2
access: target thread=t3
access: target thread=t4
access: target thread=t5
access: target thread=t6
access: target thread=t7
access: target thread=t8
access: target thread=t9
access: target thread=t10
access: target thread=t11
access: target thread=t12
access: target thread=t13
access: target thread=t14
register 456 [call] [receive] [Receive a phone call from customer]
register 789 [meeting] [schedule] [Schedule a meeting with team]
register 234 [task] [complete] [Complete the assigned task]
register 567 [reminder] [set] [Set a reminder for the deadline]
register 890 [notification] [send] [Send a notification to all users]
register 345 [message] [send] [Send a message to colleague]
register 678 [event] [create] [Create a new event in the calendar]
register 901 [reminder] [delete] [Delete a reminder from the list]
register 432 [meeting] [cancel] [Cancel the scheduled meeting]
register 765 [task] [assign] [Assign a new task to team member]
register 098 [notification] [read] [Read the received notification]
register 321 [email] [reply] [Reply to the client's email]
register 654 [message] [receive] [Receive a message from friend]
access: caller thread=Thread[pool-1-thread-1,5,main]
access: caller thread=Thread[Thread-2,5,main]
access: caller thread=Thread[pool-1-thread-2,5,main]
access: caller thread=Thread[Thread-3,5,main]
access: caller thread=Thread[pool-1-thread-3,5,main]
access: caller thread=Thread[Thread-4,5,main]
access: caller thread=Thread[pool-1-thread-4,5,main]
access: caller thread=Thread[Thread-5,5,main]
access: caller thread=Thread[pool-1-thread-5,5,main]
access: caller thread=Thread[Thread-6,5,main]
access: caller thread=Thread[pool-1-thread-6,5,main]
access: caller thread=Thread[Thread-7,5,main]
access: caller thread=Thread[pool-1-thread-7,5,main]
access: caller thread=Thread[Thread-8,5,main]
Received ban for the parent [TASK_456] on the node [NODE_2], reason: [Resource exhaustion]
Received ban for the parent [TASK_789] on the node [NODE_3], reason: [Authorization failure]
Received ban for the parent [TASK_234] on the node [NODE_1], reason: [Network failure]
Received ban for the parent [TASK_567] on the node [NODE_2], reason: [Server error]
Received ban for the parent [TASK_890] on the node [NODE_3], reason: [Timeout]
Received ban for the parent [TASK_345] on the node [NODE_1], reason: [Memory overflow]
Received ban for the parent [TASK_678] on the node [NODE_2], reason: [Invalid configuration]
Received ban for the parent [TASK_901] on the node [NODE_3], reason: [Database error]
Received ban for the parent [TASK_412] on the node [NODE_1], reason: [File not found]
Received ban for the parent [TASK_654] on the node [NODE_2], reason: [Security breach]
Received ban for the parent [TASK_987] on the node [NODE_3], reason: [Unknown error]
Received ban for the parent [TASK_123] on the node [NODE_1], reason: [Insufficient permissions]
Received ban for the parent [TASK_456] on the node [NODE_2], reason: [Disk full]
Removing ban for the parent [875] on the node [456]
Removing ban for the parent [982] on the node [789]
Removing ban for the parent [253] on the node [159]
Removing ban for the parent [736] on the node [246]
Removing ban for the parent [618] on the node [357]
Removing ban for the parent [314] on the node [468]
Removing ban for the parent [497] on the node [579]
Removing ban for the parent [865] on the node [678]
Removing ban for the parent [932] on the node [791]
Removing ban for the parent [684] on the node [896]
Removing ban for the parent [456] on the node [937]
Removing ban for the parent [273] on the node [418]
Removing ban for the parent [539] on the node [127]
Exception cause unwrapping ran for 10 levels... FileNotFoundException
Exception cause unwrapping ran for 10 levels... IOException
Exception cause unwrapping ran for 10 levels... ArrayIndexOutOfBoundsException
Exception cause unwrapping ran for 10 levels... ClassNotFoundException
Exception cause unwrapping ran for 10 levels... NoSuchElementException
Exception cause unwrapping ran for 10 levels... IllegalArgumentException
Exception cause unwrapping ran for 10 levels... IllegalStateException
Exception cause unwrapping ran for 10 levels... NumberFormatException
Exception cause unwrapping ran for 10 levels... ArithmeticException
Exception cause unwrapping ran for 10 levels... IndexOutOfBoundsException
Exception cause unwrapping ran for 10 levels... NullPointerException
Exception cause unwrapping ran for 10 levels... FileNotFoundException
Exception cause unwrapping ran for 10 levels... IOException
failed to remove the parent ban for task 456 on node B
failed to remove the parent ban for task 789 on node C
failed to remove the parent ban for task 234 on node D
failed to remove the parent ban for task 567 on node E
failed to remove the parent ban for task 890 on node F
failed to remove the parent ban for task 345 on node G
failed to remove the parent ban for task 678 on node H
failed to remove the parent ban for task 901 on node I
failed to remove the parent ban for task 456 on node J
failed to remove the parent ban for task 789 on node K
failed to remove the parent ban for task 123 on node L
failed to remove the parent ban for task 456 on node M
failed to remove the parent ban for task 789 on node N
Sending remove ban for tasks with the parent [task456] to the node [node-2]
Sending remove ban for tasks with the parent [task789] to the node [node-3]
Sending remove ban for tasks with the parent [task321] to the node [node-4]
Sending remove ban for tasks with the parent [task654] to the node [node-5]
Sending remove ban for tasks with the parent [task987] to the node [node-6]
Sending remove ban for tasks with the parent [task543] to the node [node-7]
Sending remove ban for tasks with the parent [task876] to the node [node-8]
Sending remove ban for tasks with the parent [task210] to the node [node-9]
Sending remove ban for tasks with the parent [task543] to the node [node-10]
Sending remove ban for tasks with the parent [task876] to the node [node-11]
Sending remove ban for tasks with the parent [task210] to the node [node-12]
Sending remove ban for tasks with the parent [task543] to the node [node-13]
Sending remove ban for tasks with the parent [task876] to the node [node-14]
Cannot send ban for tasks with the parent [task002] to the node [node002]
Cannot send ban for tasks with the parent [task003] to the node [node003]
Cannot send ban for tasks with the parent [task004] to the node [node004]
Cannot send ban for tasks with the parent [task005] to the node [node005]
Cannot send ban for tasks with the parent [task006] to the node [node006]
Cannot send ban for tasks with the parent [task007] to the node [node007]
Cannot send ban for tasks with the parent [task008] to the node [node008]
Cannot send ban for tasks with the parent [task009] to the node [node009]
Cannot send ban for tasks with the parent [task010] to the node [node010]
Cannot send ban for tasks with the parent [task011] to the node [node011]
Cannot send ban for tasks with the parent [task012] to the node [node012]
Cannot send ban for tasks with the parent [task013] to the node [node013]
Cannot send ban for tasks with the parent [task014] to the node [node014]
sent ban for tasks with the parent [task-789] to the node [node-012]
sent ban for tasks with the parent [task-345] to the node [node-678]
sent ban for tasks with the parent [task-901] to the node [node-234]
sent ban for tasks with the parent [task-567] to the node [node-890]
sent ban for tasks with the parent [task-123] to the node [node-456]
sent ban for tasks with the parent [task-789] to the node [node-012]
sent ban for tasks with the parent [task-345] to the node [node-678]
sent ban for tasks with the parent [task-901] to the node [node-234]
sent ban for tasks with the parent [task-567] to the node [node-890]
sent ban for tasks with the parent [task-123] to the node [node-456]
sent ban for tasks with the parent [task-789] to the node [node-012]
sent ban for tasks with the parent [task-345] to the node [node-678]
sent ban for tasks with the parent [task-901] to the node [node-234]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=0.8, memory=0.6, disk=0.4], current_end_value=0.6, new_end_value=0.5]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=0.9, memory=0.7, disk=0.3], current_end_value=0.7, new_end_value=0.6]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=0.7, memory=0.8, disk=0.5], current_end_value=0.8, new_end_value=0.7]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=0.6, memory=0.9, disk=0.6], current_end_value=0.9, new_end_value=0.8]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=0.5, memory=0.4, disk=0.7], current_end_value=0.4, new_end_value=0.3]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=0.4, memory=0.3, disk=0.8], current_end_value=0.3, new_end_value=0.2]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=0.3, memory=0.2, disk=0.9], current_end_value=0.2, new_end_value=0.1]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=0.2, memory=0.1, disk=0.1], current_end_value=0.1, new_end_value=0.0]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=0.1, memory=0.0, disk=0.2], current_end_value=0.0, new_end_value=-0.1]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=0.0, memory=-0.1, disk=0.3], current_end_value=-0.1, new_end_value=-0.2]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=-0.1, memory=-0.2, disk=0.4], current_end_value=-0.2, new_end_value=-0.3]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=-0.2, memory=-0.3, disk=0.5], current_end_value=-0.3, new_end_value=-0.4]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=-0.3, memory=-0.4, disk=0.6], current_end_value=-0.4, new_end_value=-0.5]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=-0.4, memory=-0.5, disk=0.7], current_end_value=-0.5, new_end_value=-0.6]
dropping resource usage update as the new value is lower than current value [resource_stats=[cpu=-0.5, memory=-0.6, disk=0.8], current_end_value=-0.6, new_end_value=-0.7]
startProbe(192.168.1.1) not probing local node
startProbe(172.16.0.1) not probing local node
startProbe(10.1.1.1) not probing local node
startProbe(192.168.0.2) not probing local node
startProbe(172.31.0.1) not probing local node
startProbe(10.2.0.1) not probing local node
startProbe(192.168.1.2) not probing local node
startProbe(172.16.1.1) not probing local node
startProbe(10.1.2.1) not probing local node
startProbe(192.168.0.3) not probing local node
startProbe(172.31.1.1) not probing local node
startProbe(10.2.1.1) not probing local node
startProbe(192.168.1.3) not probing local node
cancelling child tasks of [456] on child nodes [3, 4]
cancelling child tasks of [789] on child nodes [5, 6]
cancelling child tasks of [abc] on child nodes [7, 8]
cancelling child tasks of [def] on child nodes [9, 10]
cancelling child tasks of [ghi] on child nodes [11, 12]
cancelling child tasks of [jkl] on child nodes [13, 14]
cancelling child tasks of [mno] on child nodes [15, 16]
cancelling child tasks of [pqr] on child nodes [17, 18]
cancelling child tasks of [stu] on child nodes [19, 20]
cancelling child tasks of [vwx] on child nodes [21, 22]
cancelling child tasks of [yz0] on child nodes [23, 24]
cancelling child tasks of [123] on child nodes [25, 26]
cancelling child tasks of [abc] on child nodes [27, 28]
--> done cluster_health, status yellow
--> done cluster_health, status red
--> done cluster_health, status unknown
--> done cluster_health, status green
--> done cluster_health, status yellow
--> done cluster_health, status red
--> done cluster_health, status unknown
--> done cluster_health, status green
--> done cluster_health, status yellow
--> done cluster_health, status red
--> done cluster_health, status unknown
--> done cluster_health, status green
--> done cluster_health, status yellow
startProbe(192.168.0.1:8080) not running
startProbe(10.0.0.1:8080) not running
startProbe(172.16.0.1:8080) not running
startProbe(localhost:8080) not running
startProbe(127.0.0.2:8080) not running
startProbe(192.168.0.2:8080) not running
startProbe(10.0.0.2:8080) not running
startProbe(172.16.0.2:8080) not running
startProbe(localhost:8081) not running
startProbe(127.0.0.3:8080) not running
startProbe(192.168.0.3:8080) not running
startProbe(10.0.0.3:8080) not running
startProbe(172.16.0.3:8080) not running
task [456] is cancelled
task [789] is cancelled
task [102] is cancelled
task [205] is cancelled
task [308] is cancelled
task [411] is cancelled
task [514] is cancelled
task [617] is cancelled
task [720] is cancelled
task [823] is cancelled
task [926] is cancelled
task [1030] is cancelled
task [1134] is cancelled
commit - Commit changes
status - View the status of the repository
pull - Pull changes from a remote repository
push - Push changes to a remote repository
clone - Clone a repository
branch - Manage branches
log - View the commit history
merge - Merge branches
reset - Reset changes
fetch - Fetch changes from a remote repository
rebase - Rebase changes
tag - Manage tags
diff - View the difference between commits
unexpected exception in wakeup FileNotFoundException
unexpected exception in wakeup ArrayIndexOutOfBoundsException
unexpected exception in wakeup IllegalArgumentException
unexpected exception in wakeup ClassCastException
unexpected exception in wakeup NoSuchElementException
unexpected exception in wakeup NumberFormatException
unexpected exception in wakeup StringIndexOutOfBoundsException
unexpected exception in wakeup NullPointerException
unexpected exception in wakeup FileNotFoundException
unexpected exception in wakeup ArrayIndexOutOfBoundsException
unexpected exception in wakeup IllegalArgumentException
unexpected exception in wakeup ClassCastException
unexpected exception in wakeup NoSuchElementException
child tasks of parent [Task002] are completed
child tasks of parent [Task003] are completed
child tasks of parent [Task004] are completed
child tasks of parent [Task005] are completed
child tasks of parent [Task006] are completed
child tasks of parent [Task007] are completed
child tasks of parent [Task008] are completed
child tasks of parent [Task009] are completed
child tasks of parent [Task010] are completed
child tasks of parent [Task011] are completed
child tasks of parent [Task012] are completed
child tasks of parent [Task013] are completed
child tasks of parent [Task014] are completed
probing cluster-manager nodes from cluster state: node2
probing cluster-manager nodes from cluster state: node3
probing cluster-manager nodes from cluster state: node4
probing cluster-manager nodes from cluster state: node5
probing cluster-manager nodes from cluster state: node6
probing cluster-manager nodes from cluster state: node7
probing cluster-manager nodes from cluster state: node8
probing cluster-manager nodes from cluster state: node9
probing cluster-manager nodes from cluster state: node10
probing cluster-manager nodes from cluster state: node11
probing cluster-manager nodes from cluster state: node12
probing cluster-manager nodes from cluster state: node13
probing cluster-manager nodes from cluster state: node14
cancelling task [456] and its descendants
cancelling task [789] and its descendants
cancelling task [987] and its descendants
cancelling task [654] and its descendants
cancelling task [321] and its descendants
cancelling task [246] and its descendants
cancelling task [135] and its descendants
cancelling task [579] and its descendants
cancelling task [864] and its descendants
cancelling task [951] and its descendants
cancelling task [357] and its descendants
cancelling task [468] and its descendants
cancelling task [273] and its descendants
task [5678] doesn't have any children that should be cancelled
task [91011] doesn't have any children that should be cancelled
task [121314] doesn't have any children that should be cancelled
task [151617] doesn't have any children that should be cancelled
task [181920] doesn't have any children that should be cancelled
task [212223] doesn't have any children that should be cancelled
task [242526] doesn't have any children that should be cancelled
task [272829] doesn't have any children that should be cancelled
task [303132] doesn't have any children that should be cancelled
task [333435] doesn't have any children that should be cancelled
task [363738] doesn't have any children that should be cancelled
task [394041] doesn't have any children that should be cancelled
task [424344] doesn't have any children that should be cancelled
deactivating and setting leader to Michael
deactivating and setting leader to Emily
deactivating and setting leader to David
deactivating and setting leader to Sarah
deactivating and setting leader to Jessica
deactivating and setting leader to Daniel
deactivating and setting leader to Olivia
deactivating and setting leader to Ethan
deactivating and setting leader to Ava
deactivating and setting leader to Benjamin
deactivating and setting leader to Mia
deactivating and setting leader to William
deactivating and setting leader to Sophia
activating with node2
activating with node3
activating with node4
activating with node5
activating with node6
activating with node7
activating with node8
activating with node9
activating with node10
activating with node11
activating with node12
activating with node13
activating with node14
ERROR: javadocs are missing
INFO: javadocs are missing
WARNING: javadocs are missing
ERROR: javadocs are missing
INFO: javadocs are missing
WARNING: javadocs are missing
ERROR: javadocs are missing
INFO: javadocs are missing
WARNING: javadocs are missing
ERROR: javadocs are missing
INFO: javadocs are missing
WARNING: javadocs are missing
ERROR: javadocs are missing
setting findPeersInterval to [30] as node commission status = [false] for local node [node-2]
setting findPeersInterval to [15] as node commission status = [true] for local node [node-3]
setting findPeersInterval to [20] as node commission status = [false] for local node [node-4]
setting findPeersInterval to [5] as node commission status = [true] for local node [node-5]
setting findPeersInterval to [25] as node commission status = [true] for local node [node-6]
setting findPeersInterval to [8] as node commission status = [false] for local node [node-7]
setting findPeersInterval to [12] as node commission status = [true] for local node [node-8]
setting findPeersInterval to [18] as node commission status = [false] for local node [node-9]
setting findPeersInterval to [35] as node commission status = [true] for local node [node-10]
setting findPeersInterval to [14] as node commission status = [false] for local node [node-11]
setting findPeersInterval to [23] as node commission status = [true] for local node [node-12]
setting findPeersInterval to [7] as node commission status = [false] for local node [node-13]
setting findPeersInterval to [28] as node commission status = [true] for local node [node-14]
--> stopped node[02], remaining nodes 11
--> stopped node[03], remaining nodes 10
--> stopped node[04], remaining nodes 09
--> stopped node[05], remaining nodes 08
--> stopped node[06], remaining nodes 07
--> stopped node[07], remaining nodes 06
--> stopped node[08], remaining nodes 05
--> stopped node[09], remaining nodes 04
--> stopped node[10], remaining nodes 03
--> stopped node[11], remaining nodes 02
--> stopped node[12], remaining nodes 01
--> stopped node[13], remaining nodes 00
--> stopped node[14], remaining nodes 00
changed cluster state triggered by [8] snapshot state updates and resulted in starting [6] shard snapshots
changed cluster state triggered by [2] snapshot state updates and resulted in starting [1] shard snapshots
changed cluster state triggered by [4] snapshot state updates and resulted in starting [2] shard snapshots
changed cluster state triggered by [7] snapshot state updates and resulted in starting [5] shard snapshots
changed cluster state triggered by [6] snapshot state updates and resulted in starting [4] shard snapshots
changed cluster state triggered by [1] snapshot state updates and resulted in starting [3] shard snapshots
changed cluster state triggered by [3] snapshot state updates and resulted in starting [2] shard snapshots
changed cluster state triggered by [9] snapshot state updates and resulted in starting [7] shard snapshots
changed cluster state triggered by [10] snapshot state updates and resulted in starting [8] shard snapshots
changed cluster state triggered by [12] snapshot state updates and resulted in starting [10] shard snapshots
changed cluster state triggered by [11] snapshot state updates and resulted in starting [9] shard snapshots
changed cluster state triggered by [15] snapshot state updates and resulted in starting [13] shard snapshots
changed cluster state triggered by [14] snapshot state updates and resulted in starting [12] shard snapshots
[2] opened probe connection
[3] opened probe connection
[4] opened probe connection
[5] opened probe connection
[6] opened probe connection
[7] opened probe connection
[8] opened probe connection
[9] opened probe connection
[10] opened probe connection
[11] opened probe connection
[12] opened probe connection
[13] opened probe connection
[14] opened probe connection
[09H23M17S] opening probe connection
[15H45M02S] opening probe connection
[06H52M13S] opening probe connection
[18H08M59S] opening probe connection
[21H16M47S] opening probe connection
[10H32M58S] opening probe connection
[14H09M25S] opening probe connection
[17H23M51S] opening probe connection
[08H41M33S] opening probe connection
[13H05M07S] opening probe connection
[20H30M14S] opening probe connection
[16H15M39S] opening probe connection
[07H27M20S] opening probe connection
seed addresses: 192.168.1.2
seed addresses: 192.168.1.3
seed addresses: 192.168.1.4
seed addresses: 192.168.1.5
seed addresses: 192.168.1.6
seed addresses: 192.168.1.7
seed addresses: 192.168.1.8
seed addresses: 192.168.1.9
seed addresses: 192.168.1.10
seed addresses: 192.168.1.11
seed addresses: 192.168.1.12
seed addresses: 192.168.1.13
seed addresses: 192.168.1.14
Received clone shard snapshot status update [error] but this shard is not tracked in [shard-2]
Received clone shard snapshot status update [paused] but this shard is not tracked in [shard-3]
Received clone shard snapshot status update [in progress] but this shard is not tracked in [shard-4]
Received clone shard snapshot status update [completed with issues] but this shard is not tracked in [shard-5]
Received clone shard snapshot status update [unknown] but this shard is not tracked in [shard-6]
Received clone shard snapshot status update [cancelled] but this shard is not tracked in [shard-7]
Received clone shard snapshot status update [pending] but this shard is not tracked in [shard-8]
Received clone shard snapshot status update [failed] but this shard is not tracked in [shard-9]
Received clone shard snapshot status update [incomplete] but this shard is not tracked in [shard-10]
Received clone shard snapshot status update [aborted] but this shard is not tracked in [shard-11]
Received clone shard snapshot status update [terminated] but this shard is not tracked in [shard-12]
Received clone shard snapshot status update [interrupted] but this shard is not tracked in [shard-13]
Received clone shard snapshot status update [finished] but this shard is not tracked in [shard-14]
expected, but did not find, a dynamic hosts list at [servers.cfg]
expected, but did not find, a dynamic hosts list at [config.json]
expected, but did not find, a dynamic hosts list at [hosts.yaml]
expected, but did not find, a dynamic hosts list at [cluster.ini]
expected, but did not find, a dynamic hosts list at [servers.txt]
expected, but did not find, a dynamic hosts list at [hosts.cfg]
expected, but did not find, a dynamic hosts list at [config.ini]
expected, but did not find, a dynamic hosts list at [servers.json]
expected, but did not find, a dynamic hosts list at [hosts.yaml]
expected, but did not find, a dynamic hosts list at [cluster.txt]
expected, but did not find, a dynamic hosts list at [config.cfg]
expected, but did not find, a dynamic hosts list at [servers.ini]
expected, but did not find, a dynamic hosts list at [hosts.json]
using discovery type [ec2] and seed hosts providers [10.0.0.1, 10.0.0.2]
using discovery type [kubernetes] and seed hosts providers [172.10.10.1, 172.10.10.2]
using discovery type [azure] and seed hosts providers [192.168.1.1, 192.168.1.2]
using discovery type [gcp] and seed hosts providers [10.20.30.40]
using discovery type [dns] and seed hosts providers [example.com]
using discovery type [manual] and seed hosts providers [192.168.0.1, 192.168.0.2]
using discovery type [config] and seed hosts providers [config1, config2]
using discovery type [file] and seed hosts providers [file1, file2]
using discovery type [consul] and seed hosts providers [consul1, consul2]
using discovery type [etcd] and seed hosts providers [etcd1, etcd2]
using discovery type [gossip] and seed hosts providers [gossip1, gossip2]
using discovery type [zookeeper] and seed hosts providers [zoo1, zoo2]
using discovery type [simple] and seed hosts providers [127.0.0.1, 127.0.0.2]
using discovery type [aws] and seed hosts providers [arn:aws:dynamodb:us-west-2:account-id:table/TableName]
Received shard snapshot status update [COMPLETED] but this shard is not tracked in [shard2]
Received shard snapshot status update [FAILED] but this shard is not tracked in [shard3]
Received shard snapshot status update [IN_PROGRESS] but this shard is not tracked in [shard4]
Received shard snapshot status update [COMPLETED] but this shard is not tracked in [shard5]
Received shard snapshot status update [FAILED] but this shard is not tracked in [shard6]
Received shard snapshot status update [IN_PROGRESS] but this shard is not tracked in [shard7]
Received shard snapshot status update [COMPLETED] but this shard is not tracked in [shard8]
Received shard snapshot status update [FAILED] but this shard is not tracked in [shard9]
Received shard snapshot status update [IN_PROGRESS] but this shard is not tracked in [shard10]
Received shard snapshot status update [COMPLETED] but this shard is not tracked in [shard11]
Received shard snapshot status update [FAILED] but this shard is not tracked in [shard12]
Received shard snapshot status update [IN_PROGRESS] but this shard is not tracked in [shard13]
Received shard snapshot status update [COMPLETED] but this shard is not tracked in [shard14]
creating crypto client [Software][AWSKMS]
creating crypto client [PKCS11][GemaltoHSM]
creating crypto client [CloudHSM][GoogleKeyManagement]
creating crypto client [KMIP][IBMKeyProtect]
creating crypto client [TPM][AzureConfidentialComputing]
creating crypto client [AWSKMS][AmazonCloudHSM]
creating crypto client [AzureKeyVault][HSM]
creating crypto client [GoogleKeyManagement][PKCS11]
creating crypto client [AWS CloudHSM][AWSKMS]
creating crypto client [IBMKeyProtect][CloudHSM]
creating crypto client [AzureConfidentialComputing][KMIP]
creating crypto client [nCipherHSM][AWSCloudHSM]
creating crypto client [YubiHSM][GoogleCloudHSM]
creating crypto client [Software][AzureKeyVault]
Please install the following custom plugins manually: pluginB
Please install the following custom plugins manually: pluginC
Please install the following custom plugins manually: pluginD
Please install the following custom plugins manually: pluginE
Please install the following custom plugins manually: pluginF
Please install the following custom plugins manually: pluginG
Please install the following custom plugins manually: pluginH
Please install the following custom plugins manually: pluginI
Please install the following custom plugins manually: pluginJ
Please install the following custom plugins manually: pluginK
Please install the following custom plugins manually: pluginL
Please install the following custom plugins manually: pluginM
Please install the following custom plugins manually: pluginN
Starting clone [002] on [NodeB] with generation [7]
Starting clone [003] on [NodeC] with generation [12]
Starting clone [004] on [NodeD] with generation [5]
Starting clone [005] on [NodeE] with generation [9]
Starting clone [006] on [NodeF] with generation [6]
Starting clone [007] on [NodeG] with generation [11]
Starting clone [008] on [NodeH] with generation [8]
Starting clone [009] on [NodeI] with generation [13]
Starting clone [010] on [NodeJ] with generation [4]
Starting clone [011] on [NodeK] with generation [3]
Starting clone [012] on [NodeL] with generation [14]
Starting clone [013] on [NodeM] with generation [1]
Starting clone [014] on [NodeN] with generation [15]
Failed to notify listeners NullPointerException
Failed to notify listeners ArrayIndexOutOfBoundsException
Failed to notify listeners ClassCastException
Failed to notify listeners IllegalArgumentException
Failed to notify listeners IllegalStateException
Failed to notify listeners ArithmeticException
Failed to notify listeners NoSuchElementException
Failed to notify listeners UnsupportedOperationException
Failed to notify listeners FileNotFoundException
Failed to notify listeners InterruptedException
Failed to notify listeners NumberFormatException
Failed to notify listeners OutOfMemoryError
Failed to notify listeners StackOverflowError
Unexpected failure during cluster state update: IOException
Unexpected failure during cluster state update: ArrayIndexOutOfBoundsException
Unexpected failure during cluster state update: IllegalArgumentException
Unexpected failure during cluster state update: OutOfMemoryError
Unexpected failure during cluster state update: StackOverflowError
Unexpected failure during cluster state update: NoSuchMethodException
Unexpected failure during cluster state update: ClassCastException
Unexpected failure during cluster state update: ArithmeticException
Unexpected failure during cluster state update: InterruptedException
Unexpected failure during cluster state update: FileNotFoundException
Unexpected failure during cluster state update: UnsupportedOperationException
Unexpected failure during cluster state update: NoSuchFieldException
Unexpected failure during cluster state update: AssertionError
Failing all snapshot operation listeners because this node is not cluster-manager any longer NullPointerException
Failing all snapshot operation listeners because this node is not cluster-manager any longer IndexOutOfBoundsException
Failing all snapshot operation listeners because this node is not cluster-manager any longer IllegalArgumentException
Failing all snapshot operation listeners because this node is not cluster-manager any longer IllegalStateException
Failing all snapshot operation listeners because this node is not cluster-manager any longer ArrayIndexOutOfBoundsException
Failing all snapshot operation listeners because this node is not cluster-manager any longer ClassCastException
Failing all snapshot operation listeners because this node is not cluster-manager any longer NoSuchElementException
Failing all snapshot operation listeners because this node is not cluster-manager any longer NumberFormatException
Failing all snapshot operation listeners because this node is not cluster-manager any longer AssertionError
Failing all snapshot operation listeners because this node is not cluster-manager any longer IllegalArgumentException
Failing all snapshot operation listeners because this node is not cluster-manager any longer IllegalStateException
Failing all snapshot operation listeners because this node is not cluster-manager any longer NullPointerException
Failing all snapshot operation listeners because this node is not cluster-manager any longer ArrayIndexOutOfBoundsException
snapshots abc deleted
snapshots xyz deleted
snapshots def deleted
snapshots 456 deleted
snapshots ghi deleted
snapshots jkl deleted
snapshots mno deleted
snapshots 789 deleted
snapshots pqr deleted
snapshots stu deleted
snapshots vwx deleted
snapshots yz deleted
snapshots abc2 deleted
Found a running instance of elasticsearch at http://192.168.0.1:9200
Found a running instance of elasticsearch at http://elastic-server:9200
Found a running instance of elasticsearch at http://10.0.0.1:9200
Found a running instance of elasticsearch at http://192.168.1.100:9200
Found a running instance of elasticsearch at http://elasticsearch:9200
Found a running instance of elasticsearch at http://172.16.0.1:9200
Found a running instance of elasticsearch at http://elastic-instance:9200
Found a running instance of elasticsearch at http://es-server:9200
Found a running instance of elasticsearch at http://10.1.1.1:9200
Found a running instance of elasticsearch at http://192.168.2.200:9200
Found a running instance of elasticsearch at http://elastic-ip:9200
Found a running instance of elasticsearch at http://172.18.0.1:9200
Found a running instance of elasticsearch at http://es-instance:9200
Delete [newComment] could not execute directly and was queued
Delete [newPost] could not execute directly and was queued
Delete [newMessage] could not execute directly and was queued
Delete [newTask] could not execute directly and was queued
Delete [newUser] could not execute directly and was queued
Delete [newProduct] could not execute directly and was queued
Delete [newOrder] could not execute directly and was queued
Delete [newCategory] could not execute directly and was queued
Delete [newInvoice] could not execute directly and was queued
Delete [newReview] could not execute directly and was queued
Delete [newPayment] could not execute directly and was queued
Delete [newSubscription] could not execute directly and was queued
Delete [newAppointment] could not execute directly and was queued
Did not find a running instance of elasticsearch at 192.168.0.1:9200
Did not find a running instance of elasticsearch at 10.0.0.1:9200
Did not find a running instance of elasticsearch at 127.0.0.1:9200
Did not find a running instance of elasticsearch at 172.16.0.1:9200
Did not find a running instance of elasticsearch at myserver:9200
Did not find a running instance of elasticsearch at dev-elastic-server:9200
Did not find a running instance of elasticsearch at prod-elastic-server:9200
Did not find a running instance of elasticsearch at staging-elastic-server:9200
Did not find a running instance of elasticsearch at test-elastic-server:9200
Did not find a running instance of elasticsearch at es1.example.com:9200
Did not find a running instance of elasticsearch at es2.example.com:9200
Did not find a running instance of elasticsearch at es3.example.com:9200
Did not find a running instance of elasticsearch at es4.example.com:9200
-> removing plugin2...
-> removing plugin3...
-> removing plugin4...
-> removing plugin5...
-> removing plugin6...
-> removing plugin7...
-> removing plugin8...
-> removing plugin9...
-> removing plugin10...
-> removing plugin11...
-> removing plugin12...
-> removing plugin13...
-> removing plugin14...
Successfully aborted snapshot [snapshot2]
Successfully aborted snapshot [snapshot3]
Successfully aborted snapshot [snapshot4]
Successfully aborted snapshot [snapshot5]
Successfully aborted snapshot [snapshot6]
Successfully aborted snapshot [snapshot7]
Successfully aborted snapshot [snapshot8]
Successfully aborted snapshot [snapshot9]
Successfully aborted snapshot [snapshot10]
Successfully aborted snapshot [snapshot11]
Successfully aborted snapshot [snapshot12]
Successfully aborted snapshot [snapshot13]
Successfully aborted snapshot [snapshot14]
Number of copies: 2
Number of copies: 3
Number of copies: 4
Number of copies: 5
Number of copies: 6
Number of copies: 7
Number of copies: 8
Number of copies: 9
Number of copies: 10
Number of copies: 11
Number of copies: 12
Number of copies: 13
Number of copies: 14
Number of nodes: 20
Number of nodes: 30
Number of nodes: 40
Number of nodes: 50
Number of nodes: 60
Number of nodes: 70
Number of nodes: 80
Number of nodes: 90
Number of nodes: 100
Number of nodes: 110
Number of nodes: 120
Number of nodes: 130
Number of nodes: 140
-> Downloading def-plugin from maven central
-> Downloading xyz-plugin from maven central
-> Downloading 123-plugin from maven central
-> Downloading 456-plugin from maven central
-> Downloading 789-plugin from maven central
-> Downloading foo-plugin from maven central
-> Downloading bar-plugin from maven central
-> Downloading baz-plugin from maven central
-> Downloading hello-plugin from maven central
-> Downloading world-plugin from maven central
-> Downloading awesome-plugin from maven central
-> Downloading cool-plugin from maven central
-> Downloading nice-plugin from maven central
Removing failed snapshot clone [snapshot2] from cluster state
Removing failed snapshot clone [snapshot3] from cluster state
Removing failed snapshot clone [snapshot4] from cluster state
Removing failed snapshot clone [snapshot5] from cluster state
Removing failed snapshot clone [snapshot6] from cluster state
Removing failed snapshot clone [snapshot7] from cluster state
Removing failed snapshot clone [snapshot8] from cluster state
Removing failed snapshot clone [snapshot9] from cluster state
Removing failed snapshot clone [snapshot10] from cluster state
Removing failed snapshot clone [snapshot11] from cluster state
Removing failed snapshot clone [snapshot12] from cluster state
Removing failed snapshot clone [snapshot13] from cluster state
Removing failed snapshot clone [snapshot14] from cluster state
-> Downloading security from opensearch
-> Downloading logstash from opensearch
-> Downloading kibana from opensearch
-> Downloading prometheus from opensearch
-> Downloading elasticsearch-hq from opensearch
-> Downloading grafana from opensearch
-> Downloading beats from opensearch
-> Downloading watcher from opensearch
-> Downloading curator from opensearch
-> Downloading logstash-input-jdbc from opensearch
-> Downloading opensearch-alerting from opensearch
-> Downloading opensearch-sql from opensearch
-> Downloading opensearch-dashboards from opensearch
-> Downloading opensearch-monitoring from opensearch
failed to notify callback NullPointerException
failed to notify callback ArrayIndexOutOfBoundsException
failed to notify callback IllegalArgumentException
failed to notify callback IllegalStateException
failed to notify callback IndexOutOfBoundsException
failed to notify callback ClassCastException
failed to notify callback ArithmeticException
failed to notify callback NoSuchElementException
failed to notify callback NumberFormatException
failed to notify callback OutOfMemoryError
failed to notify callback StackOverflowError
failed to notify callback AssertionError
failed to notify callback InterruptedException
-> Rolled back entry2
-> Rolled back entry3
-> Rolled back entry4
-> Rolled back entry5
-> Rolled back entry6
-> Rolled back entry7
-> Rolled back entry8
-> Rolled back entry9
-> Rolled back entry10
-> Rolled back entry11
-> Rolled back entry12
-> Rolled back entry13
-> Rolled back entry14
starting shard that we were waiting for [shard2] on node [node2]
starting shard that we were waiting for [shard3] on node [node3]
starting shard that we were waiting for [shard4] on node [node4]
starting shard that we were waiting for [shard5] on node [node5]
starting shard that we were waiting for [shard6] on node [node6]
starting shard that we were waiting for [shard7] on node [node7]
starting shard that we were waiting for [shard8] on node [node8]
starting shard that we were waiting for [shard9] on node [node9]
starting shard that we were waiting for [shard10] on node [node10]
starting shard that we were waiting for [shard11] on node [node11]
starting shard that we were waiting for [shard12] on node [node12]
starting shard that we were waiting for [shard13] on node [node13]
starting shard that we were waiting for [shard14] on node [node14]
failing snapshot of shard [2] on closed node [node2]
failing snapshot of shard [3] on closed node [node3]
failing snapshot of shard [4] on closed node [node4]
failing snapshot of shard [5] on closed node [node5]
failing snapshot of shard [6] on closed node [node6]
failing snapshot of shard [7] on closed node [node7]
failing snapshot of shard [8] on closed node [node8]
failing snapshot of shard [9] on closed node [node9]
failing snapshot of shard [10] on closed node [node10]
failing snapshot of shard [11] on closed node [node11]
failing snapshot of shard [12] on closed node [node12]
failing snapshot of shard [13] on closed node [node13]
failing snapshot of shard [14] on closed node [node14]
failed to write candidates FileNotFoundException
failed to write candidates NullPointerException
failed to write candidates IOException
failed to write candidates ArrayIndexOutOfBoundsException
failed to write candidates IllegalArgumentException
failed to write candidates NoSuchElementException
failed to write candidates NumberFormatException
failed to write candidates ClassCastException
failed to write candidates ConcurrentModificationException
failed to write candidates TimeoutException
failed to write candidates OutOfMemoryError
failed to write candidates StackOverflowError
failed to write candidates AssertionError
-> Failed rolling back entry2
-> Failed rolling back entry3
-> Failed rolling back entry4
-> Failed rolling back entry5
-> Failed rolling back entry6
-> Failed rolling back entry7
-> Failed rolling back entry8
-> Failed rolling back entry9
-> Failed rolling back entry10
-> Failed rolling back entry11
-> Failed rolling back entry12
-> Failed rolling back entry13
-> Failed rolling back entry14
removing not yet start clone operation [snapshot2]
removing not yet start clone operation [snapshot3]
removing not yet start clone operation [snapshot4]
removing not yet start clone operation [snapshot5]
removing not yet start clone operation [snapshot6]
removing not yet start clone operation [snapshot7]
removing not yet start clone operation [snapshot8]
removing not yet start clone operation [snapshot9]
removing not yet start clone operation [snapshot10]
removing not yet start clone operation [snapshot11]
removing not yet start clone operation [snapshot12]
removing not yet start clone operation [snapshot13]
removing not yet start clone operation [snapshot14]
-> Rolling back entry2
-> Rolling back entry3
-> Rolling back entry4
-> Rolling back entry5
-> Rolling back entry6
-> Rolling back entry7
-> Rolling back entry8
-> Rolling back entry9
-> Rolling back entry10
-> Rolling back entry11
-> Rolling back entry12
-> Rolling back entry13
-> Rolling back entry14
--> [node2] stepped down as cluster-manager
--> [node3] stepped down as cluster-manager
--> [node4] stepped down as cluster-manager
--> [node5] stepped down as cluster-manager
--> [node6] stepped down as cluster-manager
--> [node7] stepped down as cluster-manager
--> [node8] stepped down as cluster-manager
--> [node9] stepped down as cluster-manager
--> [node10] stepped down as cluster-manager
--> [node11] stepped down as cluster-manager
--> [node12] stepped down as cluster-manager
--> [node13] stepped down as cluster-manager
--> [node14] stepped down as cluster-manager
--> unfreezing node [node2]
--> unfreezing node [node3]
--> unfreezing node [node4]
--> unfreezing node [node5]
--> unfreezing node [node6]
--> unfreezing node [node7]
--> unfreezing node [node8]
--> unfreezing node [node9]
--> unfreezing node [node10]
--> unfreezing node [node11]
--> unfreezing node [node12]
--> unfreezing node [node13]
--> unfreezing node [node14]
Cluster state update after failed shard clone [2] failed
Cluster state update after failed shard clone [3] failed
Cluster state update after failed shard clone [4] failed
Cluster state update after failed shard clone [5] failed
Cluster state update after failed shard clone [6] failed
Cluster state update after failed shard clone [7] failed
Cluster state update after failed shard clone [8] failed
Cluster state update after failed shard clone [9] failed
Cluster state update after failed shard clone [10] failed
Cluster state update after failed shard clone [11] failed
Cluster state update after failed shard clone [12] failed
Cluster state update after failed shard clone [13] failed
Cluster state update after failed shard clone [14] failed
-> Installing pluginB
-> Installing pluginC
-> Installing pluginD
-> Installing pluginE
-> Installing pluginF
-> Installing pluginG
-> Installing pluginH
-> Installing pluginI
-> Installing pluginJ
-> Installing pluginK
-> Installing pluginL
-> Installing pluginM
-> Installing pluginN
--> new detected cluster-manager node [Node 2]
--> new detected cluster-manager node [Node 3]
--> new detected cluster-manager node [Node 4]
--> new detected cluster-manager node [Node 5]
--> new detected cluster-manager node [Node 6]
--> new detected cluster-manager node [Node 7]
--> new detected cluster-manager node [Node 8]
--> new detected cluster-manager node [Node 9]
--> new detected cluster-manager node [Node 10]
--> new detected cluster-manager node [Node 11]
--> new detected cluster-manager node [Node 12]
--> new detected cluster-manager node [Node 13]
--> new detected cluster-manager node [Node 14]
database_connector
logging_library
authentication_module
email_service
caching_framework
search_engine
messaging_system
payment_gateway
image_processing_tool
analytics_platform
queueing_system
reporting_tool
backup_service
--> freezing node [node2]
--> freezing node [node3]
--> freezing node [node4]
--> freezing node [node5]
--> freezing node [node6]
--> freezing node [node7]
--> freezing node [node8]
--> freezing node [node9]
--> freezing node [node10]
--> freezing node [node11]
--> freezing node [node12]
--> freezing node [node13]
--> freezing node [node14]
Could not register setting setting2
Could not register setting setting3
Could not register setting setting4
Could not register setting setting5
Could not register setting setting6
Could not register setting setting7
Could not register setting setting8
Could not register setting setting9
Could not register setting setting10
Could not register setting setting11
Could not register setting setting12
Could not register setting setting13
Could not register setting setting14
Marked [2] as failed clone from [snapshotC] to [snapshotD]
Marked [3] as failed clone from [snapshotE] to [snapshotF]
Marked [4] as failed clone from [snapshotG] to [snapshotH]
Marked [5] as failed clone from [snapshotI] to [snapshotJ]
Marked [6] as failed clone from [snapshotK] to [snapshotL]
Marked [7] as failed clone from [snapshotM] to [snapshotN]
Marked [8] as failed clone from [snapshotO] to [snapshotP]
Marked [9] as failed clone from [snapshotQ] to [snapshotR]
Marked [10] as failed clone from [snapshotS] to [snapshotT]
Marked [11] as failed clone from [snapshotU] to [snapshotV]
Marked [12] as failed clone from [snapshotW] to [snapshotX]
Marked [13] as failed clone from [snapshotY] to [snapshotZ]
Marked [14] as failed clone from [snapshotAA] to [snapshotBB]
Exception IOException while trying to clone shard 456
Exception OutOfMemoryError while trying to clone shard 789
Exception DatabaseException while trying to clone shard 012
Exception NetworkException while trying to clone shard 345
Exception FileNotFoundException while trying to clone shard 678
Exception InterruptedException while trying to clone shard 901
Exception InvalidInputException while trying to clone shard 234
Exception SecurityException while trying to clone shard 567
Exception AssertionError while trying to clone shard 890
Exception ClassCastException while trying to clone shard 123
Exception TimeoutException while trying to clone shard 456
Exception ArrayIndexOutOfBoundsException while trying to clone shard 789
Exception NullPointerException while trying to clone shard 012
--> isolating [NodeB]
--> isolating [NodeC]
--> isolating [NodeD]
--> isolating [NodeE]
--> isolating [NodeF]
--> isolating [NodeG]
--> isolating [NodeH]
--> isolating [NodeI]
--> isolating [NodeJ]
--> isolating [NodeK]
--> isolating [NodeL]
--> isolating [NodeM]
--> isolating [NodeN]
Created opensearch keystore in /usr/local/opensearch/config/keystore
Created opensearch keystore in /etc/opensearch/config/keystore
Created opensearch keystore in /opt/opensearch/config/keystore
Created opensearch keystore in /home/user/opensearch/config/keystore
Created opensearch keystore in /srv/opensearch/config/keystore
Created opensearch keystore in /var/lib/opensearch/config/keystore
Created opensearch keystore in /usr/share/opensearch/config/keystore
Created opensearch keystore in /etc/default/opensearch/config/keystore
Created opensearch keystore in /opt/local/opensearch/config/keystore
Created opensearch keystore in /home/opensearch/config/keystore
Created opensearch keystore in /srv/opensearch-sandbox/config/keystore
Created opensearch keystore in /var/config/keystore
Created opensearch keystore in /usr/local/share/opensearch/config/keystore
Setting [password] is insecure, but a secure variant [password_secure] is advised to be used instead
Setting [apiKey] is insecure, but a secure variant [apiKey_secure] is advised to be used instead
Setting [token] is insecure, but a secure variant [token_secure] is advised to be used instead
Setting [accessKey] is insecure, but a secure variant [accessKey_secure] is advised to be used instead
Setting [secretKey] is insecure, but a secure variant [secretKey_secure] is advised to be used instead
Setting [databaseUsername] is insecure, but a secure variant [databaseUsername_secure] is advised to be used instead
Setting [databasePassword] is insecure, but a secure variant [databasePassword_secure] is advised to be used instead
Setting [email] is insecure, but a secure variant [email_secure] is advised to be used instead
Setting [sessionKey] is insecure, but a secure variant [sessionKey_secure] is advised to be used instead
Setting [apiSecret] is insecure, but a secure variant [apiSecret_secure] is advised to be used instead
Setting [userPassword] is insecure, but a secure variant [userPassword_secure] is advised to be used instead
Setting [jwtSecret] is insecure, but a secure variant [jwtSecret_secure] is advised to be used instead
Setting [sslCertificate] is insecure, but a secure variant [sslCertificate_secure] is advised to be used instead
Setting [privateKey] is insecure, but a secure variant [privateKey_secure] is advised to be used instead
---> legit elected cluster-manager node=my-node-002
---> legit elected cluster-manager node=my-node-003
---> legit elected cluster-manager node=my-node-004
---> legit elected cluster-manager node=my-node-005
---> legit elected cluster-manager node=my-node-006
---> legit elected cluster-manager node=my-node-007
---> legit elected cluster-manager node=my-node-008
---> legit elected cluster-manager node=my-node-009
---> legit elected cluster-manager node=my-node-010
---> legit elected cluster-manager node=my-node-011
---> legit elected cluster-manager node=my-node-012
---> legit elected cluster-manager node=my-node-013
---> legit elected cluster-manager node=my-node-014
Marked repo2 as successfully cloned from snapshot3 to snapshot4
Marked repo3 as successfully cloned from snapshot5 to snapshot6
Marked repo4 as successfully cloned from snapshot7 to snapshot8
Marked repo5 as successfully cloned from snapshot9 to snapshot10
Marked repo6 as successfully cloned from snapshot11 to snapshot12
Marked repo7 as successfully cloned from snapshot13 to snapshot14
Marked repo8 as successfully cloned from snapshot15 to snapshot16
Marked repo9 as successfully cloned from snapshot17 to snapshot18
Marked repo10 as successfully cloned from snapshot19 to snapshot20
Marked repo11 as successfully cloned from snapshot21 to snapshot22
Marked repo12 as successfully cloned from snapshot23 to snapshot24
Marked repo13 as successfully cloned from snapshot25 to snapshot26
Marked repo14 as successfully cloned from snapshot27 to snapshot28
Failed to get index-metadata from repository data for index index2
Failed to get index-metadata from repository data for index index3
Failed to get index-metadata from repository data for index index4
Failed to get index-metadata from repository data for index index5
Failed to get index-metadata from repository data for index index6
Failed to get index-metadata from repository data for index index7
Failed to get index-metadata from repository data for index index8
Failed to get index-metadata from repository data for index index9
Failed to get index-metadata from repository data for index index10
Failed to get index-metadata from repository data for index index11
Failed to get index-metadata from repository data for index index12
Failed to get index-metadata from repository data for index index13
Failed to get index-metadata from repository data for index index14
sniffed nodes: node2
sniffed nodes: node3
sniffed nodes: node4
sniffed nodes: node5
sniffed nodes: node6
sniffed nodes: node7
sniffed nodes: node8
sniffed nodes: node9
sniffed nodes: node10
sniffed nodes: node11
sniffed nodes: node12
sniffed nodes: node13
sniffed nodes: node14
Failed to get repository data while cloning shard [shard-2] from [snapshot3] to [snapshot4]
Failed to get repository data while cloning shard [shard-3] from [snapshot5] to [snapshot6]
Failed to get repository data while cloning shard [shard-4] from [snapshot7] to [snapshot8]
Failed to get repository data while cloning shard [shard-5] from [snapshot9] to [snapshot10]
Failed to get repository data while cloning shard [shard-6] from [snapshot11] to [snapshot12]
Failed to get repository data while cloning shard [shard-7] from [snapshot13] to [snapshot14]
Failed to get repository data while cloning shard [shard-8] from [snapshot15] to [snapshot16]
Failed to get repository data while cloning shard [shard-9] from [snapshot17] to [snapshot18]
Failed to get repository data while cloning shard [shard-10] from [snapshot19] to [snapshot20]
Failed to get repository data while cloning shard [shard-11] from [snapshot21] to [snapshot22]
Failed to get repository data while cloning shard [shard-12] from [snapshot23] to [snapshot24]
Failed to get repository data while cloning shard [shard-13] from [snapshot25] to [snapshot26]
Failed to get repository data while cloning shard [shard-14] from [snapshot27] to [snapshot28]
error while sniffing nodes NullReferenceException
error while sniffing nodes IndexOutOfBoundsException
error while sniffing nodes IllegalArgumentException
error while sniffing nodes NoSuchElementException
error while sniffing nodes FileNotFoundException
error while sniffing nodes ClassCastException
error while sniffing nodes InterruptedException
error while sniffing nodes ArrayIndexOutOfBoundsException
error while sniffing nodes NullPointerException
error while sniffing nodes NumberFormatException
error while sniffing nodes SecurityException
error while sniffing nodes IllegalStateException
error while sniffing nodes UnsupportedOperationException
Did not find expected entry [abc] in the cluster state
Did not find expected entry [xyz] in the cluster state
Did not find expected entry [456] in the cluster state
Did not find expected entry [def] in the cluster state
Did not find expected entry [789] in the cluster state
Did not find expected entry [mno] in the cluster state
Did not find expected entry [987] in the cluster state
Did not find expected entry [pqr] in the cluster state
Did not find expected entry [stu] in the cluster state
Did not find expected entry [654] in the cluster state
Did not find expected entry [vwx] in the cluster state
Did not find expected entry [321] in the cluster state
Did not find expected entry [ghi] in the cluster state
snapshot clone backup2 started
snapshot clone backup3 started
snapshot clone backup4 started
snapshot clone backup5 started
snapshot clone backup6 started
snapshot clone backup7 started
snapshot clone backup8 started
snapshot clone backup9 started
snapshot clone backup10 started
snapshot clone backup11 started
snapshot clone backup12 started
snapshot clone backup13 started
snapshot clone backup14 started
no published hash for the consistent secure setting [setting2] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting3] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting4] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting5] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting6] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting7] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting8] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting9] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting10] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting11] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting12] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting13] but it also does NOT exist on the local node
no published hash for the consistent secure setting [setting14] but it also does NOT exist on the local node
snapshot [2021-01-02] started
snapshot [2021-01-03] started
snapshot [2021-01-04] started
snapshot [2021-01-05] started
snapshot [2021-01-06] started
snapshot [2021-01-07] started
snapshot [2021-01-08] started
snapshot [2021-01-09] started
snapshot [2021-01-10] started
snapshot [2021-01-11] started
snapshot [2021-01-12] started
snapshot [2021-01-13] started
snapshot [2021-01-14] started
no published hash for the consistent secure setting [setting2] but it exists on the local node
no published hash for the consistent secure setting [setting3] but it exists on the local node
no published hash for the consistent secure setting [setting4] but it exists on the local node
no published hash for the consistent secure setting [setting5] but it exists on the local node
no published hash for the consistent secure setting [setting6] but it exists on the local node
no published hash for the consistent secure setting [setting7] but it exists on the local node
no published hash for the consistent secure setting [setting8] but it exists on the local node
no published hash for the consistent secure setting [setting9] but it exists on the local node
no published hash for the consistent secure setting [setting10] but it exists on the local node
no published hash for the consistent secure setting [setting11] but it exists on the local node
no published hash for the consistent secure setting [setting12] but it exists on the local node
no published hash for the consistent secure setting [setting13] but it exists on the local node
no published hash for the consistent secure setting [setting14] but it exists on the local node
[FAILURE] [snapshot] updated snapshot state
[ERROR] [snapshot] updated snapshot state
[IN PROGRESS] [snapshot] updated snapshot state
[COMPLETE] [snapshot] updated snapshot state
[PENDING] [snapshot] updated snapshot state
[WARNING] [snapshot] updated snapshot state
[SKIPPED] [snapshot] updated snapshot state
[CANCELED] [snapshot] updated snapshot state
[PAUSED] [snapshot] updated snapshot state
[RESUMED] [snapshot] updated snapshot state
[READY] [snapshot] updated snapshot state
[PROCESSING] [snapshot] updated snapshot state
[IDLE] [snapshot] updated snapshot state
[STOPPED] [snapshot] updated snapshot state
--> using seed node address 10.0.0.1
--> using seed node address 172.16.0.1
--> using seed node address 192.168.0.123
--> using seed node address 10.1.1.1
--> using seed node address 172.16.1.1
--> using seed node address 192.168.2.1
--> using seed node address 10.0.1.1
--> using seed node address 172.16.2.1
--> using seed node address 192.168.1.100
--> using seed node address 10.5.5.5
--> using seed node address 172.16.3.1
--> using seed node address 192.168.3.1
--> using seed node address 10.0.2.1
Time taken (in milliseconds) to complete shallow copy snapshot, for index index2, shard 2 and snapshot 456 is 800
Time taken (in milliseconds) to complete shallow copy snapshot, for index index3, shard 3 and snapshot 789 is 600
Time taken (in milliseconds) to complete shallow copy snapshot, for index index4, shard 4 and snapshot 234 is 700
Time taken (in milliseconds) to complete shallow copy snapshot, for index index5, shard 5 and snapshot 567 is 900
Time taken (in milliseconds) to complete shallow copy snapshot, for index index6, shard 6 and snapshot 890 is 550
Time taken (in milliseconds) to complete shallow copy snapshot, for index index7, shard 7 and snapshot 321 is 750
Time taken (in milliseconds) to complete shallow copy snapshot, for index index8, shard 8 and snapshot 654 is 650
Time taken (in milliseconds) to complete shallow copy snapshot, for index index9, shard 9 and snapshot 987 is 450
Time taken (in milliseconds) to complete shallow copy snapshot, for index index10, shard 10 and snapshot 432 is 850
Time taken (in milliseconds) to complete shallow copy snapshot, for index index11, shard 11 and snapshot 765 is 550
Time taken (in milliseconds) to complete shallow copy snapshot, for index index12, shard 12 and snapshot 98 is 700
Time taken (in milliseconds) to complete shallow copy snapshot, for index index13, shard 13 and snapshot 876 is 750
Time taken (in milliseconds) to complete shallow copy snapshot, for index index14, shard 14 and snapshot 210 is 450
waiting for [node2] to have no cluster-manager
waiting for [node3] to have no cluster-manager
waiting for [node4] to have no cluster-manager
waiting for [node5] to have no cluster-manager
waiting for [node6] to have no cluster-manager
waiting for [node7] to have no cluster-manager
waiting for [node8] to have no cluster-manager
waiting for [node9] to have no cluster-manager
waiting for [node10] to have no cluster-manager
waiting for [node11] to have no cluster-manager
waiting for [node12] to have no cluster-manager
waiting for [node13] to have no cluster-manager
waiting for [node14] to have no cluster-manager
Shallow Copy Snapshot Failed for Shard [index_2][shard_2] for snapshot snapshot_2, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_3][shard_3] for snapshot snapshot_3, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_4][shard_4] for snapshot snapshot_4, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_5][shard_5] for snapshot snapshot_5, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_6][shard_6] for snapshot snapshot_6, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_7][shard_7] for snapshot snapshot_7, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_8][shard_8] for snapshot snapshot_8, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_9][shard_9] for snapshot snapshot_9, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_10][shard_10] for snapshot snapshot_10, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_11][shard_11] for snapshot snapshot_11, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_12][shard_12] for snapshot snapshot_12, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_13][shard_13] for snapshot snapshot_13, releasing acquired lock from remote store
Shallow Copy Snapshot Failed for Shard [index_14][shard_14] for snapshot snapshot_14, releasing acquired lock from remote store
adding node [456]
adding node [789]
adding node [987]
adding node [654]
adding node [321]
adding node [234]
adding node [567]
adding node [890]
adding node [012]
adding node [345]
adding node [678]
adding node [901]
adding node [210]
waiting for node2 to be removed from cluster
waiting for node3 to be removed from cluster
waiting for node4 to be removed from cluster
waiting for node5 to be removed from cluster
waiting for node6 to be removed from cluster
waiting for node7 to be removed from cluster
waiting for node8 to be removed from cluster
waiting for node9 to be removed from cluster
waiting for node10 to be removed from cluster
waiting for node11 to be removed from cluster
waiting for node12 to be removed from cluster
waiting for node13 to be removed from cluster
waiting for node14 to be removed from cluster
the consistent secure setting [21b7l38] does not exist on the local node but there is a published hash for it
the consistent secure setting [9c4e62d] does not exist on the local node but there is a published hash for it
the consistent secure setting [4b3g98d] does not exist on the local node but there is a published hash for it
the consistent secure setting [7k8u23t] does not exist on the local node but there is a published hash for it
the consistent secure setting [1a3r78z] does not exist on the local node but there is a published hash for it
the consistent secure setting [6v9n43q] does not exist on the local node but there is a published hash for it
the consistent secure setting [2x7y98h] does not exist on the local node but there is a published hash for it
the consistent secure setting [5m2k94b] does not exist on the local node but there is a published hash for it
the consistent secure setting [8d6b31j] does not exist on the local node but there is a published hash for it
the consistent secure setting [3z9p62x] does not exist on the local node but there is a published hash for it
the consistent secure setting [9l1c85d] does not exist on the local node but there is a published hash for it
the consistent secure setting [4t2v97g] does not exist on the local node but there is a published hash for it
the consistent secure setting [7h8r43y] does not exist on the local node but there is a published hash for it
blocking request from cluster-manager cluster2 to node2
blocking request from cluster-manager cluster3 to node3
blocking request from cluster-manager cluster4 to node4
blocking request from cluster-manager cluster5 to node5
blocking request from cluster-manager cluster6 to node6
blocking request from cluster-manager cluster7 to node7
blocking request from cluster-manager cluster8 to node8
blocking request from cluster-manager cluster9 to node9
blocking request from cluster-manager cluster10 to node10
blocking request from cluster-manager cluster11 to node11
blocking request from cluster-manager cluster12 to node12
blocking request from cluster-manager cluster13 to node13
blocking request from cluster-manager cluster14 to node14
[2] - Adding shard to the queue
[3] - Adding shard to the queue
[4] - Adding shard to the queue
[5] - Adding shard to the queue
[6] - Adding shard to the queue
[7] - Adding shard to the queue
[8] - Adding shard to the queue
[9] - Adding shard to the queue
[10] - Adding shard to the queue
[11] - Adding shard to the queue
[12] - Adding shard to the queue
[13] - Adding shard to the queue
[14] - Adding shard to the queue
Failed to update snapshot state Error_2
Failed to update snapshot state Error_3
Failed to update snapshot state Error_4
Failed to update snapshot state Error_5
Failed to update snapshot state Error_6
Failed to update snapshot state Error_7
Failed to update snapshot state Error_8
Failed to update snapshot state Error_9
Failed to update snapshot state Error_10
Failed to update snapshot state Error_11
Failed to update snapshot state Error_12
Failed to update snapshot state Error_13
Failed to update snapshot state Error_14
Failed to update restore state data
Failed to update restore state record
Failed to update restore state system
Failed to update restore state file
Failed to update restore state database
Failed to update restore state connection
Failed to update restore state cache
Failed to update restore state session
Failed to update restore state operation
Failed to update restore state configuration
Failed to update restore state log
Failed to update restore state table
Failed to update restore state index
no longer cluster-manager while processing restore state update [image.jpg]
no longer cluster-manager while processing restore state update [data.xml]
no longer cluster-manager while processing restore state update [config.properties]
no longer cluster-manager while processing restore state update [document.docx]
no longer cluster-manager while processing restore state update [backup.sql]
no longer cluster-manager while processing restore state update [video.mp4]
no longer cluster-manager while processing restore state update [log.txt]
no longer cluster-manager while processing restore state update [template.html]
no longer cluster-manager while processing restore state update [presentation.pptx]
no longer cluster-manager while processing restore state update [code.java]
no longer cluster-manager while processing restore state update [audio.mp3]
no longer cluster-manager while processing restore state update [spreadsheet.xlsx]
no longer cluster-manager while processing restore state update [picture.png]
allowing requests from non cluster-manager node2 to cluster-manager manager2, waiting for two join request
allowing requests from non cluster-manager node3 to cluster-manager manager3, waiting for two join request
allowing requests from non cluster-manager node4 to cluster-manager manager4, waiting for two join request
allowing requests from non cluster-manager node5 to cluster-manager manager5, waiting for two join request
allowing requests from non cluster-manager node6 to cluster-manager manager6, waiting for two join request
allowing requests from non cluster-manager node7 to cluster-manager manager7, waiting for two join request
allowing requests from non cluster-manager node8 to cluster-manager manager8, waiting for two join request
allowing requests from non cluster-manager node9 to cluster-manager manager9, waiting for two join request
allowing requests from non cluster-manager node10 to cluster-manager manager10, waiting for two join request
allowing requests from non cluster-manager node11 to cluster-manager manager11, waiting for two join request
allowing requests from non cluster-manager node12 to cluster-manager manager12, waiting for two join request
allowing requests from non cluster-manager node13 to cluster-manager manager13, waiting for two join request
allowing requests from non cluster-manager node14 to cluster-manager manager14, waiting for two join request
blocking cluster state publishing from cluster-manager [node3] to non cluster-manager [node4]
blocking cluster state publishing from cluster-manager [node5] to non cluster-manager [node6]
blocking cluster state publishing from cluster-manager [node7] to non cluster-manager [node8]
blocking cluster state publishing from cluster-manager [node9] to non cluster-manager [node10]
blocking cluster state publishing from cluster-manager [node11] to non cluster-manager [node12]
blocking cluster state publishing from cluster-manager [node13] to non cluster-manager [node14]
blocking cluster state publishing from cluster-manager [node15] to non cluster-manager [node16]
blocking cluster state publishing from cluster-manager [node17] to non cluster-manager [node18]
blocking cluster state publishing from cluster-manager [node19] to non cluster-manager [node20]
blocking cluster state publishing from cluster-manager [node21] to non cluster-manager [node22]
blocking cluster state publishing from cluster-manager [node23] to non cluster-manager [node24]
blocking cluster state publishing from cluster-manager [node25] to non cluster-manager [node26]
blocking cluster state publishing from cluster-manager [node27] to non cluster-manager [node28]
blocking requests from non cluster-manager node2 to cluster-manager manager2
blocking requests from non cluster-manager node3 to cluster-manager manager3
blocking requests from non cluster-manager node4 to cluster-manager manager4
blocking requests from non cluster-manager node5 to cluster-manager manager5
blocking requests from non cluster-manager node6 to cluster-manager manager6
blocking requests from non cluster-manager node7 to cluster-manager manager7
blocking requests from non cluster-manager node8 to cluster-manager manager8
blocking requests from non cluster-manager node9 to cluster-manager manager9
blocking requests from non cluster-manager node10 to cluster-manager manager10
blocking requests from non cluster-manager node11 to cluster-manager manager11
blocking requests from non cluster-manager node12 to cluster-manager manager12
blocking requests from non cluster-manager node13 to cluster-manager manager13
blocking requests from non cluster-manager node14 to cluster-manager manager14
skipping node node2 with http disabled
skipping node node3 with http disabled
skipping node node4 with http disabled
skipping node node5 with http disabled
skipping node node6 with http disabled
skipping node node7 with http disabled
skipping node node8 with http disabled
skipping node node9 with http disabled
skipping node node10 with http disabled
skipping node node11 with http disabled
skipping node node12 with http disabled
skipping node node13 with http disabled
skipping node node14 with http disabled
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node002)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node003)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node004)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node005)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node006)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node007)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node008)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node009)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node010)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node011)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node012)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node013)
wait until elected cluster-manager has been removed and a new 2 node cluster was from (via node014)
snapshot shard size for snapshot_002: 1856 bytes
snapshot shard size for snapshot_003: 2198 bytes
snapshot shard size for snapshot_004: 1667 bytes
snapshot shard size for snapshot_005: 1532 bytes
snapshot shard size for snapshot_006: 2015 bytes
snapshot shard size for snapshot_007: 1948 bytes
snapshot shard size for snapshot_008: 1573 bytes
snapshot shard size for snapshot_009: 2310 bytes
snapshot shard size for snapshot_010: 1756 bytes
snapshot shard size for snapshot_011: 1892 bytes
snapshot shard size for snapshot_012: 2067 bytes
snapshot shard size for snapshot_013: 1423 bytes
snapshot shard size for snapshot_014: 2256 bytes
the published hash c951fd12 of the consistent secure setting SHA-512 differs from the locally computed one 378fde65
the published hash b87d032a of the consistent secure setting RSA-2048 differs from the locally computed one a543ed78
the published hash 9a4cb1ef of the consistent secure setting PBKDF2 differs from the locally computed one f32de456
the published hash e673fa90 of the consistent secure setting HMAC-SHA256 differs from the locally computed one 4652de23
the published hash f8eecb65 of the consistent secure setting ECDSA differs from the locally computed one 987bdc21
the published hash 126ab04c of the consistent secure setting AES-128 differs from the locally computed one 857fca34
the published hash c938dce6 of the consistent secure setting Blowfish differs from the locally computed one 63b4de92
the published hash 789ed76b of the consistent secure setting SHA-256 differs from the locally computed one a875ec31
the published hash 1a9ce456 of the consistent secure setting RSA-4096 differs from the locally computed one 9bc7de54
the published hash bc6def32 of the consistent secure setting Serpent differs from the locally computed one 5476ca98
the published hash 873dcab4 of the consistent secure setting Whirlpool differs from the locally computed one 3219fe87
the published hash 2b3eac65 of the consistent secure setting SHA-1 differs from the locally computed one c76dfb23
the published hash 4f6ca832 of the consistent secure setting AES-192 differs from the locally computed one b575de14
waiting for isolated node [node-2] to have no cluster-manager
waiting for isolated node [node-3] to have no cluster-manager
waiting for isolated node [node-4] to have no cluster-manager
waiting for isolated node [node-5] to have no cluster-manager
waiting for isolated node [node-6] to have no cluster-manager
waiting for isolated node [node-7] to have no cluster-manager
waiting for isolated node [node-8] to have no cluster-manager
waiting for isolated node [node-9] to have no cluster-manager
waiting for isolated node [node-10] to have no cluster-manager
waiting for isolated node [node-11] to have no cluster-manager
waiting for isolated node [node-12] to have no cluster-manager
waiting for isolated node [node-13] to have no cluster-manager
waiting for isolated node [node-14] to have no cluster-manager
waiting for nodes to de-elect cluster-manager [node2]
waiting for nodes to de-elect cluster-manager [node3]
waiting for nodes to de-elect cluster-manager [node4]
waiting for nodes to de-elect cluster-manager [node5]
waiting for nodes to de-elect cluster-manager [node6]
waiting for nodes to de-elect cluster-manager [node7]
waiting for nodes to de-elect cluster-manager [node8]
waiting for nodes to de-elect cluster-manager [node9]
waiting for nodes to de-elect cluster-manager [node10]
waiting for nodes to de-elect cluster-manager [node11]
waiting for nodes to de-elect cluster-manager [node12]
waiting for nodes to de-elect cluster-manager [node13]
waiting for nodes to de-elect cluster-manager [node14]
Verifying if document exists after isolating node[Orange] via node[Banana]
Verifying if document exists after isolating node[Pineapple] via node[Grape]
Verifying if document exists after isolating node[Lemon] via node[Watermelon]
Verifying if document exists after isolating node[Mango] via node[Apple]
Verifying if document exists after isolating node[Banana] via node[Orange]
Verifying if document exists after isolating node[Grape] via node[Pineapple]
Verifying if document exists after isolating node[Watermelon] via node[Lemon]
Verifying if document exists after isolating node[Cherry] via node[Pear]
Verifying if document exists after isolating node[Pear] via node[Cherry]
Verifying if document exists after isolating node[Strawberry] via node[Kiwi]
Verifying if document exists after isolating node[Kiwi] via node[Strawberry]
Verifying if document exists after isolating node[Blueberry] via node[Blackberry]
Verifying if document exists after isolating node[Blackberry] via node[Blueberry]
Verifying if document exists via node[notIsolatedNode2]
Verifying if document exists via node[notIsolatedNode3]
Verifying if document exists via node[notIsolatedNode4]
Verifying if document exists via node[notIsolatedNode5]
Verifying if document exists via node[notIsolatedNode6]
Verifying if document exists via node[notIsolatedNode7]
Verifying if document exists via node[notIsolatedNode8]
Verifying if document exists via node[notIsolatedNode9]
Verifying if document exists via node[notIsolatedNode10]
Verifying if document exists via node[notIsolatedNode11]
Verifying if document exists via node[notIsolatedNode12]
Verifying if document exists via node[notIsolatedNode13]
Verifying if document exists via node[notIsolatedNode14]
done validating (iteration [2])
done validating (iteration [3])
done validating (iteration [4])
done validating (iteration [5])
done validating (iteration [6])
done validating (iteration [7])
done validating (iteration [8])
done validating (iteration [9])
done validating (iteration [10])
done validating (iteration [11])
done validating (iteration [12])
done validating (iteration [13])
done validating (iteration [14])
validating through node node2 ([15] acked docs)
validating through node node3 ([8] acked docs)
validating through node node4 ([21] acked docs)
validating through node node5 ([12] acked docs)
validating through node node6 ([7] acked docs)
validating through node node7 ([18] acked docs)
validating through node node8 ([9] acked docs)
validating through node node9 ([14] acked docs)
validating through node node10 ([11] acked docs)
validating through node node11 ([13] acked docs)
validating through node node12 ([17] acked docs)
validating through node node13 ([6] acked docs)
validating through node node14 ([19] acked docs)
indexing 2000 docs per indexer during partition
indexing 5000 docs per indexer during partition
indexing 10000 docs per indexer during partition
indexing 20000 docs per indexer during partition
indexing 50000 docs per indexer during partition
indexing 100000 docs per indexer during partition
indexing 200000 docs per indexer during partition
indexing 500000 docs per indexer during partition
indexing 1000000 docs per indexer during partition
indexing 5000000 docs per indexer during partition
indexing 10000000 docs per indexer during partition
indexing 20000000 docs per indexer during partition
indexing 50000000 docs per indexer during partition
starting disruptions & indexing (iteration [2])
starting disruptions & indexing (iteration [3])
starting disruptions & indexing (iteration [4])
starting disruptions & indexing (iteration [5])
starting disruptions & indexing (iteration [6])
starting disruptions & indexing (iteration [7])
starting disruptions & indexing (iteration [8])
starting disruptions & indexing (iteration [9])
starting disruptions & indexing (iteration [10])
starting disruptions & indexing (iteration [11])
starting disruptions & indexing (iteration [12])
starting disruptions & indexing (iteration [13])
starting disruptions & indexing (iteration [14])
failed to apply settings RuntimeException
failed to apply settings IOException
failed to apply settings NullPointerException
failed to apply settings IllegalArgumentException
failed to apply settings ArrayIndexOutOfBoundsException
failed to apply settings AssertionError
failed to apply settings NoSuchMethodError
failed to apply settings ClassCastException
failed to apply settings OutOfMemoryError
failed to apply settings StackOverflowError
failed to apply settings ArithmeticException
failed to apply settings IndexOutOfBoundsException
failed to apply settings NoClassDefFoundError
failed to apply settings UnsupportedOperationException
indexing 2000 docs per indexer before partition
indexing 3000 docs per indexer before partition
indexing 4000 docs per indexer before partition
indexing 5000 docs per indexer before partition
indexing 6000 docs per indexer before partition
indexing 7000 docs per indexer before partition
indexing 8000 docs per indexer before partition
indexing 9000 docs per indexer before partition
indexing 10000 docs per indexer before partition
indexing 11000 docs per indexer before partition
indexing 12000 docs per indexer before partition
indexing 13000 docs per indexer before partition
indexing 14000 docs per indexer before partition
[Thread-2] decreased counter : 2
[Thread-3] decreased counter : 1
[Thread-4] decreased counter : 3
[Thread-5] decreased counter : 0
[Thread-6] decreased counter : 2
[Thread-7] decreased counter : 1
[Thread-8] decreased counter : 4
[Thread-9] decreased counter : 1
[Thread-10] decreased counter : 3
[Thread-11] decreased counter : 0
[Thread-12] decreased counter : 2
[Thread-13] decreased counter : 3
[Thread-14] decreased counter : 1
[Thread-2] Acquired semaphore and it has 1 permits left
[Thread-3] Acquired semaphore and it has 2 permits left
[Thread-4] Acquired semaphore and it has 0 permits left
[Thread-5] Acquired semaphore and it has 3 permits left
[Thread-6] Acquired semaphore and it has 1 permits left
[Thread-7] Acquired semaphore and it has 2 permits left
[Thread-8] Acquired semaphore and it has 0 permits left
[Thread-9] Acquired semaphore and it has 3 permits left
[Thread-10] Acquired semaphore and it has 1 permits left
[Thread-11] Acquired semaphore and it has 2 permits left
[Thread-12] Acquired semaphore and it has 0 permits left
[Thread-13] Acquired semaphore and it has 3 permits left
[Thread-14] Acquired semaphore and it has 1 permits left
starting indexers using conflict mode aggressive
starting indexers using conflict mode normal
starting indexers using conflict mode strict
starting indexers using conflict mode custom
starting indexers using conflict mode automatic
starting indexers using conflict mode random
starting indexers using conflict mode selective
starting indexers using conflict mode sequential
starting indexers using conflict mode parallel
starting indexers using conflict mode conservative
starting indexers using conflict mode concurrent
starting indexers using conflict mode optimal
starting indexers using conflict mode balanced
starting indexers using conflict mode adaptable
disruption scheme [B] added
disruption scheme [C] added
disruption scheme [D] added
disruption scheme [E] added
disruption scheme [F] added
disruption scheme [G] added
disruption scheme [H] added
disruption scheme [I] added
disruption scheme [J] added
disruption scheme [K] added
disruption scheme [L] added
disruption scheme [M] added
disruption scheme [N] added
Error message: [IndexOutOfBoundsException]
Error message: [FileNotFoundException]
Error message: [NumberFormatException]
Error message: [ArrayIndexOutOfBoundsException]
Error message: [ClassCastException]
Error message: [NoSuchElementException]
Error message: [IllegalArgumentException]
Error message: [IllegalStateException]
Error message: [UnsupportedOperationException]
Error message: [ArithmeticException]
Error message: [NullPointerException]
Error message: [IndexOutOfBoundsException]
Error message: [FileNotFoundException]
fetching snapshot shard size for shard-2
fetching snapshot shard size for shard-3
fetching snapshot shard size for shard-4
fetching snapshot shard size for shard-5
fetching snapshot shard size for shard-6
fetching snapshot shard size for shard-7
fetching snapshot shard size for shard-8
fetching snapshot shard size for shard-9
fetching snapshot shard size for shard-10
fetching snapshot shard size for shard-11
fetching snapshot shard size for shard-12
fetching snapshot shard size for shard-13
fetching snapshot shard size for shard-14
Expected to find the rounding in 100 iterations but didn't for 1632470400000 using HOUR
Expected to find the rounding in 100 iterations but didn't for 1632556800000 using WEEK
Expected to find the rounding in 100 iterations but didn't for 1632643200000 using MINUTE
Expected to find the rounding in 100 iterations but didn't for 1632729600000 using SECOND
Expected to find the rounding in 100 iterations but didn't for 1632816000000 using MILLISECOND
Expected to find the rounding in 100 iterations but didn't for 1632902400000 using MONTH
Expected to find the rounding in 100 iterations but didn't for 1632988800000 using YEAR
Expected to find the rounding in 100 iterations but didn't for 1633075200000 using QUARTER
Expected to find the rounding in 100 iterations but didn't for 1633161600000 using HOUR
Expected to find the rounding in 100 iterations but didn't for 1633248000000 using WEEK
Expected to find the rounding in 100 iterations but didn't for 1633334400000 using MINUTE
Expected to find the rounding in 100 iterations but didn't for 1633420800000 using SECOND
Expected to find the rounding in 100 iterations but didn't for 1633507200000 using MILLISECOND
number of fields [5], estimated bytes [512]
number of fields [8], estimated bytes [256]
number of fields [3], estimated bytes [128]
number of fields [9], estimated bytes [2048]
number of fields [6], estimated bytes [1024]
number of fields [12], estimated bytes [512]
number of fields [7], estimated bytes [256]
number of fields [4], estimated bytes [128]
number of fields [11], estimated bytes [2048]
number of fields [2], estimated bytes [1024]
number of fields [14], estimated bytes [512]
number of fields [1], estimated bytes [256]
number of fields [15], estimated bytes [128]
Attempting to store [password]: [123456], then update to [654321]
Attempting to store [email]: [alice@example.com], then update to [bob@example.com]
Attempting to store [phone]: [123-456-7890], then update to [987-654-3210]
Attempting to store [address]: [123 Main St], then update to [456 Elm St]
Attempting to store [age]: [25], then update to [30]
Attempting to store [salary]: [$50,000], then update to [$60,000]
Attempting to store [position]: [Manager], then update to [Director]
Attempting to store [category]: [Electronics], then update to [Appliances]
Attempting to store [quantity]: [10], then update to [5]
Attempting to store [color]: [Blue], then update to [Red]
Attempting to store [weight]: [1.5 kg], then update to [2 kg]
Attempting to store [height]: [180 cm], then update to [185 cm]
Attempting to store [temperature]: [25C], then update to [30C]
reroute after snapshot shard size update failed IndexOutOfBoundsException
reroute after snapshot shard size update failed NullPointerException
reroute after snapshot shard size update failed IllegalArgumentException
reroute after snapshot shard size update failed FileNotFoundException
reroute after snapshot shard size update failed SecurityException
reroute after snapshot shard size update failed ArithmeticException
reroute after snapshot shard size update failed ArrayIndexOutOfBoundsException
reroute after snapshot shard size update failed ClassCastException
reroute after snapshot shard size update failed NoSuchElementException
reroute after snapshot shard size update failed NumberFormatException
reroute after snapshot shard size update failed NullPointerException
reroute after snapshot shard size update failed AssertionError
reroute after snapshot shard size update failed IllegalStateException
expected allocation ids: ghi789 actual allocation ids: jkl012
expected allocation ids: mno345 actual allocation ids: pqr678
expected allocation ids: stu901 actual allocation ids: vwx234
expected allocation ids: yz567 actual allocation ids: abc890
expected allocation ids: def123 actual allocation ids: ghi456
expected allocation ids: jkl789 actual allocation ids: mno012
expected allocation ids: pqr345 actual allocation ids: stu678
expected allocation ids: vwx901 actual allocation ids: yz234
expected allocation ids: abc567 actual allocation ids: def890
expected allocation ids: ghi123 actual allocation ids: jkl456
expected allocation ids: mno789 actual allocation ids: pqr012
expected allocation ids: stu345 actual allocation ids: vwx678
expected allocation ids: yz901 actual allocation ids: abc234
--> adding allocation command for shard 1
--> adding allocation command for shard 2
--> adding allocation command for shard 3
--> adding allocation command for shard 4
--> adding allocation command for shard 5
--> adding allocation command for shard 6
--> adding allocation command for shard 7
--> adding allocation command for shard 8
--> adding allocation command for shard 9
--> adding allocation command for shard 10
--> adding allocation command for shard 11
--> adding allocation command for shard 12
--> adding allocation command for shard 13
freeing search context [98275]
freeing search context [12467]
freeing search context [67591]
freeing search context [30987]
freeing search context [87652]
freeing search context [12897]
freeing search context [76541]
freeing search context [42568]
freeing search context [78321]
freeing search context [98763]
freeing search context [54379]
freeing search context [34276]
freeing search context [92784]
freeing search context [14308]
Bulk [5678] executed with failures
Bulk [9012] executed with failures
Bulk [3456] executed with failures
Bulk [7890] executed with failures
Bulk [2345] executed with failures
Bulk [6789] executed with failures
Bulk [0123] executed with failures
Bulk [4567] executed with failures
Bulk [8901] executed with failures
Bulk [1231] executed with failures
Bulk [2312] executed with failures
Bulk [3123] executed with failures
Bulk [1212] executed with failures
Bulk [2323] executed with failures
--> asserting primary terms terms on node2
--> asserting primary terms terms on node3
--> asserting primary terms terms on node4
--> asserting primary terms terms on node5
--> asserting primary terms terms on node6
--> asserting primary terms terms on node7
--> asserting primary terms terms on node8
--> asserting primary terms terms on node9
--> asserting primary terms terms on node10
--> asserting primary terms terms on node11
--> asserting primary terms terms on node12
--> asserting primary terms terms on node13
--> asserting primary terms terms on node14
--> failing primary of shard2 on node node1
--> failing primary of shard3 on node node3
--> failing primary of shard4 on node node2
--> failing primary of shard5 on node node1
--> failing primary of shard6 on node node3
--> failing primary of shard7 on node node2
--> failing primary of shard8 on node node1
--> failing primary of shard9 on node node3
--> failing primary of shard10 on node node2
--> failing primary of shard11 on node node1
--> failing primary of shard12 on node node3
--> failing primary of shard13 on node node2
--> failing primary of shard14 on node node1
----> node node2 has 3 shards
----> node node3 has 8 shards
----> node node4 has 6 shards
----> node node5 has 2 shards
----> node node6 has 4 shards
----> node node7 has 9 shards
----> node node8 has 1 shards
----> node node9 has 7 shards
----> node node10 has 10 shards
----> node node11 has 5 shards
----> node node12 has 3 shards
----> node node13 has 8 shards
----> node node14 has 6 shards
--> waiting for shards to relocate off path [path2]
--> waiting for shards to relocate off path [path3]
--> waiting for shards to relocate off path [path4]
--> waiting for shards to relocate off path [path5]
--> waiting for shards to relocate off path [path6]
--> waiting for shards to relocate off path [path7]
--> waiting for shards to relocate off path [path8]
--> waiting for shards to relocate off path [path9]
--> waiting for shards to relocate off path [path10]
--> waiting for shards to relocate off path [path11]
--> waiting for shards to relocate off path [path12]
--> waiting for shards to relocate off path [path13]
--> waiting for shards to relocate off path [path14]
--> shards on good path: [shard2]
--> shards on good path: [shard3]
--> shards on good path: [shard4]
--> shards on good path: [shard5]
--> shards on good path: [shard6]
--> shards on good path: [shard7]
--> shards on good path: [shard8]
--> shards on good path: [shard9]
--> shards on good path: [shard10]
--> shards on good path: [shard11]
--> shards on good path: [shard12]
--> shards on good path: [shard13]
--> shards on good path: [shard14]
unable to gather network information: TimeoutException
unable to gather network information: ConnectionException
unable to gather network information: SocketException
unable to gather network information: UnknownHostException
unable to gather network information: SSLHandshakeException
unable to gather network information: ServerException
unable to gather network information: DNSException
unable to gather network information: AuthenticationException
unable to gather network information: ProxyException
unable to gather network information: FirewallException
unable to gather network information: ConfigurationException
unable to gather network information: ResourceException
unable to gather network information: PermissionException
unable to gather network information: DataFormatException
Bulk [f9d6d203-6cdd-452f-8f0a-a104e9dc2888] completed in 187 milliseconds
Bulk [eb182184-8c69-4f2b-b263-2eef0fb43e0f] completed in 312 milliseconds
Bulk [85677c0a-d673-4cd1-95fc-351164906f81] completed in 482 milliseconds
Bulk [ad138cca-e73f-4728-9a6c-645cea08ed7b] completed in 391 milliseconds
Bulk [4e0a69b7-0bca-4e8b-81cc-df767297b165] completed in 670 milliseconds
Bulk [c3093ca6-9a1b-4470-a5d0-41eae6bd781d] completed in 815 milliseconds
Bulk [68f7f4ee-f9c5-4a3b-b7a1-dce98dd9e14d] completed in 539 milliseconds
Bulk [5780b67f-e9e4-4b97-940a-d9ae7e41f93c] completed in 267 milliseconds
Bulk [996c09e2-8e26-4cef-b6bb-030493ec8a8d] completed in 389 milliseconds
Bulk [5ffcc0e0-0a23-42fe-b418-856c4f6ce7f4] completed in 577 milliseconds
Bulk [63501228-515e-4d2d-9116-1b8b9d6e4e29] completed in 156 milliseconds
Bulk [1e462c90-09c6-4df2-b53a-1d90784c2d9c] completed in 698 milliseconds
Bulk [340d7ac0-fb5b-4e9c-a0e8-dbf7e635381b] completed in 415 milliseconds
unexpected FileNotFoundException
unexpected NullPointerException
unexpected IOException
unexpected IllegalArgumentException
unexpected ArrayIndexOutOfBoundsException
unexpected NoSuchElementException
unexpected UnsupportedOperationException
unexpected ClassCastException
unexpected InterruptedException
unexpected ArithmeticException
unexpected SecurityException
unexpected ClassNotFoundException
unexpected IndexOutOfBoundsException
Cluster state: ACTIVE
Cluster state: INACTIVE
Cluster state: ERROR
Cluster state: RECOVERING
Cluster state: STANDBY
Cluster state: MAINTENANCE
Cluster state: INITIALIZING
Cluster state: RESIZING
Cluster state: UPDATING
Cluster state: DELETING
Cluster state: READY
Cluster state: RUNNING
Cluster state: PAUSED
Cluster state: STOPPED
Executing bulk def456 with 100 requests
Executing bulk ghi789 with 150 requests
Executing bulk jkl012 with 200 requests
Executing bulk mno345 with 250 requests
Executing bulk pqr678 with 300 requests
Executing bulk stu901 with 350 requests
Executing bulk vwx234 with 400 requests
Executing bulk yza567 with 450 requests
Executing bulk bcd890 with 500 requests
Executing bulk efg123 with 550 requests
Executing bulk hij456 with 600 requests
Executing bulk klm789 with 650 requests
Executing bulk nop012 with 700 requests
Fetch phase failed NullPointerException
Fetch phase failed ArrayIndexOutOfBoundsException
Fetch phase failed IllegalArgumentException
Fetch phase failed FileNotFoundException
Fetch phase failed ClassCastException
Fetch phase failed NoSuchElementException
Fetch phase failed ArithmeticException
Fetch phase failed OutOfMemoryError
Fetch phase failed StackOverflowError
Fetch phase failed InterruptedException
Fetch phase failed UnsupportedOperationException
Fetch phase failed AssertionError
Fetch phase failed ConcurrentModificationException
ERROR authentication: Invalid credentials
INFO database: Connection closed
WARN security: Access denied
FATAL storage: Disk failure
DEBUG cache: Cache miss
ERROR calculation: Division by zero
FATAL server: Server crash
INFO application: Application started
WARN validation: Input validation failed
DEBUG algorithm: Algorithm execution started
ERROR network: Connection timeout
INFO database: Query executed
FATAL security: Security breach
the template dummy setting was updated to 10
the template dummy setting was updated to 15
the template dummy setting was updated to 20
the template dummy setting was updated to 25
the template dummy setting was updated to 30
the template dummy setting was updated to 35
the template dummy setting was updated to 40
the template dummy setting was updated to 45
the template dummy setting was updated to 50
the template dummy setting was updated to 55
the template dummy setting was updated to 60
the template dummy setting was updated to 65
the template dummy setting was updated to 70
--> excluding cluster-manager node originalClusterManager2
--> excluding cluster-manager node originalClusterManager3
--> excluding cluster-manager node originalClusterManager4
--> excluding cluster-manager node originalClusterManager5
--> excluding cluster-manager node originalClusterManager6
--> excluding cluster-manager node originalClusterManager7
--> excluding cluster-manager node originalClusterManager8
--> excluding cluster-manager node originalClusterManager9
--> excluding cluster-manager node originalClusterManager10
--> excluding cluster-manager node originalClusterManager11
--> excluding cluster-manager node originalClusterManager12
--> excluding cluster-manager node originalClusterManager13
--> excluding cluster-manager node originalClusterManager14
Received cluster state update. Setting nodeId=[node2] and clusterUuid=[67890]
Received cluster state update. Setting nodeId=[node3] and clusterUuid=[ABCDE]
Received cluster state update. Setting nodeId=[node4] and clusterUuid=[FGHIJ]
Received cluster state update. Setting nodeId=[node5] and clusterUuid=[KLMNO]
Received cluster state update. Setting nodeId=[node6] and clusterUuid=[PQRST]
Received cluster state update. Setting nodeId=[node7] and clusterUuid=[UVWXY]
Received cluster state update. Setting nodeId=[node8] and clusterUuid=[Z1234]
Received cluster state update. Setting nodeId=[node9] and clusterUuid=[56789]
Received cluster state update. Setting nodeId=[node10] and clusterUuid=[ABCDE]
Received cluster state update. Setting nodeId=[node11] and clusterUuid=[FGHIJ]
Received cluster state update. Setting nodeId=[node12] and clusterUuid=[KLMNO]
Received cluster state update. Setting nodeId=[node13] and clusterUuid=[PQRST]
Received cluster state update. Setting nodeId=[node14] and clusterUuid=[UVWXY]
Dfs phase failed: ArrayIndexOutOfBoundsException
Dfs phase failed: IOException
Dfs phase failed: IllegalArgumentException
Dfs phase failed: NoSuchMethodException
Dfs phase failed: ClassCastException
Dfs phase failed: IndexOutOfBoundsException
Dfs phase failed: FileNotFoundException
Dfs phase failed: UnsupportedOperationException
Dfs phase failed: ArithmeticException
Dfs phase failed: SecurityException
Dfs phase failed: NoSuchElementException
Dfs phase failed: NullPointerException
Dfs phase failed: ArrayIndexOutOfBoundsException
--> original cluster manager - name ClusterB, zone Zone2
--> original cluster manager - name ClusterC, zone Zone3
--> original cluster manager - name ClusterD, zone Zone4
--> original cluster manager - name ClusterE, zone Zone5
--> original cluster manager - name ClusterF, zone Zone6
--> original cluster manager - name ClusterG, zone Zone7
--> original cluster manager - name ClusterH, zone Zone8
--> original cluster manager - name ClusterI, zone Zone9
--> original cluster manager - name ClusterJ, zone Zone10
--> original cluster manager - name ClusterK, zone Zone11
--> original cluster manager - name ClusterL, zone Zone12
--> original cluster manager - name ClusterM, zone Zone13
--> original cluster manager - name ClusterN, zone Zone14
--> starting decommissioning nodes in zone 'b'
--> starting decommissioning nodes in zone 'c'
--> starting decommissioning nodes in zone 'd'
--> starting decommissioning nodes in zone 'e'
--> starting decommissioning nodes in zone 'f'
--> starting decommissioning nodes in zone 'g'
--> starting decommissioning nodes in zone 'h'
--> starting decommissioning nodes in zone 'i'
--> starting decommissioning nodes in zone 'j'
--> starting decommissioning nodes in zone 'k'
--> starting decommissioning nodes in zone 'l'
--> starting decommissioning nodes in zone 'm'
--> starting decommissioning nodes in zone 'n'
--> starting decommissioning nodes in zone 'o'
Final cluster state:[Cluster is undergoing rebalancing]
Final cluster state:[Cluster has lost a node]
Final cluster state:[Cluster is at full capacity]
Final cluster state:[Cluster is experiencing high traffic]
Final cluster state:[Cluster is performing maintenance]
Final cluster state:[Cluster is recovering from a failure]
Final cluster state:[Cluster is scaling up]
Final cluster state:[Cluster is scaling down]
Final cluster state:[Cluster is initializing]
Final cluster state:[Cluster is being upgraded]
Final cluster state:[Cluster is in read-only mode]
Final cluster state:[Cluster is quiescing]
Final cluster state:[Cluster is starting up]
Hole intersections (3): [4, 5, 6]
Hole intersections (7): [8, 9, 10]
Hole intersections (12): [13, 14, 15]
Hole intersections (16): [17, 18, 19]
Hole intersections (21): [22, 23, 24]
Hole intersections (25): [26, 27, 28]
Hole intersections (30): [31, 32, 33]
Hole intersections (34): [35, 36, 37]
Hole intersections (39): [40, 41, 42]
Hole intersections (43): [44, 45, 46]
Hole intersections (48): [49, 50, 51]
Hole intersections (52): [53, 54, 55]
Hole intersections (57): [58, 59, 60]
Using concurrent aggregation processor over segments (experimental) for request with context id 5678
Using concurrent aggregation processor over segments (experimental) for request with context id 9012
Using concurrent aggregation processor over segments (experimental) for request with context id 3456
Using concurrent aggregation processor over segments (experimental) for request with context id 7890
Using concurrent aggregation processor over segments (experimental) for request with context id 2345
Using concurrent aggregation processor over segments (experimental) for request with context id 6789
Using concurrent aggregation processor over segments (experimental) for request with context id 0123
Using concurrent aggregation processor over segments (experimental) for request with context id 4567
Using concurrent aggregation processor over segments (experimental) for request with context id 8901
Using concurrent aggregation processor over segments (experimental) for request with context id 5432
Using concurrent aggregation processor over segments (experimental) for request with context id 9876
Using concurrent aggregation processor over segments (experimental) for request with context id 3210
Using concurrent aggregation processor over segments (experimental) for request with context id 7654
dropping [update] to [node2]
dropping [refresh] to [node3]
dropping [copy] to [node4]
dropping [rename] to [node5]
dropping [insert] to [node6]
dropping [truncate] to [node7]
dropping [upload] to [node8]
dropping [download] to [node9]
dropping [archive] to [node10]
dropping [merge] to [node11]
dropping [backup] to [node12]
dropping [restore] to [node13]
dropping [compress] to [node14]
--> shard size: 50
--> shard size: 100
--> shard size: 200
--> shard size: 500
--> shard size: 1000
--> shard size: 2000
--> shard size: 5000
--> shard size: 10000
--> shard size: 20000
--> shard size: 50000
--> shard size: 100000
--> shard size: 200000
--> shard size: 500000
--> shard on node2 - shard2
--> shard on node3 - shard3
--> shard on node4 - shard4
--> shard on node5 - shard5
--> shard on node6 - shard6
--> shard on node7 - shard7
--> shard on node8 - shard8
--> shard on node9 - shard9
--> shard on node10 - shard10
--> shard on node11 - shard11
--> shard on node12 - shard12
--> shard on node13 - shard13
--> shard on node14 - shard14
Component: Memory
Component: Hard Drive
Component: Motherboard
Component: Graphics Card
Component: Power Supply
Component: Network Card
Component: Cooling System
Component: Sound Card
Component: Optical Drive
Component: Keyboard
Component: Mouse
Component: Monitor
Component: Speaker
Component: USB Drive
Using non-concurrent aggregation processor over segments for request with context id 67890
Using non-concurrent aggregation processor over segments for request with context id 24680
Using non-concurrent aggregation processor over segments for request with context id 13579
Using non-concurrent aggregation processor over segments for request with context id 98765
Using non-concurrent aggregation processor over segments for request with context id 43210
Using non-concurrent aggregation processor over segments for request with context id 56789
Using non-concurrent aggregation processor over segments for request with context id 10203
Using non-concurrent aggregation processor over segments for request with context id 34567
Using non-concurrent aggregation processor over segments for request with context id 89123
Using non-concurrent aggregation processor over segments for request with context id 45678
Using non-concurrent aggregation processor over segments for request with context id 29784
Using non-concurrent aggregation processor over segments for request with context id 64985
Using non-concurrent aggregation processor over segments for request with context id 18274
checking warningOption=strict and warnings=5
checking warningOption=none and warnings=0
checking warningOption=default and warnings=3
checking warningOption=quiet and warnings=1
checking warningOption=max and warnings=7
checking warningOption=low and warnings=2
checking warningOption=medium and warnings=4
checking warningOption=high and warnings=6
checking warningOption=off and warnings=0
checking warningOption=all and warnings=9
checking warningOption=limited and warnings=1
checking warningOption=essential and warnings=2
checking warningOption=custom and warnings=8
--> exclude: [node2, node3], include: [node4]
--> exclude: [node5, node6, node7], include: [node8, node9]
--> exclude: [node10, node11, node12, node13], include: [node14, node15, node16]
--> exclude: [node17, node18, node19, node20, node21], include: [node22, node23, node24, node25]
--> exclude: [node26, node27, node28, node29, node30, node31], include: [node32, node33, node34, node35, node36]
--> exclude: [node37, node38, node39, node40, node41, node42, node43], include: [node44, node45, node46, node47, node48, node49]
--> exclude: [node50, node51, node52, node53, node54, node55, node56, node57], include: [node58, node59, node60, node61, node62, node63, node64]
--> exclude: [node65, node66, node67, node68, node69, node70, node71, node72, node73], include: [node74, node75, node76, node77, node78, node79, node80, node81]
--> exclude: [node82, node83, node84, node85, node86, node87, node88, node89, node90, node91], include: [node92, node93, node94, node95, node96, node97, node98, node99, node100]
updated [server] already in denylist
updated [database] already in denylist
updated [user] already in denylist
updated [file] already in denylist
updated [application] already in denylist
updated [service] already in denylist
updated [config] already in denylist
updated [plugin] already in denylist
updated [endpoint] already in denylist
updated [gateway] already in denylist
updated [protocol] already in denylist
updated [resource] already in denylist
updated [connection] already in denylist
updated [interface] already in denylist
Using concurrent search over segments (experimental) for request with context id DEF456
Using concurrent search over segments (experimental) for request with context id GHI789
Using concurrent search over segments (experimental) for request with context id JKL012
Using concurrent search over segments (experimental) for request with context id MNO345
Using concurrent search over segments (experimental) for request with context id PQR678
Using concurrent search over segments (experimental) for request with context id STU901
Using concurrent search over segments (experimental) for request with context id VWX234
Using concurrent search over segments (experimental) for request with context id YZA567
Using concurrent search over segments (experimental) for request with context id BCD890
Using concurrent search over segments (experimental) for request with context id EFG123
Using concurrent search over segments (experimental) for request with context id HIJ456
Using concurrent search over segments (experimental) for request with context id KLM789
Using concurrent search over segments (experimental) for request with context id NOP012
added [user] to denylist
added [IP] to denylist
added [domain] to denylist
added [address] to denylist
added [file] to denylist
added [system] to denylist
added [server] to denylist
added [endpoint] to denylist
added [URL] to denylist
added [database] to denylist
added [client] to denylist
added [request] to denylist
added [resource] to denylist
added [config] to denylist
Using non-concurrent search over segments for request with context id 456
Using non-concurrent search over segments for request with context id 789
Using non-concurrent search over segments for request with context id 012
Using non-concurrent search over segments for request with context id 345
Using non-concurrent search over segments for request with context id 678
Using non-concurrent search over segments for request with context id 901
Using non-concurrent search over segments for request with context id 234
Using non-concurrent search over segments for request with context id 567
Using non-concurrent search over segments for request with context id 890
Using non-concurrent search over segments for request with context id 123
Using non-concurrent search over segments for request with context id 456
Using non-concurrent search over segments for request with context id 789
Using non-concurrent search over segments for request with context id 012
failed to update search pipelines: ConnectionTimeoutException
failed to update search pipelines: ParseException
failed to update search pipelines: AuthenticationException
failed to update search pipelines: ResourceNotFoundException
failed to update search pipelines: IllegalOperationException
failed to update search pipelines: IndexOutOfBoundsException
failed to update search pipelines: TimeoutException
failed to update search pipelines: IOException
failed to update search pipelines: InvalidParameterException
failed to update search pipelines: UnsupportedOperationException
failed to update search pipelines: ServiceUnavailableException
failed to update search pipelines: AuthorizationException
failed to update search pipelines: QueryTimeoutException
failed to update search pipelines: DuplicateKeyException
removed [node2] from denylist
removed [node3] from denylist
removed [node4] from denylist
removed [node5] from denylist
removed [node6] from denylist
removed [node7] from denylist
removed [node8] from denylist
removed [node9] from denylist
removed [node10] from denylist
removed [node11] from denylist
removed [node12] from denylist
removed [node13] from denylist
removed [node14] from denylist
Holes: [4, 5, 6]
Holes: [7, 8, 9]
Holes: [10, 11, 12]
Holes: [13, 14, 15]
Holes: [16, 17, 18]
Holes: [19, 20, 21]
Holes: [22, 23, 24]
Holes: [25, 26, 27]
Holes: [28, 29, 30]
Holes: [31, 32, 33]
Holes: [34, 35, 36]
Holes: [37, 38, 39]
Holes: [40, 41, 42]
Arrays.toString(result[0][1])
Arrays.toString(result[0][2])
Arrays.toString(result[0][3])
Arrays.toString(result[0][4])
Arrays.toString(result[1][0])
Arrays.toString(result[1][1])
Arrays.toString(result[1][2])
Arrays.toString(result[1][3])
Arrays.toString(result[1][4])
Arrays.toString(result[2][0])
Arrays.toString(result[2][1])
Arrays.toString(result[2][2])
Arrays.toString(result[2][3])
shift: [5]
shift: [2]
shift: [-1]
shift: [4]
shift: [0]
shift: [6]
shift: [-3]
shift: [1]
shift: [-2]
shift: [7]
shift: [-5]
shift: [9]
shift: [-4]
error while reading response for trace purposes IOException
error while reading response for trace purposes NullPointerException
error while reading response for trace purposes TimeoutException
error while reading response for trace purposes ParseException
error while reading response for trace purposes IndexOutOfBoundsException
error while reading response for trace purposes IllegalArgumentException
error while reading response for trace purposes FileNotFoundException
error while reading response for trace purposes ArithmeticException
error while reading response for trace purposes NoSuchElementException
error while reading response for trace purposes OutOfMemoryError
error while reading response for trace purposes ArrayIndexOutOfBoundsException
error while reading response for trace purposes ClassCastException
error while reading response for trace purposes SecurityException
error while reading response for trace purposes NullPointerException
Slice count using lucene default [8]
Slice count using lucene default [16]
Slice count using lucene default [32]
Slice count using lucene default [64]
Slice count using lucene default [128]
Slice count using lucene default [256]
Slice count using lucene default [512]
Slice count using lucene default [1024]
Slice count using lucene default [2048]
Slice count using lucene default [4096]
Slice count using lucene default [8192]
Slice count using lucene default [16384]
Slice count using lucene default [32768]
error while reading request for trace purposes IOException
error while reading request for trace purposes NullPointerException
error while reading request for trace purposes ArrayIndexOutOfBoundsException
error while reading request for trace purposes IllegalArgumentException
error while reading request for trace purposes RuntimeException
error while reading request for trace purposes FileNotFoundException
error while reading request for trace purposes NoSuchElementException
error while reading request for trace purposes SocketTimeoutException
error while reading request for trace purposes ClassCastException
error while reading request for trace purposes NullPointerException
error while reading request for trace purposes ArrayIndexOutOfBoundsException
error while reading request for trace purposes NumberFormatException
error while reading request for trace purposes IndexOutOfBoundsException
Slice count using max target slice supplier [7]
Slice count using max target slice supplier [14]
Slice count using max target slice supplier [5]
Slice count using max target slice supplier [9]
Slice count using max target slice supplier [12]
Slice count using max target slice supplier [8]
Slice count using max target slice supplier [11]
Slice count using max target slice supplier [6]
Slice count using max target slice supplier [13]
Slice count using max target slice supplier [4]
Slice count using max target slice supplier [15]
Slice count using max target slice supplier [3]
Slice count using max target slice supplier [16]
Unable to detect content encoding: IOException
Unable to detect content encoding: MalformedURLException
Unable to detect content encoding: UnsupportedEncodingException
Unable to detect content encoding: UnknownHostException
Unable to detect content encoding: ConnectException
Unable to detect content encoding: SocketTimeoutException
Unable to detect content encoding: SSLHandshakeException
Unable to detect content encoding: FileNotFoundException
Unable to detect content encoding: NullPointerException
Unable to detect content encoding: ParseException
Unable to detect content encoding: ArrayIndexOutOfBoundsException
Unable to detect content encoding: IllegalArgumentException
Unable to detect content encoding: ClassCastException
heap usage not dominated by search requests [40%/80%]
heap usage not dominated by search requests [75%/80%]
heap usage not dominated by search requests [55%/80%]
heap usage not dominated by search requests [70%/80%]
heap usage not dominated by search requests [45%/80%]
heap usage not dominated by search requests [65%/80%]
heap usage not dominated by search requests [50%/80%]
heap usage not dominated by search requests [35%/80%]
heap usage not dominated by search requests [68%/80%]
heap usage not dominated by search requests [57%/80%]
heap usage not dominated by search requests [42%/80%]
heap usage not dominated by search requests [32%/80%]
heap usage not dominated by search requests [73%/80%]
Error while executing bulk request IOException
Error while executing bulk request NullPointerException
Error while executing bulk request ArrayIndexOutOfBoundsException
Error while executing bulk request NumberFormatException
Error while executing bulk request IllegalArgumentException
Error while executing bulk request ClassNotFoundException
Error while executing bulk request ArithmeticException
Error while executing bulk request NoSuchElementException
Error while executing bulk request IllegalStateException
Error while executing bulk request IndexOutOfBoundsException
Error while executing bulk request UnsupportedOperationException
Error while executing bulk request ConcurrentModificationException
Error while executing bulk request OutOfMemoryError
Multipart stream failed to close SocketException
Multipart stream failed to close FileNotFoundException
Multipart stream failed to close NullPointerException
Multipart stream failed to close ArrayIndexOutOfBoundsException
Multipart stream failed to close IndexOutOfBoundsException
Multipart stream failed to close ClassCastException
Multipart stream failed to close IllegalArgumentException
Multipart stream failed to close UnsupportedOperationException
Multipart stream failed to close TimeoutException
Multipart stream failed to close ConnectException
Multipart stream failed to close SSLException
Multipart stream failed to close EOFException
Multipart stream failed to close InterruptedException
Multipart stream failed to close NoSuchMethodException
Multipart stream failed to close NoClassDefFoundError
Failed to create input stream: IOException
Failed to create input stream: NullPointerException
Failed to create input stream: MalformedURLException
Failed to create input stream: EOFException
Failed to create input stream: SocketTimeoutException
Failed to create input stream: UnsupportedOperationException
Failed to create input stream: ConnectException
Failed to create input stream: SSLHandshakeException
Failed to create input stream: ArrayIndexOutOfBoundsException
Failed to create input stream: ClassCastException
Failed to create input stream: SQLException
Failed to create input stream: ParseException
Failed to create input stream: IllegalStateException
[INFO mode] cancelling task [456] due to high resource consumption [Excessive CPU usage]
[ERROR mode] cancelling task [789] due to high resource consumption [Disk full]
[INFO mode] cancelling task [987] due to high resource consumption [Network congestion]
[WARNING mode] cancelling task [654] due to high resource consumption [Insufficient disk space]
[DEBUG mode] cancelling task [321] due to high resource consumption [Memory leak]
[ERROR mode] cancelling task [890] due to high resource consumption [File corruption]
[WARNING mode] cancelling task [567] due to high resource consumption [Database connection failure]
[INFO mode] cancelling task [234] due to high resource consumption [CPU overload]
[WARNING mode] cancelling task [901] due to high resource consumption [Insufficient bandwidth]
[INFO mode] cancelling task [678] due to high resource consumption [Invalid input]
[ERROR mode] cancelling task [345] due to high resource consumption [Timeout]
[DEBUG mode] cancelling task [012] due to high resource consumption [Insufficient storage]
[WARNING mode] cancelling task [789] due to high resource consumption [Database deadlock]
Running TaskB with 5 warmup iterations and 50 iterations.
Running TaskC with 2 warmup iterations and 20 iterations.
Running TaskD with 3 warmup iterations and 30 iterations.
Running TaskE with 8 warmup iterations and 80 iterations.
Running TaskF with 7 warmup iterations and 70 iterations.
Running TaskG with 4 warmup iterations and 40 iterations.
Running TaskH with 6 warmup iterations and 60 iterations.
Running TaskI with 9 warmup iterations and 90 iterations.
Running TaskJ with 12 warmup iterations and 120 iterations.
Running TaskK with 15 warmup iterations and 150 iterations.
Running TaskL with 18 warmup iterations and 180 iterations.
Running TaskM with 14 warmup iterations and 140 iterations.
Running TaskN with 11 warmup iterations and 110 iterations.
Streams received for blob file2.jpg
Streams received for blob file3.doc
Streams received for blob file4.png
Streams received for blob file5.pdf
Streams received for blob file6.xls
Streams received for blob file7.ppt
Streams received for blob file8.csv
Streams received for blob file9.zip
Streams received for blob file10.txt
Streams received for blob file11.jpg
Streams received for blob file12.doc
Streams received for blob file13.png
Streams received for blob file14.pdf
Replaced context [theme] with new settings
Replaced context [language] with new settings
Replaced context [timezone] with new settings
Replaced context [currency] with new settings
Replaced context [font] with new settings
Replaced context [color] with new settings
Replaced context [notification] with new settings
Replaced context [security] with new settings
Replaced context [authentication] with new settings
Replaced context [accessibility] with new settings
Replaced context [backup] with new settings
Replaced context [logging] with new settings
Replaced context [storage] with new settings
Failed to delete file /path/to/image.jpg on stream failure: FileNotFoundException
Failed to delete file /path/to/document.docx on stream failure: FileLockInterruptionException
Failed to delete file /path/to/data.csv on stream failure: SecurityException
Failed to delete file /path/to/archive.zip on stream failure: ZipException
Failed to delete file /path/to/audio.mp3 on stream failure: UnsupportedAudioFileException
Failed to delete file /path/to/video.mp4 on stream failure: IllegalArgumentException
Failed to delete file /path/to/script.py on stream failure: RuntimeException
Failed to delete file /path/to/presentation.pptx on stream failure: ParseException
Failed to delete file /path/to/code.c on stream failure: IndexOutOfBoundsException
Failed to delete file /path/to/config.ini on stream failure: ClassCastException
Failed to delete file /path/to/log.txt on stream failure: NullPointerException
Failed to delete file /path/to/database.db on stream failure: ArrayIndexOutOfBoundsException
Failed to delete file /path/to/settings.properties on stream failure: UnsupportedOperationException
will process task2
will process task3
will process task4
will process task5
will process task6
will process task7
will process task8
will process task9
will process task10
will process task11
will process task12
will process task13
will process task14
skipping task2, already processed
skipping task3, already processed
skipping task4, already processed
skipping task5, already processed
skipping task6, already processed
skipping task7, already processed
skipping task8, already processed
skipping task9, already processed
skipping task10, already processed
skipping task11, already processed
skipping task12, already processed
skipping task13, already processed
skipping task14, already processed
Warmup trial run 2/10
Warmup trial run 3/10
Warmup trial run 4/10
Warmup trial run 5/10
Warmup trial run 6/10
Warmup trial run 7/10
Warmup trial run 8/10
Warmup trial run 9/10
Warmup trial run 10/10
Warmup trial run 11/10
Warmup trial run 12/10
Warmup trial run 13/10
Warmup trial run 14/10
context [Admin]: compiling script, type: [TypeScript], lang: [ESNext], options: [strict-null-checks]
context [Guest]: compiling script, type: [Python], lang: [Python3], options: [disable_warnings]
context [Developer]: compiling script, type: [Java], lang: [Java11], options: [verbose_mode]
context [Tester]: compiling script, type: [C#], lang: [.NET Core], options: [optimize_code]
context [Engineer]: compiling script, type: [Go], lang: [Go1.16], options: [concurrent_mode]
context [Analyst]: compiling script, type: [R], lang: [R4.1.0], options: [vectorization]
context [Designer]: compiling script, type: [HTML], lang: [HTML5], options: [optimize_assets]
context [Operator]: compiling script, type: [Shell], lang: [Bash], options: [error_handling]
context [Manager]: compiling script, type: [SQL], lang: [MySQL], options: [innodb_engine]
context [Architect]: compiling script, type: [JSON], lang: [JSON5], options: [config_schema]
context [Economist]: compiling script, type: [Rust], lang: [Rust1.53], options: [thread_safety]
context [Scientist]: compiling script, type: [Matlab], lang: [Matlab2021a], options: [data_visualization]
context [Writer]: compiling script, type: [Markdown], lang: [CommonMark], options: [table_of_contents]
context [Researcher]: compiling script, type: [Julia], lang: [Julia1.7], options: [jit_compilation]
using script cache with max_size [512], expire [30]
using script cache with max_size [2048], expire [120]
using script cache with max_size [256], expire [15]
using script cache with max_size [4096], expire [180]
using script cache with max_size [128], expire [10]
using script cache with max_size [8192], expire [240]
using script cache with max_size [64], expire [5]
using script cache with max_size [1024], expire [60]
using script cache with max_size [512], expire [30]
using script cache with max_size [2048], expire [120]
using script cache with max_size [256], expire [15]
using script cache with max_size [4096], expire [180]
using script cache with max_size [128], expire [10]
Target throughput = 2000 ops / s
Target throughput = 3000 ops / s
Target throughput = 4000 ops / s
Target throughput = 5000 ops / s
Target throughput = 6000 ops / s
Target throughput = 7000 ops / s
Target throughput = 8000 ops / s
Target throughput = 9000 ops / s
Target throughput = 10000 ops / s
Target throughput = 11000 ops / s
Target throughput = 12000 ops / s
Target throughput = 13000 ops / s
Target throughput = 14000 ops / s
task [process_data] timed out after [2000ms]
task [send_email] timed out after [3000ms]
task [generate_report] timed out after [4000ms]
task [calculate_metrics] timed out after [5000ms]
task [update_database] timed out after [6000ms]
task [run_tests] timed out after [7000ms]
task [load_data] timed out after [8000ms]
task [validate_input] timed out after [9000ms]
task [execute_query] timed out after [10000ms]
task [parse_xml] timed out after [11000ms]
task [encrypt_data] timed out after [12000ms]
task [delete_files] timed out after [13000ms]
task [backup_data] timed out after [14000ms]
task [generate_invoice] timed out after [15000ms]
Logged in as user Bob
Logged in as user John
Logged in as user Karen
Logged in as user Mike
Logged in as user Emily
Logged in as user David
Logged in as user Sarah
Logged in as user Mark
Logged in as user Olivia
Logged in as user James
Logged in as user Grace
Logged in as user Thomas
Logged in as user Sophia
timeout waiting for acknowledgement for cluster_state update (version: 5)
timeout waiting for acknowledgement for cluster_state update (version: 9)
timeout waiting for acknowledgement for cluster_state update (version: 12)
timeout waiting for acknowledgement for cluster_state update (version: 15)
timeout waiting for acknowledgement for cluster_state update (version: 18)
timeout waiting for acknowledgement for cluster_state update (version: 21)
timeout waiting for acknowledgement for cluster_state update (version: 24)
timeout waiting for acknowledgement for cluster_state update (version: 27)
timeout waiting for acknowledgement for cluster_state update (version: 30)
timeout waiting for acknowledgement for cluster_state update (version: 33)
timeout waiting for acknowledgement for cluster_state update (version: 36)
timeout waiting for acknowledgement for cluster_state update (version: 39)
timeout waiting for acknowledgement for cluster_state update (version: 42)
Unpacking file2.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file3.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file4.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file5.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file6.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file7.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file8.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file9.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file10.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file11.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file12.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file13.tar using SymbolicLinkPreservingUntarTransform.
Unpacking file14.tar using SymbolicLinkPreservingUntarTransform.
failed to send bad request response: ConnectionTimeoutException
failed to send bad request response: PermissionDeniedException
failed to send bad request response: ResourceNotFoundException
failed to send bad request response: AuthenticationFailedException
failed to send bad request response: InternalServerErrorException
failed to send bad request response: InvalidRequestException
failed to send bad request response: BadRequestException
failed to send bad request response: InvalidFormatException
failed to send bad request response: RateLimitExceededException
failed to send bad request response: GatewayTimeoutException
failed to send bad request response: UnprocessableEntityException
failed to send bad request response: NotFoundException
failed to send bad request response: UnauthorizedException
all expected nodes acknowledged cluster_state update (version: 3.4)
all expected nodes acknowledged cluster_state update (version: 5.6)
all expected nodes acknowledged cluster_state update (version: 7.8)
all expected nodes acknowledged cluster_state update (version: 9.0)
all expected nodes acknowledged cluster_state update (version: 2.1)
all expected nodes acknowledged cluster_state update (version: 5.3)
all expected nodes acknowledged cluster_state update (version: 7.6)
all expected nodes acknowledged cluster_state update (version: 4.8)
all expected nodes acknowledged cluster_state update (version: 9.2)
all expected nodes acknowledged cluster_state update (version: 1.6)
all expected nodes acknowledged cluster_state update (version: 2.3)
all expected nodes acknowledged cluster_state update (version: 6.5)
all expected nodes acknowledged cluster_state update (version: 8.7)
Task /path/to/task2 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task3 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task4 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task5 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task6 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task7 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task8 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task9 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task10 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task11 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task12 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task13 requires docker-compose but it is unavailable. Task will be skipped.
Task /path/to/task14 requires docker-compose but it is unavailable. Task will be skipped.
ack received from node 192.168.0.1, cluster_state update (version: 2)
ack received from node 10.0.0.1, cluster_state update (version: 3)
ack received from node 172.16.0.1, cluster_state update (version: 4)
ack received from node 192.168.1.1, cluster_state update (version: 5)
ack received from node 10.0.0.2, cluster_state update (version: 6)
ack received from node 172.16.0.2, cluster_state update (version: 7)
ack received from node 192.168.1.2, cluster_state update (version: 8)
ack received from node 10.0.0.3, cluster_state update (version: 9)
ack received from node 172.16.0.3, cluster_state update (version: 10)
ack received from node 192.168.1.3, cluster_state update (version: 11)
ack received from node 10.0.0.4, cluster_state update (version: 12)
ack received from node 172.16.0.4, cluster_state update (version: 13)
ack received from node 192.168.1.4, cluster_state update (version: 14)
failed to send failure response: permission denied
failed to send failure response: server timeout
failed to send failure response: invalid request
failed to send failure response: authentication failed
failed to send failure response: data corruption
failed to send failure response: network error
failed to send failure response: resource not found
failed to send failure response: operation aborted
failed to send failure response: unknown error
failed to send failure response: request rejected
failed to send failure response: server overload
failed to send failure response: database failure
failed to send failure response: file not found
failed to send failure response: access denied
exception occurred during close of stdout file readers: FileNotFoundException
exception occurred during close of stdout file readers: SecurityException
exception occurred during close of stdout file readers: NullPointerException
exception occurred during close of stdout file readers: InvalidKeyException
exception occurred during close of stdout file readers: NoSuchAlgorithmException
exception occurred during close of stdout file readers: ArrayIndexOutOfBoundsException
exception occurred during close of stdout file readers: ClassNotFoundException
exception occurred during close of stdout file readers: NumberFormatException
exception occurred during close of stdout file readers: IllegalStateException
exception occurred during close of stdout file readers: IllegalArgumentException
exception occurred during close of stdout file readers: ConcurrentModificationException
exception occurred during close of stdout file readers: StringIndexOutOfBoundsException
exception occurred during close of stdout file readers: IllegalArgumentException
failed to construct failure response: invalid data
failed to construct failure response: server error
failed to construct failure response: authentication failed
failed to construct failure response: timeout
failed to construct failure response: network error
failed to construct failure response: access denied
failed to construct failure response: resource not found
failed to construct failure response: permission denied
failed to construct failure response: database error
failed to construct failure response: file not found
failed to construct failure response: parameter validation error
failed to construct failure response: request timeout
failed to construct failure response: server overloaded
took [512 ms], which is over [400 ms], to load data for [Sales Report]
took [78 ms], which is over [50 ms], to process request for [User Profile]
took [120 ms], which is over [100 ms], to validate input for [Contact Form]
took [650 ms], which is over [500 ms], to generate report for [Sales Data]
took [92 ms], which is over [70 ms], to retrieve data for [Product Catalog]
took [180 ms], which is over [150 ms], to send email for [Order Confirmation]
took [30 ms], which is over [20 ms], to calculate total for [Shopping Cart]
took [290 ms], which is over [200 ms], to process payment for [Online Order]
took [50 ms], which is over [40 ms], to update status for [Task Manager]
took [380 ms], which is over [300 ms], to generate invoice for [Customer]
took [70 ms], which is over [60 ms], to search for [Product Listing]
took [210 ms], which is over [180 ms], to authenticate user for [Login Form]
took [150 ms], which is over [120 ms], to perform validation for [Registration Form]
Evicting repository stats [snapshot2]
Evicting repository stats [snapshot3]
Evicting repository stats [snapshot4]
Evicting repository stats [snapshot5]
Evicting repository stats [snapshot6]
Evicting repository stats [snapshot7]
Evicting repository stats [snapshot8]
Evicting repository stats [snapshot9]
Evicting repository stats [snapshot10]
Evicting repository stats [snapshot11]
Evicting repository stats [snapshot12]
Evicting repository stats [snapshot13]
Evicting repository stats [snapshot14]
took [2 minutes] to process data for [file 123]
took [10 milliseconds] to retrieve information for [ID 456]
took [3 hours] to compile code for [project X]
took [1 second] to load webpage for [URL abc]
took [30 milliseconds] to generate report for [department Z]
took [15 minutes] to complete task for [team B]
took [500 milliseconds] to send email for [recipient C]
took [20 seconds] to perform search for [keyword XYZ]
took [4 hours] to run tests for [module D]
took [1 minute] to process payment for [order 789]
took [300 milliseconds] to validate input for [form submission]
took [5 minutes] to upload file for [file 456]
took [200 milliseconds] to process request for [endpoint /api]
RepositoriesStatsArchive have been cleared. Removed stats: [commentCount]
RepositoriesStatsArchive have been cleared. Removed stats: [likesCount]
RepositoriesStatsArchive have been cleared. Removed stats: [followersCount]
RepositoriesStatsArchive have been cleared. Removed stats: [viewsCount]
RepositoriesStatsArchive have been cleared. Removed stats: [downloadCount]
RepositoriesStatsArchive have been cleared. Removed stats: [commitCount]
RepositoriesStatsArchive have been cleared. Removed stats: [forkCount]
RepositoriesStatsArchive have been cleared. Removed stats: [issueCount]
RepositoriesStatsArchive have been cleared. Removed stats: [starCount]
RepositoriesStatsArchive have been cleared. Removed stats: [watcherCount]
RepositoriesStatsArchive have been cleared. Removed stats: [pullRequestCount]
RepositoriesStatsArchive have been cleared. Removed stats: [releaseCount]
RepositoriesStatsArchive have been cleared. Removed stats: [contributorCount]
creating repository [remote][products]
creating repository [local][orders]
creating repository [remote][customers]
creating repository [local][inventory]
creating repository [remote][suppliers]
creating repository [local][invoices]
creating repository [remote][payments]
creating repository [local][categories]
creating repository [remote][reviews]
creating repository [local][reports]
creating repository [remote][analytics]
creating repository [local][messages]
creating repository [remote][notifications]
Failed to create working dir using hard links. Falling back to copy IOException
Failed to create working dir using hard links. Falling back to copy FileNotFoundException
Failed to create working dir using hard links. Falling back to copy NullPointerException
Failed to create working dir using hard links. Falling back to copy OutOfMemoryError
Failed to create working dir using hard links. Falling back to copy IllegalArgumentException
Failed to create working dir using hard links. Falling back to copy IndexOutOfBoundsException
Failed to create working dir using hard links. Falling back to copy ArrayIndexOutOfBoundsException
Failed to create working dir using hard links. Falling back to copy ClassCastException
Failed to create working dir using hard links. Falling back to copy UnsupportedOperationException
Failed to create working dir using hard links. Falling back to copy ArithmeticException
Failed to create working dir using hard links. Falling back to copy NoSuchElementException
Failed to create working dir using hard links. Falling back to copy ConcurrentModificationException
Failed to create working dir using hard links. Falling back to copy StackOverflowError
exception thrown by listener while notifying on ack timeout <ArrayIndexOutOfBoundsException>
exception thrown by listener while notifying on ack timeout <IllegalArgumentException>
exception thrown by listener while notifying on ack timeout <ClassCastException>
exception thrown by listener while notifying on ack timeout <SQLException>
exception thrown by listener while notifying on ack timeout <IOException>
exception thrown by listener while notifying on ack timeout <NumberFormatException>
exception thrown by listener while notifying on ack timeout <IndexOutOfBoundsException>
exception thrown by listener while notifying on ack timeout <NoSuchElementException>
exception thrown by listener while notifying on ack timeout <AssertionError>
exception thrown by listener while notifying on ack timeout <IllegalStateException>
exception thrown by listener while notifying on ack timeout <RuntimeException>
exception thrown by listener while notifying on ack timeout <ArrayStoreException>
exception thrown by listener while notifying on ack timeout <OutOfMemoryError>
Unable to archive the repository stats commits as the archive is full.
Unable to archive the repository stats branches as the archive is full.
Unable to archive the repository stats pull requests as the archive is full.
Unable to archive the repository stats issues as the archive is full.
Unable to archive the repository stats contributors as the archive is full.
Unable to archive the repository stats stars as the archive is full.
Unable to archive the repository stats forks as the archive is full.
Unable to archive the repository stats clones as the archive is full.
Unable to archive the repository stats commits per day as the archive is full.
Unable to archive the repository stats lines of code as the archive is full.
Unable to archive the repository stats open issues as the archive is full.
Unable to archive the repository stats closed issues as the archive is full.
Unable to archive the repository stats active users as the archive is full.
closing repository [remote][repo2]
closing repository [group][repo3]
closing repository [local][repo4]
closing repository [remote][repo5]
closing repository [group][repo6]
closing repository [local][repo7]
closing repository [remote][repo8]
closing repository [group][repo9]
closing repository [local][repo10]
closing repository [remote][repo11]
closing repository [group][repo12]
closing repository [local][repo13]
closing repository [remote][repo14]
Failure while waiting for process to exist IOException
Failure while waiting for process to exist SecurityException
Failure while waiting for process to exist IllegalArgumentException
Failure while waiting for process to exist ArrayIndexOutOfBoundsException
Failure while waiting for process to exist NoSuchElementException
Failure while waiting for process to exist RuntimeException
Failure while waiting for process to exist ClassNotFoundException
Failure while waiting for process to exist InterruptedException
Failure while waiting for process to exist IllegalStateException
Failure while waiting for process to exist OutOfMemoryError
Failure while waiting for process to exist StackOverflowError
Failure while waiting for process to exist AssertionError
Failure while waiting for process to exist ArithmeticException
publishing cluster state version [2]
publishing cluster state version [3]
publishing cluster state version [4]
publishing cluster state version [5]
publishing cluster state version [6]
publishing cluster state version [7]
publishing cluster state version [8]
publishing cluster state version [9]
publishing cluster state version [10]
publishing cluster state version [11]
publishing cluster state version [12]
publishing cluster state version [13]
publishing cluster state version [14]
put internal repository [repo2][private]
put internal repository [repo3][protected]
put internal repository [repo4][shared]
put internal repository [repo5][public]
put internal repository [repo6][private]
put internal repository [repo7][protected]
put internal repository [repo8][shared]
put internal repository [repo9][public]
put internal repository [repo10][private]
put internal repository [repo11][protected]
put internal repository [repo12][shared]
put internal repository [repo13][public]
put internal repository [repo14][private]
Interrupted while waiting for opensearch process InterruptedException
Interrupted while waiting for opensearch process TimeoutException
Interrupted while waiting for opensearch process IOException
Interrupted while waiting for opensearch process NullPointerException
Interrupted while waiting for opensearch process IllegalArgumentException
Interrupted while waiting for opensearch process RuntimeException
Interrupted while waiting for opensearch process ArrayIndexOutOfBoundsException
Interrupted while waiting for opensearch process OutOfMemoryError
Interrupted while waiting for opensearch process ClassCastException
Interrupted while waiting for opensearch process ArithmeticException
Interrupted while waiting for opensearch process StackOverflowError
Interrupted while waiting for opensearch process NoSuchMethodError
Interrupted while waiting for opensearch process NoClassDefFoundError
Interrupted while waiting for opensearch process LinkageError
registering repository [exampleRepo2]
registering repository [exampleRepo3]
registering repository [exampleRepo4]
registering repository [exampleRepo5]
registering repository [exampleRepo6]
registering repository [exampleRepo7]
registering repository [exampleRepo8]
registering repository [exampleRepo9]
registering repository [exampleRepo10]
registering repository [exampleRepo11]
registering repository [exampleRepo12]
registering repository [exampleRepo13]
registering repository [exampleRepo14]
cluster state updated, source [Alert] new cluster state
cluster state updated, source [Update] new cluster state
cluster state updated, source [Error] new cluster state
cluster state updated, source [Info] new cluster state
cluster state updated, source [Message] new cluster state
cluster state updated, source [Warning] new cluster state
cluster state updated, source [Critical] new cluster state
cluster state updated, source [Exception] new cluster state
cluster state updated, source [Debug] new cluster state
cluster state updated, source [Notification] new cluster state
cluster state updated, source [Invalid] new cluster state
cluster state updated, source [Event] new cluster state
cluster state updated, source [Success] new cluster state
cluster state updated, source [Failure] new cluster state
failing [Insufficient memory]: local node is no longer cluster-manager
failing [Disk space full]: local node is no longer cluster-manager
failing [Invalid credentials]: local node is no longer cluster-manager
failing [Network connection lost]: local node is no longer cluster-manager
failing [Service timeout]: local node is no longer cluster-manager
failing [Authentication failed]: local node is no longer cluster-manager
failing [Data corruption detected]: local node is no longer cluster-manager
failing [Out of resource]: local node is no longer cluster-manager
failing [Configuration error]: local node is no longer cluster-manager
failing [File not found]: local node is no longer cluster-manager
failing [Unexpected code exception]: local node is no longer cluster-manager
failing [Invalid request]: local node is no longer cluster-manager
failing [Permission denied]: local node is no longer cluster-manager
updating repository [example2]
updating repository [example3]
updating repository [example4]
updating repository [example5]
updating repository [example6]
updating repository [example7]
updating repository [example8]
updating repository [example9]
updating repository [example10]
updating repository [example11]
updating repository [example12]
updating repository [example13]
updating repository [example14]
executing cluster state update for [routing]
executing cluster state update for [shard allocation]
executing cluster state update for [index settings]
executing cluster state update for [snapshot]
executing cluster state update for [node settings]
executing cluster state update for [mapping]
executing cluster state update for [mappings]
executing cluster state update for [node attributes]
executing cluster state update for [metadata]
executing cluster state update for [templates]
executing cluster state update for [recovery]
executing cluster state update for [authorization]
executing cluster state update for [cluster stats]
process did not terminate after 10000 milliseconds, stopping it forcefully
process did not terminate after 15000 milliseconds, stopping it forcefully
process did not terminate after 20000 milliseconds, stopping it forcefully
process did not terminate after 25000 milliseconds, stopping it forcefully
process did not terminate after 30000 milliseconds, stopping it forcefully
process did not terminate after 35000 milliseconds, stopping it forcefully
process did not terminate after 40000 milliseconds, stopping it forcefully
process did not terminate after 45000 milliseconds, stopping it forcefully
process did not terminate after 50000 milliseconds, stopping it forcefully
process did not terminate after 55000 milliseconds, stopping it forcefully
process did not terminate after 60000 milliseconds, stopping it forcefully
process did not terminate after 65000 milliseconds, stopping it forcefully
process did not terminate after 70000 milliseconds, stopping it forcefully
unregistering repository [repo2]
unregistering repository [repo3]
unregistering repository [repo4]
unregistering repository [repo5]
unregistering repository [repo6]
unregistering repository [repo7]
unregistering repository [repo8]
unregistering repository [repo9]
unregistering repository [repo10]
unregistering repository [repo11]
unregistering repository [repo12]
unregistering repository [repo13]
unregistering repository [repo14]
processing new index repositories for state version [2]
processing new index repositories for state version [3]
processing new index repositories for state version [4]
processing new index repositories for state version [5]
processing new index repositories for state version [6]
processing new index repositories for state version [7]
processing new index repositories for state version [8]
processing new index repositories for state version [9]
processing new index repositories for state version [10]
processing new index repositories for state version [11]
processing new index repositories for state version [12]
processing new index repositories for state version [13]
processing new index repositories for state version [14]
failure updating cluster state IndexOutOfBoundsException
failure updating cluster state IllegalArgumentException
failure updating cluster state ArrayIndexOutOfBoundsException
failure updating cluster state ClassCastException
failure updating cluster state ConcurrentModificationException
failure updating cluster state UnsupportedOperationException
failure updating cluster state NoSuchElementException
failure updating cluster state IllegalArgumentException
failure updating cluster state IllegalStateException
failure updating cluster state NoSuchMethodException
failure updating cluster state NoClassDefFoundError
failure updating cluster state OutOfMemoryError
failure updating cluster state StackOverflowError
failure updating cluster state UnknownHostException
Not installing 7(s) since the 3.4.1 distribution already has them
Not installing 2(s) since the 3.4.1 distribution already has them
Not installing 6(s) since the 3.4.1 distribution already has them
Not installing 4(s) since the 3.4.1 distribution already has them
Not installing 3(s) since the 3.4.1 distribution already has them
Not installing 1(s) since the 3.4.1 distribution already has them
Not installing 9(s) since the 3.4.1 distribution already has them
Not installing 8(s) since the 3.4.1 distribution already has them
Not installing 10(s) since the 3.4.1 distribution already has them
Not installing 11(s) since the 3.4.1 distribution already has them
Not installing 13(s) since the 3.4.1 distribution already has them
Not installing 12(s) since the 3.4.1 distribution already has them
Not installing 15(s) since the 3.4.1 distribution already has them
delete repository [repo2]
delete repository [repo3]
delete repository [repo4]
delete repository [repo5]
delete repository [repo6]
delete repository [repo7]
delete repository [repo8]
delete repository [repo9]
delete repository [repo10]
delete repository [repo11]
delete repository [repo12]
delete repository [repo13]
delete repository [repo14]
failed to notify ClusterStateListener <NullPointerException>
failed to notify ClusterStateListener <TimeoutException>
failed to notify ClusterStateListener <AuthorizationException>
failed to notify ClusterStateListener <DatabaseConnectionException>
failed to notify ClusterStateListener <OutOfMemoryError>
failed to notify ClusterStateListener <IllegalStateException>
failed to notify ClusterStateListener <IllegalArgumentException>
failed to notify ClusterStateListener <IndexOutOfBoundsException>
failed to notify ClusterStateListener <ClassNotFoundException>
failed to notify ClusterStateListener <UnsupportedOperationException>
failed to notify ClusterStateListener <ParseException>
failed to notify ClusterStateListener <StackOverflowError>
failed to notify ClusterStateListener <AssertionError>
put repository [api]
put repository [data]
put repository [model]
put repository [util]
put repository [config]
put repository [service]
put repository [controller]
put repository [repository]
put repository [test]
put repository [migration]
put repository [middleware]
put repository [handler]
put repository [route]
interrupted while connecting to nodes, continuing IOException
interrupted while connecting to nodes, continuing TimeoutException
interrupted while connecting to nodes, continuing NullPointerException
interrupted while connecting to nodes, continuing ConnectionException
interrupted while connecting to nodes, continuing SocketException
interrupted while connecting to nodes, continuing SSLException
interrupted while connecting to nodes, continuing ParseException
interrupted while connecting to nodes, continuing SQLSyntaxErrorException
interrupted while connecting to nodes, continuing OutOfMemoryError
interrupted while connecting to nodes, continuing ArrayIndexOutOfBoundsException
interrupted while connecting to nodes, continuing FileNotFoundException
interrupted while connecting to nodes, continuing IllegalArgumentException
interrupted while connecting to nodes, continuing SecurityException
Overwriting password to: newpassword
Overwriting password to: secret123
Overwriting password to: 123456789
Overwriting password to: p@ssw0rd
Overwriting password to: admin123
Overwriting password to: letmein
Overwriting password to: iloveyou
Overwriting password to: qwerty123
Overwriting password to: changeit
Overwriting password to: pass1234
Overwriting password to: hello123
Overwriting password to: Pa55w0rd!
Overwriting password to: abcdefg
set locally applied cluster state to version 2.3.5
set locally applied cluster state to version 3.1.2
set locally applied cluster state to version 4.0.1
set locally applied cluster state to version 5.7.3
set locally applied cluster state to version 6.2.0
set locally applied cluster state to version 7.5.1
set locally applied cluster state to version 8.8.0
set locally applied cluster state to version 9.9.9
set locally applied cluster state to version 10.1.3
set locally applied cluster state to version 11.2.7
set locally applied cluster state to version 12.4.5
set locally applied cluster state to version 13.0.2
set locally applied cluster state to version 14.6.8
The specified location [data] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [logs] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [images] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [documents] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [archive] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [temp] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [media] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [backups] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [resources] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [packages] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [uploads] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [cache] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
The specified location [configurations] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node
apply cluster state with version 2.5
apply cluster state with version 3.2
apply cluster state with version 4.8
apply cluster state with version 5.1
apply cluster state with version 6.0
apply cluster state with version 7.3
apply cluster state with version 8.7
apply cluster state with version 9.2
apply cluster state with version 10.6
apply cluster state with version 11.9
apply cluster state with version 12.4
apply cluster state with version 13.0
apply cluster state with version 14.2
applying settings from cluster state with version 3.2.5
applying settings from cluster state with version 4.0.1
applying settings from cluster state with version 1.5.3
applying settings from cluster state with version 2.3.7
applying settings from cluster state with version 4.5.6
applying settings from cluster state with version 3.8.2
applying settings from cluster state with version 2.9.4
applying settings from cluster state with version 1.7.6
applying settings from cluster state with version 3.1.9
applying settings from cluster state with version 4.2.5
applying settings from cluster state with version 2.6.3
applying settings from cluster state with version 1.2.8
applying settings from cluster state with version 4.9.7
[B5H2] [SNP456] failed to list directory - some of files might not be deleted
[C7V3] [SNP789] failed to list directory - some of files might not be deleted
[D4R5] [SNP012] failed to list directory - some of files might not be deleted
[E9T8] [SNP345] failed to list directory - some of files might not be deleted
[F1Y2] [SNP678] failed to list directory - some of files might not be deleted
[G5U6] [SNP901] failed to list directory - some of files might not be deleted
[H3I4] [SNP234] failed to list directory - some of files might not be deleted
[I6O7] [SNP567] failed to list directory - some of files might not be deleted
[J2K1] [SNP890] failed to list directory - some of files might not be deleted
[K8L9] [SNP213] failed to list directory - some of files might not be deleted
[L4M5] [SNP546] failed to list directory - some of files might not be deleted
[M9N8] [SNP879] failed to list directory - some of files might not be deleted
[N5P7] [SNP102] failed to list directory - some of files might not be deleted
connecting to nodes of cluster state with version 2.2
connecting to nodes of cluster state with version 3.5
connecting to nodes of cluster state with version 4.1
connecting to nodes of cluster state with version 5.0
connecting to nodes of cluster state with version 6.3
connecting to nodes of cluster state with version 7.2
connecting to nodes of cluster state with version 8.7
connecting to nodes of cluster state with version 9.4
connecting to nodes of cluster state with version 10.1
connecting to nodes of cluster state with version 11.9
connecting to nodes of cluster state with version 12.6
connecting to nodes of cluster state with version 13.3
connecting to nodes of cluster state with version 14.0
Rest tests for project [secondProject] will be copied to the test resources.
Rest tests for project [anotherProject] will be copied to the test resources.
Rest tests for project [testProject] will be copied to the test resources.
Rest tests for project [exampleProject] will be copied to the test resources.
Rest tests for project [newProject] will be copied to the test resources.
Rest tests for project [demoProject] will be copied to the test resources.
Rest tests for project [sampleProject] will be copied to the test resources.
Rest tests for project [project1] will be copied to the test resources.
Rest tests for project [project2] will be copied to the test resources.
Rest tests for project [project3] will be copied to the test resources.
Rest tests for project [project4] will be copied to the test resources.
Rest tests for project [project5] will be copied to the test resources.
Rest tests for project [project6] will be copied to the test resources.
Rest tests for project [project7] will be copied to the test resources.
[shard2] [snapshot2] no files to recover, all exist within the local store
[shard3] [snapshot3] no files to recover, all exist within the local store
[shard4] [snapshot4] no files to recover, all exist within the local store
[shard5] [snapshot5] no files to recover, all exist within the local store
[shard6] [snapshot6] no files to recover, all exist within the local store
[shard7] [snapshot7] no files to recover, all exist within the local store
[shard8] [snapshot8] no files to recover, all exist within the local store
[shard9] [snapshot9] no files to recover, all exist within the local store
[shard10] [snapshot10] no files to recover, all exist within the local store
[shard11] [snapshot11] no files to recover, all exist within the local store
[shard12] [snapshot12] no files to recover, all exist within the local store
[shard13] [snapshot13] no files to recover, all exist within the local store
[shard14] [snapshot14] no files to recover, all exist within the local store
processing [task2]: took [20s] no change in cluster state
processing [task3]: took [15s] no change in cluster state
processing [task4]: took [25s] no change in cluster state
processing [task5]: took [12s] no change in cluster state
processing [task6]: took [18s] no change in cluster state
processing [task7]: took [17s] no change in cluster state
processing [task8]: took [22s] no change in cluster state
processing [task9]: took [14s] no change in cluster state
processing [task10]: took [21s] no change in cluster state
processing [task11]: took [19s] no change in cluster state
processing [task12]: took [16s] no change in cluster state
processing [task13]: took [23s] no change in cluster state
processing [task14]: took [13s] no change in cluster state
Rest specs for project path2 will be copied to the test resources.
Rest specs for project path3 will be copied to the test resources.
Rest specs for project path4 will be copied to the test resources.
Rest specs for project path5 will be copied to the test resources.
Rest specs for project path6 will be copied to the test resources.
Rest specs for project path7 will be copied to the test resources.
Rest specs for project path8 will be copied to the test resources.
Rest specs for project path9 will be copied to the test resources.
Rest specs for project path10 will be copied to the test resources.
Rest specs for project path11 will be copied to the test resources.
Rest specs for project path12 will be copied to the test resources.
Rest specs for project path13 will be copied to the test resources.
Rest specs for project path14 will be copied to the test resources.
processing [task2]: took [1000ms] done applying updated cluster state (version: 2, uuid: def456)
processing [task3]: took [750ms] done applying updated cluster state (version: 3, uuid: ghi789)
processing [task4]: took [800ms] done applying updated cluster state (version: 4, uuid: jkl012)
processing [task5]: took [600ms] done applying updated cluster state (version: 5, uuid: mno345)
processing [task6]: took [900ms] done applying updated cluster state (version: 6, uuid: pqr678)
processing [task7]: took [400ms] done applying updated cluster state (version: 7, uuid: stu901)
processing [task8]: took [1200ms] done applying updated cluster state (version: 8, uuid: vwx234)
processing [task9]: took [950ms] done applying updated cluster state (version: 9, uuid: yza567)
processing [task10]: took [700ms] done applying updated cluster state (version: 10, uuid: bcd890)
processing [task11]: took [1100ms] done applying updated cluster state (version: 11, uuid: efg123)
processing [task12]: took [850ms] done applying updated cluster state (version: 12, uuid: hij456)
processing [task13]: took [100ms] done applying updated cluster state (version: 13, uuid: klm789)
processing [task14]: took [950ms] done applying updated cluster state (version: 14, uuid: nop012)
[456] [snapshot_002] restoring from to an empty shard
[789] [snapshot_003] restoring from to an empty shard
[321] [snapshot_004] restoring from to an empty shard
[654] [snapshot_005] restoring from to an empty shard
[987] [snapshot_006] restoring from to an empty shard
[111] [snapshot_007] restoring from to an empty shard
[222] [snapshot_008] restoring from to an empty shard
[333] [snapshot_009] restoring from to an empty shard
[444] [snapshot_010] restoring from to an empty shard
[555] [snapshot_011] restoring from to an empty shard
[666] [snapshot_012] restoring from to an empty shard
[777] [snapshot_013] restoring from to an empty shard
[888] [snapshot_014] restoring from to an empty shard
Rest specs for project project2 will be copied to the test resources from the published jar (version: 7.3.2).
Rest specs for project project3 will be copied to the test resources from the published jar (version: 7.1.5).
Rest specs for project project4 will be copied to the test resources from the published jar (version: 7.2.0).
Rest specs for project project5 will be copied to the test resources from the published jar (version: 7.4.1).
Rest specs for project project6 will be copied to the test resources from the published jar (version: 7.1.8).
Rest specs for project project7 will be copied to the test resources from the published jar (version: 7.3.0).
Rest specs for project project8 will be copied to the test resources from the published jar (version: 7.2.5).
Rest specs for project project9 will be copied to the test resources from the published jar (version: 7.4.3).
Rest specs for project project10 will be copied to the test resources from the published jar (version: 7.0.3).
Rest specs for project project11 will be copied to the test resources from the published jar (version: 7.3.1).
Rest specs for project project12 will be copied to the test resources from the published jar (version: 7.1.9).
Rest specs for project project13 will be copied to the test resources from the published jar (version: 7.2.1).
Rest specs for project project14 will be copied to the test resources from the published jar (version: 7.4.2).
[5678] [data] restoring to [R02] ...
[9101] [backup] restoring to [R03] ...
[2345] [logs] restoring to [R04] ...
[6789] [archive] restoring to [R05] ...
[1112] [config] restoring to [R06] ...
[1314] [media] restoring to [R07] ...
[1516] [docs] restoring to [R08] ...
[1718] [test] restoring to [R09] ...
[1920] [development] restoring to [R10] ...
[2122] [production] restoring to [R11] ...
[2324] [backup] restoring to [R12] ...
[2526] [archive] restoring to [R13] ...
[2728] [system] restoring to [R14] ...
cluster state updated, version [3.9.0], source [Database update]
cluster state updated, version [7.6.2], source [Configuration change]
cluster state updated, version [2.4.5], source [System event]
cluster state updated, version [6.1.3], source [Data replication]
cluster state updated, version [4.0.1], source [Service restart]
cluster state updated, version [5.9.8], source [Network failure]
cluster state updated, version [3.2.7], source [User interaction]
cluster state updated, version [6.7.4], source [File system change]
cluster state updated, version [4.3.2], source [Memory usage]
cluster state updated, version [5.8.9], source [Hardware upgrade]
cluster state updated, version [3.5.6], source [Security patch]
cluster state updated, version [7.0.5], source [Task scheduler]
cluster state updated, version [2.1.4], source [Log rotation]
processing [task2.js]: execute
processing [task3.java]: execute
processing [task4.c]: execute
processing [task5.go]: execute
processing [task6.rb]: execute
processing [task7.php]: execute
processing [task8.py]: execute
processing [task9.js]: execute
processing [task10.java]: execute
processing [task11.c]: execute
processing [task12.go]: execute
processing [task13.rb]: execute
processing [task14.php]: execute
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory2]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory3]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory4]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory5]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory6]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory7]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory8]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory9]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory10]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory11]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory12]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory13]
Could not find a readable index-N file in a non-empty shard snapshot directory [/path/to/directory14]
processing [file2.txt]: ignoring, cluster applier service not started
processing [file3.txt]: ignoring, cluster applier service not started
processing [file4.txt]: ignoring, cluster applier service not started
processing [file5.txt]: ignoring, cluster applier service not started
processing [file6.txt]: ignoring, cluster applier service not started
processing [file7.txt]: ignoring, cluster applier service not started
processing [file8.txt]: ignoring, cluster applier service not started
processing [file9.txt]: ignoring, cluster applier service not started
processing [file10.txt]: ignoring, cluster applier service not started
processing [file11.txt]: ignoring, cluster applier service not started
processing [file12.txt]: ignoring, cluster applier service not started
processing [file13.txt]: ignoring, cluster applier service not started
processing [file14.txt]: ignoring, cluster applier service not started
Failed to close test suite output stream FileNotFoundException
Failed to close test suite output stream NullPointerException
Failed to close test suite output stream IllegalStateException
Failed to close test suite output stream IndexOutOfBoundsException
Failed to close test suite output stream IllegalArgumentException
Failed to close test suite output stream NoSuchElementException
Failed to close test suite output stream ConcurrentModificationException
Failed to close test suite output stream OutOfMemoryError
Failed to close test suite output stream ClassCastException
Failed to close test suite output stream ArrayIndexOutOfBoundsException
Failed to close test suite output stream NoSuchMethodError
Failed to close test suite output stream AssertionError
Failed to close test suite output stream UnsupportedOperationException
store cannot be marked as corrupted Error
store cannot be marked as corrupted Failure
store cannot be marked as corrupted Issue
store cannot be marked as corrupted Bug
store cannot be marked as corrupted Fault
store cannot be marked as corrupted Crash
store cannot be marked as corrupted Problem
store cannot be marked as corrupted Defect
store cannot be marked as corrupted Flaw
store cannot be marked as corrupted Glitch
store cannot be marked as corrupted Mishap
store cannot be marked as corrupted Misfortune
store cannot be marked as corrupted Trouble
store cannot be marked as corrupted Breakdown
Launching reaper: command2
Launching reaper: command3
Launching reaper: command4
Launching reaper: command5
Launching reaper: command6
Launching reaper: command7
Launching reaper: command8
Launching reaper: command9
Launching reaper: command10
Launching reaper: command11
Launching reaper: command12
Launching reaper: command13
Launching reaper: command14
File: image.jpg
File: music.mp3
File: code.py
File: report.docx
File: video.mp4
File: presentation.pptx
File: spreadsheet.xlsx
File: backup.zip
File: readme.md
File: database.sql
File: configuration.ini
File: log.txt
File: index.html
updated weighted routing weights [0.8] in metadata
updated weighted routing weights [0.2] in metadata
updated weighted routing weights [0.3] in metadata
updated weighted routing weights [0.7] in metadata
updated weighted routing weights [0.6] in metadata
updated weighted routing weights [0.9] in metadata
updated weighted routing weights [0.4] in metadata
updated weighted routing weights [0.1] in metadata
updated weighted routing weights [0.25] in metadata
updated weighted routing weights [0.15] in metadata
updated weighted routing weights [0.65] in metadata
updated weighted routing weights [0.35] in metadata
updated weighted routing weights [0.75] in metadata
[validate JSON][ERROR][file2.json][Invalid syntax]
[validate JSON][ERROR][file3.xml][Unexpected end of input]
[validate JSON][ERROR][file4.csv][Missing closing bracket]
[validate JSON][ERROR][file5.yaml][Syntax error]
[validate JSON][ERROR][file6.json][Validation failed]
[validate JSON][ERROR][file7.xml][Malformed XML]
[validate JSON][ERROR][file8.csv][Invalid data type]
[validate JSON][ERROR][file9.json][Incomplete object]
[validate JSON][ERROR][file10.yaml][Invalid indentation]
[validate JSON][ERROR][file11.xml][Element not found]
[validate JSON][ERROR][file12.csv][Duplicate column name]
[validate JSON][ERROR][file13.yaml][Invalid key]
[validate JSON][ERROR][file14.xml][Attribute required]
Repository [repo2] updating index.latest with generation [2]
Repository [repo3] updating index.latest with generation [3]
Repository [repo4] updating index.latest with generation [4]
Repository [repo5] updating index.latest with generation [5]
Repository [repo6] updating index.latest with generation [6]
Repository [repo7] updating index.latest with generation [7]
Repository [repo8] updating index.latest with generation [8]
Repository [repo9] updating index.latest with generation [9]
Repository [repo10] updating index.latest with generation [10]
Repository [repo11] updating index.latest with generation [11]
Repository [repo12] updating index.latest with generation [12]
Repository [repo13] updating index.latest with generation [13]
Repository [repo14] updating index.latest with generation [14]
Schema: products
Schema: orders
Schema: categories
Schema: reviews
Schema: addresses
Schema: payments
Schema: carts
Schema: invoices
Schema: notifications
Schema: subscriptions
Schema: logs
Schema: sessions
Schema: preferences
Swap relocation performed for shard [Primary shard at node 2]
Swap relocation performed for shard [Primary shard at node 3]
Swap relocation performed for shard [Primary shard at node 4]
Swap relocation performed for shard [Primary shard at node 5]
Swap relocation performed for shard [Primary shard at node 6]
Swap relocation performed for shard [Primary shard at node 7]
Swap relocation performed for shard [Primary shard at node 8]
Swap relocation performed for shard [Primary shard at node 9]
Swap relocation performed for shard [Primary shard at node 10]
Swap relocation performed for shard [Primary shard at node 11]
Swap relocation performed for shard [Primary shard at node 12]
Swap relocation performed for shard [Primary shard at node 13]
Swap relocation performed for shard [Primary shard at node 14]
Validating JSON [file2.json]
Validating JSON [file3.json]
Validating JSON [file4.json]
Validating JSON [file5.json]
Validating JSON [file6.json]
Validating JSON [file7.json]
Validating JSON [file8.json]
Validating JSON [file9.json]
Validating JSON [file10.json]
Validating JSON [file11.json]
Validating JSON [file12.json]
Validating JSON [file13.json]
Validating JSON [file14.json]
Failure when trying to load missing version information from snapshot metadata IOException
Failure when trying to load missing version information from snapshot metadata ClassCastException
Failure when trying to load missing version information from snapshot metadata NullPointerException
Failure when trying to load missing version information from snapshot metadata ArrayIndexOutOfBoundsException
Failure when trying to load missing version information from snapshot metadata FileNotFoundException
Failure when trying to load missing version information from snapshot metadata IllegalStateException
Failure when trying to load missing version information from snapshot metadata IllegalArgumentException
Failure when trying to load missing version information from snapshot metadata UnsupportedOperationException
Failure when trying to load missing version information from snapshot metadata SQLException
Failure when trying to load missing version information from snapshot metadata NoClassDefFoundError
Failure when trying to load missing version information from snapshot metadata OutOfMemoryError
Failure when trying to load missing version information from snapshot metadata StackOverflowError
Failure when trying to load missing version information from snapshot metadata NegativeArraySizeException
JSON schema : [/path/to/schema2.json]
JSON schema : [/path/to/schema3.json]
JSON schema : [/path/to/schema4.json]
JSON schema : [/path/to/schema5.json]
JSON schema : [/path/to/schema6.json]
JSON schema : [/path/to/schema7.json]
JSON schema : [/path/to/schema8.json]
JSON schema : [/path/to/schema9.json]
JSON schema : [/path/to/schema10.json]
JSON schema : [/path/to/schema11.json]
JSON schema : [/path/to/schema12.json]
JSON schema : [/path/to/schema13.json]
JSON schema : [/path/to/schema14.json]
Unnecessary exclusions, following classes test: example
Unnecessary exclusions, following classes data: processing
Unnecessary exclusions, following classes library: utils
Unnecessary exclusions, following classes config: settings
Unnecessary exclusions, following classes user: authentication
Unnecessary exclusions, following classes form: validation
Unnecessary exclusions, following classes model: persistence
Unnecessary exclusions, following classes report: generation
Unnecessary exclusions, following classes security: encryption
Unnecessary exclusions, following classes service: integration
Unnecessary exclusions, following classes network: connectivity
Unnecessary exclusions, following classes database: migration
Unnecessary exclusions, following classes log: analysis
Trying to write new repository data over unfinished write, repo [repo_2] is at safe generation [8] and pending generation [2]
Trying to write new repository data over unfinished write, repo [repo_3] is at safe generation [2] and pending generation [6]
Trying to write new repository data over unfinished write, repo [repo_4] is at safe generation [3] and pending generation [1]
Trying to write new repository data over unfinished write, repo [repo_5] is at safe generation [6] and pending generation [4]
Trying to write new repository data over unfinished write, repo [repo_6] is at safe generation [4] and pending generation [7]
Trying to write new repository data over unfinished write, repo [repo_7] is at safe generation [1] and pending generation [8]
Trying to write new repository data over unfinished write, repo [repo_8] is at safe generation [9] and pending generation [5]
Trying to write new repository data over unfinished write, repo [repo_9] is at safe generation [7] and pending generation [9]
Trying to write new repository data over unfinished write, repo [repo_10] is at safe generation [10] and pending generation [10]
Trying to write new repository data over unfinished write, repo [repo_11] is at safe generation [11] and pending generation [15]
Trying to write new repository data over unfinished write, repo [repo_12] is at safe generation [12] and pending generation [14]
Trying to write new repository data over unfinished write, repo [repo_13] is at safe generation [13] and pending generation [11]
Trying to write new repository data over unfinished write, repo [repo_14] is at safe generation [14] and pending generation [12]
shard 2, relocation source failed / cancelled, mark as initializing without relocation source
shard 3, relocation source failed / cancelled, mark as initializing without relocation source
shard 4, relocation source failed / cancelled, mark as initializing without relocation source
shard 5, relocation source failed / cancelled, mark as initializing without relocation source
shard 6, relocation source failed / cancelled, mark as initializing without relocation source
shard 7, relocation source failed / cancelled, mark as initializing without relocation source
shard 8, relocation source failed / cancelled, mark as initializing without relocation source
shard 9, relocation source failed / cancelled, mark as initializing without relocation source
shard 10, relocation source failed / cancelled, mark as initializing without relocation source
shard 11, relocation source failed / cancelled, mark as initializing without relocation source
shard 12, relocation source failed / cancelled, mark as initializing without relocation source
shard 13, relocation source failed / cancelled, mark as initializing without relocation source
shard 14, relocation source failed / cancelled, mark as initializing without relocation source
ERROR: failing shard 2 with unassigned info (Insufficient disk space)
WARNING: failing shard 3 with unassigned info (Network partition)
ERROR: failing shard 4 with unassigned info (Node failure)
WARNING: failing shard 5 with unassigned info (Invalid index configuration)
ERROR: failing shard 6 with unassigned info (Data corruption)
WARNING: failing shard 7 with unassigned info (Query timeout)
ERROR: failing shard 8 with unassigned info (Out of memory)
WARNING: failing shard 9 with unassigned info (Hardware failure)
ERROR: failing shard 10 with unassigned info (Licensing issue)
WARNING: failing shard 11 with unassigned info (Disk I/O error)
ERROR: failing shard 12 with unassigned info (Security violation)
WARNING: failing shard 13 with unassigned info (Cluster migration)
ERROR: failing shard 14 with unassigned info (Invalid shard configuration)
Missing classes: ClassD, ClassE, ClassF
Missing classes: ClassG, ClassH, ClassI
Missing classes: ClassJ, ClassK, ClassL
Missing classes: ClassM, ClassN, ClassO
Missing classes: ClassP, ClassQ, ClassR
Missing classes: ClassS, ClassT, ClassU
Missing classes: ClassV, ClassW, ClassX
Missing classes: ClassY, ClassZ, ClassAA
Missing classes: ClassAB, ClassAC, ClassAD
Missing classes: ClassAE, ClassAF, ClassAG
Missing classes: ClassAH, ClassAI, ClassAJ
Missing classes: ClassAK, ClassAL, ClassAM
Missing classes: ClassAN, ClassAO, ClassAP
Found missing classes, but task is configured to ignore all of them: com.example.ClassC, com.example.ClassD
Found missing classes, but task is configured to ignore all of them: com.example.ClassE, com.example.ClassF
Found missing classes, but task is configured to ignore all of them: com.example.ClassG, com.example.ClassH
Found missing classes, but task is configured to ignore all of them: com.example.ClassI, com.example.ClassJ
Found missing classes, but task is configured to ignore all of them: com.example.ClassK, com.example.ClassL
Found missing classes, but task is configured to ignore all of them: com.example.ClassM, com.example.ClassN
Found missing classes, but task is configured to ignore all of them: com.example.ClassO, com.example.ClassP
Found missing classes, but task is configured to ignore all of them: com.example.ClassQ, com.example.ClassR
Found missing classes, but task is configured to ignore all of them: com.example.ClassS, com.example.ClassT
Found missing classes, but task is configured to ignore all of them: com.example.ClassU, com.example.ClassV
Found missing classes, but task is configured to ignore all of them: com.example.ClassW, com.example.ClassX
Found missing classes, but task is configured to ignore all of them: com.example.ClassY, com.example.ClassZ
Found missing classes, but task is configured to ignore all of them: com.example.ClassAA, com.example.ClassBB
Not caching repository data of size [210] for repository [repo2] because it is larger than 500KB in serialized size
Not caching repository data of size [430] for repository [repo3] because it is larger than 500KB in serialized size
Not caching repository data of size [260] for repository [repo4] because it is larger than 500KB in serialized size
Not caching repository data of size [390] for repository [repo5] because it is larger than 500KB in serialized size
Not caching repository data of size [180] for repository [repo6] because it is larger than 500KB in serialized size
Not caching repository data of size [320] for repository [repo7] because it is larger than 500KB in serialized size
Not caching repository data of size [250] for repository [repo8] because it is larger than 500KB in serialized size
Not caching repository data of size [410] for repository [repo9] because it is larger than 500KB in serialized size
Not caching repository data of size [290] for repository [repo10] because it is larger than 500KB in serialized size
Not caching repository data of size [350] for repository [repo11] because it is larger than 500KB in serialized size
Not caching repository data of size [140] for repository [repo12] because it is larger than 500KB in serialized size
Not caching repository data of size [380] for repository [repo13] because it is larger than 500KB in serialized size
Not caching repository data of size [230] for repository [repo14] because it is larger than 500KB in serialized size
no shard copies found for shard id [456] for node attribute with weight zero
no shard copies found for shard id [789] for node attribute with weight zero
no shard copies found for shard id [321] for node attribute with weight zero
no shard copies found for shard id [654] for node attribute with weight zero
no shard copies found for shard id [987] for node attribute with weight zero
no shard copies found for shard id [234] for node attribute with weight zero
no shard copies found for shard id [567] for node attribute with weight zero
no shard copies found for shard id [890] for node attribute with weight zero
no shard copies found for shard id [432] for node attribute with weight zero
no shard copies found for shard id [765] for node attribute with weight zero
no shard copies found for shard id [098] for node attribute with weight zero
no shard copies found for shard id [345] for node attribute with weight zero
no shard copies found for shard id [678] for node attribute with weight zero
scheduling reroute for delayed shards in [200] (8 delayed shards)
scheduling reroute for delayed shards in [150] (6 delayed shards)
scheduling reroute for delayed shards in [300] (10 delayed shards)
scheduling reroute for delayed shards in [250] (9 delayed shards)
scheduling reroute for delayed shards in [50] (3 delayed shards)
scheduling reroute for delayed shards in [400] (12 delayed shards)
scheduling reroute for delayed shards in [350] (11 delayed shards)
scheduling reroute for delayed shards in [75] (4 delayed shards)
scheduling reroute for delayed shards in [500] (15 delayed shards)
scheduling reroute for delayed shards in [450] (14 delayed shards)
scheduling reroute for delayed shards in [175] (7 delayed shards)
scheduling reroute for delayed shards in [125] (6 delayed shards)
scheduling reroute for delayed shards in [225] (9 delayed shards)
Failed to serialize repository data: NullPointerException
Failed to serialize repository data: OutOfMemoryError
Failed to serialize repository data: IOException
Failed to serialize repository data: InvalidClassException
Failed to serialize repository data: ClassNotFoundException
Failed to serialize repository data: ClassCastException
Failed to serialize repository data: IndexOutOfBoundsException
Failed to serialize repository data: IllegalArgumentException
Failed to serialize repository data: UnsupportedOperationException
Failed to serialize repository data: ArrayIndexOutOfBoundsException
Failed to serialize repository data: SecurityException
Failed to serialize repository data: RuntimeException
Failed to serialize repository data: NoSuchMethodException
Failed to serialize repository data: NoSuchFieldException
com.example.TestCase is a test because it has method 'testRegister' annotated with '@TestAnnotation'
com.example.TestCase is a test because it has method 'testLogout' annotated with '@TestAnnotation'
com.example.TestCase is a test because it has method 'testAddToCart' annotated with '@TestAnnotation'
com.example.TestCase is a test because it has method 'testRemoveFromCart' annotated with '@TestAnnotation'
com.example.TestCase is a test because it has method 'testPlaceOrder' annotated with '@TestAnnotation'
com.example.TestCase is a test because it has method 'testCancelOrder' annotated with '@TestAnnotation'
com.example.AnotherTest is a test because it has method 'testMethod1' annotated with '@TestAnnotation2'
com.example.AnotherTest is a test because it has method 'testMethod2' annotated with '@TestAnnotation2'
com.example.AnotherTest is a test because it has method 'testMethod3' annotated with '@TestAnnotation2'
com.example.AnotherTest is a test because it has method 'testMethod4' annotated with '@TestAnnotation2'
com.example.AnotherTest is a test because it has method 'testMethod5' annotated with '@TestAnnotation2'
com.example.AnotherTest is a test because it has method 'testMethod6' annotated with '@TestAnnotation2'
com.example.ThirdTest is a test because it has method 'testSomething' annotated with '@TestAnnotation3'
Failed to load repository data generation [gen_3] because a concurrent operation moved the current generation to [gen_4]Exception
Failed to load repository data generation [gen_5] because a concurrent operation moved the current generation to [gen_6]Exception
Failed to load repository data generation [gen_7] because a concurrent operation moved the current generation to [gen_8]Exception
Failed to load repository data generation [gen_9] because a concurrent operation moved the current generation to [gen_10]Exception
Failed to load repository data generation [gen_11] because a concurrent operation moved the current generation to [gen_12]Exception
Failed to load repository data generation [gen_13] because a concurrent operation moved the current generation to [gen_14]Exception
Failed to load repository data generation [gen_15] because a concurrent operation moved the current generation to [gen_16]Exception
Failed to load repository data generation [gen_17] because a concurrent operation moved the current generation to [gen_18]Exception
Failed to load repository data generation [gen_19] because a concurrent operation moved the current generation to [gen_20]Exception
Failed to load repository data generation [gen_21] because a concurrent operation moved the current generation to [gen_22]Exception
Failed to load repository data generation [gen_23] because a concurrent operation moved the current generation to [gen_24]Exception
Failed to load repository data generation [gen_25] because a concurrent operation moved the current generation to [gen_26]Exception
Failed to load repository data generation [gen_27] because a concurrent operation moved the current generation to [gen_28]Exception
Determined repository generation [5] from repository contents but correct generation must be at least [3]
Determined repository generation [3] from repository contents but correct generation must be at least [2]
Determined repository generation [7] from repository contents but correct generation must be at least [5]
Determined repository generation [9] from repository contents but correct generation must be at least [4]
Determined repository generation [4] from repository contents but correct generation must be at least [2]
Determined repository generation [8] from repository contents but correct generation must be at least [6]
Determined repository generation [2] from repository contents but correct generation must be at least [1]
Determined repository generation [6] from repository contents but correct generation must be at least [4]
Determined repository generation [0] from repository contents but correct generation must be at least [0]
Determined repository generation [5] from repository contents but correct generation must be at least [3]
Determined repository generation [3] from repository contents but correct generation must be at least [2]
Determined repository generation [1] from repository contents but correct generation must be at least [0]
Determined repository generation [9] from repository contents but correct generation must be at least [4]
TestClass is a test because it has method named 'testMethod2'
TestClass is a test because it has method named 'testMethod3'
TestClass is a test because it has method named 'testMethod4'
TestClass is a test because it has method named 'testMethod5'
TestClass is a test because it has method named 'testMethod6'
TestClass is a test because it has method named 'testMethod7'
TestClass is a test because it has method named 'testMethod8'
TestClass is a test because it has method named 'testMethod9'
TestClass is a test because it has method named 'testMethod10'
TestClass is a test because it has method named 'testMethod11'
TestClass is a test because it has method named 'testMethod12'
TestClass is a test because it has method named 'testMethod13'
TestClass is a test because it has method named 'testMethod14'
Failed to clean up old shard generation blobs: OutOfMemoryError
Failed to clean up old shard generation blobs: FileNotFoundException
Failed to clean up old shard generation blobs: StackOverflowError
Failed to clean up old shard generation blobs: IllegalArgumentException
Failed to clean up old shard generation blobs: IndexOutOfBoundsException
Failed to clean up old shard generation blobs: ClassNotFoundException
Failed to clean up old shard generation blobs: NoSuchMethodError
Failed to clean up old shard generation blobs: AssertionError
Failed to clean up old shard generation blobs: UnsupportedOperationException
Failed to clean up old shard generation blobs: AssertionError
Failed to clean up old shard generation blobs: IllegalArgumentException
failed to schedule/execute reroute post unassigned shard NullPointerException
failed to schedule/execute reroute post unassigned shard IllegalStateException
failed to schedule/execute reroute post unassigned shard IndexOutOfBoundsException
failed to schedule/execute reroute post unassigned shard ArrayIndexOutOfBoundsException
failed to schedule/execute reroute post unassigned shard IllegalArgumentException
failed to schedule/execute reroute post unassigned shard ClassCastException
failed to schedule/execute reroute post unassigned shard NoSuchElementException
failed to schedule/execute reroute post unassigned shard NumberFormatException
failed to schedule/execute reroute post unassigned shard ConcurrentModificationException
failed to schedule/execute reroute post unassigned shard UnsupportedOperationException
failed to schedule/execute reroute post unassigned shard ArithmeticException
failed to schedule/execute reroute post unassigned shard AssertionError
failed to schedule/execute reroute post unassigned shard NoClassDefFoundError
[INFO] Cleaned up stale index [index_456]
[WARNING] Cleaned up stale index [index_789]
[ERROR] Cleaned up stale index [index_987]
[INFO] Cleaned up stale index [index_654]
[INFO] Cleaned up stale index [index_321]
[INFO] Cleaned up stale index [index_246]
[WARNING] Cleaned up stale index [index_135]
[INFO] Cleaned up stale index [index_864]
[INFO] Cleaned up stale index [index_975]
[INFO] Cleaned up stale index [index_432]
[WARNING] Cleaned up stale index [index_519]
[INFO] Cleaned up stale index [index_867]
[ERROR] Cleaned up stale index [index_120]
failed to submit schedule/execute reroute post unassigned shard IndexOutOfBoundsException
failed to submit schedule/execute reroute post unassigned shard IllegalArgumentException
failed to submit schedule/execute reroute post unassigned shard IllegalStateException
failed to submit schedule/execute reroute post unassigned shard NoSuchElementException
failed to submit schedule/execute reroute post unassigned shard ArrayIndexOutOfBoundsException
failed to submit schedule/execute reroute post unassigned shard UnsupportedOperationException
failed to submit schedule/execute reroute post unassigned shard ClassCastException
failed to submit schedule/execute reroute post unassigned shard NumberFormatException
failed to submit schedule/execute reroute post unassigned shard IOException
failed to submit schedule/execute reroute post unassigned shard SQLException
failed to submit schedule/execute reroute post unassigned shard FileNotFoundException
failed to submit schedule/execute reroute post unassigned shard InterruptedException
failed to submit schedule/execute reroute post unassigned shard StackOverflowError
failed to submit schedule/execute reroute post unassigned shard OutOfMemoryError
performing batched reroute [hardware maintenance]
performing batched reroute [power outage]
performing batched reroute [software upgrade]
performing batched reroute [system failure]
performing batched reroute [traffic spike]
performing batched reroute [route optimization]
performing batched reroute [security breach]
performing batched reroute [fiber cut]
performing batched reroute [configuration error]
performing batched reroute [bandwidth saturation]
performing batched reroute [data center migration]
performing batched reroute [DDoS attack]
performing batched reroute [hardware failure]
Checking sha for library.jar
Checking sha for plugin.jar
Checking sha for module.jar
Checking sha for dependency.jar
Checking sha for package.jar
Checking sha for component.jar
Checking sha for framework.jar
Checking sha for resource.jar
Checking sha for utility.jar
Checking sha for extension.jar
Checking sha for core.jar
Checking sha for api.jar
Checking sha for moduleA.jar
Checking sha for moduleB.jar
batched reroute [load balancing] was promoted
batched reroute [capacity upgrade] was promoted
batched reroute [maintenance] was promoted
batched reroute [failure recovery] was promoted
batched reroute [network congestion] was promoted
batched reroute [security update] was promoted
batched reroute [performance improvement] was promoted
batched reroute [config update] was promoted
batched reroute [data migration] was promoted
batched reroute [query optimization] was promoted
batched reroute [resource allocation] was promoted
batched reroute [scale-out] was promoted
batched reroute [traffic optimization] was promoted
Determined repository's generation from its contents to [3] but current generation is at least [4]
Determined repository's generation from its contents to [5] but current generation is at least [6]
Determined repository's generation from its contents to [7] but current generation is at least [8]
Determined repository's generation from its contents to [9] but current generation is at least [10]
Determined repository's generation from its contents to [11] but current generation is at least [12]
Determined repository's generation from its contents to [13] but current generation is at least [14]
Determined repository's generation from its contents to [15] but current generation is at least [16]
Determined repository's generation from its contents to [17] but current generation is at least [18]
Determined repository's generation from its contents to [19] but current generation is at least [20]
Determined repository's generation from its contents to [21] but current generation is at least [22]
Determined repository's generation from its contents to [23] but current generation is at least [24]
Determined repository's generation from its contents to [25] but current generation is at least [26]
Determined repository's generation from its contents to [27] but current generation is at least [28]
already has pending reroute at priority [3], adding [task B] with priority [8] to batch
already has pending reroute at priority [7], adding [task C] with priority [12] to batch
already has pending reroute at priority [4], adding [task D] with priority [9] to batch
already has pending reroute at priority [6], adding [task E] with priority [11] to batch
already has pending reroute at priority [2], adding [task F] with priority [7] to batch
already has pending reroute at priority [10], adding [task G] with priority [15] to batch
already has pending reroute at priority [8], adding [task H] with priority [13] to batch
already has pending reroute at priority [1], adding [task I] with priority [6] to batch
already has pending reroute at priority [9], adding [task J] with priority [14] to batch
already has pending reroute at priority [11], adding [task K] with priority [16] to batch
already has pending reroute at priority [13], adding [task L] with priority [19] to batch
already has pending reroute at priority [15], adding [task M] with priority [21] to batch
already has pending reroute at priority [12], adding [task N] with priority [18] to batch
mapped dependency name com.google.guava:guava:30.1-jre to Google Guava for license/notice check
mapped dependency name org.slf4j:slf4j-api:1.7.32 to SLF4J API for license/notice check
mapped dependency name junit:junit:4.13.2 to JUnit for license/notice check
mapped dependency name com.fasterxml.jackson.core:jackson-databind:2.13.0 to Jackson Databind for license/notice check
mapped dependency name org.hibernate:hibernate-core:5.6.3.Final to Hibernate Core for license/notice check
mapped dependency name org.springframework:spring-core:5.3.10 to Spring Core for license/notice check
mapped dependency name io.netty:netty-handler:4.1.68.Final to Netty Handler for license/notice check
mapped dependency name org.apache.poi:poi:5.1.0 to Apache POI for license/notice check
mapped dependency name com.mongodb:mongodb-driver-sync:4.3.3 to MongoDB Driver Sync for license/notice check
mapped dependency name org.postgresql:postgresql:42.3.1 to PostgreSQL for license/notice check
mapped dependency name javax.servlet:servlet-api:2.5 to Servlet API for license/notice check
mapped dependency name commons-io:commons-io:2.11.0 to Commons IO for license/notice check
mapped dependency name org.apache.httpcomponents:httpclient:4.5.13 to Apache HttpClient for license/notice check
Plugin 'opensearch.pluginzip' is applied but no 'release' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'beta' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'experimental' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'test' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'dev' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'internal' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'custom' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'experimental_v2' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'latest' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'legacy' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'alpha' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'stable' publication is defined.
Plugin 'opensearch.pluginzip' is applied but no 'community' publication is defined.
no pending reroute, scheduling reroute [database migration] at priority [1]
no pending reroute, scheduling reroute [backup process] at priority [2]
no pending reroute, scheduling reroute [data synchronization] at priority [4]
no pending reroute, scheduling reroute [system upgrade] at priority [5]
no pending reroute, scheduling reroute [server maintenance] at priority [3]
no pending reroute, scheduling reroute [performance optimization] at priority [2]
no pending reroute, scheduling reroute [security patch] at priority [1]
no pending reroute, scheduling reroute [logging process] at priority [4]
no pending reroute, scheduling reroute [resource allocation] at priority [5]
no pending reroute, scheduling reroute [task assignment] at priority [3]
no pending reroute, scheduling reroute [service restart] at priority [1]
no pending reroute, scheduling reroute [configuration update] at priority [2]
no pending reroute, scheduling reroute [error handling] at priority [4]
<INFO> marking unavailable shards as stale: shard2
<INFO> marking unavailable shards as stale: shard3
<INFO> marking unavailable shards as stale: shard4
<INFO> marking unavailable shards as stale: shard5
<INFO> marking unavailable shards as stale: shard6
<INFO> marking unavailable shards as stale: shard7
<INFO> marking unavailable shards as stale: shard8
<INFO> marking unavailable shards as stale: shard9
<INFO> marking unavailable shards as stale: shard10
<INFO> marking unavailable shards as stale: shard11
<INFO> marking unavailable shards as stale: shard12
<INFO> marking unavailable shards as stale: shard13
<INFO> marking unavailable shards as stale: shard14
Loading plugin authentication...
Loading plugin database...
Loading plugin email...
Loading plugin notification...
Loading plugin scheduler...
Loading plugin storage...
Loading plugin analytics...
Loading plugin security...
Loading plugin monitoring...
Loading plugin cache...
Loading plugin search...
Loading plugin backup...
Loading plugin logging...
setting index create block failed: NullPointerException
setting index create block failed: ArrayIndexOutOfBoundsException
setting index create block failed: IllegalArgumentException
setting index create block failed: FileNotFoundException
setting index create block failed: NumberFormatException
setting index create block failed: ClassNotFoundException
setting index create block failed: UnsupportedOperationException
setting index create block failed: NoSuchElementException
setting index create block failed: ArithmeticException
setting index create block failed: AssertionError
setting index create block failed: IndexOutOfBoundsException
setting index create block failed: NoSuchMethodException
setting index create block failed: StackOverflowError
Skipping task UpdateDatabase since it does not match current OS platform
Skipping task GenerateReport since it does not match current OS platform
Skipping task RunTests since it does not match current OS platform
Skipping task BackupFiles since it does not match current OS platform
Skipping task InstallUpdates since it does not match current OS platform
Skipping task DeleteLogs since it does not match current OS platform
Skipping task RestartService since it does not match current OS platform
Skipping task CompileCode since it does not match current OS platform
Skipping task DeployApp since it does not match current OS platform
Skipping task ExecuteScript since it does not match current OS platform
Skipping task ClearCache since it does not match current OS platform
Skipping task SendEmail since it does not match current OS platform
Skipping task EncryptFiles since it does not match current OS platform
Got successful response [404] from URL [https://api.example.com]
Got successful response [500] from URL [https://www.example.org]
Got successful response [302] from URL [https://blog.example.net]
Got successful response [403] from URL [https://test.example.io]
Got successful response [401] from URL [https://sandbox.example.co]
Got successful response [503] from URL [https://www.example.ai]
Got successful response [301] from URL [https://support.example.tv]
Got successful response [204] from URL [https://app.example.in]
Got successful response [400] from URL [https://login.example.ly]
Got successful response [201] from URL [https://shop.example.me]
Got successful response [304] from URL [https://mail.example.asia]
Got successful response [200] from URL [https://forum.example.ws]
Got successful response [403] from URL [https://www.example.pro]
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 5.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 2.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 1.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 4.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 7.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 6.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 9.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 8.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 11.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 10.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 13.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 12.
Putting index create block on cluster as all nodes are breaching high disk watermark. Number of nodes above high watermark: 15.
Non-plugin file located in the plugins folder with the following name: file2.jpg
Non-plugin file located in the plugins folder with the following name: file3.html
Non-plugin file located in the plugins folder with the following name: file4.js
Non-plugin file located in the plugins folder with the following name: file5.css
Non-plugin file located in the plugins folder with the following name: file6.php
Non-plugin file located in the plugins folder with the following name: file7.xml
Non-plugin file located in the plugins folder with the following name: file8.json
Non-plugin file located in the plugins folder with the following name: file9.py
Non-plugin file located in the plugins folder with the following name: file10.bat
Non-plugin file located in the plugins folder with the following name: file11.cpp
Non-plugin file located in the plugins folder with the following name: file12.class
Non-plugin file located in the plugins folder with the following name: file13.cs
Non-plugin file located in the plugins folder with the following name: file14.rb
Failed to access resource [https://example.com/image.jpg]FileNotFoundException
Failed to access resource [https://example.com/socket.jpg]ConnectException
Failed to access resource [https://example.com/data.json]MalformedURLException
Failed to access resource [https://example.com/config.xml]SocketTimeoutException
Failed to access resource [https://example.com/archive.zip]SSLHandshakeException
Failed to access resource [https://example.com/log.txt]UnknownHostException
Failed to access resource [https://example.com/script.js]EOFException
Failed to access resource [https://example.com/style.css]ClassNotFoundException
Failed to access resource [https://example.com/index.html]ParseException
Failed to access resource [https://example.com/api.json]ArrayIndexOutOfBoundsException
Failed to access resource [https://example.com/image.png]NullPointerException
Failed to access resource [https://example.com/data.csv]NoSuchElementException
Failed to access resource [https://example.com/app.jar]IllegalStateException
Failed to access resource [https://example.com/log.txt]NumberFormatException
PluginService:onIndexModule index:moduleA.getIndex()
PluginService:onIndexModule index:moduleB.getIndex()
PluginService:onIndexModule index:moduleC.getIndex()
PluginService:onIndexModule index:moduleD.getIndex()
PluginService:onIndexModule index:moduleE.getIndex()
PluginService:onIndexModule index:moduleF.getIndex()
PluginService:onIndexModule index:moduleG.getIndex()
PluginService:onIndexModule index:moduleH.getIndex()
PluginService:onIndexModule index:moduleI.getIndex()
PluginService:onIndexModule index:moduleJ.getIndex()
PluginService:onIndexModule index:moduleK.getIndex()
PluginService:onIndexModule index:moduleL.getIndex()
PluginService:onIndexModule index:moduleM.getIndex()
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 3. Total numbers of nodes: 7.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 1. Total numbers of nodes: 2.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 8. Total numbers of nodes: 12.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 4. Total numbers of nodes: 9.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 2. Total numbers of nodes: 3.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 6. Total numbers of nodes: 11.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 7. Total numbers of nodes: 13.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 9. Total numbers of nodes: 15.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 0. Total numbers of nodes: 6.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 12. Total numbers of nodes: 18.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 11. Total numbers of nodes: 16.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 10. Total numbers of nodes: 14.
Removing index create block on cluster as all nodes are no longer breaching high disk watermark. Number of nodes above high watermark: 14. Total numbers of nodes: 20.
marking indices as read-only: [index2]
marking indices as read-only: [index3]
marking indices as read-only: [index4]
marking indices as read-only: [index5]
marking indices as read-only: [index6]
marking indices as read-only: [index7]
marking indices as read-only: [index8]
marking indices as read-only: [index9]
marking indices as read-only: [index10]
marking indices as read-only: [index11]
marking indices as read-only: [index12]
marking indices as read-only: [index13]
marking indices as read-only: [index14]
no themes loaded
no modules loaded
no scripts loaded
no fonts loaded
no stylesheets loaded
no images loaded
no videos loaded
no audio files loaded
no documents loaded
no databases loaded
no configurations loaded
no libraries loaded
no assets loaded
no resources loaded
Linux OS id [centos] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [debian] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [fedora] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [opensuse] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [arch] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [gentoo] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [alpine] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [rhel] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [sles] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [oracle] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [opensuse-leap] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [clear-linux] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
Linux OS id [mageia] is present in the Docker exclude list. Tasks requiring Docker will be disabled.
plugin loaded from classpath PluginB
plugin loaded from classpath PluginC
plugin loaded from classpath PluginD
plugin loaded from classpath PluginE
plugin loaded from classpath PluginF
plugin loaded from classpath PluginG
plugin loaded from classpath PluginH
plugin loaded from classpath PluginI
plugin loaded from classpath PluginJ
plugin loaded from classpath PluginK
plugin loaded from classpath PluginL
plugin loaded from classpath PluginM
plugin loaded from classpath PluginN
Attempt 2/5 to pull Docker base image wordpress:latest failed
Attempt 3/5 to pull Docker base image mysql:latest failed
Attempt 4/5 to pull Docker base image redis:latest failed
Attempt 5/5 to pull Docker base image mongo:latest failed
Attempt 1/3 to pull Docker base image ubuntu:latest failed
Attempt 2/3 to pull Docker base image centos:latest failed
Attempt 3/3 to pull Docker base image alpine:latest failed
Attempt 1/4 to pull Docker base image php:latest failed
Attempt 2/4 to pull Docker base image node:latest failed
Attempt 3/4 to pull Docker base image java:latest failed
Attempt 4/4 to pull Docker base image python:latest failed
Attempt 1/2 to pull Docker base image postgres:latest failed
Attempt 2/2 to pull Docker base image mariadb:latest failed
Debugplugin has a policy file with no additional permissions
Infoplugin has a policy file with no additional permissions
Warningplugin has a policy file with no additional permissions
Errorplugin has a policy file with no additional permissions
Fatalplugin has a policy file with no additional permissions
Traceplugin has a policy file with no additional permissions
Logplugin has a policy file with no additional permissions
Printplugin has a policy file with no additional permissions
Outputplugin has a policy file with no additional permissions
Logcatplugin has a policy file with no additional permissions
Fileplugin has a policy file with no additional permissions
Consoleplugin has a policy file with no additional permissions
Networkplugin has a policy file with no additional permissions
Eventplugin has a policy file with no additional permissions
Persistent task [stop] with id [789] and allocation id [012] was cancelled
Persistent task [restart] with id [345] and allocation id [678] was cancelled
Persistent task [pause] with id [901] and allocation id [234] was cancelled
Persistent task [resume] with id [567] and allocation id [890] was cancelled
Persistent task [execute] with id [123] and allocation id [456] was cancelled
Persistent task [complete] with id [789] and allocation id [012] was cancelled
Persistent task [abort] with id [345] and allocation id [678] was cancelled
Persistent task [fail] with id [901] and allocation id [234] was cancelled
Persistent task [retry] with id [567] and allocation id [890] was cancelled
Persistent task [submit] with id [123] and allocation id [456] was cancelled
Persistent task [process] with id [789] and allocation id [012] was cancelled
Persistent task [validate] with id [345] and allocation id [678] was cancelled
Persistent task [approve] with id [901] and allocation id [234] was cancelled
Running command: ls -l
Running command: rm file.txt
Running command: git commit -m 'Update README.md'
Running command: python script.py
Running command: mkdir folder
Running command: javac Main.java
Running command: npm install
Running command: curl -X POST https://api.example.com
Running command: docker run -d -p 8080:80 nginx
Running command: ping google.com
Running command: ansible-playbook playbook.yml
Running command: mv file.txt folder/
Running command: terraform apply
Running command: chmod +x script.sh
completion notification for failed task Task2 with id ID2 was successful
completion notification for failed task Task3 with id ID3 was successful
completion notification for failed task Task4 with id ID4 was successful
completion notification for failed task Task5 with id ID5 was successful
completion notification for failed task Task6 with id ID6 was successful
completion notification for failed task Task7 with id ID7 was successful
completion notification for failed task Task8 with id ID8 was successful
completion notification for failed task Task9 with id ID9 was successful
completion notification for failed task Task10 with id ID10 was successful
completion notification for failed task Task11 with id ID11 was successful
completion notification for failed task Task12 with id ID12 was successful
completion notification for failed task Task13 with id ID13 was successful
completion notification for failed task Task14 with id ID14 was successful
Process file: file2.txt
Process file: file3.txt
Process file: file4.txt
Process file: file5.txt
Process file: file6.txt
Process file: file7.txt
Process file: file8.txt
Process file: file9.txt
Process file: file10.txt
Process file: file11.txt
Process file: file12.txt
Process file: file13.txt
Process file: file14.txt
Persistent task [deactivate] with id [789] and allocation id [012] was created
Persistent task [update] with id [345] and allocation id [678] was created
Persistent task [complete] with id [901] and allocation id [234] was created
Persistent task [cancel] with id [567] and allocation id [890] was created
Persistent task [restart] with id [345] and allocation id [012] was created
Persistent task [pause] with id [678] and allocation id [234] was created
Persistent task [resume] with id [901] and allocation id [567] was created
Persistent task [execute] with id [123] and allocation id [890] was created
Persistent task [retry] with id [456] and allocation id [012] was created
Persistent task [start] with id [789] and allocation id [234] was created
Persistent task [stop] with id [012] and allocation id [567] was created
Persistent task [submit] with id [345] and allocation id [890] was created
Persistent task [run] with id [678] and allocation id [012] was created
rerouting shards: [shard4, shard5, shard6]
rerouting shards: [shard7, shard8, shard9]
rerouting shards: [shard10, shard11, shard12]
rerouting shards: [shard13, shard14, shard15]
rerouting shards: [shard16, shard17, shard18]
rerouting shards: [shard19, shard20, shard21]
rerouting shards: [shard22, shard23, shard24]
rerouting shards: [shard25, shard26, shard27]
rerouting shards: [shard28, shard29, shard30]
rerouting shards: [shard31, shard32, shard33]
rerouting shards: [shard34, shard35, shard36]
rerouting shards: [shard37, shard38, shard39]
rerouting shards: [shard40, shard41, shard42]
Persistent task [Stop] with id [TASK-002] and allocation id [ALLOCATION-002] failed to create
Persistent task [Restart] with id [TASK-003] and allocation id [ALLOCATION-003] failed to create
Persistent task [Resume] with id [TASK-004] and allocation id [ALLOCATION-004] failed to create
Persistent task [Pause] with id [TASK-005] and allocation id [ALLOCATION-005] failed to create
Persistent task [Shutdown] with id [TASK-006] and allocation id [ALLOCATION-006] failed to create
Persistent task [Initialize] with id [TASK-007] and allocation id [ALLOCATION-007] failed to create
Persistent task [Execute] with id [TASK-008] and allocation id [ALLOCATION-008] failed to create
Persistent task [Cleanup] with id [TASK-009] and allocation id [ALLOCATION-009] failed to create
Persistent task [Validate] with id [TASK-010] and allocation id [ALLOCATION-010] failed to create
Persistent task [Copy] with id [TASK-011] and allocation id [ALLOCATION-011] failed to create
Persistent task [Archiv] with id [TASK-012] and allocation id [ALLOCATION-012] failed to create
Persistent task [Merge] with id [TASK-013] and allocation id [ALLOCATION-013] failed to create
Persistent task [Split] with id [TASK-014] and allocation id [ALLOCATION-014] failed to create
high disk watermark exceeded on node2 but an automatic reroute has occurred in the last [15s], skipping reroute
high disk watermark exceeded on node3 but an automatic reroute has occurred in the last [20s], skipping reroute
high disk watermark exceeded on node4 but an automatic reroute has occurred in the last [15s], skipping reroute
high disk watermark exceeded on node5 but an automatic reroute has occurred in the last [10s], skipping reroute
high disk watermark exceeded on node6 but an automatic reroute has occurred in the last [25s], skipping reroute
high disk watermark exceeded on node7 but an automatic reroute has occurred in the last [15s], skipping reroute
high disk watermark exceeded on node8 but an automatic reroute has occurred in the last [20s], skipping reroute
high disk watermark exceeded on node9 but an automatic reroute has occurred in the last [10s], skipping reroute
high disk watermark exceeded on node10 but an automatic reroute has occurred in the last [15s], skipping reroute
high disk watermark exceeded on node11 but an automatic reroute has occurred in the last [20s], skipping reroute
high disk watermark exceeded on node12 but an automatic reroute has occurred in the last [25s], skipping reroute
high disk watermark exceeded on node13 but an automatic reroute has occurred in the last [10s], skipping reroute
high disk watermark exceeded on node14 but an automatic reroute has occurred in the last [15s], skipping reroute
low disk watermark [90%] no longer exceeded on D:\\
low disk watermark [80%] no longer exceeded on E:\\
low disk watermark [85%] no longer exceeded on F:\\
low disk watermark [75%] no longer exceeded on G:\\
low disk watermark [70%] no longer exceeded on H:\\
low disk watermark [65%] no longer exceeded on I:\\
low disk watermark [60%] no longer exceeded on J:\\
low disk watermark [55%] no longer exceeded on K:\\
low disk watermark [50%] no longer exceeded on L:\\
low disk watermark [45%] no longer exceeded on M:\\
low disk watermark [40%] no longer exceeded on N:\\
low disk watermark [35%] no longer exceeded on O:\\
low disk watermark [30%] no longer exceeded on P:\\
Found unregistered persistent task [executeTask] with id [789] and allocation id [012] - cancelling
Found unregistered persistent task [runProcess] with id [345] and allocation id [678] - cancelling
Found unregistered persistent task [performAction] with id [901] and allocation id [234] - cancelling
Found unregistered persistent task [handleTask] with id [567] and allocation id [890] - cancelling
Found unregistered persistent task [processData] with id [432] and allocation id [765] - cancelling
Found unregistered persistent task [completeTask] with id [987] and allocation id [210] - cancelling
Found unregistered persistent task [executeAction] with id [654] and allocation id [098] - cancelling
Found unregistered persistent task [invokeTask] with id [321] and allocation id [654] - cancelling
Found unregistered persistent task [performOperation] with id [876] and allocation id [109] - cancelling
Found unregistered persistent task [handleEvent] with id [543] and allocation id [432] - cancelling
Found unregistered persistent task [processRequest] with id [210] and allocation id [543] - cancelling
Found unregistered persistent task [completeAction] with id [321] and allocation id [876] - cancelling
Found unregistered persistent task [executeProcess] with id [543] and allocation id [765] - cancelling
periodic persistent task assignment check running for cluster state 5.0.2
periodic persistent task assignment check running for cluster state 3.7.0
periodic persistent task assignment check running for cluster state 2.5.4
periodic persistent task assignment check running for cluster state 6.1.3
periodic persistent task assignment check running for cluster state 4.4.7
periodic persistent task assignment check running for cluster state 3.2.9
periodic persistent task assignment check running for cluster state 5.2.0
periodic persistent task assignment check running for cluster state 2.1.6
periodic persistent task assignment check running for cluster state 6.3.8
periodic persistent task assignment check running for cluster state 3.9.5
periodic persistent task assignment check running for cluster state 4.5.1
periodic persistent task assignment check running for cluster state 5.4.6
periodic persistent task assignment check running for cluster state 2.7.3
flood stage disk watermark [90%] exceeded on nvme0n1, all indices on this node will be marked read-only
flood stage disk watermark [85%] exceeded on sdb, all indices on this node will be marked read-only
flood stage disk watermark [90%] exceeded on sdc, all indices on this node will be marked read-only
flood stage disk watermark [80%] exceeded on vda, all indices on this node will be marked read-only
flood stage disk watermark [95%] exceeded on vdb, all indices on this node will be marked read-only
flood stage disk watermark [75%] exceeded on sdd, all indices on this node will be marked read-only
flood stage disk watermark [80%] exceeded on vdc, all indices on this node will be marked read-only
flood stage disk watermark [70%] exceeded on hdc, all indices on this node will be marked read-only
flood stage disk watermark [85%] exceeded on vdd, all indices on this node will be marked read-only
flood stage disk watermark [75%] exceeded on hda, all indices on this node will be marked read-only
flood stage disk watermark [70%] exceeded on hdb, all indices on this node will be marked read-only
flood stage disk watermark [60%] exceeded on hdd, all indices on this node will be marked read-only
flood stage disk watermark [65%] exceeded on vde, all indices on this node will be marked read-only
ignoring task 2 because assignment is the same B
ignoring task 3 because assignment is the same C
ignoring task 4 because assignment is the same D
ignoring task 5 because assignment is the same E
ignoring task 6 because assignment is the same F
ignoring task 7 because assignment is the same G
ignoring task 8 because assignment is the same H
ignoring task 9 because assignment is the same I
ignoring task 10 because assignment is the same J
ignoring task 11 because assignment is the same K
ignoring task 12 because assignment is the same L
ignoring task 13 because assignment is the same M
ignoring task 14 because assignment is the same N
ignoring task 2 because it is still running
ignoring task 3 because it is still running
ignoring task 4 because it is still running
ignoring task 5 because it is still running
ignoring task 6 because it is still running
ignoring task 7 because it is still running
ignoring task 8 because it is still running
ignoring task 9 because it is still running
ignoring task 10 because it is still running
ignoring task 11 because it is still running
ignoring task 12 because it is still running
ignoring task 13 because it is still running
ignoring task 14 because it is still running
using node_concurrent_outgoing_recoveries [2], node_concurrent_incoming_recoveries [5], node_initial_primaries_recoveries [8], node_initial_replicas_recoveries [6]
using node_concurrent_outgoing_recoveries [9], node_concurrent_incoming_recoveries [1], node_initial_primaries_recoveries [7], node_initial_replicas_recoveries [4]
using node_concurrent_outgoing_recoveries [3], node_concurrent_incoming_recoveries [8], node_initial_primaries_recoveries [6], node_initial_replicas_recoveries [1]
using node_concurrent_outgoing_recoveries [6], node_concurrent_incoming_recoveries [4], node_initial_primaries_recoveries [2], node_initial_replicas_recoveries [5]
using node_concurrent_outgoing_recoveries [1], node_concurrent_incoming_recoveries [7], node_initial_primaries_recoveries [4], node_initial_replicas_recoveries [3]
using node_concurrent_outgoing_recoveries [5], node_concurrent_incoming_recoveries [3], node_initial_primaries_recoveries [1], node_initial_replicas_recoveries [8]
using node_concurrent_outgoing_recoveries [8], node_concurrent_incoming_recoveries [6], node_initial_primaries_recoveries [5], node_initial_replicas_recoveries [7]
using node_concurrent_outgoing_recoveries [7], node_concurrent_incoming_recoveries [2], node_initial_primaries_recoveries [9], node_initial_replicas_recoveries [4]
using node_concurrent_outgoing_recoveries [6], node_concurrent_incoming_recoveries [9], node_initial_primaries_recoveries [4], node_initial_replicas_recoveries [8]
using node_concurrent_outgoing_recoveries [3], node_concurrent_incoming_recoveries [1], node_initial_primaries_recoveries [7], node_initial_replicas_recoveries [9]
using node_concurrent_outgoing_recoveries [9], node_concurrent_incoming_recoveries [5], node_initial_primaries_recoveries [2], node_initial_replicas_recoveries [4]
using node_concurrent_outgoing_recoveries [4], node_concurrent_incoming_recoveries [8], node_initial_primaries_recoveries [6], node_initial_replicas_recoveries [3]
using node_concurrent_outgoing_recoveries [1], node_concurrent_incoming_recoveries [3], node_initial_primaries_recoveries [5], node_initial_replicas_recoveries [2]
using node_concurrent_outgoing_recoveries [8], node_concurrent_incoming_recoveries [4], node_initial_primaries_recoveries [7], node_initial_replicas_recoveries [5]
failed to reassign persistent tasks: ArrayIndexOutOfBoundsException
failed to reassign persistent tasks: IllegalArgumentException
failed to reassign persistent tasks: ClassCastException
failed to reassign persistent tasks: ArithmeticException
failed to reassign persistent tasks: IllegalStateException
failed to reassign persistent tasks: IndexOutOfBoundsException
failed to reassign persistent tasks: FileNotFoundException
failed to reassign persistent tasks: UnsupportedOperationException
failed to reassign persistent tasks: NoSuchMethodException
failed to reassign persistent tasks: OutOfMemoryError
failed to reassign persistent tasks: StackOverflowError
failed to reassign persistent tasks: RuntimeException
failed to reassign persistent tasks: AssertionError
checking task reassignment for cluster state 2
checking task reassignment for cluster state 3
checking task reassignment for cluster state 4
checking task reassignment for cluster state 5
checking task reassignment for cluster state 6
checking task reassignment for cluster state 7
checking task reassignment for cluster state 8
checking task reassignment for cluster state 9
checking task reassignment for cluster state 10
checking task reassignment for cluster state 11
checking task reassignment for cluster state 12
checking task reassignment for cluster state 13
checking task reassignment for cluster state 14
Unassigning task 456 with allocation id 654
Unassigning task 789 with allocation id 321
Unassigning task 102 with allocation id 430
Unassigning task 205 with allocation id 873
Unassigning task 308 with allocation id 216
Unassigning task 511 with allocation id 649
Unassigning task 614 with allocation id 278
Unassigning task 717 with allocation id 895
Unassigning task 820 with allocation id 762
Unassigning task 923 with allocation id 439
Unassigning task 1026 with allocation id 986
Unassigning task 1129 with allocation id 567
Unassigning task 1232 with allocation id 324
Evaluating node: node2 for autoExpandReplica eligibility of index: index2
Evaluating node: node3 for autoExpandReplica eligibility of index: index3
Evaluating node: node4 for autoExpandReplica eligibility of index: index4
Evaluating node: node5 for autoExpandReplica eligibility of index: index5
Evaluating node: node6 for autoExpandReplica eligibility of index: index6
Evaluating node: node7 for autoExpandReplica eligibility of index: index7
Evaluating node: node8 for autoExpandReplica eligibility of index: index8
Evaluating node: node9 for autoExpandReplica eligibility of index: index9
Evaluating node: node10 for autoExpandReplica eligibility of index: index10
Evaluating node: node11 for autoExpandReplica eligibility of index: index11
Evaluating node: node12 for autoExpandReplica eligibility of index: index12
Evaluating node: node13 for autoExpandReplica eligibility of index: index13
Evaluating node: node14 for autoExpandReplica eligibility of index: index14
trying to update state on task abc with unexpected allocation id def
trying to update state on task xyz with unexpected allocation id 789
trying to update state on task qwe with unexpected allocation id rty
trying to update state on task 987 with unexpected allocation id 654
trying to update state on task jkl with unexpected allocation id mno
trying to update state on task pqr with unexpected allocation id stu
trying to update state on task vwx with unexpected allocation id yz
trying to update state on task 321 with unexpected allocation id 654
trying to update state on task 987 with unexpected allocation id 123
trying to update state on task abc with unexpected allocation id 789
trying to update state on task xyz with unexpected allocation id def
trying to update state on task qwe with unexpected allocation id 456
trying to update state on task jkl with unexpected allocation id stu
trying to update state on non-existing task 5678
trying to update state on non-existing task 9123
trying to update state on non-existing task 4567
trying to update state on non-existing task 8901
trying to update state on non-existing task 2345
trying to update state on non-existing task 6789
trying to update state on non-existing task 3210
trying to update state on non-existing task 7890
trying to update state on non-existing task 3456
trying to update state on non-existing task 7890
trying to update state on non-existing task 7654
trying to update state on non-existing task 0987
trying to update state on non-existing task 5432
Shard: shard2 has target pool: poolB. Cannot allocate on node: node2 with target pool: poolA
Shard: shard3 has target pool: poolC. Cannot allocate on node: node3 with target pool: poolD
Shard: shard4 has target pool: poolD. Cannot allocate on node: node4 with target pool: poolC
Shard: shard5 has target pool: poolE. Cannot allocate on node: node5 with target pool: poolF
Shard: shard6 has target pool: poolF. Cannot allocate on node: node6 with target pool: poolE
Shard: shard7 has target pool: poolG. Cannot allocate on node: node7 with target pool: poolH
Shard: shard8 has target pool: poolH. Cannot allocate on node: node8 with target pool: poolG
Shard: shard9 has target pool: poolI. Cannot allocate on node: node9 with target pool: poolJ
Shard: shard10 has target pool: poolJ. Cannot allocate on node: node10 with target pool: poolI
Shard: shard11 has target pool: poolK. Cannot allocate on node: node11 with target pool: poolL
Shard: shard12 has target pool: poolL. Cannot allocate on node: node12 with target pool: poolK
Shard: shard13 has target pool: poolM. Cannot allocate on node: node13 with target pool: poolN
Shard: shard14 has target pool: poolN. Cannot allocate on node: node14 with target pool: poolM
The task Task2 with id 234 was found but it has a different allocation id 789, status is not updated
The task Task3 with id 345 was found but it has a different allocation id 912, status is not updated
The task Task4 with id 456 was found but it has a different allocation id 345, status is not updated
The task Task5 with id 567 was found but it has a different allocation id 678, status is not updated
The task Task6 with id 678 was found but it has a different allocation id 234, status is not updated
The task Task7 with id 789 was found but it has a different allocation id 567, status is not updated
The task Task8 with id 890 was found but it has a different allocation id 901, status is not updated
The task Task9 with id 901 was found but it has a different allocation id 890, status is not updated
The task Task10 with id 912 was found but it has a different allocation id 678, status is not updated
The task Task11 with id 123 was found but it has a different allocation id 345, status is not updated
The task Task12 with id 234 was found but it has a different allocation id 567, status is not updated
The task Task13 with id 345 was found but it has a different allocation id 901, status is not updated
The task Task14 with id 456 was found but it has a different allocation id 912, status is not updated
Shard: [shardRouting2] has target pool: [shardPool2]. Cannot allocate on node: [node.node()2] without the [DiscoveryNodeRole.DATA_ROLE2] node role
Shard: [shardRouting3] has target pool: [shardPool3]. Cannot allocate on node: [node.node()3] without the [DiscoveryNodeRole.DATA_ROLE3] node role
Shard: [shardRouting4] has target pool: [shardPool4]. Cannot allocate on node: [node.node()4] without the [DiscoveryNodeRole.DATA_ROLE4] node role
Shard: [shardRouting5] has target pool: [shardPool5]. Cannot allocate on node: [node.node()5] without the [DiscoveryNodeRole.DATA_ROLE5] node role
Shard: [shardRouting6] has target pool: [shardPool6]. Cannot allocate on node: [node.node()6] without the [DiscoveryNodeRole.DATA_ROLE6] node role
Shard: [shardRouting7] has target pool: [shardPool7]. Cannot allocate on node: [node.node()7] without the [DiscoveryNodeRole.DATA_ROLE7] node role
Shard: [shardRouting8] has target pool: [shardPool8]. Cannot allocate on node: [node.node()8] without the [DiscoveryNodeRole.DATA_ROLE8] node role
Shard: [shardRouting9] has target pool: [shardPool9]. Cannot allocate on node: [node.node()9] without the [DiscoveryNodeRole.DATA_ROLE9] node role
Shard: [shardRouting10] has target pool: [shardPool10]. Cannot allocate on node: [node.node()10] without the [DiscoveryNodeRole.DATA_ROLE10] node role
Shard: [shardRouting11] has target pool: [shardPool11]. Cannot allocate on node: [node.node()11] without the [DiscoveryNodeRole.DATA_ROLE11] node role
Shard: [shardRouting12] has target pool: [shardPool12]. Cannot allocate on node: [node.node()12] without the [DiscoveryNodeRole.DATA_ROLE12] node role
Shard: [shardRouting13] has target pool: [shardPool13]. Cannot allocate on node: [node.node()13] without the [DiscoveryNodeRole.DATA_ROLE13] node role
Shard: [shardRouting14] has target pool: [shardPool14]. Cannot allocate on node: [node.node()14] without the [DiscoveryNodeRole.DATA_ROLE14] node role
The task [352] wasn't found, status is not updated
The task [125] wasn't found, status is not updated
The task [901] wasn't found, status is not updated
The task [649] wasn't found, status is not updated
The task [237] wasn't found, status is not updated
The task [815] wasn't found, status is not updated
The task [426] wasn't found, status is not updated
The task [783] wasn't found, status is not updated
The task [524] wasn't found, status is not updated
The task [679] wasn't found, status is not updated
The task [164] wasn't found, status is not updated
The task [343] wasn't found, status is not updated
The task [597] wasn't found, status is not updated
The task [871] wasn't found, status is not updated
persistent task 456 failed with error code 404
persistent task 789 failed with error code 503
persistent task 321 failed with error code 400
persistent task 654 failed with error code 502
persistent task 987 failed with error code 403
persistent task 135 failed with error code 501
persistent task 864 failed with error code 405
persistent task 246 failed with error code 502
persistent task 579 failed with error code 401
persistent task 753 failed with error code 503
persistent task 864 failed with error code 404
persistent task 159 failed with error code 500
persistent task 975 failed with error code 401
Preventing snapshotted shard [2] from being moved away from node [node2]
Preventing snapshotted shard [3] from being moved away from node [node1]
Preventing snapshotted shard [4] from being moved away from node [node3]
Preventing snapshotted shard [5] from being moved away from node [node2]
Preventing snapshotted shard [6] from being moved away from node [node3]
Preventing snapshotted shard [7] from being moved away from node [node1]
Preventing snapshotted shard [8] from being moved away from node [node2]
Preventing snapshotted shard [9] from being moved away from node [node1]
Preventing snapshotted shard [10] from being moved away from node [node3]
Preventing snapshotted shard [11] from being moved away from node [node2]
Preventing snapshotted shard [12] from being moved away from node [node3]
Preventing snapshotted shard [13] from being moved away from node [node1]
Preventing snapshotted shard [14] from being moved away from node [node2]
notification for task [delete] with id [5678] was successful
notification for task [update] with id [9876] was successful
notification for task [archive] with id [5432] was successful
notification for task [create] with id [3456] was successful
notification for task [send] with id [7890] was successful
notification for task [approve] with id [2345] was successful
notification for task [reject] with id [6789] was successful
notification for task [validate] with id [8901] was successful
notification for task [cancel] with id [4321] was successful
notification for task [execute] with id [6543] was successful
notification for task [review] with id [1098] was successful
notification for task [complete] with id [8765] was successful
notification for task [assign] with id [2109] was successful
getDiskUsage(subtractLeavingShards=false) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=1) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=0) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=enable) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=disable) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=on) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=off) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=yes) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=no) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=1.5) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=2.5) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=high) returning diskUsageWithRelocations
getDiskUsage(subtractLeavingShards=low) returning diskUsageWithRelocations
unable to determine disk usage for node-2, defaulting to average across nodes [200GB total] [80GB free] [40% free]
unable to determine disk usage for node-3, defaulting to average across nodes [150GB total] [30GB free] [80% free]
unable to determine disk usage for node-4, defaulting to average across nodes [120GB total] [60GB free] [50% free]
unable to determine disk usage for node-5, defaulting to average across nodes [180GB total] [90GB free] [50% free]
unable to determine disk usage for node-6, defaulting to average across nodes [90GB total] [45GB free] [50% free]
unable to determine disk usage for node-7, defaulting to average across nodes [160GB total] [70GB free] [50% free]
unable to determine disk usage for node-8, defaulting to average across nodes [110GB total] [55GB free] [50% free]
unable to determine disk usage for node-9, defaulting to average across nodes [130GB total] [65GB free] [50% free]
unable to determine disk usage for node-10, defaulting to average across nodes [140GB total] [70GB free] [50% free]
unable to determine disk usage for node-11, defaulting to average across nodes [170GB total] [85GB free] [50% free]
unable to determine disk usage for node-12, defaulting to average across nodes [100GB total] [40GB free] [60% free]
unable to determine disk usage for node-13, defaulting to average across nodes [200GB total] [100GB free] [50% free]
unable to determine disk usage for node-14, defaulting to average across nodes [180GB total] [90GB free] [50% free]
less than the required 85% free disk threshold (600GB) on node Node2, shard cannot remain
less than the required 90% free disk threshold (700GB) on node Node3, shard cannot remain
less than the required 75% free disk threshold (450GB) on node Node4, shard cannot remain
less than the required 85% free disk threshold (550GB) on node Node5, shard cannot remain
less than the required 90% free disk threshold (800GB) on node Node6, shard cannot remain
less than the required 80% free disk threshold (400GB) on node Node7, shard cannot remain
less than the required 85% free disk threshold (550GB) on node Node8, shard cannot remain
less than the required 90% free disk threshold (700GB) on node Node9, shard cannot remain
less than the required 75% free disk threshold (450GB) on node Node10, shard cannot remain
less than the required 85% free disk threshold (600GB) on node Node11, shard cannot remain
less than the required 90% free disk threshold (750GB) on node Node12, shard cannot remain
less than the required 80% free disk threshold (500GB) on node Node13, shard cannot remain
less than the required 85% free disk threshold (600GB) on node Node14, shard cannot remain
remote backed storage repository with name archive2 and type azure created
remote backed storage repository with name snapshot3 and type google created
remote backed storage repository with name backup4 and type aws created
remote backed storage repository with name archive5 and type s3 created
remote backed storage repository with name snapshot6 and type google created
remote backed storage repository with name backup7 and type azure created
remote backed storage repository with name archive8 and type aws created
remote backed storage repository with name snapshot9 and type s3 created
remote backed storage repository with name backup10 and type google created
remote backed storage repository with name archive11 and type azure created
remote backed storage repository with name snapshot12 and type aws created
remote backed storage repository with name backup13 and type s3 created
remote backed storage repository with name archive14 and type google created
less than the required 200000000 free bytes threshold (190000000 bytes free) on node 2, shard cannot remain
less than the required 500000000 free bytes threshold (480000000 bytes free) on node 3, shard cannot remain
less than the required 150000000 free bytes threshold (140000000 bytes free) on node 4, shard cannot remain
less than the required 300000000 free bytes threshold (280000000 bytes free) on node 5, shard cannot remain
less than the required 400000000 free bytes threshold (390000000 bytes free) on node 6, shard cannot remain
less than the required 600000000 free bytes threshold (580000000 bytes free) on node 7, shard cannot remain
less than the required 250000000 free bytes threshold (240000000 bytes free) on node 8, shard cannot remain
less than the required 700000000 free bytes threshold (680000000 bytes free) on node 9, shard cannot remain
less than the required 350000000 free bytes threshold (330000000 bytes free) on node 10, shard cannot remain
less than the required 450000000 free bytes threshold (440000000 bytes free) on node 11, shard cannot remain
less than the required 550000000 free bytes threshold (520000000 bytes free) on node 12, shard cannot remain
less than the required 800000000 free bytes threshold (790000000 bytes free) on node 13, shard cannot remain
less than the required 900000000 free bytes threshold (880000000 bytes free) on node 14, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 75% on node node-2 including 8192000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 90% on node node-3 including 4096000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 85% on node node-4 including 6144000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 70% on node node-5 including 10240000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 95% on node node-6 including 3072000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 60% on node node-7 including 6144000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 75% on node node-8 including 4096000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 70% on node node-9 including 8192000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 80% on node node-10 including 5120000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 85% on node node-11 including 4096000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 90% on node node-12 including 6144000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 95% on node node-13 including 8192000 bytes of relocations, shard cannot remain
fewer free bytes remaining than the size of all incoming shards: usage 60% on node node-14 including 3072000 bytes of relocations, shard cannot remain
timed out while waiting for initial discovery state - timeout: 10000
timed out while waiting for initial discovery state - timeout: 15000
timed out while waiting for initial discovery state - timeout: 20000
timed out while waiting for initial discovery state - timeout: 25000
timed out while waiting for initial discovery state - timeout: 30000
timed out while waiting for initial discovery state - timeout: 35000
timed out while waiting for initial discovery state - timeout: 40000
timed out while waiting for initial discovery state - timeout: 45000
timed out while waiting for initial discovery state - timeout: 50000
timed out while waiting for initial discovery state - timeout: 55000
timed out while waiting for initial discovery state - timeout: 60000
timed out while waiting for initial discovery state - timeout: 65000
timed out while waiting for initial discovery state - timeout: 70000
waiting to join the cluster. timeout [2000]
waiting to join the cluster. timeout [3000]
waiting to join the cluster. timeout [4000]
waiting to join the cluster. timeout [5000]
waiting to join the cluster. timeout [6000]
waiting to join the cluster. timeout [7000]
waiting to join the cluster. timeout [8000]
waiting to join the cluster. timeout [9000]
waiting to join the cluster. timeout [10000]
waiting to join the cluster. timeout [11000]
waiting to join the cluster. timeout [12000]
waiting to join the cluster. timeout [13000]
waiting to join the cluster. timeout [14000]
after allocating [shard456] node [node2] would have more than the allowed 80% free disk threshold (82% free), preventing allocation
after allocating [shard789] node [node3] would have more than the allowed 80% free disk threshold (70% free), preventing allocation
after allocating [shard012] node [node4] would have more than the allowed 80% free disk threshold (78% free), preventing allocation
after allocating [shard345] node [node5] would have more than the allowed 80% free disk threshold (65% free), preventing allocation
after allocating [shard678] node [node6] would have more than the allowed 80% free disk threshold (80% free), preventing allocation
after allocating [shard901] node [node7] would have more than the allowed 80% free disk threshold (77% free), preventing allocation
after allocating [shard234] node [node8] would have more than the allowed 80% free disk threshold (85% free), preventing allocation
after allocating [shard567] node [node9] would have more than the allowed 80% free disk threshold (68% free), preventing allocation
after allocating [shard890] node [node10] would have more than the allowed 80% free disk threshold (73% free), preventing allocation
after allocating [shard123] node [node11] would have more than the allowed 80% free disk threshold (79% free), preventing allocation
after allocating [shard456] node [node12] would have more than the allowed 80% free disk threshold (72% free), preventing allocation
after allocating [shard789] node [node13] would have more than the allowed 80% free disk threshold (87% free), preventing allocation
after allocating [shard012] node [node14] would have more than the allowed 80% free disk threshold (60% free), preventing allocation
Identity on so found plugins implementing: plugin2
Identity on so found plugins implementing: plugin3
Identity on so found plugins implementing: plugin4
Identity on so found plugins implementing: plugin5
Identity on so found plugins implementing: plugin6
Identity on so found plugins implementing: plugin7
Identity on so found plugins implementing: plugin8
Identity on so found plugins implementing: plugin9
Identity on so found plugins implementing: plugin10
Identity on so found plugins implementing: plugin11
Identity on so found plugins implementing: plugin12
Identity on so found plugins implementing: plugin13
Identity on so found plugins implementing: plugin14
more than the allowed 80.5% used disk threshold (68.9% used) on node [node2], preventing allocation
more than the allowed 87.8% used disk threshold (74.6% used) on node [node3], preventing allocation
more than the allowed 82.7% used disk threshold (69.8% used) on node [node4], preventing allocation
more than the allowed 89.1% used disk threshold (76.5% used) on node [node5], preventing allocation
more than the allowed 84.2% used disk threshold (71.2% used) on node [node6], preventing allocation
more than the allowed 81.9% used disk threshold (68.3% used) on node [node7], preventing allocation
more than the allowed 88.3% used disk threshold (75.2% used) on node [node8], preventing allocation
more than the allowed 83.4% used disk threshold (70.5% used) on node [node9], preventing allocation
more than the allowed 90.0% used disk threshold (77.9% used) on node [node10], preventing allocation
more than the allowed 86.5% used disk threshold (73.8% used) on node [node11], preventing allocation
more than the allowed 79.8% used disk threshold (67.1% used) on node [node12], preventing allocation
more than the allowed 77.1% used disk threshold (65.4% used) on node [node13], preventing allocation
more than the allowed 92.3% used disk threshold (79.7% used) on node [node14], preventing allocation
version [7.10.2] is a pre-release version of OpenSearch and is not suitable for production
version [6.8.0] is a pre-release version of OpenSearch and is not suitable for production
version [1.2.3] is a pre-release version of OpenSearch and is not suitable for production
version [2.4.1] is a pre-release version of OpenSearch and is not suitable for production
version [5.6.0] is a pre-release version of OpenSearch and is not suitable for production
version [3.1.2] is a pre-release version of OpenSearch and is not suitable for production
version [4.5.0] is a pre-release version of OpenSearch and is not suitable for production
version [9.9.9] is a pre-release version of OpenSearch and is not suitable for production
version [6.0.0] is a pre-release version of OpenSearch and is not suitable for production
version [3.0.1] is a pre-release version of OpenSearch and is not suitable for production
version [7.0.2] is a pre-release version of OpenSearch and is not suitable for production
version [5.5.5] is a pre-release version of OpenSearch and is not suitable for production
version [2.1.0] is a pre-release version of OpenSearch and is not suitable for production
more than the allowed 80% used disk threshold (70% used) on node [node2], but allowing allocation because primary has never been allocated
more than the allowed 60% used disk threshold (50% used) on node [node3], but allowing allocation because primary has never been allocated
more than the allowed 70% used disk threshold (60% used) on node [node4], but allowing allocation because primary has never been allocated
more than the allowed 50% used disk threshold (40% used) on node [node5], but allowing allocation because primary has never been allocated
more than the allowed 80% used disk threshold (70% used) on node [node6], but allowing allocation because primary has never been allocated
more than the allowed 70% used disk threshold (60% used) on node [node7], but allowing allocation because primary has never been allocated
more than the allowed 60% used disk threshold (50% used) on node [node8], but allowing allocation because primary has never been allocated
more than the allowed 90% used disk threshold (80% used) on node [node9], but allowing allocation because primary has never been allocated
more than the allowed 50% used disk threshold (40% used) on node [node10], but allowing allocation because primary has never been allocated
more than the allowed 60% used disk threshold (50% used) on node [node11], but allowing allocation because primary has never been allocated
more than the allowed 70% used disk threshold (60% used) on node [node12], but allowing allocation because primary has never been allocated
more than the allowed 80% used disk threshold (70% used) on node [node13], but allowing allocation because primary has never been allocated
more than the allowed 90% used disk threshold (80% used) on node [node14], but allowing allocation because primary has never been allocated
JVM arguments [-Xmx1024m, -Xms512m, -XX:MaxMetaspaceSize=256m]
JVM arguments [-Xmx2048m, -Xms1024m, -XX:MaxMetaspaceSize=512m]
JVM arguments [-Xmx4096m, -Xms2048m, -XX:MaxMetaspaceSize=1024m]
JVM arguments [-Xmx8192m, -Xms4096m, -XX:MaxMetaspaceSize=2048m]
JVM arguments [-Xmx16384m, -Xms8192m, -XX:MaxMetaspaceSize=4096m]
JVM arguments [-Xmx32768m, -Xms16384m, -XX:MaxMetaspaceSize=8192m]
JVM arguments [-Xmx65536m, -Xms32768m, -XX:MaxMetaspaceSize=16384m]
JVM arguments [-Xmx131072m, -Xms65536m, -XX:MaxMetaspaceSize=32768m]
JVM arguments [-Xmx262144m, -Xms131072m, -XX:MaxMetaspaceSize=65536m]
JVM arguments [-Xmx524288m, -Xms262144m, -XX:MaxMetaspaceSize=131072m]
JVM arguments [-Xmx1048576m, -Xms524288m, -XX:MaxMetaspaceSize=262144m]
JVM arguments [-Xmx2097152m, -Xms1048576m, -XX:MaxMetaspaceSize=524288m]
JVM arguments [-Xmx4194304m, -Xms2097152m, -XX:MaxMetaspaceSize=1048576m]
less than the required 80% free bytes threshold (20% bytes free) on node node2, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (12% bytes free) on node node3, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (18% bytes free) on node node4, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (25% bytes free) on node node5, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (17% bytes free) on node node6, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (22% bytes free) on node node7, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (14% bytes free) on node node8, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (23% bytes free) on node node9, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (10% bytes free) on node node10, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (19% bytes free) on node node11, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (16% bytes free) on node node12, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (21% bytes free) on node node13, preventing allocation even though primary has never been allocated
less than the required 80% free bytes threshold (13% bytes free) on node node14, preventing allocation even though primary has never been allocated
JVM home [/usr/local/openjdk-11], using bundled JDK/JRE [false]
JVM home [/usr/lib/jvm/java-1.7.0-openjdk], using bundled JDK/JRE [true]
JVM home [/opt/java/jdk1.6.0_45], using bundled JDK/JRE [false]
JVM home [/usr/lib/jvm/java-1.11.0-openjdk-amd64], using bundled JDK/JRE [true]
JVM home [/usr/lib/jvm/java-1.8.0-openjdk-amd64], using bundled JDK/JRE [true]
JVM home [/Library/Java/JavaVirtualMachines/jdk1.8.0_212.jdk/Contents/Home], using bundled JDK/JRE [false]
JVM home [/usr/java], using bundled JDK/JRE [true]
JVM home [/usr/lib/jvm/java-8-oracle], using bundled JDK/JRE [false]
JVM home [/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el8_2.x86_64], using bundled JDK/JRE [true]
JVM home [/usr/lib/jvm/java-1.8.0-oracle-1.8.0.262.b17-1.el7.x86_64], using bundled JDK/JRE [false]
JVM home [/opt/jdk1.8.0_212], using bundled JDK/JRE [true]
JVM home [/usr/lib/jvm/java-11-openjdk-amd64], using bundled JDK/JRE [true]
JVM home [/usr/lib/jvm/java-8-openjdk-amd64], using bundled JDK/JRE [true]
less than the required 100MB free bytes threshold (90MB free) on node 2, preventing allocation
less than the required 100MB free bytes threshold (85MB free) on node 3, preventing allocation
less than the required 100MB free bytes threshold (80MB free) on node 4, preventing allocation
less than the required 100MB free bytes threshold (75MB free) on node 5, preventing allocation
less than the required 100MB free bytes threshold (70MB free) on node 6, preventing allocation
less than the required 100MB free bytes threshold (65MB free) on node 7, preventing allocation
less than the required 100MB free bytes threshold (60MB free) on node 8, preventing allocation
less than the required 100MB free bytes threshold (55MB free) on node 9, preventing allocation
less than the required 100MB free bytes threshold (50MB free) on node 10, preventing allocation
less than the required 100MB free bytes threshold (45MB free) on node 11, preventing allocation
less than the required 100MB free bytes threshold (40MB free) on node 12, preventing allocation
less than the required 100MB free bytes threshold (35MB free) on node 13, preventing allocation
less than the required 100MB free bytes threshold (30MB free) on node 14, preventing allocation
less than the required 200MB free bytes threshold (150MB free) on node 002, preventing allocation even though primary has never been allocated
less than the required 300MB free bytes threshold (225MB free) on node 003, preventing allocation even though primary has never been allocated
less than the required 400MB free bytes threshold (300MB free) on node 004, preventing allocation even though primary has never been allocated
less than the required 500MB free bytes threshold (375MB free) on node 005, preventing allocation even though primary has never been allocated
less than the required 600MB free bytes threshold (450MB free) on node 006, preventing allocation even though primary has never been allocated
less than the required 700MB free bytes threshold (525MB free) on node 007, preventing allocation even though primary has never been allocated
less than the required 800MB free bytes threshold (600MB free) on node 008, preventing allocation even though primary has never been allocated
less than the required 900MB free bytes threshold (675MB free) on node 009, preventing allocation even though primary has never been allocated
less than the required 1000MB free bytes threshold (750MB free) on node 010, preventing allocation even though primary has never been allocated
less than the required 1100MB free bytes threshold (825MB free) on node 011, preventing allocation even though primary has never been allocated
less than the required 1200MB free bytes threshold (900MB free) on node 012, preventing allocation even though primary has never been allocated
less than the required 1300MB free bytes threshold (975MB free) on node 013, preventing allocation even though primary has never been allocated
less than the required 1400MB free bytes threshold (1050MB free) on node 014, preventing allocation even though primary has never been allocated
node [B] has 25% used disk
node [C] has 40% used disk
node [D] has 15% used disk
node [E] has 5% used disk
node [F] has 30% used disk
node [G] has 20% used disk
node [H] has 35% used disk
node [I] has 8% used disk
node [J] has 28% used disk
node [K] has 12% used disk
node [L] has 22% used disk
node [M] has 18% used disk
node [N] has 33% used disk
version[1.0.0], pid[1234], build[release/abc123/2024-01-10], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_281/25.281-b09]
version[2.0.0], pid[2345], build[debug/def456/2024-01-11], OS[Linux/5.4.0-65-generic/x86_64], JVM[AdoptOpenJDK/OpenJDK 64-Bit Server VM/11.0.10+9/11.0.10+9]
version[3.0.0], pid[3456], build[alpha/ghi789/2024-01-12], OS[Mac OS X/10.15.7/x86_64], JVM[Amazon.com Inc./OpenJDK 64-Bit Server VM/15.0.2+7/15.0.2+7]
version[4.0.0], pid[4567], build[beta/jkl012/2024-01-13], OS[Windows Server 2019/10.0/amd64], JVM[Azul Systems, Inc./Zing 64-Bit Tiered VM/8.0.282.8.0.282.8-b1/1.8.0_282]
version[5.0.0], pid[5678], build[stable/mno345/2024-01-14], OS[Ubuntu/20.04.1 LTS/x86_64], JVM[Red Hat, Inc./OpenJDK 64-Bit Server VM/14.0.2+12/14.0.2+12]
version[6.0.0], pid[6789], build[release/pqr678/2024-01-15], OS[CentOS/7.9.2009/x86_64], JVM[SAP SE/SAP Machine/11.0.10+9-LTS/11.0.10+9-LTS]
version[7.0.0], pid[7890], build[debug/stu901/2024-01-16], OS[Debian/10.7/x86_64], JVM[Eclipse Foundation/Eclipse OpenJ9 VM/openj9-0.24.0/openj9-0.24.0]
version[8.0.0], pid[8901], build[alpha/vwx234/2024-01-17], OS[Fedora/33/x86_64], JVM[BellSoft/Liberica JDK 15/15.0.2+10/15.0.2+10]
version[9.0.0], pid[9012], build[beta/yzw567/2024-01-18], OS[FreeBSD/12.2/amd64], JVM[JetBrains s.r.o./OpenJDK 64-Bit Server VM/1.8.0_275-b01/25.275-b01]
version[10.0.0], pid[0123], build[stable/abc890/2024-01-19], OS[OpenBSD/6.8/amd64], JVM[GraalVM/GraalVM 21.0.0/11.0.10/11.0.10+8-jvmci-21.0-b06]
version[11.0.0], pid[1230], build[release/def123/2024-01-20], OS[Windows 7/6.1/x86], JVM[Oracle Corporation/Java HotSpot(TM) Client VM/1.7.0_80/24.80-b11]
version[12.0.0], pid[2340], build[debug/ghi456/2024-01-21], OS[Linux/4.15.0-135-generic/i686], JVM[AdoptOpenJDK/OpenJDK Client VM/8u282-b08/25.282-b08]
version[13.0.0], pid[3450], build[alpha/jkl789/2024-01-22], OS[Mac OS X/10.14.6/x86_64], JVM[Amazon.com Inc./OpenJDK 64-Bit Server VM/13.0.2+8/13.0.2+8]
version[14.0.0], pid[4560], build[beta/mno012/2024-01-23], OS[Windows Server 2016/10.0/amd64], JVM[Azul Systems, Inc./Zulu 64-Bit Server VM/15.0.2+7/15.0.2+7]
version[15.0.0], pid[5670], build[stable/pqr345/2024-01-24], OS[Ubuntu/18.04.5 LTS/x86_64], JVM[Red Hat, Inc./OpenJDK 64-Bit Server VM/16+36/16+36]
fewer free bytes remaining than the size of all incoming shards: usage 50% on node node-2 including 300000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 90% on node node-3 including 180000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 70% on node node-4 including 200000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 60% on node node-5 including 280000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 80% on node node-6 including 260000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 85% on node node-7 including 220000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 55% on node node-8 including 280000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 65% on node node-9 including 190000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 40% on node node-10 including 230000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 75% on node node-11 including 260000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 80% on node node-12 including 250000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 45% on node node-13 including 270000 bytes of relocations, preventing allocation
fewer free bytes remaining than the size of all incoming shards: usage 70% on node node-14 including 240000 bytes of relocations, preventing allocation
cannot compute used memory when total memory is 0 and free memory is 200
cannot compute used memory when total memory is 0 and free memory is 300
cannot compute used memory when total memory is 0 and free memory is 400
cannot compute used memory when total memory is 0 and free memory is 500
cannot compute used memory when total memory is 0 and free memory is 600
cannot compute used memory when total memory is 0 and free memory is 700
cannot compute used memory when total memory is 0 and free memory is 800
cannot compute used memory when total memory is 0 and free memory is 900
cannot compute used memory when total memory is 0 and free memory is 1000
cannot compute used memory when total memory is 0 and free memory is 1100
cannot compute used memory when total memory is 0 and free memory is 1200
cannot compute used memory when total memory is 0 and free memory is 1300
cannot compute used memory when total memory is 0 and free memory is 1400
cannot compute used swap when total swap is 0 and free swap is 200MB
cannot compute used swap when total swap is 0 and free swap is 300MB
cannot compute used swap when total swap is 0 and free swap is 400MB
cannot compute used swap when total swap is 0 and free swap is 500MB
cannot compute used swap when total swap is 0 and free swap is 600MB
cannot compute used swap when total swap is 0 and free swap is 700MB
cannot compute used swap when total swap is 0 and free swap is 800MB
cannot compute used swap when total swap is 0 and free swap is 900MB
cannot compute used swap when total swap is 0 and free swap is 1GB
cannot compute used swap when total swap is 0 and free swap is 1.1GB
cannot compute used swap when total swap is 0 and free swap is 1.2GB
cannot compute used swap when total swap is 0 and free swap is 1.3GB
cannot compute used swap when total swap is 0 and free swap is 1.4GB
Shard [shard2] can not be moved away due to [ReplicaShardMoveDecision]
Shard [shard3] can not be moved away due to [BalancedShardMoveDecision]
Shard [shard4] can not be moved away due to [PrimaryShardMoveDecision]
Shard [shard5] can not be moved away due to [ReplicaShardMoveDecision]
Shard [shard6] can not be moved away due to [BalancedShardMoveDecision]
Shard [shard7] can not be moved away due to [PrimaryShardMoveDecision]
Shard [shard8] can not be moved away due to [ReplicaShardMoveDecision]
Shard [shard9] can not be moved away due to [BalancedShardMoveDecision]
Shard [shard10] can not be moved away due to [PrimaryShardMoveDecision]
Shard [shard11] can not be moved away due to [ReplicaShardMoveDecision]
Shard [shard12] can not be moved away due to [BalancedShardMoveDecision]
Shard [shard13] can not be moved away due to [PrimaryShardMoveDecision]
Shard [shard14] can not be moved away due to [ReplicaShardMoveDecision]
error reading control group stats File not found
error reading control group stats Invalid input
error reading control group stats Permission denied
error reading control group stats Connection refused
error reading control group stats Runtime error
error reading control group stats Database query failed
error reading control group stats Invalid token
error reading control group stats Network timeout
error reading control group stats Server not responding
error reading control group stats Unexpected response
error reading control group stats Access denied
error reading control group stats Invalid request
error reading control group stats Unknown error
error reading control group stats Resource exhausted
Shard can not be allocated on node [5] due to [AllocationDecider]
Shard can not be allocated on node [3] due to [BalancingDecider]
Shard can not be allocated on node [7] due to [FilterAllocationDecider]
Shard can not be allocated on node [2] due to [AwarenessAllocationDecider]
Shard can not be allocated on node [4] due to [ClusterSettingsAllocationDecider]
Shard can not be allocated on node [9] due to [RebalanceOnlyWhenActiveAllocationDecider]
Shard can not be allocated on node [6] due to [NodeVersionAllocationDecider]
Shard can not be allocated on node [8] due to [DiskThresholdDecider]
Shard can not be allocated on node [11] due to [AwarenessAllocationDecider]
Shard can not be allocated on node [10] due to [ThresholdDecider]
Shard can not be allocated on node [14] due to [BalancingDecider]
Shard can not be allocated on node [13] due to [FilterAllocationDecider]
Shard can not be allocated on node [12] due to [ClusterSettingsAllocationDecider]
Shard [1] can not be forcefully allocated to node [node-2] due to [IncompatibleNodeAttributesDecider].
Shard [2] can not be forcefully allocated to node [node-3] due to [DiskThresholdDecider].
Shard [3] can not be forcefully allocated to node [node-4] due to [AwarenessAllocationDecider].
Shard [4] can not be forcefully allocated to node [node-5] due to [SameShardAllocationDecider].
Shard [5] can not be forcefully allocated to node [node-6] due to [FilterAllocationDecider].
Shard [6] can not be forcefully allocated to node [node-7] due to [ShardFilterAllocationDecider].
Shard [7] can not be forcefully allocated to node [node-8] due to [RelocationThresholdDecider].
Shard [8] can not be forcefully allocated to node [node-9] due to [DelayedAllocationDecider].
Shard [9] can not be forcefully allocated to node [node-10] due to [DiskComparatorDecider].
Shard [10] can not be forcefully allocated to node [node-11] due to [ThrottlingAllocationDecider].
Shard [11] can not be forcefully allocated to node [node-12] due to [IgnoreShardFilterAllocationDecider].
Shard [12] can not be forcefully allocated to node [node-13] due to [BalancerAllocationDecider].
Shard [13] can not be forcefully allocated to node [node-14] due to [ExclusionAllocationDecider].
error reading /proc/loadavg RuntimeError
error reading /proc/loadavg IOException
error reading /proc/loadavg NullPointerException
error reading /proc/loadavg ArrayIndexOutOfBoundsException
error reading /proc/loadavg IllegalArgumentException
error reading /proc/loadavg FileNotFoundException
error reading /proc/loadavg OutOfMemoryError
error reading /proc/loadavg NoSuchElementException
error reading /proc/loadavg StackOverflowError
error reading /proc/loadavg NumberFormatException
error reading /proc/loadavg AssertionError
error reading /proc/loadavg ClassCastException
error reading /proc/loadavg IndexOutOfBoundsException
Shard [shard_2] can not remain on node [node_2] due to [AllocationDecider]
Shard [shard_3] can not remain on node [node_3] due to [AllocationDecider]
Shard [shard_4] can not remain on node [node_4] due to [AllocationDecider]
Shard [shard_5] can not remain on node [node_5] due to [AllocationDecider]
Shard [shard_6] can not remain on node [node_1] due to [AllocationDecider]
Shard [shard_7] can not remain on node [node_2] due to [AllocationDecider]
Shard [shard_8] can not remain on node [node_3] due to [AllocationDecider]
Shard [shard_9] can not remain on node [node_4] due to [AllocationDecider]
Shard [shard_10] can not remain on node [node_5] due to [AllocationDecider]
Shard [shard_11] can not remain on node [node_1] due to [AllocationDecider]
Shard [shard_12] can not remain on node [node_2] due to [AllocationDecider]
Shard [shard_13] can not remain on node [node_3] due to [AllocationDecider]
Shard [shard_14] can not remain on node [node_4] due to [AllocationDecider]
OS reported a negative total swap space size 128GB
OS reported a negative total swap space size 256GB
OS reported a negative total swap space size 512GB
OS reported a negative total swap space size 1TB
OS reported a negative total swap space size 2TB
OS reported a negative total swap space size 4TB
OS reported a negative total swap space size 8TB
OS reported a negative total swap space size 16TB
OS reported a negative total swap space size 32TB
OS reported a negative total swap space size 64TB
OS reported a negative total swap space size 128TB
OS reported a negative total swap space size 256TB
OS reported a negative total swap space size 512TB
Shard [shard2] should be ignored for node [node-002]
Shard [shard3] should be ignored for node [node-003]
Shard [shard4] should be ignored for node [node-004]
Shard [shard5] should be ignored for node [node-005]
Shard [shard6] should be ignored for node [node-006]
Shard [shard7] should be ignored for node [node-007]
Shard [shard8] should be ignored for node [node-008]
Shard [shard9] should be ignored for node [node-009]
Shard [shard10] should be ignored for node [node-010]
Shard [shard11] should be ignored for node [node-011]
Shard [shard12] should be ignored for node [node-012]
Shard [shard13] should be ignored for node [node-013]
Shard [shard14] should be ignored for node [node-014]
Can not allocate [shard2] on node [node2] due to [AllocationDeciderImpl]
Can not allocate [shard3] on node [node3] due to [AllocationDeciderImpl]
Can not allocate [shard4] on node [node4] due to [AllocationDeciderImpl]
Can not allocate [shard5] on node [node5] due to [AllocationDeciderImpl]
Can not allocate [shard6] on node [node6] due to [AllocationDeciderImpl]
Can not allocate [shard7] on node [node7] due to [AllocationDeciderImpl]
Can not allocate [shard8] on node [node8] due to [AllocationDeciderImpl]
Can not allocate [shard9] on node [node9] due to [AllocationDeciderImpl]
Can not allocate [shard10] on node [node10] due to [AllocationDeciderImpl]
Can not allocate [shard11] on node [node11] due to [AllocationDeciderImpl]
Can not allocate [shard12] on node [node12] due to [AllocationDeciderImpl]
Can not allocate [shard13] on node [node13] due to [AllocationDeciderImpl]
Can not allocate [shard14] on node [node14] due to [AllocationDeciderImpl]
OS reported a negative free swap space size [8GB]
OS reported a negative free swap space size [16GB]
OS reported a negative free swap space size [32GB]
OS reported a negative free swap space size [64GB]
OS reported a negative free swap space size [128GB]
OS reported a negative free swap space size [256GB]
OS reported a negative free swap space size [512GB]
OS reported a negative free swap space size [1TB]
OS reported a negative free swap space size [2TB]
OS reported a negative free swap space size [4TB]
OS reported a negative free swap space size [8TB]
OS reported a negative free swap space size [16TB]
OS reported a negative free swap space size [32TB]
Relocated shard [shard2] to node [node3] during primary Rebalance
Relocated shard [shard3] to node [node1] during primary Rebalance
Relocated shard [shard4] to node [node2] during primary Rebalance
Relocated shard [shard5] to node [node3] during primary Rebalance
Relocated shard [shard6] to node [node1] during primary Rebalance
Relocated shard [shard7] to node [node2] during primary Rebalance
Relocated shard [shard8] to node [node3] during primary Rebalance
Relocated shard [shard9] to node [node1] during primary Rebalance
Relocated shard [shard10] to node [node2] during primary Rebalance
Relocated shard [shard11] to node [node3] during primary Rebalance
Relocated shard [shard12] to node [node1] during primary Rebalance
Relocated shard [shard13] to node [node2] during primary Rebalance
Relocated shard [shard14] to node [node3] during primary Rebalance
exception retrieving free swap space size IndexOutOfBoundsException
exception retrieving free swap space size IOException
exception retrieving free swap space size NullPointerException
exception retrieving free swap space size NumberFormatException
exception retrieving free swap space size ClassNotFoundException
exception retrieving free swap space size IllegalArgumentException
exception retrieving free swap space size ArrayIndexOutOfBoundsException
exception retrieving free swap space size NoSuchElementException
exception retrieving free swap space size ArithmeticException
exception retrieving free swap space size IllegalStateException
exception retrieving free swap space size ConcurrentModificationException
exception retrieving free swap space size OutOfMemoryError
exception retrieving free swap space size StackOverflowError
OS reported a negative total memory value [-512]
OS reported a negative total memory value [-1024]
OS reported a negative total memory value [-2048]
OS reported a negative total memory value [-4096]
OS reported a negative total memory value [-8192]
OS reported a negative total memory value [-16384]
OS reported a negative total memory value [-32768]
OS reported a negative total memory value [-65536]
OS reported a negative total memory value [-131072]
OS reported a negative total memory value [-262144]
OS reported a negative total memory value [-524288]
OS reported a negative total memory value [-1048576]
OS reported a negative total memory value [-2097152]
Relocating shard [2] from node [B] to node [C]. AllocationDecision: [Allocate]. AllocationExplanation: [Scaling]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [3] from node [C] to node [D]. AllocationDecision: [Move]. AllocationExplanation: [High CPU usage]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [4] from node [D] to node [E]. AllocationDecision: [Allocate]. AllocationExplanation: [Increased Memory]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [5] from node [E] to node [F]. AllocationDecision: [Move]. AllocationExplanation: [Network Latency]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [6] from node [F] to node [G]. AllocationDecision: [Allocate]. AllocationExplanation: [Disk Space]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [7] from node [G] to node [H]. AllocationDecision: [Move]. AllocationExplanation: [High CPU usage]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [8] from node [H] to node [I]. AllocationDecision: [Allocate]. AllocationExplanation: [Scaling]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [9] from node [I] to node [J]. AllocationDecision: [Move]. AllocationExplanation: [Network Latency]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [10] from node [J] to node [K]. AllocationDecision: [Allocate]. AllocationExplanation: [Increased Memory]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [11] from node [K] to node [L]. AllocationDecision: [Move]. AllocationExplanation: [Disk Space]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [12] from node [L] to node [M]. AllocationDecision: [Allocate]. AllocationExplanation: [Balancing]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [13] from node [M] to node [N]. AllocationDecision: [Allocate]. AllocationExplanation: [Scaling]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Relocating shard [14] from node [N] to node [O]. AllocationDecision: [Move]. AllocationExplanation: [High CPU usage]. RebalanceDecision: [None]. RebalanceExplanation: [No need for rebalancing]
Avg shard limit reached for node: [node2]. Removing from queue.
Avg shard limit reached for node: [node3]. Removing from queue.
Avg shard limit reached for node: [node4]. Removing from queue.
Avg shard limit reached for node: [node5]. Removing from queue.
Avg shard limit reached for node: [node6]. Removing from queue.
Avg shard limit reached for node: [node7]. Removing from queue.
Avg shard limit reached for node: [node8]. Removing from queue.
Avg shard limit reached for node: [node9]. Removing from queue.
Avg shard limit reached for node: [node10]. Removing from queue.
Avg shard limit reached for node: [node11]. Removing from queue.
Avg shard limit reached for node: [node12]. Removing from queue.
Avg shard limit reached for node: [node13]. Removing from queue.
Avg shard limit reached for node: [node14]. Removing from queue.
OS reported a negative free memory value [-256 MB]
OS reported a negative free memory value [-128 MB]
OS reported a negative free memory value [-64 MB]
OS reported a negative free memory value [-32 MB]
OS reported a negative free memory value [-16 MB]
OS reported a negative free memory value [-8 MB]
OS reported a negative free memory value [-4 MB]
OS reported a negative free memory value [-2 MB]
OS reported a negative free memory value [-1 MB]
OS reported a negative free memory value [-512 KB]
OS reported a negative free memory value [-256 KB]
OS reported a negative free memory value [-128 KB]
OS reported a negative free memory value [-64 KB]
Cannot allocate any shard to node: [node_2]. Removing from queue. Node level decisions: [decision_2],[explanation_2]
Cannot allocate any shard to node: [node_3]. Removing from queue. Node level decisions: [decision_3],[explanation_3]
Cannot allocate any shard to node: [node_4]. Removing from queue. Node level decisions: [decision_4],[explanation_4]
Cannot allocate any shard to node: [node_5]. Removing from queue. Node level decisions: [decision_5],[explanation_5]
Cannot allocate any shard to node: [node_6]. Removing from queue. Node level decisions: [decision_6],[explanation_6]
Cannot allocate any shard to node: [node_7]. Removing from queue. Node level decisions: [decision_7],[explanation_7]
Cannot allocate any shard to node: [node_8]. Removing from queue. Node level decisions: [decision_8],[explanation_8]
Cannot allocate any shard to node: [node_9]. Removing from queue. Node level decisions: [decision_9],[explanation_9]
Cannot allocate any shard to node: [node_10]. Removing from queue. Node level decisions: [decision_10],[explanation_10]
Cannot allocate any shard to node: [node_11]. Removing from queue. Node level decisions: [decision_11],[explanation_11]
Cannot allocate any shard to node: [node_12]. Removing from queue. Node level decisions: [decision_12],[explanation_12]
Cannot allocate any shard to node: [node_13]. Removing from queue. Node level decisions: [decision_13],[explanation_13]
Cannot allocate any shard to node: [node_14]. Removing from queue. Node level decisions: [decision_14],[explanation_14]
Cannot allocate shard: shard2 on node [node2]. Decisions: [decision2]
Cannot allocate shard: shard3 on node [node3]. Decisions: [decision3]
Cannot allocate shard: shard4 on node [node4]. Decisions: [decision4]
Cannot allocate shard: shard5 on node [node5]. Decisions: [decision5]
Cannot allocate shard: shard6 on node [node6]. Decisions: [decision6]
Cannot allocate shard: shard7 on node [node7]. Decisions: [decision7]
Cannot allocate shard: shard8 on node [node8]. Decisions: [decision8]
Cannot allocate shard: shard9 on node [node9]. Decisions: [decision9]
Cannot allocate shard: shard10 on node [node10]. Decisions: [decision10]
Cannot allocate shard: shard11 on node [node11]. Decisions: [decision11]
Cannot allocate shard: shard12 on node [node12]. Decisions: [decision12]
Cannot allocate shard: shard13 on node [node13]. Decisions: [decision13]
Cannot allocate shard: shard14 on node [node14]. Decisions: [decision14]
failed to monitor NullPointerException
failed to monitor ArrayIndexOutOfBoundsException
failed to monitor FileNotFoundException
failed to monitor IllegalArgumentException
failed to monitor InterruptedException
failed to monitor NumberFormatException
failed to monitor OutOfMemoryError
failed to monitor StackOverflowError
failed to monitor StringIndexOutOfBoundsException
failed to monitor UnknownHostException
failed to monitor UnsupportedOperationException
failed to monitor ClassCastException
failed to monitor NoSuchElementException
Ignoring shard: [shard-002] as is cannot be allocated to any node. Shard level decisions: [DECISION-002][Explanation-002].
Ignoring shard: [shard-003] as is cannot be allocated to any node. Shard level decisions: [DECISION-003][Explanation-003].
Ignoring shard: [shard-004] as is cannot be allocated to any node. Shard level decisions: [DECISION-004][Explanation-004].
Ignoring shard: [shard-005] as is cannot be allocated to any node. Shard level decisions: [DECISION-005][Explanation-005].
Ignoring shard: [shard-006] as is cannot be allocated to any node. Shard level decisions: [DECISION-006][Explanation-006].
Ignoring shard: [shard-007] as is cannot be allocated to any node. Shard level decisions: [DECISION-007][Explanation-007].
Ignoring shard: [shard-008] as is cannot be allocated to any node. Shard level decisions: [DECISION-008][Explanation-008].
Ignoring shard: [shard-009] as is cannot be allocated to any node. Shard level decisions: [DECISION-009][Explanation-009].
Ignoring shard: [shard-010] as is cannot be allocated to any node. Shard level decisions: [DECISION-010][Explanation-010].
Ignoring shard: [shard-011] as is cannot be allocated to any node. Shard level decisions: [DECISION-011][Explanation-011].
Ignoring shard: [shard-012] as is cannot be allocated to any node. Shard level decisions: [DECISION-012][Explanation-012].
Ignoring shard: [shard-013] as is cannot be allocated to any node. Shard level decisions: [DECISION-013][Explanation-013].
Ignoring shard: [shard-014] as is cannot be allocated to any node. Shard level decisions: [DECISION-014][Explanation-014].
enabled [true], interval [3000], gc_threshold [15], overhead [60, 80, 100]
enabled [false], interval [2000], gc_threshold [8], overhead [45, 65, 85]
enabled [false], interval [1000], gc_threshold [12], overhead [55, 75, 95]
enabled [true], interval [4000], gc_threshold [14], overhead [58, 78, 98]
enabled [true], interval [6000], gc_threshold [9], overhead [52, 72, 92]
enabled [false], interval [1500], gc_threshold [13], overhead [56, 76, 96]
enabled [true], interval [2500], gc_threshold [11], overhead [54, 74, 94]
enabled [false], interval [3500], gc_threshold [16], overhead [62, 82, 102]
enabled [true], interval [4500], gc_threshold [7], overhead [48, 68, 88]
enabled [false], interval [7000], gc_threshold [18], overhead [66, 86, 106]
enabled [true], interval [5500], gc_threshold [20], overhead [70, 90, 110]
enabled [true], interval [8000], gc_threshold [5], overhead [40, 60, 80]
enabled [false], interval [9000], gc_threshold [6], overhead [42, 62, 82]
Allocating shards for index: [products]
Allocating shards for index: [orders]
Allocating shards for index: [reviews]
Allocating shards for index: [logs]
Allocating shards for index: [images]
Allocating shards for index: [categories]
Allocating shards for index: [tags]
Allocating shards for index: [messages]
Allocating shards for index: [notifications]
Allocating shards for index: [settings]
Allocating shards for index: [invoices]
Allocating shards for index: [payments]
Allocating shards for index: [subscribers]
unexpected exception reading filesystem info NullPointerException
unexpected exception reading filesystem info FileNotFoundException
unexpected exception reading filesystem info ArrayIndexOutOfBoundsException
unexpected exception reading filesystem info ClassCastException
unexpected exception reading filesystem info IllegalArgumentException
unexpected exception reading filesystem info NoSuchElementException
unexpected exception reading filesystem info NumberFormatException
unexpected exception reading filesystem info IllegalArgumentException
unexpected exception reading filesystem info ArithmeticException
unexpected exception reading filesystem info SecurityException
unexpected exception reading filesystem info RuntimeException
unexpected exception reading filesystem info NoSuchElementException
unexpected exception reading filesystem info IllegalStateException
Allocating unassigned replicas. Nodes available in queue: [5]
Allocating unassigned replicas. Nodes available in queue: [3]
Allocating unassigned primaries. Nodes available in queue: [8]
Allocating unassigned replicas. Nodes available in queue: [4]
Allocating unassigned primaries. Nodes available in queue: [7]
Allocating unassigned replicas. Nodes available in queue: [6]
Allocating unassigned replicas. Nodes available in queue: [2]
Allocating unassigned primaries. Nodes available in queue: [9]
Allocating unassigned primaries. Nodes available in queue: [12]
Allocating unassigned replicas. Nodes available in queue: [11]
Allocating unassigned replicas. Nodes available in queue: [15]
Allocating unassigned primaries. Nodes available in queue: [13]
Allocating unassigned replicas. Nodes available in queue: [14]
using refresh_interval [1000]
using refresh_interval [2000]
using refresh_interval [3000]
using refresh_interval [4000]
using refresh_interval [5000]
using refresh_interval [6000]
using refresh_interval [7000]
using refresh_interval [8000]
using refresh_interval [9000]
using refresh_interval [10000]
using refresh_interval [11000]
using refresh_interval [12000]
using refresh_interval [13000]
health check of [login/health] failed, took [150ms] which is above the healthy threshold of [100]
health check of [orders/health] failed, took [180ms] which is above the healthy threshold of [100]
health check of [payment/health] failed, took [220ms] which is above the healthy threshold of [100]
health check of [catalog/health] failed, took [300ms] which is above the healthy threshold of [100]
health check of [users/health] failed, took [140ms] which is above the healthy threshold of [100]
health check of [inventory/health] failed, took [210ms] which is above the healthy threshold of [100]
health check of [search/health] failed, took [180ms] which is above the healthy threshold of [100]
health check of [notifications/health] failed, took [140ms] which is above the healthy threshold of [100]
health check of [analytics/health] failed, took [195ms] which is above the healthy threshold of [100]
health check of [billing/health] failed, took [260ms] which is above the healthy threshold of [100]
health check of [messages/health] failed, took [165ms] which is above the healthy threshold of [100]
health check of [storage/health] failed, took [290ms] which is above the healthy threshold of [100]
health check of [notifications/health] failed, took [170ms] which is above the healthy threshold of [100]
health check of [/api/v1/logout] took [250ms] which is above the warn threshold of [200]
health check of [/api/v1/users] took [180ms] which is above the warn threshold of [150]
health check of [/api/v1/orders] took [90ms] which is above the warn threshold of [80]
health check of [/api/v1/products] took [210ms] which is above the warn threshold of [200]
health check of [/api/v1/customers] took [110ms] which is above the warn threshold of [100]
health check of [/api/v1/invoices] took [350ms] which is above the warn threshold of [300]
health check of [/api/v1/notifications] took [130ms] which is above the warn threshold of [100]
health check of [/api/v1/messages] took [70ms] which is above the warn threshold of [50]
health check of [/api/v1/settings] took [160ms] which is above the warn threshold of [150]
health check of [/api/v1/profiles] took [180ms] which is above the warn threshold of [150]
health check of [/api/v1/reviews] took [200ms] which is above the warn threshold of [180]
health check of [/api/v1/comments] took [120ms] which is above the warn threshold of [100]
health check of [/api/v1/notifications] took [300ms] which is above the warn threshold of [200]
Node: [node456] can still accept shards. Adding it back to the queue.
Node: [node789] can still accept shards. Adding it back to the queue.
Node: [node112] can still accept shards. Adding it back to the queue.
Node: [node225] can still accept shards. Adding it back to the queue.
Node: [node338] can still accept shards. Adding it back to the queue.
Node: [node451] can still accept shards. Adding it back to the queue.
Node: [node564] can still accept shards. Adding it back to the queue.
Node: [node677] can still accept shards. Adding it back to the queue.
Node: [node790] can still accept shards. Adding it back to the queue.
Node: [node813] can still accept shards. Adding it back to the queue.
Node: [node926] can still accept shards. Adding it back to the queue.
Node: [node1039] can still accept shards. Adding it back to the queue.
Node: [node1152] can still accept shards. Adding it back to the queue.
health check succeeded
health check succeeded
health check succeeded
health check succeeded
health check succeeded
health check succeeded
health check succeeded
health check succeeded
health check succeeded
health check succeeded
health check succeeded
health check succeeded
health check succeeded
health check succeeded
health check succeeded
Node: [node2] cannot accept any more shards. Removing it from queue.
Node: [node3] cannot accept any more shards. Removing it from queue.
Node: [node4] cannot accept any more shards. Removing it from queue.
Node: [node5] cannot accept any more shards. Removing it from queue.
Node: [node6] cannot accept any more shards. Removing it from queue.
Node: [node7] cannot accept any more shards. Removing it from queue.
Node: [node8] cannot accept any more shards. Removing it from queue.
Node: [node9] cannot accept any more shards. Removing it from queue.
Node: [node10] cannot accept any more shards. Removing it from queue.
Node: [node11] cannot accept any more shards. Removing it from queue.
Node: [node12] cannot accept any more shards. Removing it from queue.
Node: [node13] cannot accept any more shards. Removing it from queue.
Node: [node14] cannot accept any more shards. Removing it from queue.
health check failedArrayIndexOutOfBoundsException
health check failedIllegalArgumentException
health check failedFileNotFoundException
health check failedOutOfMemoryError
health check failedClassNotFoundException
health check failedNoSuchElementException
health check failedNumberFormatException
health check failedStackOverflowError
health check failedArithmeticException
health check failedIndexOutOfBoundsException
health check failedAssertionError
health check failedIllegalStateException
health check failedUnknownError
health check failedUnsupportedOperationException
failed to update ingest pipelines: FileNotFound Exception
failed to update ingest pipelines: IndexOutOfBounds Exception
failed to update ingest pipelines: ClassCast Exception
failed to update ingest pipelines: Arithmetic Exception
failed to update ingest pipelines: InvalidFormatException
failed to update ingest pipelines: OutOfMemory Exception
failed to update ingest pipelines: StackOverflow Exception
failed to update ingest pipelines: NumberFormatException
failed to update ingest pipelines: IllegalArgumentException
failed to update ingest pipelines: SecurityException
failed to update ingest pipelines: IllegalAccessException
failed to update ingest pipelines: NoSuchMethodException
failed to update ingest pipelines: UnsupportedOperationException
failed to update ingest pipelines: ConcurrentModificationException
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No excluded nodes found. Returning...
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No remote searcher nodes available for unassigned remote shards.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No unassigned remote shards found.
No shards of [1] can relocate from [node-789] to [node-012]
No shards of [2] can relocate from [node-345] to [node-678]
No shards of [3] can relocate from [node-901] to [node-234]
No shards of [4] can relocate from [node-567] to [node-890]
No shards of [5] can relocate from [node-123] to [node-456]
No shards of [6] can relocate from [node-789] to [node-012]
No shards of [7] can relocate from [node-345] to [node-678]
No shards of [8] can relocate from [node-901] to [node-234]
No shards of [9] can relocate from [node-567] to [node-890]
No shards of [10] can relocate from [node-123] to [node-456]
No shards of [11] can relocate from [node-789] to [node-012]
No shards of [12] can relocate from [node-345] to [node-678]
No shards of [13] can relocate from [node-901] to [node-234]
not deleting shard shard-2, the update task state version[7] is not equal to cluster state before shard active api call [7]
not deleting shard shard-3, the update task state version[15] is not equal to cluster state before shard active api call [11]
not deleting shard shard-4, the update task state version[9] is not equal to cluster state before shard active api call [6]
not deleting shard shard-5, the update task state version[12] is not equal to cluster state before shard active api call [8]
not deleting shard shard-6, the update task state version[8] is not equal to cluster state before shard active api call [7]
not deleting shard shard-7, the update task state version[6] is not equal to cluster state before shard active api call [5]
not deleting shard shard-8, the update task state version[11] is not equal to cluster state before shard active api call [10]
not deleting shard shard-9, the update task state version[14] is not equal to cluster state before shard active api call [13]
not deleting shard shard-10, the update task state version[5] is not equal to cluster state before shard active api call [4]
not deleting shard shard-11, the update task state version[13] is not equal to cluster state before shard active api call [9]
not deleting shard shard-12, the update task state version[7] is not equal to cluster state before shard active api call [6]
not deleting shard shard-13, the update task state version[10] is not equal to cluster state before shard active api call [9]
not deleting shard shard-14, the update task state version[8] is not equal to cluster state before shard active api call [7]
Try relocating shard of [2] from [node789] to [node012]
Try relocating shard of [3] from [node345] to [node678]
Try relocating shard of [4] from [node901] to [node234]
Try relocating shard of [5] from [node567] to [node890]
Try relocating shard of [6] from [node123] to [node456]
Try relocating shard of [7] from [node789] to [node012]
Try relocating shard of [8] from [node345] to [node678]
Try relocating shard of [9] from [node901] to [node234]
Try relocating shard of [10] from [node567] to [node890]
Try relocating shard of [11] from [node123] to [node456]
Try relocating shard of [12] from [node789] to [node012]
Try relocating shard of [13] from [node345] to [node678]
Try relocating shard of [14] from [node901] to [node234]
Assigned shard [27] to [node543]
Assigned shard [56] to [node987]
Assigned shard [42] to [node246]
Assigned shard [17] to [node654]
Assigned shard [83] to [node321]
Assigned shard [91] to [node789]
Assigned shard [33] to [node012]
Assigned shard [75] to [node876]
Assigned shard [19] to [node109]
Assigned shard [63] to [node543]
Assigned shard [88] to [node246]
Assigned shard [47] to [node987]
Assigned shard [22] to [node321]
not deleting shard shard002, the latest cluster state version[12] is not equal to cluster state before shard active api call [11]
not deleting shard shard003, the latest cluster state version[8] is not equal to cluster state before shard active api call [7]
not deleting shard shard004, the latest cluster state version[15] is not equal to cluster state before shard active api call [14]
not deleting shard shard005, the latest cluster state version[20] is not equal to cluster state before shard active api call [19]
not deleting shard shard006, the latest cluster state version[6] is not equal to cluster state before shard active api call [5]
not deleting shard shard007, the latest cluster state version[11] is not equal to cluster state before shard active api call [10]
not deleting shard shard008, the latest cluster state version[9] is not equal to cluster state before shard active api call [8]
not deleting shard shard009, the latest cluster state version[18] is not equal to cluster state before shard active api call [17]
not deleting shard shard010, the latest cluster state version[13] is not equal to cluster state before shard active api call [12]
not deleting shard shard011, the latest cluster state version[7] is not equal to cluster state before shard active api call [6]
not deleting shard shard012, the latest cluster state version[14] is not equal to cluster state before shard active api call [13]
not deleting shard shard013, the latest cluster state version[16] is not equal to cluster state before shard active api call [15]
not deleting shard shard014, the latest cluster state version[19] is not equal to cluster state before shard active api call [18]
No Node found to assign shard [B2]
No Node found to assign shard [C3]
No Node found to assign shard [D4]
No Node found to assign shard [E5]
No Node found to assign shard [F6]
No Node found to assign shard [G7]
No Node found to assign shard [H8]
No Node found to assign shard [I9]
No Node found to assign shard [J10]
No Node found to assign shard [K11]
No Node found to assign shard [L12]
No Node found to assign shard [M13]
No Node found to assign shard [N14]
not deleting shard 2, expected 5 active copies, but only 4 found active copies
not deleting shard 3, expected 2 active copies, but only 1 found active copies
not deleting shard 4, expected 1 active copies, but only 0 found active copies
not deleting shard 5, expected 7 active copies, but only 6 found active copies
not deleting shard 6, expected 4 active copies, but only 3 found active copies
not deleting shard 7, expected 9 active copies, but only 8 found active copies
not deleting shard 8, expected 6 active copies, but only 4 found active copies
not deleting shard 9, expected 3 active copies, but only 1 found active copies
not deleting shard 10, expected 8 active copies, but only 7 found active copies
not deleting shard 11, expected 5 active copies, but only 3 found active copies
not deleting shard 12, expected 2 active copies, but only 0 found active copies
not deleting shard 13, expected 7 active copies, but only 5 found active copies
not deleting shard 14, expected 4 active copies, but only 3 found active copies
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
Start allocating unassigned shards
suppressing exception on completion (it was already bubbled up or the operation was aborted)NullPointerException
suppressing exception on completion (it was already bubbled up or the operation was aborted)ArrayIndexOutOfBoundsException
suppressing exception on completion (it was already bubbled up or the operation was aborted)ClassCastException
suppressing exception on completion (it was already bubbled up or the operation was aborted)IllegalArgumentException
suppressing exception on completion (it was already bubbled up or the operation was aborted)IndexOutOfBoundsException
suppressing exception on completion (it was already bubbled up or the operation was aborted)ArithmeticException
suppressing exception on completion (it was already bubbled up or the operation was aborted)SecurityException
suppressing exception on completion (it was already bubbled up or the operation was aborted)NoSuchElementException
suppressing exception on completion (it was already bubbled up or the operation was aborted)UnsupportedOperationException
suppressing exception on completion (it was already bubbled up or the operation was aborted)StackOverflowError
suppressing exception on completion (it was already bubbled up or the operation was aborted)OutOfMemoryError
suppressing exception on completion (it was already bubbled up or the operation was aborted)RuntimeException
suppressing exception on completion (it was already bubbled up or the operation was aborted)AssertionError
suppressing exception on completion (it was already bubbled up or the operation was aborted)ExceptionInInitializerError
Error while marking replication completed RuntimeException
Error while marking replication completed NullPointerException
Error while marking replication completed IndexOutOfBoundsException
Error while marking replication completed IOException
Error while marking replication completed IllegalArgumentException
Error while marking replication completed ArrayIndexOutOfBoundsException
Error while marking replication completed ClassCastException
Error while marking replication completed OutOfMemoryError
Error while marking replication completed StackOverflowError
Error while marking replication completed NoSuchElementException
Error while marking replication completed ArithmeticException
Error while marking replication completed StringIndexOutOfBoundsException
Error while marking replication completed NumberFormatException
Error while marking replication completed AssertionError
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Cannot move any replica shard in the cluster as movePrimaryFirst is enabled and primary shardsare being throttled. Skipping shard iteration
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Shard is already closed, closing replication
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster as there is no node on which shards can be allocated. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
Cannot move any shard in the cluster due to cluster concurrent recoveries getting breached. Skipping shard iteration
[replication id 2] Source node completed sending files to target node [targetId_2], timing: 150ms
[replication id 3] Source node completed sending files to target node [targetId_3], timing: 200ms
[replication id 4] Source node completed sending files to target node [targetId_4], timing: 180ms
[replication id 5] Source node completed sending files to target node [targetId_5], timing: 120ms
[replication id 6] Source node completed sending files to target node [targetId_6], timing: 220ms
[replication id 7] Source node completed sending files to target node [targetId_7], timing: 190ms
[replication id 8] Source node completed sending files to target node [targetId_8], timing: 250ms
[replication id 9] Source node completed sending files to target node [targetId_9], timing: 300ms
[replication id 10] Source node completed sending files to target node [targetId_10], timing: 280ms
[replication id 11] Source node completed sending files to target node [targetId_11], timing: 230ms
[replication id 12] Source node completed sending files to target node [targetId_12], timing: 170ms
[replication id 13] Source node completed sending files to target node [targetId_13], timing: 220ms
[replication id 14] Source node completed sending files to target node [targetId_14], timing: 260ms
Couldn't find shard to relocate from node [789] to node [321]
Couldn't find shard to relocate from node [654] to node [987]
Couldn't find shard to relocate from node [234] to node [567]
Couldn't find shard to relocate from node [890] to node [123]
Couldn't find shard to relocate from node [456] to node [789]
Couldn't find shard to relocate from node [321] to node [654]
Couldn't find shard to relocate from node [987] to node [234]
Couldn't find shard to relocate from node [567] to node [890]
Couldn't find shard to relocate from node [123] to node [456]
Couldn't find shard to relocate from node [789] to node [321]
Couldn't find shard to relocate from node [654] to node [987]
Couldn't find shard to relocate from node [234] to node [567]
Couldn't find shard to relocate from node [890] to node [123]
delaying replication of shard02 as it is not listed as assigned to target node node01
delaying replication of shard03 as it is not listed as assigned to target node node03
delaying replication of shard04 as it is not listed as assigned to target node node02
delaying replication of shard05 as it is not listed as assigned to target node node01
delaying replication of shard06 as it is not listed as assigned to target node node03
delaying replication of shard07 as it is not listed as assigned to target node node02
delaying replication of shard08 as it is not listed as assigned to target node node01
delaying replication of shard09 as it is not listed as assigned to target node node03
delaying replication of shard10 as it is not listed as assigned to target node node01
delaying replication of shard11 as it is not listed as assigned to target node node03
delaying replication of shard12 as it is not listed as assigned to target node node02
delaying replication of shard13 as it is not listed as assigned to target node node02
delaying replication of shard14 as it is not listed as assigned to target node node01
Balancing from node [789] weight: [2.1] to node [101] weight: [5.6]  delta: [-3.5]
Balancing from node [234] weight: [7.8] to node [567] weight: [0.9]  delta: [6.9]
Balancing from node [890] weight: [2.3] to node [123] weight: [4.5]  delta: [-2.2]
Balancing from node [456] weight: [3.2] to node [789] weight: [2.1]  delta: [1.1]
Balancing from node [101] weight: [5.6] to node [234] weight: [7.8]  delta: [-2.2]
Balancing from node [567] weight: [0.9] to node [890] weight: [2.3]  delta: [-1.4]
Balancing from node [123] weight: [4.5] to node [456] weight: [3.2]  delta: [1.3]
Balancing from node [789] weight: [2.1] to node [101] weight: [5.6]  delta: [-3.5]
Balancing from node [234] weight: [7.8] to node [567] weight: [0.9]  delta: [6.9]
Balancing from node [890] weight: [2.3] to node [123] weight: [4.5]  delta: [-2.2]
Balancing from node [456] weight: [3.2] to node [789] weight: [2.1]  delta: [1.1]
Balancing from node [101] weight: [5.6] to node [234] weight: [7.8]  delta: [-2.2]
Balancing from node [567] weight: [0.9] to node [890] weight: [2.3]  delta: [-1.4]
Balancing from node [123] weight: [4.5] to node [456] weight: [3.2]  delta: [1.3]
[replication id 258] Source node failed to send files to target node [node2], timing: 154ms
[replication id 392] Source node failed to send files to target node [node3], timing: 187ms
[replication id 536] Source node failed to send files to target node [node4], timing: 203ms
[replication id 675] Source node failed to send files to target node [node5], timing: 264ms
[replication id 798] Source node failed to send files to target node [node6], timing: 199ms
[replication id 912] Source node failed to send files to target node [node7], timing: 287ms
[replication id 1021] Source node failed to send files to target node [node8], timing: 172ms
[replication id 1125] Source node failed to send files to target node [node9], timing: 216ms
[replication id 1224] Source node failed to send files to target node [node10], timing: 234ms
[replication id 1318] Source node failed to send files to target node [node11], timing: 150ms
[replication id 1407] Source node failed to send files to target node [node12], timing: 183ms
[replication id 1491] Source node failed to send files to target node [node13], timing: 201ms
[replication id 1570] Source node failed to send files to target node [node14], timing: 266ms
Stop balancing index [7]  min_node [9] weight: [15]  max_node [6] weight: [28]  delta: [2]
Stop balancing index [4]  min_node [8] weight: [32]  max_node [5] weight: [19]  delta: [1]
Stop balancing index [2]  min_node [6] weight: [18]  max_node [3] weight: [37]  delta: [3]
Stop balancing index [5]  min_node [4] weight: [22]  max_node [7] weight: [31]  delta: [5]
Stop balancing index [3]  min_node [2] weight: [29]  max_node [4] weight: [16]  delta: [2]
Stop balancing index [8]  min_node [7] weight: [23]  max_node [9] weight: [11]  delta: [4]
Stop balancing index [6]  min_node [5] weight: [17]  max_node [8] weight: [24]  delta: [1]
Stop balancing index [9]  min_node [3] weight: [26]  max_node [5] weight: [14]  delta: [3]
Stop balancing index [7]  min_node [1] weight: [21]  max_node [4] weight: [38]  delta: [2]
Stop balancing index [5]  min_node [7] weight: [18]  max_node [2] weight: [36]  delta: [4]
Stop balancing index [2]  min_node [8] weight: [34]  max_node [6] weight: [15]  delta: [3]
Stop balancing index [4]  min_node [9] weight: [14]  max_node [5] weight: [27]  delta: [2]
Stop balancing index [6]  min_node [4] weight: [20]  max_node [7] weight: [13]  delta: [1]
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as single node only
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance as it is disabled
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
skipping rebalance due to in-flight shard/store fetches
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Start balancing cluster
Downloading segments files from remote store file2.jpg
Downloading segments files from remote store file3.mp3
Downloading segments files from remote store file4.docx
Downloading segments files from remote store file5.pdf
Downloading segments files from remote store file6.png
Downloading segments files from remote store file7.xls
Downloading segments files from remote store file8.pptx
Downloading segments files from remote store file9.zip
Downloading segments files from remote store file10.txt
Downloading segments files from remote store file11.jpg
Downloading segments files from remote store file12.mp3
Downloading segments files from remote store file13.docx
Downloading segments files from remote store file14.pdf
Cluster health status changed from [Degraded] to [Critical] (reason: [Disk full]).
Cluster health status changed from [Critical] to [Healthy] (reason: [Network congestion]).
Cluster health status changed from [Healthy] to [Degraded] (reason: [CPU overload]).
Cluster health status changed from [Degraded] to [Critical] (reason: [Memory shortage]).
Cluster health status changed from [Critical] to [Healthy] (reason: [Software bug]).
Cluster health status changed from [Healthy] to [Degraded] (reason: [Power outage]).
Cluster health status changed from [Degraded] to [Critical] (reason: [Database corruption]).
Cluster health status changed from [Critical] to [Healthy] (reason: [Security breach]).
Cluster health status changed from [Healthy] to [Degraded] (reason: [Service instability]).
Cluster health status changed from [Degraded] to [Critical] (reason: [Configuration error]).
Cluster health status changed from [Critical] to [Healthy] (reason: [Data loss]).
Cluster health status changed from [Healthy] to [Degraded] (reason: [Backup failure]).
Cluster health status changed from [Degraded] to [Critical] (reason: [System crash]).
Cluster health status changed from [Critical] to [Healthy] (reason: [Software update]).
Override handler for allocation id 456
Override handler for allocation id 789
Override handler for allocation id 890
Override handler for allocation id 234
Override handler for allocation id 567
Override handler for allocation id 901
Override handler for allocation id 345
Override handler for allocation id 678
Override handler for allocation id 912
Override handler for allocation id 456
Override handler for allocation id 789
Override handler for allocation id 890
Override handler for allocation id 234
replication/recovery cancelled (reason: [disk full])
replication/recovery cancelled (reason: [server error])
replication/recovery cancelled (reason: [insufficient memory])
replication/recovery cancelled (reason: [file corruption])
replication/recovery cancelled (reason: [power outage])
replication/recovery cancelled (reason: [data inconsistency])
replication/recovery cancelled (reason: [invalid credentials])
replication/recovery cancelled (reason: [software bug])
replication/recovery cancelled (reason: [time constraint])
replication/recovery cancelled (reason: [database lock])
replication/recovery cancelled (reason: [network congestion])
replication/recovery cancelled (reason: [resource overload])
replication/recovery cancelled (reason: [config mismatch])
[monitor] rescheduling check for [456]. last access time is [2022-01-02 14:20:30]
[monitor] rescheduling check for [789]. last access time is [2022-01-03 08:45:10]
[monitor] rescheduling check for [987]. last access time is [2022-01-04 16:10:55]
[monitor] rescheduling check for [654]. last access time is [2022-01-05 11:25:40]
[monitor] rescheduling check for [321]. last access time is [2022-01-06 09:15:20]
[monitor] rescheduling check for [111]. last access time is [2022-01-07 12:05:35]
[monitor] rescheduling check for [222]. last access time is [2022-01-08 15:50:00]
[monitor] rescheduling check for [333]. last access time is [2022-01-09 07:40:45]
[monitor] rescheduling check for [444]. last access time is [2022-01-10 17:55:30]
[monitor] rescheduling check for [555]. last access time is [2022-01-11 13:10:25]
[monitor] rescheduling check for [666]. last access time is [2022-01-12 10:20:05]
[monitor] rescheduling check for [777]. last access time is [2022-01-13 14:35:50]
[monitor] rescheduling check for [888]. last access time is [2022-01-14 08:00:15]
[monitor] no status found for [456], shutting down
[monitor] no status found for [789], shutting down
[monitor] no status found for [abc], shutting down
[monitor] no status found for [def], shutting down
[monitor] no status found for [ghi], shutting down
[monitor] no status found for [jkl], shutting down
[monitor] no status found for [mno], shutting down
[monitor] no status found for [pqr], shutting down
[monitor] no status found for [stu], shutting down
[monitor] no status found for [vwx], shutting down
[monitor] no status found for [yz1], shutting down
[monitor] no status found for [234], shutting down
[monitor] no status found for [567], shutting down
unexpected error while checking for node reconnects<SocketTimeoutException>
unexpected error while checking for node reconnects<ClassCastException>
unexpected error while checking for node reconnects<IOException>
unexpected error while checking for node reconnects<SQLException>
unexpected error while checking for node reconnects<OutOfMemoryError>
unexpected error while checking for node reconnects<IndexOutOfBoundsException>
unexpected error while checking for node reconnects<StackOverflowError>
unexpected error while checking for node reconnects<FileNotFoundException>
unexpected error while checking for node reconnects<NumberFormatException>
unexpected error while checking for node reconnects<AssertionError>
unexpected error while checking for node reconnects<ArrayIndexOutOfBoundsException>
unexpected error while checking for node reconnects<NoSuchElementException>
unexpected error while checking for node reconnects<UnsupportedOperationException>
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.
Templates were partially upgraded to version 8.5
Templates were partially upgraded to version 9.2
Templates were partially upgraded to version 6.4
Templates were partially upgraded to version 7.8
Templates were partially upgraded to version 8.1
Templates were partially upgraded to version 9.3
Templates were partially upgraded to version 6.7
Templates were partially upgraded to version 7.2
Templates were partially upgraded to version 8.9
Templates were partially upgraded to version 9.6
Templates were partially upgraded to version 6.1
Templates were partially upgraded to version 7.5
Templates were partially upgraded to version 8.4
Templates were upgraded successfully to version 7.12.0
Templates were upgraded successfully to version 8.2.1
Templates were upgraded successfully to version 6.9.3
Templates were upgraded successfully to version 7.1.5
Templates were upgraded successfully to version 8.0.2
Templates were upgraded successfully to version 6.5.0
Templates were upgraded successfully to version 7.3.1
Templates were upgraded successfully to version 8.1.4
Templates were upgraded successfully to version 6.7.2
Templates were upgraded successfully to version 7.8.0
Templates were upgraded successfully to version 8.3.6
Templates were upgraded successfully to version 6.3.9
Templates were upgraded successfully to version 7.4.7
Error deleting template [settings], request was not acknowledged
Error deleting template [report], request was not acknowledged
Error deleting template [email], request was not acknowledged
Error deleting template [dashboard], request was not acknowledged
Error deleting template [notification], request was not acknowledged
Error deleting template [calendar], request was not acknowledged
Error deleting template [taskList], request was not acknowledged
Error deleting template [profile], request was not acknowledged
Error deleting template [document], request was not acknowledged
Error deleting template [invoice], request was not acknowledged
Error deleting template [project], request was not acknowledged
Error deleting template [contact], request was not acknowledged
Error deleting template [reminder], request was not acknowledged
Error deleting template [note], request was not acknowledged
[shardId 1] Failed to publish checkpoint, timing: 214
[shardId 2] Failed to publish checkpoint, timing: 187
[shardId 3] Failed to publish checkpoint, timing: 246
[shardId 4] Failed to publish checkpoint, timing: 158
[shardId 5] Failed to publish checkpoint, timing: 279
[shardId 6] Failed to publish checkpoint, timing: 195
[shardId 7] Failed to publish checkpoint, timing: 217
[shardId 8] Failed to publish checkpoint, timing: 175
[shardId 9] Failed to publish checkpoint, timing: 201
[shardId 10] Failed to publish checkpoint, timing: 223
[shardId 11] Failed to publish checkpoint, timing: 181
[shardId 12] Failed to publish checkpoint, timing: 206
[shardId 13] Failed to publish checkpoint, timing: 239
Starting template upgrade to version 2.3.0, 6 templates will be updated and 4 will be removed
Starting template upgrade to version 2.3.0, 4 templates will be updated and 1 will be removed
Starting template upgrade to version 2.3.0, 7 templates will be updated and 3 will be removed
Starting template upgrade to version 2.3.0, 3 templates will be updated and 2 will be removed
Starting template upgrade to version 2.3.0, 6 templates will be updated and 1 will be removed
Starting template upgrade to version 2.3.0, 5 templates will be updated and 3 will be removed
Starting template upgrade to version 2.3.0, 7 templates will be updated and 2 will be removed
Starting template upgrade to version 2.3.0, 4 templates will be updated and 3 will be removed
Starting template upgrade to version 2.3.0, 6 templates will be updated and 2 will be removed
Starting template upgrade to version 2.3.0, 3 templates will be updated and 1 will be removed
Starting template upgrade to version 2.3.0, 5 templates will be updated and 4 will be removed
Starting template upgrade to version 2.3.0, 7 templates will be updated and 1 will be removed
Starting template upgrade to version 2.3.0, 4 templates will be updated and 2 will be removed
failed to update system index metadata: IndexOutOfBoundsException
failed to update system index metadata: FileNotFoundException
failed to update system index metadata: IllegalArgumentException
failed to update system index metadata: ArrayIndexOutOfBoundsException
failed to update system index metadata: ClassCastException
failed to update system index metadata: NoSuchFieldException
failed to update system index metadata: UnsupportedOperationException
failed to update system index metadata: OutOfMemoryError
failed to update system index metadata: StackOverflowError
failed to update system index metadata: ArithmeticException
failed to update system index metadata: IOException
failed to update system index metadata: NoSuchMethodException
failed to update system index metadata: InvalidFormatException
finalizing recovery took [567]
finalizing recovery took [723]
finalizing recovery took [890]
finalizing recovery took [432]
finalizing recovery took [675]
finalizing recovery took [789]
finalizing recovery took [345]
finalizing recovery took [876]
finalizing recovery took [432]
finalizing recovery took [567]
finalizing recovery took [987]
finalizing recovery took [654]
finalizing recovery took [234]
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
performing relocation hand-off
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
finalizing recovery
recovery [phase2]: took [5 minutes]
recovery [phase2]: took [2 hours]
recovery [phase2]: took [500 milliseconds]
recovery [phase2]: took [3 seconds]
recovery [phase2]: took [1 hour]
recovery [phase2]: took [10 seconds]
recovery [phase2]: took [30 minutes]
recovery [phase2]: took [15 seconds]
recovery [phase2]: took [45 minutes]
recovery [phase2]: took [3 hours]
recovery [phase2]: took [20 seconds]
recovery [phase2]: took [1 minute]
recovery [phase2]: took [2 minutes]
[2] ignoring tasks - index meta data doesn't exist
[3] ignoring tasks - index meta data doesn't exist
[4] ignoring tasks - index meta data doesn't exist
[5] ignoring tasks - index meta data doesn't exist
[6] ignoring tasks - index meta data doesn't exist
[7] ignoring tasks - index meta data doesn't exist
[8] ignoring tasks - index meta data doesn't exist
[9] ignoring tasks - index meta data doesn't exist
[10] ignoring tasks - index meta data doesn't exist
[11] ignoring tasks - index meta data doesn't exist
[12] ignoring tasks - index meta data doesn't exist
[13] ignoring tasks - index meta data doesn't exist
[14] ignoring tasks - index meta data doesn't exist
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
recovery [phase1]: prepare remote engine for translog
ignoring a mapping task of type [DataBackup] with a null index.
ignoring a mapping task of type [DataMigration] with a null index.
ignoring a mapping task of type [DataValidation] with a null index.
ignoring a mapping task of type [DataTransformation] with a null index.
ignoring a mapping task of type [DataAnalysis] with a null index.
ignoring a mapping task of type [DataSync] with a null index.
ignoring a mapping task of type [DataBackup] with a null index.
ignoring a mapping task of type [DataMigration] with a null index.
ignoring a mapping task of type [DataValidation] with a null index.
ignoring a mapping task of type [DataTransformation] with a null index.
ignoring a mapping task of type [DataAnalysis] with a null index.
ignoring a mapping task of type [DataSync] with a null index.
ignoring a mapping task of type [DataBackup] with a null index.
recovery [phase1]: remote engine start took [400ms]
recovery [phase1]: remote engine start took [150ms]
recovery [phase1]: remote engine start took [300ms]
recovery [phase1]: remote engine start took [200ms]
recovery [phase1]: remote engine start took [350ms]
recovery [phase1]: remote engine start took [100ms]
recovery [phase1]: remote engine start took [450ms]
recovery [phase1]: remote engine start took [50ms]
recovery [phase1]: remote engine start took [500ms]
recovery [phase1]: remote engine start took [50ms]
recovery [phase1]: remote engine start took [250ms]
recovery [phase1]: remote engine start took [150ms]
recovery [phase1]: remote engine start took [400ms]
created retention lease with estimated checkpoint of [200]
created retention lease with estimated checkpoint of [300]
created retention lease with estimated checkpoint of [400]
created retention lease with estimated checkpoint of [500]
created retention lease with estimated checkpoint of [600]
created retention lease with estimated checkpoint of [700]
created retention lease with estimated checkpoint of [800]
created retention lease with estimated checkpoint of [900]
created retention lease with estimated checkpoint of [1000]
created retention lease with estimated checkpoint of [1100]
created retention lease with estimated checkpoint of [1200]
created retention lease with estimated checkpoint of [1300]
created retention lease with estimated checkpoint of [1400]
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
cloning primary's retention lease
recovery [phase1]: recovering_files [5] with total_size [1GB], reusing_files [2] with total_size [500MB]
recovery [phase1]: recovering_files [8] with total_size [1.5GB], reusing_files [4] with total_size [800MB]
recovery [phase1]: recovering_files [12] with total_size [3GB], reusing_files [6] with total_size [1.2GB]
recovery [phase1]: recovering_files [15] with total_size [2.5GB], reusing_files [7] with total_size [1.6GB]
recovery [phase1]: recovering_files [6] with total_size [1.2GB], reusing_files [3] with total_size [600MB]
recovery [phase1]: recovering_files [9] with total_size [1.8GB], reusing_files [4] with total_size [900MB]
recovery [phase1]: recovering_files [3] with total_size [600MB], reusing_files [1] with total_size [200MB]
recovery [phase1]: recovering_files [7] with total_size [1.6GB], reusing_files [3] with total_size [700MB]
recovery [phase1]: recovering_files [11] with total_size [2.8GB], reusing_files [5] with total_size [1.1GB]
recovery [phase1]: recovering_files [4] with total_size [800MB], reusing_files [2] with total_size [400MB]
recovery [phase1]: recovering_files [14] with total_size [2.2GB], reusing_files [6] with total_size [1.4GB]
recovery [phase1]: recovering_files [13] with total_size [2.6GB], reusing_files [6] with total_size [1.5GB]
recovery [phase1]: recovering_files [16] with total_size [3.2GB], reusing_files [8] with total_size [1.8GB]
recovery [phase1]: recovering [image.jpg], does not exist in remote
recovery [phase1]: recovering [socket.jpg], does not exist in remote
recovery [phase1]: recovering [data.csv], does not exist in remote
recovery [phase1]: recovering [document.docx], does not exist in remote
recovery [phase1]: recovering [presentation.pptx], does not exist in remote
recovery [phase1]: recovering [archive.zip], does not exist in remote
recovery [phase1]: recovering [config.xml], does not exist in remote
recovery [phase1]: recovering [log.txt], does not exist in remote
recovery [phase1]: recovering [video.mp4], does not exist in remote
recovery [phase1]: recovering [database.db], does not exist in remote
recovery [phase1]: recovering [script.js], does not exist in remote
recovery [phase1]: recovering [styles.css], does not exist in remote
recovery [phase1]: recovering [index.html], does not exist in remote
recovery [phase1]: not recovering [file2.jpg], exist in local store and has checksum [987654], size [2048]
recovery [phase1]: not recovering [file3.doc], exist in local store and has checksum [567890], size [512]
recovery [phase1]: not recovering [file4.png], exist in local store and has checksum [123456], size [4096]
recovery [phase1]: not recovering [file5.xlsx], exist in local store and has checksum [654321], size [8192]
recovery [phase1]: not recovering [file6.txt], exist in local store and has checksum [234567], size [256]
recovery [phase1]: not recovering [file7.docx], exist in local store and has checksum [789012], size [16384]
recovery [phase1]: not recovering [file8.jpeg], exist in local store and has checksum [345678], size [128]
recovery [phase1]: not recovering [file9.pdf], exist in local store and has checksum [901234], size [32768]
recovery [phase1]: not recovering [file10.zip], exist in local store and has checksum [456789], size [64]
recovery [phase1]: not recovering [file11.txt], exist in local store and has checksum [890123], size [8192]
recovery [phase1]: not recovering [file12.docx], exist in local store and has checksum [567890], size [1024]
recovery [phase1]: not recovering [file13.jpg], exist in local store and has checksum [234567], size [4096]
recovery [phase1]: not recovering [file14.pdf], exist in local store and has checksum [901234], size [256]
removing template [orderConfirmationEmail]
removing template [passwordResetEmail]
removing template [newsletterSubscriptionEmail]
removing template [feedbackRequestEmail]
removing template [deliveryNotificationEmail]
removing template [invoicePaymentReminderEmail]
removing template [accountVerificationEmail]
removing template [eventReminderEmail]
removing template [membershipRenewalEmail]
removing template [appointmentConfirmationEmail]
removing template [passwordChangeNotificationEmail]
removing template [orderCancellationEmail]
removing template [refundNotificationEmail]
removing template [productUpdateNotificationEmail]
add block block002 to index 002 succeeded
add block block003 to index 003 succeeded
add block block004 to index 004 succeeded
add block block005 to index 005 succeeded
add block block006 to index 006 succeeded
add block block007 to index 007 succeeded
add block block008 to index 008 succeeded
add block block009 to index 009 succeeded
add block block010 to index 010 succeeded
add block block011 to index 011 succeeded
add block block012 to index 012 succeeded
add block block013 to index 013 succeeded
add block block014 to index 014 succeeded
verification of shards before blocking 1 succeeded but block has been removed in the meantime
verification of shards before blocking 2 succeeded but block has been removed in the meantime
verification of shards before blocking 3 succeeded but block has been removed in the meantime
verification of shards before blocking 4 succeeded but block has been removed in the meantime
verification of shards before blocking 5 succeeded but block has been removed in the meantime
verification of shards before blocking 6 succeeded but block has been removed in the meantime
verification of shards before blocking 7 succeeded but block has been removed in the meantime
verification of shards before blocking 8 succeeded but block has been removed in the meantime
verification of shards before blocking 9 succeeded but block has been removed in the meantime
verification of shards before blocking 10 succeeded but block has been removed in the meantime
verification of shards before blocking 11 succeeded but block has been removed in the meantime
verification of shards before blocking 12 succeeded but block has been removed in the meantime
verification of shards before blocking 13 succeeded but block has been removed in the meantime
releasing snapshot caused exceptionFileNotFoundException
releasing snapshot caused exceptionOutOfMemoryError
releasing snapshot caused exceptionArrayIndexOutOfBoundsException
releasing snapshot caused exceptionIllegalArgumentException
releasing snapshot caused exceptionNoSuchElementException
releasing snapshot caused exceptionIllegalStateException
releasing snapshot caused exceptionArithmeticException
releasing snapshot caused exceptionClassCastException
releasing snapshot caused exceptionIndexOutOfBoundsException
releasing snapshot caused exceptionNumberFormatException
releasing snapshot caused exceptionNullPointerException
releasing snapshot caused exceptionStackOverflowError
releasing snapshot caused exceptionUnsupportedOperationException
using max_bytes_per_sec[50]
using max_bytes_per_sec[200]
using max_bytes_per_sec[75]
using max_bytes_per_sec[150]
using max_bytes_per_sec[125]
using max_bytes_per_sec[80]
using max_bytes_per_sec[180]
using max_bytes_per_sec[60]
using max_bytes_per_sec[90]
using max_bytes_per_sec[110]
using max_bytes_per_sec[70]
using max_bytes_per_sec[130]
using max_bytes_per_sec[160]
verification of shards for 2 succeeded, but block finalization already occurred (possibly for another block) [def456]
verification of shards for 3 succeeded, but block finalization already occurred (possibly for another block) [ghi789]
verification of shards for 4 succeeded, but block finalization already occurred (possibly for another block) [jkl012]
verification of shards for 5 succeeded, but block finalization already occurred (possibly for another block) [mno345]
verification of shards for 6 succeeded, but block finalization already occurred (possibly for another block) [pqr678]
verification of shards for 7 succeeded, but block finalization already occurred (possibly for another block) [stu901]
verification of shards for 8 succeeded, but block finalization already occurred (possibly for another block) [vwx234]
verification of shards for 9 succeeded, but block finalization already occurred (possibly for another block) [yz015]
verification of shards for 10 succeeded, but block finalization already occurred (possibly for another block) [abc246]
verification of shards for 11 succeeded, but block finalization already occurred (possibly for another block) [def567]
verification of shards for 12 succeeded, but block finalization already occurred (possibly for another block) [ghi890]
verification of shards for 13 succeeded, but block finalization already occurred (possibly for another block) [jkl123]
verification of shards for 14 succeeded, but block finalization already occurred (possibly for another block) [mno456]
index_2 has been deleted since blocking it started, ignoring
index_3 has been deleted since blocking it started, ignoring
index_4 has been deleted since blocking it started, ignoring
index_5 has been deleted since blocking it started, ignoring
index_6 has been deleted since blocking it started, ignoring
index_7 has been deleted since blocking it started, ignoring
index_8 has been deleted since blocking it started, ignoring
index_9 has been deleted since blocking it started, ignoring
index_10 has been deleted since blocking it started, ignoring
index_11 has been deleted since blocking it started, ignoring
index_12 has been deleted since blocking it started, ignoring
index_13 has been deleted since blocking it started, ignoring
index_14 has been deleted since blocking it started, ignoring
[ES_index2] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index3] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index4] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index5] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index6] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index7] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index8] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index9] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index10] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index11] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index12] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index13] indices opened, but the operation timed out while waiting for enough shards to be started.
[ES_index14] indices opened, but the operation timed out while waiting for enough shards to be started.
completed closing of indices index2
completed closing of indices index3
completed closing of indices index4
completed closing of indices index5
completed closing of indices index6
completed closing of indices index7
completed closing of indices index8
completed closing of indices index9
completed closing of indices index10
completed closing of indices index11
completed closing of indices index12
completed closing of indices index13
completed closing of indices index14
closing index 2 succeeded
closing index 3 succeeded
closing index 4 succeeded
closing index 5 succeeded
closing index 6 succeeded
closing index 7 succeeded
closing index 8 succeeded
closing index 9 succeeded
closing index 10 succeeded
closing index 11 succeeded
closing index 12 succeeded
closing index 13 succeeded
closing index 14 succeeded
delaying recovery due to missing mapping changesIndexOutOfBoundsException
delaying recovery due to missing mapping changesArrayIndexOutOfBoundsException
delaying recovery due to missing mapping changesIllegalArgumentException
delaying recovery due to missing mapping changesIllegalStateException
delaying recovery due to missing mapping changesFileNotFoundException
delaying recovery due to missing mapping changesNoSuchElementException
delaying recovery due to missing mapping changesConcurrentModificationException
delaying recovery due to missing mapping changesUnsupportedOperationException
delaying recovery due to missing mapping changesClassCastException
delaying recovery due to missing mapping changesNumberFormatException
delaying recovery due to missing mapping changesAssertionError
delaying recovery due to missing mapping changesStackOverflowError
delaying recovery due to missing mapping changesOutOfMemoryError
delaying recovery due to missing mapping changesNoClassDefFoundError
verification of shards before closing 2 succeeded but block has been removed in the meantime
verification of shards before closing 3 succeeded but block has been removed in the meantime
verification of shards before closing 4 succeeded but block has been removed in the meantime
verification of shards before closing 5 succeeded but block has been removed in the meantime
verification of shards before closing 6 succeeded but block has been removed in the meantime
verification of shards before closing 7 succeeded but block has been removed in the meantime
verification of shards before closing 8 succeeded but block has been removed in the meantime
verification of shards before closing 9 succeeded but block has been removed in the meantime
verification of shards before closing 10 succeeded but block has been removed in the meantime
verification of shards before closing 11 succeeded but block has been removed in the meantime
verification of shards before closing 12 succeeded but block has been removed in the meantime
verification of shards before closing 13 succeeded but block has been removed in the meantime
verification of shards before closing 14 succeeded but block has been removed in the meantime
verification of shards before closing 1 failed [missing shard]
verification of shards before closing 2 failed [timeout]
verification of shards before closing 3 failed [data inconsistency]
verification of shards before closing 4 failed [database connection error]
verification of shards before closing 5 failed [disk full]
verification of shards before closing 6 failed [invalid checksum]
verification of shards before closing 7 failed [unreachable node]
verification of shards before closing 8 failed [concurrency issue]
verification of shards before closing 9 failed [authentication failed]
verification of shards before closing 10 failed [file not found]
verification of shards before closing 11 failed [memory allocation error]
verification of shards before closing 12 failed [network congestion]
verification of shards before closing 13 failed [invalid configuration]
index_2 has been deleted since it was blocked before closing, ignoring
index_3 has been deleted since it was blocked before closing, ignoring
index_4 has been deleted since it was blocked before closing, ignoring
index_5 has been deleted since it was blocked before closing, ignoring
index_6 has been deleted since it was blocked before closing, ignoring
index_7 has been deleted since it was blocked before closing, ignoring
index_8 has been deleted since it was blocked before closing, ignoring
index_9 has been deleted since it was blocked before closing, ignoring
index_10 has been deleted since it was blocked before closing, ignoring
index_11 has been deleted since it was blocked before closing, ignoring
index_12 has been deleted since it was blocked before closing, ignoring
index_13 has been deleted since it was blocked before closing, ignoring
index_14 has been deleted since it was blocked before closing, ignoring
index 2 has since been deleted, ignoring
index 3 has since been deleted, ignoring
index 4 has since been deleted, ignoring
index 5 has since been deleted, ignoring
index 6 has since been deleted, ignoring
index 7 has since been deleted, ignoring
index 8 has since been deleted, ignoring
index 9 has since been deleted, ignoring
index 10 has since been deleted, ignoring
index 11 has since been deleted, ignoring
index 12 has since been deleted, ignoring
index 13 has since been deleted, ignoring
index 14 has since been deleted, ignoring
<ERROR> shard folder empty, recovering all files
<INFO> shard folder empty, recovering all files
<ALERT> shard folder empty, recovering all files
<DEBUG> shard folder empty, recovering all files
<CRITICAL> shard folder empty, recovering all files
<NOTICE> shard folder empty, recovering all files
<SUCCESS> shard folder empty, recovering all files
<FAILURE> shard folder empty, recovering all files
<ALARM> shard folder empty, recovering all files
<CRASH> shard folder empty, recovering all files
<EMERGENCY> shard folder empty, recovering all files
<NOTIFICATION> shard folder empty, recovering all files
<INFO> shard folder empty, recovering all files
primary shard 2 is unassigned, ignoring
primary shard 3 is unassigned, ignoring
primary shard 4 is unassigned, ignoring
primary shard 5 is unassigned, ignoring
primary shard 6 is unassigned, ignoring
primary shard 7 is unassigned, ignoring
primary shard 8 is unassigned, ignoring
primary shard 9 is unassigned, ignoring
primary shard 10 is unassigned, ignoring
primary shard 11 is unassigned, ignoring
primary shard 12 is unassigned, ignoring
primary shard 13 is unassigned, ignoring
primary shard 14 is unassigned, ignoring
node456 preparing shard for peer recovery
node789 preparing shard for peer recovery
node123 preparing shard for peer recovery
node456 preparing shard for peer recovery
node789 preparing shard for peer recovery
node123 preparing shard for peer recovery
node456 preparing shard for peer recovery
node789 preparing shard for peer recovery
node123 preparing shard for peer recovery
node456 preparing shard for peer recovery
node789 preparing shard for peer recovery
node123 preparing shard for peer recovery
node456 preparing shard for peer recovery
index 2 has been blocked before closing and is now deleted, ignoring
index 3 has been blocked before closing and is now deleted, ignoring
index 4 has been blocked before closing and is now deleted, ignoring
index 5 has been blocked before closing and is now deleted, ignoring
index 6 has been blocked before closing and is now deleted, ignoring
index 7 has been blocked before closing and is now deleted, ignoring
index 8 has been blocked before closing and is now deleted, ignoring
index 9 has been blocked before closing and is now deleted, ignoring
index 10 has been blocked before closing and is now deleted, ignoring
index 11 has been blocked before closing and is now deleted, ignoring
index 12 has been blocked before closing and is now deleted, ignoring
index 13 has been blocked before closing and is now deleted, ignoring
index 14 has been blocked before closing and is now deleted, ignoring
index 2 already has block B, ignoring
index 3 already has block C, ignoring
index 4 already has block D, ignoring
index 5 already has block E, ignoring
index 6 already has block F, ignoring
index 7 already has block G, ignoring
index 8 already has block H, ignoring
index 9 already has block I, ignoring
index 10 already has block J, ignoring
index 11 already has block K, ignoring
index 12 already has block L, ignoring
index 13 already has block M, ignoring
index 14 already has block N, ignoring
index 2 is already closed, ignoring
index 3 is already closed, ignoring
index 4 is already closed, ignoring
index 5 is already closed, ignoring
index 6 is already closed, ignoring
index 7 is already closed, ignoring
index 8 is already closed, ignoring
index 9 is already closed, ignoring
index 10 is already closed, ignoring
index 11 is already closed, ignoring
index 12 is already closed, ignoring
index 13 is already closed, ignoring
index 14 is already closed, ignoring
not running recovery with id [5678] - can not find it (probably finished)
not running recovery with id [1234] - can not find it (probably finished)
not running recovery with id [8765] - can not find it (probably finished)
not running recovery with id [4321] - can not find it (probably finished)
not running recovery with id [7890] - can not find it (probably finished)
not running recovery with id [3456] - can not find it (probably finished)
not running recovery with id [0987] - can not find it (probably finished)
not running recovery with id [6543] - can not find it (probably finished)
not running recovery with id [2109] - can not find it (probably finished)
not running recovery with id [5678] - can not find it (probably finished)
not running recovery with id [4323] - can not find it (probably finished)
not running recovery with id [9090] - can not find it (probably finished)
not running recovery with id [6767] - can not find it (probably finished)
will try to reestablish recovery with id [5678] in [5 minutes] (reason [server error])
will try to reestablish recovery with id [91011] in [15 minutes] (reason [timeout])
will try to reestablish recovery with id [121314] in [20 minutes] (reason [network congestion])
will try to reestablish recovery with id [151617] in [8 minutes] (reason [memory overflow])
will try to reestablish recovery with id [181920] in [12 minutes] (reason [database corruption])
will try to reestablish recovery with id [212223] in [6 minutes] (reason [power outage])
will try to reestablish recovery with id [242526] in [18 minutes] (reason [disk failure])
will try to reestablish recovery with id [272829] in [9 minutes] (reason [invalid request])
will try to reestablish recovery with id [303132] in [14 minutes] (reason [encryption error])
will try to reestablish recovery with id [333435] in [7 minutes] (reason [authentication failed])
will try to reestablish recovery with id [363738] in [11 minutes] (reason [data inconsistency])
will try to reestablish recovery with id [394041] in [13 minutes] (reason [configuration issue])
will try to reestablish recovery with id [424344] in [16 minutes] (reason [software bug])
will retry recovery with id [456] in [30 seconds] (reason [timeout])
will retry recovery with id [789] in [5 seconds] (reason [server error])
will retry recovery with id [321] in [20 seconds] (reason [connection lost])
will retry recovery with id [654] in [15 seconds] (reason [service unavailable])
will retry recovery with id [987] in [8 seconds] (reason [invalid credentials])
will retry recovery with id [159] in [12 seconds] (reason [database error])
will retry recovery with id [753] in [25 seconds] (reason [memory overflow])
will retry recovery with id [852] in [7 seconds] (reason [input validation failed])
will retry recovery with id [468] in [15 seconds] (reason [file not found])
will retry recovery with id [246] in [10 seconds] (reason [authentication failed])
will retry recovery with id [369] in [23 seconds] (reason [unexpected response])
will retry recovery with id [147] in [6 seconds] (reason [resource conflict])
will retry recovery with id [258] in [18 seconds] (reason [permission denied])
15 tombstones purged from the cluster state. Previous tombstone size: 200. Current tombstone size: 185.
5 tombstones purged from the cluster state. Previous tombstone size: 75. Current tombstone size: 70.
20 tombstones purged from the cluster state. Previous tombstone size: 150. Current tombstone size: 130.
8 tombstones purged from the cluster state. Previous tombstone size: 120. Current tombstone size: 112.
2 tombstones purged from the cluster state. Previous tombstone size: 30. Current tombstone size: 28.
12 tombstones purged from the cluster state. Previous tombstone size: 80. Current tombstone size: 68.
6 tombstones purged from the cluster state. Previous tombstone size: 90. Current tombstone size: 84.
18 tombstones purged from the cluster state. Previous tombstone size: 220. Current tombstone size: 202.
3 tombstones purged from the cluster state. Previous tombstone size: 50. Current tombstone size: 47.
16 tombstones purged from the cluster state. Previous tombstone size: 180. Current tombstone size: 164.
7 tombstones purged from the cluster state. Previous tombstone size: 110. Current tombstone size: 103.
11 tombstones purged from the cluster state. Previous tombstone size: 140. Current tombstone size: 129.
9 tombstones purged from the cluster state. Previous tombstone size: 130. Current tombstone size: 121.
cleaning temporary file [temp2.txt]
cleaning temporary file [temp3.txt]
cleaning temporary file [temp4.txt]
cleaning temporary file [temp5.txt]
cleaning temporary file [temp6.txt]
cleaning temporary file [temp7.txt]
cleaning temporary file [temp8.txt]
cleaning temporary file [temp9.txt]
cleaning temporary file [temp10.txt]
cleaning temporary file [temp11.txt]
cleaning temporary file [temp12.txt]
cleaning temporary file [temp13.txt]
cleaning temporary file [temp14.txt]
snapshot translog for recovery; current size is [5]
snapshot translog for recovery; current size is [20]
snapshot translog for recovery; current size is [15]
snapshot translog for recovery; current size is [8]
snapshot translog for recovery; current size is [12]
snapshot translog for recovery; current size is [6]
snapshot translog for recovery; current size is [19]
snapshot translog for recovery; current size is [14]
snapshot translog for recovery; current size is [7]
snapshot translog for recovery; current size is [9]
snapshot translog for recovery; current size is [17]
snapshot translog for recovery; current size is [3]
snapshot translog for recovery; current size is [13]
performing sequence numbers based recovery. starting at [245]
performing sequence numbers based recovery. starting at [379]
performing sequence numbers based recovery. starting at [421]
performing sequence numbers based recovery. starting at [563]
performing sequence numbers based recovery. starting at [624]
performing sequence numbers based recovery. starting at [778]
performing sequence numbers based recovery. starting at [811]
performing sequence numbers based recovery. starting at [944]
performing sequence numbers based recovery. starting at [1001]
performing sequence numbers based recovery. starting at [1156]
performing sequence numbers based recovery. starting at [1257]
performing sequence numbers based recovery. starting at [1322]
performing sequence numbers based recovery. starting at [1479]
no peer-recovery retention lease for 67890
no peer-recovery retention lease for 54321
no peer-recovery retention lease for 09876
no peer-recovery retention lease for 98765
no peer-recovery retention lease for 12340
no peer-recovery retention lease for 45678
no peer-recovery retention lease for 90123
no peer-recovery retention lease for 23456
no peer-recovery retention lease for 78901
no peer-recovery retention lease for 34567
no peer-recovery retention lease for 89012
no peer-recovery retention lease for 45670
no peer-recovery retention lease for 12345
performing file-based recovery followed by history replay starting at [200]
performing file-based recovery followed by history replay starting at [300]
performing file-based recovery followed by history replay starting at [400]
performing file-based recovery followed by history replay starting at [500]
performing file-based recovery followed by history replay starting at [600]
performing file-based recovery followed by history replay starting at [700]
performing file-based recovery followed by history replay starting at [800]
performing file-based recovery followed by history replay starting at [900]
performing file-based recovery followed by history replay starting at [1000]
performing file-based recovery followed by history replay starting at [1100]
performing file-based recovery followed by history replay starting at [1200]
performing file-based recovery followed by history replay starting at [1300]
performing file-based recovery followed by history replay starting at [1400]
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
history is retained by retention lock
writing out of dangling indices state for index def completed after 2000
writing out of dangling indices state for index ghi completed after 3000
writing out of dangling indices state for index jkl completed after 4000
writing out of dangling indices state for index mno completed after 5000
writing out of dangling indices state for index pqr completed after 6000
writing out of dangling indices state for index stu completed after 7000
writing out of dangling indices state for index vwx completed after 8000
writing out of dangling indices state for index yz completed after 9000
writing out of dangling indices state for index 123 completed after 10000
writing out of dangling indices state for index 456 completed after 11000
writing out of dangling indices state for index 789 completed after 12000
writing out of dangling indices state for index abcdef completed after 13000
writing out of dangling indices state for index ghijkl completed after 14000
index [order_date] is a hidden index
index [product_name] is a hidden index
index [price] is a hidden index
index [category_id] is a hidden index
index [supplier_id] is a hidden index
index [quantity] is a hidden index
index [status] is a hidden index
index [sales_rep] is a hidden index
index [customer_address] is a hidden index
index [order_id] is a hidden index
index [product_id] is a hidden index
index [discount] is a hidden index
index [order_status] is a hidden index
omit writing dangling indices state for index 2 as index is deallocated on this node
omit writing dangling indices state for index 3 as index is deallocated on this node
omit writing dangling indices state for index 4 as index is deallocated on this node
omit writing dangling indices state for index 5 as index is deallocated on this node
omit writing dangling indices state for index 6 as index is deallocated on this node
omit writing dangling indices state for index 7 as index is deallocated on this node
omit writing dangling indices state for index 8 as index is deallocated on this node
omit writing dangling indices state for index 9 as index is deallocated on this node
omit writing dangling indices state for index 10 as index is deallocated on this node
omit writing dangling indices state for index 11 as index is deallocated on this node
omit writing dangling indices state for index 12 as index is deallocated on this node
omit writing dangling indices state for index 13 as index is deallocated on this node
omit writing dangling indices state for index 14 as index is deallocated on this node
triggered dangling indices update for index2
triggered dangling indices update for index3
triggered dangling indices update for index4
triggered dangling indices update for index5
triggered dangling indices update for index6
triggered dangling indices update for index7
triggered dangling indices update for index8
triggered dangling indices update for index9
triggered dangling indices update for index10
triggered dangling indices update for index11
triggered dangling indices update for index12
triggered dangling indices update for index13
triggered dangling indices update for index14
dangling indices update already pending for index_2
dangling indices update already pending for index_3
dangling indices update already pending for index_4
dangling indices update already pending for index_5
dangling indices update already pending for index_6
dangling indices update already pending for index_7
dangling indices update already pending for index_8
dangling indices update already pending for index_9
dangling indices update already pending for index_10
dangling indices update already pending for index_11
dangling indices update already pending for index_12
dangling indices update already pending for index_13
dangling indices update already pending for index_14
scheduling next cluster info refresh in [5 minutes]
scheduling next cluster info refresh in [30 minutes]
scheduling next cluster info refresh in [1 hour]
scheduling next cluster info refresh in [15 minutes]
scheduling next cluster info refresh in [20 minutes]
scheduling next cluster info refresh in [45 minutes]
scheduling next cluster info refresh in [3 hours]
scheduling next cluster info refresh in [2 hours]
scheduling next cluster info refresh in [1 minute]
scheduling next cluster info refresh in [4 hours]
scheduling next cluster info refresh in [10 seconds]
scheduling next cluster info refresh in [2 minutes]
scheduling next cluster info refresh in [1 day]
Exception during periodic request cache cleanup: OutOfMemoryError
Exception during periodic request cache cleanup: FileNotFoundException
Exception during periodic request cache cleanup: StackOverflowError
Exception during periodic request cache cleanup: IllegalArgumentException
Exception during periodic request cache cleanup: NullPointerException
Exception during periodic request cache cleanup: IndexOutOfBoundsException
Exception during periodic request cache cleanup: ArithmeticException
Exception during periodic request cache cleanup: ClassCastException
Exception during periodic request cache cleanup: ArrayIndexOutOfBoundsException
Exception during periodic request cache cleanup: NoSuchElementException
Exception during periodic request cache cleanup: UnsupportedOperationException
Exception during periodic request cache cleanup: UnsupportedOperationException
Exception during periodic request cache cleanup: UnsupportedOperationException
Exception during periodic request cache cleanup: ConcurrentModificationException
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
cluster-manager changed, scheduled refresh job is stale
periodic field data cache cleanup finished in 101 milliseconds
periodic field data cache cleanup finished in 84 milliseconds
periodic field data cache cleanup finished in 112 milliseconds
periodic field data cache cleanup finished in 91 milliseconds
periodic field data cache cleanup finished in 105 milliseconds
periodic field data cache cleanup finished in 80 milliseconds
periodic field data cache cleanup finished in 118 milliseconds
periodic field data cache cleanup finished in 95 milliseconds
periodic field data cache cleanup finished in 109 milliseconds
periodic field data cache cleanup finished in 87 milliseconds
periodic field data cache cleanup finished in 114 milliseconds
periodic field data cache cleanup finished in 99 milliseconds
periodic field data cache cleanup finished in 103 milliseconds
refreshing cluster info [failure]
refreshing cluster info [timeout]
refreshing cluster info [new node added]
refreshing cluster info [rebalancing]
refreshing cluster info [data migration]
refreshing cluster info [network issue]
refreshing cluster info [maintenance mode]
refreshing cluster info [node removed]
refreshing cluster info [resource allocation]
refreshing cluster info [configuration change]
refreshing cluster info [scaling]
refreshing cluster info [service restart]
refreshing cluster info [cluster offline]
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
running periodic field data cache cleanup
skipping cluster info refresh [low memory] since it is disabled
skipping cluster info refresh [network issue] since it is disabled
skipping cluster info refresh [backup process] since it is disabled
skipping cluster info refresh [load balancing] since it is disabled
skipping cluster info refresh [maintenance] since it is disabled
skipping cluster info refresh [low memory] since it is disabled
skipping cluster info refresh [network issue] since it is disabled
skipping cluster info refresh [backup process] since it is disabled
skipping cluster info refresh [load balancing] since it is disabled
skipping cluster info refresh [maintenance] since it is disabled
skipping cluster info refresh [low memory] since it is disabled
skipping cluster info refresh [network issue] since it is disabled
skipping cluster info refresh [backup process] since it is disabled
ERROR schedule pending delete retry after 200 ms
INFO schedule pending delete retry after 300 ms
WARNING schedule pending delete retry after 400 ms
ERROR schedule pending delete retry after 500 ms
INFO schedule pending delete retry after 600 ms
WARNING schedule pending delete retry after 700 ms
ERROR schedule pending delete retry after 800 ms
INFO schedule pending delete retry after 900 ms
WARNING schedule pending delete retry after 1000 ms
ERROR schedule pending delete retry after 1100 ms
INFO schedule pending delete retry after 1200 ms
WARNING schedule pending delete retry after 1300 ms
ERROR schedule pending delete retry after 1400 ms
ERROR: no shard lock for pending delete
INFO: no shard lock for pending delete
WARNING: no shard lock for pending delete
ERROR: no shard lock for pending delete
INFO: no shard lock for pending delete
WARNING: no shard lock for pending delete
ERROR: no shard lock for pending delete
INFO: no shard lock for pending delete
WARNING: no shard lock for pending delete
ERROR: no shard lock for pending delete
INFO: no shard lock for pending delete
WARNING: no shard lock for pending delete
ERROR: no shard lock for pending delete
node: [node2] least available path has less than 0 total bytes of disk [512GB], skipping
node: [node3] least available path has less than 0 total bytes of disk [128GB], skipping
node: [node4] least available path has less than 0 total bytes of disk [1TB], skipping
node: [node5] least available path has less than 0 total bytes of disk [256GB], skipping
node: [node6] least available path has less than 0 total bytes of disk [512GB], skipping
node: [node7] least available path has less than 0 total bytes of disk [128GB], skipping
node: [node8] least available path has less than 0 total bytes of disk [1TB], skipping
node: [node9] least available path has less than 0 total bytes of disk [256GB], skipping
node: [node10] least available path has less than 0 total bytes of disk [512GB], skipping
node: [node11] least available path has less than 0 total bytes of disk [128GB], skipping
node: [node12] least available path has less than 0 total bytes of disk [1TB], skipping
node: [node13] least available path has less than 0 total bytes of disk [256GB], skipping
node: [node14] least available path has less than 0 total bytes of disk [512GB], skipping
Search processing pending deletes
Backup processing pending deletes
Logging processing pending deletes
Database processing pending deletes
Cache processing pending deletes
Server processing pending deletes
Email processing pending deletes
Notification processing pending deletes
Analytics processing pending deletes
Security processing pending deletes
Monitoring processing pending deletes
Reporting processing pending deletes
Authentication processing pending deletes
node: [212], most available: total disk: 800GB, available disk: 400GB / least available: total disk: 200GB, available disk: 50GB
node: [533], most available: total disk: 1200GB, available disk: 800GB / least available: total disk: 300GB, available disk: 150GB
node: [654], most available: total disk: 1500GB, available disk: 900GB / least available: total disk: 1000GB, available disk: 750GB
node: [128], most available: total disk: 800GB, available disk: 600GB / least available: total disk: 200GB, available disk: 100GB
node: [331], most available: total disk: 500GB, available disk: 200GB / least available: total disk: 100GB, available disk: 50GB
node: [453], most available: total disk: 700GB, available disk: 400GB / least available: total disk: 300GB, available disk: 150GB
node: [239], most available: total disk: 1000GB, available disk: 700GB / least available: total disk: 500GB, available disk: 300GB
node: [877], most available: total disk: 1200GB, available disk: 800GB / least available: total disk: 800GB, available disk: 600GB
node: [566], most available: total disk: 1500GB, available disk: 1000GB / least available: total disk: 500GB, available disk: 450GB
node: [401], most available: total disk: 800GB, available disk: 600GB / least available: total disk: 400GB, available disk: 300GB
node: [764], most available: total disk: 500GB, available disk: 300GB / least available: total disk: 300GB, available disk: 200GB
node: [932], most available: total disk: 700GB, available disk: 500GB / least available: total disk: 200GB, available disk: 100GB
node: [577], most available: total disk: 1000GB, available disk: 800GB / least available: total disk: 500GB, available disk: 400GB
[2] still has shard stores, leaving as is
[3] still has shard stores, leaving as is
[4] still has shard stores, leaving as is
[5] still has shard stores, leaving as is
[6] still has shard stores, leaving as is
[7] still has shard stores, leaving as is
[8] still has shard stores, leaving as is
[9] still has shard stores, leaving as is
[10] still has shard stores, leaving as is
[11] still has shard stores, leaving as is
[12] still has shard stores, leaving as is
[13] still has shard stores, leaving as is
[14] still has shard stores, leaving as is
INFO: Shard 2 deleted shard reason [Disk failure]
INFO: Shard 3 deleted shard reason [Data corruption]
INFO: Shard 4 deleted shard reason [Out of storage]
INFO: Shard 5 deleted shard reason [Hardware upgrade]
INFO: Shard 6 deleted shard reason [Network congestion]
INFO: Shard 7 deleted shard reason [Software bug]
INFO: Shard 8 deleted shard reason [Power outage]
INFO: Shard 9 deleted shard reason [Configuration error]
INFO: Shard 10 deleted shard reason [Load balancing]
INFO: Shard 11 deleted shard reason [Backup operation]
INFO: Shard 12 deleted shard reason [Security breach]
INFO: Shard 13 deleted shard reason [Maintenance window]
INFO: Shard 14 deleted shard reason [Database corruption]
Failed to update shard information for ClusterInfoUpdateJob within 15 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 20 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 25 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 30 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 35 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 40 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 45 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 50 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 55 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 60 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 65 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 70 seconds timeout
Failed to update shard information for ClusterInfoUpdateJob within 75 seconds timeout
Failed to update node information for ClusterInfoUpdateJob within 1000ms timeout
Failed to update node information for ClusterInfoUpdateJob within 1500ms timeout
Failed to update node information for ClusterInfoUpdateJob within 2000ms timeout
Failed to update node information for ClusterInfoUpdateJob within 2500ms timeout
Failed to update node information for ClusterInfoUpdateJob within 3000ms timeout
Failed to update node information for ClusterInfoUpdateJob within 3500ms timeout
Failed to update node information for ClusterInfoUpdateJob within 4000ms timeout
Failed to update node information for ClusterInfoUpdateJob within 4500ms timeout
Failed to update node information for ClusterInfoUpdateJob within 5000ms timeout
Failed to update node information for ClusterInfoUpdateJob within 5500ms timeout
Failed to update node information for ClusterInfoUpdateJob within 6000ms timeout
Failed to update node information for ClusterInfoUpdateJob within 6500ms timeout
Failed to update node information for ClusterInfoUpdateJob within 7000ms timeout
IndicesStatsAction timed out for ClusterInfoUpdateJobTimeoutException
IndicesStatsAction timed out for ClusterInfoUpdateJobIllegalArgumentException
IndicesStatsAction timed out for ClusterInfoUpdateJobArrayIndexOutOfBoundsException
IndicesStatsAction timed out for ClusterInfoUpdateJobArithmeticException
IndicesStatsAction timed out for ClusterInfoUpdateJobClassCastException
IndicesStatsAction timed out for ClusterInfoUpdateJobNumberFormatException
IndicesStatsAction timed out for ClusterInfoUpdateJobNoSuchElementException
IndicesStatsAction timed out for ClusterInfoUpdateJobIndexOutOfBoundsException
IndicesStatsAction timed out for ClusterInfoUpdateJobOutOfMemoryError
IndicesStatsAction timed out for ClusterInfoUpdateJobStackOverflowError
IndicesStatsAction timed out for ClusterInfoUpdateJobAssertionError
IndicesStatsAction timed out for ClusterInfoUpdateJobExceptionInInitializerError
IndicesStatsAction timed out for ClusterInfoUpdateJobNoClassDefFoundError
IndicesStatsAction timed out for ClusterInfoUpdateJobUnsatisfiedLinkError
ERROR: closing index service (reason [disk full][failed to write])
INFO: closing index service (reason [unexpected shutdown][network error])
WARNING: closing index service (reason [out of memory][null])
ERROR: closing index service (reason [disk full][failed to write])
INFO: closing index service (reason [unexpected shutdown][network error])
WARNING: closing index service (reason [out of memory][null])
ERROR: closing index service (reason [disk full][failed to write])
INFO: closing index service (reason [unexpected shutdown][network error])
WARNING: closing index service (reason [out of memory][null])
ERROR: closing index service (reason [disk full][failed to write])
INFO: closing index service (reason [unexpected shutdown][network error])
WARNING: closing index service (reason [out of memory][null])
ERROR: closing index service (reason [disk full][failed to write])
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobTimeoutException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobIOException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobIndexOutOfBoundsException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobIllegalArgumentException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobClassNotFoundException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobNoSuchElementException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobOutOfMemoryError
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobStackOverflowError
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobArithmeticException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobRuntimeException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobInvalidStateException
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobAssertionError
Failed to execute IndicesStatsAction for ClusterInfoUpdateJobNoClassDefFoundError
NodeStatsAction timed out for ClusterInfoUpdateJobTimeoutException
NodeStatsAction timed out for ClusterInfoUpdateJobIllegalStateException
NodeStatsAction timed out for ClusterInfoUpdateJobIndexOutOfBoundsException
NodeStatsAction timed out for ClusterInfoUpdateJobClassNotFoundException
NodeStatsAction timed out for ClusterInfoUpdateJobArithmeticException
NodeStatsAction timed out for ClusterInfoUpdateJobNumberFormatException
NodeStatsAction timed out for ClusterInfoUpdateJobArrayIndexOutOfBoundsException
NodeStatsAction timed out for ClusterInfoUpdateJobNoSuchElementException
NodeStatsAction timed out for ClusterInfoUpdateJobConcurrentModificationException
NodeStatsAction timed out for ClusterInfoUpdateJobUnsupportedOperationException
NodeStatsAction timed out for ClusterInfoUpdateJobIllegalArgumentException
NodeStatsAction timed out for ClusterInfoUpdateJobAssertionError
NodeStatsAction timed out for ClusterInfoUpdateJobStackOverflowError
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info
refreshing cluster info in background [rebalancing partitions]
refreshing cluster info in background [updating metadata]
refreshing cluster info in background [synchronizing data]
refreshing cluster info in background [checking heartbeat]
refreshing cluster info in background [recovering from failure]
refreshing cluster info in background [optimizing query execution]
refreshing cluster info in background [loading configuration]
refreshing cluster info in background [scaling resources]
refreshing cluster info in background [restarting services]
refreshing cluster info in background [compacting database]
refreshing cluster info in background [monitoring performance]
refreshing cluster info in background [updating security policies]
refreshing cluster info in background [cleaning up logs]
Removing node from cluster info: 456
Removing node from cluster info: 789
Removing node from cluster info: 321
Removing node from cluster info: 654
Removing node from cluster info: 987
Removing node from cluster info: 234
Removing node from cluster info: 567
Removing node from cluster info: 890
Removing node from cluster info: 432
Removing node from cluster info: 765
Removing node from cluster info: 098
Removing node from cluster info: 543
Removing node from cluster info: 876
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
elected as cluster-manager, scheduling cluster info update tasks
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
successfully cleared voting config exclusion and decommissioned attribute
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
Deleting the decommission attribute from the cluster state
unexpected failure occurred during decommission status updateNullPointerException
unexpected failure occurred during decommission status updateOutOfMemoryError
unexpected failure occurred during decommission status updateIllegalArgumentException
unexpected failure occurred during decommission status updateIndexOutOfBoundsException
unexpected failure occurred during decommission status updateClassCastException
unexpected failure occurred during decommission status updateArrayIndexOutOfBoundsException
unexpected failure occurred during decommission status updateStringIndexOutOfBoundsException
unexpected failure occurred during decommission status updateNoSuchElementException
unexpected failure occurred during decommission status updateNumberFormatException
unexpected failure occurred during decommission status updateConcurrentModificationException
unexpected failure occurred during decommission status updateUnsupportedOperationException
unexpected failure occurred during decommission status updateAssertionError
unexpected failure occurred during decommission status updateStackOverflowError
unexpected failure occurred during decommission status updateNoClassDefFoundError
updated the decommission status to [in progress]
updated the decommission status to [failed]
updated the decommission status to [paused]
updated the decommission status to [cancelled]
updated the decommission status to [pending]
updated the decommission status to [unknown]
updated the decommission status to [succeeded]
updated the decommission status to [error]
updated the decommission status to [waiting]
updated the decommission status to [aborted]
updated the decommission status to [terminated]
updated the decommission status to [finished]
updated the decommission status to [unsuccessful]
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
waiting to abdicate to-be-decommissioned leader
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
will proceed to drain decommissioned nodes as local node is eligible to process the request
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
local node is not eligible to process the request, throwing NotClusterManagerException to attempt a retry on an eligible node
resolved cluster manager eligible nodes [node4, node5, node6] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node7, node8, node9] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node10, node11, node12] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node13, node14, node15] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node16, node17, node18] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node19, node20, node21] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node22, node23, node24] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node25, node26, node27] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node28, node29, node30] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node31, node32, node33] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node34, node35, node36] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node37, node38, node39] that should be added to voting config exclusion
resolved cluster manager eligible nodes [node40, node41, node42] that should be added to voting config exclusion
now write some indexing buffers: total indexing heap bytes used [197MB] vs 128MB [1024MB], currently writing bytes [256MB], [4] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [243MB] vs 64MB [512MB], currently writing bytes [128MB], [2] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [180MB] vs 512MB [4096MB], currently writing bytes [1024MB], [16] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [215MB] vs 32MB [256MB], currently writing bytes [64MB], [1] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [112MB] vs 16MB [128MB], currently writing bytes [32MB], [1] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [275MB] vs 8MB [64MB], currently writing bytes [16MB], [1] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [157MB] vs 4MB [32MB], currently writing bytes [8MB], [1] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [89MB] vs 2MB [16MB], currently writing bytes [4MB], [1] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [381MB] vs 1MB [8MB], currently writing bytes [2MB], [1] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [199MB] vs 512KB [4MB], currently writing bytes [1MB], [1] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [415MB] vs 256KB [2MB], currently writing bytes [512KB], [1] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [534MB] vs 128KB [1MB], currently writing bytes [256KB], [1] shards with non-zero indexing buffer
now write some indexing buffers: total indexing heap bytes used [631MB] vs 64KB [512KB], currently writing bytes [128KB], [1] shards with non-zero indexing buffer
shard [2] is using [128MB] heap, writing [32MB] heap
shard [3] is using [256MB] heap, writing [64MB] heap
shard [4] is using [512MB] heap, writing [128MB] heap
shard [5] is using [1GB] heap, writing [256MB] heap
shard [6] is using [2GB] heap, writing [512MB] heap
shard [7] is using [4GB] heap, writing [1GB] heap
shard [8] is using [8GB] heap, writing [2GB] heap
shard [9] is using [16GB] heap, writing [4GB] heap
shard [10] is using [32GB] heap, writing [8GB] heap
shard [11] is using [64GB] heap, writing [16GB] heap
shard [12] is using [128GB] heap, writing [32GB] heap
shard [13] is using [256GB] heap, writing [64GB] heap
shard [14] is using [512GB] heap, writing [128GB] heap
shard [shard2] is using [512] heap, not writing any bytes
shard [shard3] is using [256] heap, not writing any bytes
shard [shard4] is using [128] heap, not writing any bytes
shard [shard5] is using [64] heap, not writing any bytes
shard [shard6] is using [32] heap, not writing any bytes
shard [shard7] is using [16] heap, not writing any bytes
shard [shard8] is using [8] heap, not writing any bytes
shard [shard9] is using [4] heap, not writing any bytes
shard [shard10] is using [2] heap, not writing any bytes
shard [shard11] is using [1] heap, not writing any bytes
shard [shard12] is using [512] heap, not writing any bytes
shard [shard13] is using [256] heap, not writing any bytes
shard [shard14] is using [128] heap, not writing any bytes
Decommissioning node with connections : [10.0.0.1]
Decommissioning node with connections : [172.16.0.1]
Decommissioning node with connections : [192.168.0.1]
Decommissioning node with connections : [10.1.1.1]
Decommissioning node with connections : [172.17.0.1]
Decommissioning node with connections : [192.168.2.1]
Decommissioning node with connections : [10.0.1.1]
Decommissioning node with connections : [172.18.0.1]
Decommissioning node with connections : [192.168.3.1]
Decommissioning node with connections : [10.2.0.1]
Decommissioning node with connections : [172.19.0.1]
Decommissioning node with connections : [192.168.4.1]
Decommissioning node with connections : [10.0.2.1]
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
Node stats response received is null/empty.
attempting to update current decommission status [COMPLETED] with expected status [CANCELLED]
attempting to update current decommission status [PENDING] with expected status [PROCESSING]
attempting to update current decommission status [PENDING] with expected status [COMPLETE]
attempting to update current decommission status [INACTIVE] with expected status [ACTIVE]
attempting to update current decommission status [PROCESSING] with expected status [COMPLETE]
attempting to update current decommission status [CANCELLED] with expected status [COMPLETED]
attempting to update current decommission status [PROCESSING] with expected status [PENDING]
attempting to update current decommission status [CANCELLED] with expected status [PENDING]
attempting to update current decommission status [COMPLETE] with expected status [INACTIVE]
attempting to update current decommission status [ACTIVE] with expected status [COMPLETE]
attempting to update current decommission status [PROCESSING] with expected status [PENDING]
attempting to update current decommission status [INACTIVE] with expected status [COMPLETE]
attempting to update current decommission status [COMPLETE] with expected status [CANCELLED]
timed out [7500] while waiting for removal of decommissioned nodes [node3, node4]
timed out [3000] while waiting for removal of decommissioned nodes [node5, node6]
timed out [6000] while waiting for removal of decommissioned nodes [node7, node8]
timed out [4000] while waiting for removal of decommissioned nodes [node9, node10]
timed out [5500] while waiting for removal of decommissioned nodes [node11, node12]
timed out [2000] while waiting for removal of decommissioned nodes [node13, node14]
timed out [3500] while waiting for removal of decommissioned nodes [node15, node16]
timed out [4500] while waiting for removal of decommissioned nodes [node17, node18]
timed out [6500] while waiting for removal of decommissioned nodes [node19, node20]
timed out [2500] while waiting for removal of decommissioned nodes [node21, node22]
timed out [7000] while waiting for removal of decommissioned nodes [node23, node24]
timed out [1500] while waiting for removal of decommissioned nodes [node25, node26]
timed out [8000] while waiting for removal of decommissioned nodes [node27, node28]
cluster service closed while waiting for removal of decommissioned nodes [node4, node5, node6]
cluster service closed while waiting for removal of decommissioned nodes [node7, node8, node9]
cluster service closed while waiting for removal of decommissioned nodes [node10, node11, node12]
cluster service closed while waiting for removal of decommissioned nodes [node13, node14, node15]
cluster service closed while waiting for removal of decommissioned nodes [node16, node17, node18]
cluster service closed while waiting for removal of decommissioned nodes [node19, node20, node21]
cluster service closed while waiting for removal of decommissioned nodes [node22, node23, node24]
cluster service closed while waiting for removal of decommissioned nodes [node25, node26, node27]
cluster service closed while waiting for removal of decommissioned nodes [node28, node29, node30]
cluster service closed while waiting for removal of decommissioned nodes [node31, node32, node33]
cluster service closed while waiting for removal of decommissioned nodes [node34, node35, node36]
cluster service closed while waiting for removal of decommissioned nodes [node37, node38, node39]
cluster service closed while waiting for removal of decommissioned nodes [node40, node41, node42]
Failed to call listener on global ordinals loadingIOException
Failed to call listener on global ordinals loadingIndexOutOfBoundsException
Failed to call listener on global ordinals loadingClassCastException
Failed to call listener on global ordinals loadingIllegalArgumentException
Failed to call listener on global ordinals loadingOutOfMemoryError
Failed to call listener on global ordinals loadingStackOverflowError
Failed to call listener on global ordinals loadingNoClassDefFoundError
Failed to call listener on global ordinals loadingNoSuchMethodError
Failed to call listener on global ordinals loadingAssertionError
Failed to call listener on global ordinals loadingArrayIndexOutOfBoundsException
Failed to call listener on global ordinals loadingStringIndexOutOfBoundsException
Failed to call listener on global ordinals loadingUnsatisfiedLinkError
Failed to call listener on global ordinals loadingNoSuchFieldError
successfully removed all decommissioned nodes [node4, node5, node6] from the cluster
successfully removed all decommissioned nodes [node7, node8, node9] from the cluster
successfully removed all decommissioned nodes [node10, node11, node12] from the cluster
successfully removed all decommissioned nodes [node13, node14, node15] from the cluster
successfully removed all decommissioned nodes [node16, node17, node18] from the cluster
successfully removed all decommissioned nodes [node19, node20, node21] from the cluster
successfully removed all decommissioned nodes [node22, node23, node24] from the cluster
successfully removed all decommissioned nodes [node25, node26, node27] from the cluster
successfully removed all decommissioned nodes [node28, node29, node30] from the cluster
successfully removed all decommissioned nodes [node31, node32, node33] from the cluster
successfully removed all decommissioned nodes [node34, node35, node36] from the cluster
successfully removed all decommissioned nodes [node37, node38, node39] from the cluster
successfully removed all decommissioned nodes [node40, node41, node42] from the cluster
Failed to call listener on atomic field data loadingIllegalStateException
Failed to call listener on atomic field data loadingIndexOutOfBoundsException
Failed to call listener on atomic field data loadingIllegalArgumentException
Failed to call listener on atomic field data loadingOutOfMemoryError
Failed to call listener on atomic field data loadingStackOverflowError
Failed to call listener on atomic field data loadingAssertionError
Failed to call listener on atomic field data loadingArrayIndexOutOfBoundsException
Failed to call listener on atomic field data loadingNoSuchElementException
Failed to call listener on atomic field data loadingNumberFormatException
Failed to call listener on atomic field data loadingClassCastException
Failed to call listener on atomic field data loadingStringIndexOutOfBoundsException
Failed to call listener on atomic field data loadingConcurrentModificationException
Failed to call listener on atomic field data loadingUnsupportedOperationException
Failed to call listener on atomic field data loadingRuntimeException
submitting state update task to remove [nodeB] nodes due to decommissioning
submitting state update task to remove [nodeC] nodes due to decommissioning
submitting state update task to remove [nodeD] nodes due to decommissioning
submitting state update task to remove [nodeE] nodes due to decommissioning
submitting state update task to remove [nodeF] nodes due to decommissioning
submitting state update task to remove [nodeG] nodes due to decommissioning
submitting state update task to remove [nodeH] nodes due to decommissioning
submitting state update task to remove [nodeI] nodes due to decommissioning
submitting state update task to remove [nodeJ] nodes due to decommissioning
submitting state update task to remove [nodeK] nodes due to decommissioning
submitting state update task to remove [nodeL] nodes due to decommissioning
submitting state update task to remove [nodeM] nodes due to decommissioning
submitting state update task to remove [nodeN] nodes due to decommissioning
Failed to call listener on field data cache unloadingnullPointerException
Failed to call listener on field data cache unloadingArrayIndexOutOfBoundsException
Failed to call listener on field data cache unloadingNumberFormatException
Failed to call listener on field data cache unloadingIllegalArgumentException
Failed to call listener on field data cache unloadingClassNotFoundException
Failed to call listener on field data cache unloadingFileNotFoundException
Failed to call listener on field data cache unloadingNullPointerException
Failed to call listener on field data cache unloadingIOException
Failed to call listener on field data cache unloadingArrayStoreException
Failed to call listener on field data cache unloadingOutOfMemoryError
Failed to call listener on field data cache unloadingStackOverflowError
Failed to call listener on field data cache unloadingIllegalArgumentException
Failed to call listener on field data cache unloadingUnsupportedOperationException
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following settings will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
The following customs will be removed:
can't find replica source node because primary shard node1 is not active.
can't find replica source node because primary shard node2 is not active.
can't find replica source node because primary shard node3 is not active.
can't find replica source node because primary shard node4 is not active.
can't find replica source node because primary shard node5 is not active.
can't find replica source node because primary shard node6 is not active.
can't find replica source node because primary shard node7 is not active.
can't find replica source node because primary shard node8 is not active.
can't find replica source node because primary shard node9 is not active.
can't find replica source node because primary shard node10 is not active.
can't find replica source node because primary shard node11 is not active.
can't find replica source node because primary shard node12 is not active.
can't find replica source node because primary shard node13 is not active.
can't find replica source node because primary shard node14 is not active.
can't find relocation source node for shard 2 because it is assigned to an unknown node [B].
can't find relocation source node for shard 3 because it is assigned to an unknown node [C].
can't find relocation source node for shard 4 because it is assigned to an unknown node [D].
can't find relocation source node for shard 5 because it is assigned to an unknown node [E].
can't find relocation source node for shard 6 because it is assigned to an unknown node [F].
can't find relocation source node for shard 7 because it is assigned to an unknown node [G].
can't find relocation source node for shard 8 because it is assigned to an unknown node [H].
can't find relocation source node for shard 9 because it is assigned to an unknown node [I].
can't find relocation source node for shard 10 because it is assigned to an unknown node [J].
can't find relocation source node for shard 11 because it is assigned to an unknown node [K].
can't find relocation source node for shard 12 because it is assigned to an unknown node [L].
can't find relocation source node for shard 13 because it is assigned to an unknown node [M].
can't find relocation source node for shard 14 because it is assigned to an unknown node [N].
Classes with violations: Math, Physics, Chemistry
Classes with violations: English, History, Geography
Classes with violations: Biology, Music, Art
Classes with violations: Computer Science, Economics, Psychology
Classes with violations: French, Spanish, German
Classes with violations: Philosophy, Sociology, Anthropology
Classes with violations: PE, Health, Drama
Classes with violations: Calculus, Statistics, Algebra
Classes with violations: Literature, Poetry, Creative Writing
Classes with violations: Astronomy, Geology, Ecology
Classes with violations: Business, Accounting, Marketing
Classes with violations: Ethics, Logic, Critical Thinking
Classes with violations: Chinese, Japanese, Korean
Classes with violations: Engineering, Design, Robotics
Running ` git pull ` in ` /home/user/project ` for this env: development
Running ` npm install ` in ` /var/www/html ` for this env: production
Running ` python script.py ` in ` /tmp ` for this env: testing
Running ` make clean ` in ` /usr/src/kernel ` for this env: staging
Running ` docker-compose up ` in ` /opt/app ` for this env: local
Running ` mvn package ` in ` /root/maven-project ` for this env: integration
Running ` ping google.com ` in ` /etc/network ` for this env: debug
Running ` tar -czvf backup.tar.gz * ` in ` /home/user/backup ` for this env: archive
Running ` ls -l ` in ` /mnt/usb-drive ` for this env: external
Running ` ping google.com ` in ` /etc/network ` for this env: debug
Running ` tar -czvf backup.tar.gz * ` in ` /home/user/backup ` for this env: archive
Running ` ls -l ` in ` /mnt/usb-drive ` for this env: external
cluster state updated, version [6], source [zen-disco-node-join] {added {{node-1}{xYz}{127.0.0.1}{127.0.0.1:9300}{dimr}}}
cluster state updated, version [12], source [local-gateway-elected-state] {restore_done (0) into cluster_state}
cluster state updated, version [18], source [shard-started ([test][0], node[xYz], [P], recovery_source[existing recovery])]] {started shards [[test][0]]}
cluster state updated, version [23], source [zen-disco-node-left] {removed {{node-2}{aBc}{127.0.0.2}{127.0.0.2:9300}{dimr}}}
cluster state updated, version [29], source [cluster_reroute(async_shard_fetch)] {shard allocation completed, took [15s]}
cluster state updated, version [35], source [create-index [test2], cause [api]] {index created [test2]}
cluster state updated, version [41], source [zen-disco-receive(from master [{node-1}{xYz}{127.0.0.1}{127.0.0.1:9300}{dimr}])]] {no change in cluster_state}
cluster state updated, version [47], source [put-mapping [doc]] {update_mapping [[test2][doc]]}
cluster state updated, version [53], source [shard-failed ([test2][1], node[xYz], [P], recovery_source[peer recovery]), reason [failed recovery]]] {failed shard [[test2][1]], message [failed recovery]}
cluster state updated, version [59], source [shard-started ([test2][1], node[aBc], [R], recovery_source[peer recovery])]] {started shards [[test2][1]]}
cluster state updated, version [65], source [delete-index [[test]], reason [api]] {index deleted [[test]]}
cluster state updated, version [71], source [zen-disco-node-join] {added {{node-3}{mNp}{127.0.0.3}{127.0.0.3:9300}{dimr}}}
cluster state updated, version [77], source [cluster_update_settings] {updated dynamic settings of the cluster}
cluster state updated, version [89], source [close-indices [[test2]], reason [api]] {indices closed [[test2]]}
failed to process shard failure to (potentially) send back shard failure on corruption : java.lang.NullPointerException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.index.engine.EngineException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.transport.RemoteTransportException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.action.UnavailableShardsException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.cluster.block.ClusterBlockException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.index.IndexNotFoundException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.index.shard.ShardNotFoundException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.index.shard.IndexShardClosedException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.index.shard.IndexShardNotRecoveringException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.index.shard.IndexShardRecoveringException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.index.shard.IndexShardRelocatedException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.index.shard.IndexShardStateTransitionException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.indices.recovery.RecoveryFailedException
failed to process shard failure to (potentially) send back shard failure on corruption : org.elasticsearch.indices.IndexClosedException
--> creating 50 snapshots
--> creating 100 snapshots
--> creating 200 snapshots
--> creating 500 snapshots
--> creating 1000 snapshots
--> creating 2000 snapshots
--> creating 5000 snapshots
--> creating 10000 snapshots
--> creating 20000 snapshots
--> creating 50000 snapshots
--> creating 100000 snapshots
--> creating 200000 snapshots
--> creating 500000 snapshots
--> total number of simulated failures during restore: 2
--> total number of simulated failures during restore: 11
--> total number of simulated failures during restore: 5
--> total number of simulated failures during restore: 9
--> total number of simulated failures during restore: 3
--> total number of simulated failures during restore: 6
--> total number of simulated failures during restore: 4
--> total number of simulated failures during restore: 8
--> total number of simulated failures during restore: 1
--> total number of simulated failures during restore: 10
--> total number of simulated failures during restore: 12
--> total number of simulated failures during restore: 14
--> total number of simulated failures during restore: 15
Search response: 404 Not Found
Search response: 500 Internal Server Error
Search response: 302 Found
Search response: 401 Unauthorized
Search response: 403 Forbidden
Search response: 301 Moved Permanently
Search response: 400 Bad Request
Search response: 503 Service Unavailable
Search response: 405 Method Not Allowed
Search response: 204 No Content
Search response: 201 Created
Search response: 409 Conflict
Search response: 206 Partial Content
--> create random index test_index with 500 records
--> create random index sample_index with 1000 records
--> create random index index_123 with 200 records
--> create random index records_index with 50 records
--> create random index random_index with 10000 records
--> create random index data_index with 1000 records
--> create random index index_456 with 5000 records
--> create random index index_test with 2000 records
--> create random index index_sample with 100 records
--> create random index records_test with 250 records
--> create random index index_data with 300 records
--> create random index index_random with 500 records
--> create random index test_data with 10000 records
start primary shards for index [products]: 3
start primary shards for index [orders]: 5
start primary shards for index [customers]: 2
start primary shards for index [inventory]: 6
start primary shards for index [invoices]: 4
start primary shards for index [logs]: 3
start primary shards for index [messages]: 2
start primary shards for index [notifications]: 5
start primary shards for index [payments]: 6
start primary shards for index [reviews]: 3
start primary shards for index [settings]: 2
start primary shards for index [transactions]: 4
start primary shards for index [users_data]: 5
Adding additional 15 nodes, nothing should change
Adding additional 20 nodes, nothing should change
Adding additional 25 nodes, nothing should change
Adding additional 30 nodes, nothing should change
Adding additional 35 nodes, nothing should change
Adding additional 40 nodes, nothing should change
Adding additional 45 nodes, nothing should change
Adding additional 50 nodes, nothing should change
Adding additional 55 nodes, nothing should change
Adding additional 60 nodes, nothing should change
Adding additional 65 nodes, nothing should change
Adding additional 70 nodes, nothing should change
Adding additional 75 nodes, nothing should change
Snapshot Path [snapshot1.jpg]
Snapshot Path [backup/file.txt]
Snapshot Path [photos/image.jpg]
Snapshot Path [videos/video.mp4]
Snapshot Path [documents/document.docx]
Snapshot Path [music/song.wav]
Snapshot Path [archive.zip]
Snapshot Path [logs/log.txt]
Snapshot Path [temp/file.tmp]
Snapshot Path [downloads/file.exe]
Snapshot Path [templates/template.doc]
Snapshot Path [resources/image.png]
Snapshot Path [config/config.xml]
--> checking iteration 2
--> checking iteration 3
--> checking iteration 4
--> checking iteration 5
--> checking iteration 6
--> checking iteration 7
--> checking iteration 8
--> checking iteration 9
--> checking iteration 10
--> checking iteration 11
--> checking iteration 12
--> checking iteration 13
--> checking iteration 14
deleteBlob(image.png)
deleteBlob(data.txt)
deleteBlob(video.mp4)
deleteBlob(doc.docx)
deleteBlob(audio.wav)
deleteBlob(code.java)
deleteBlob(presentation.ppt)
deleteBlob(sheet.xlsx)
deleteBlob(script.py)
deleteBlob(database.sql)
deleteBlob(config.txt)
deleteBlob(template.html)
deleteBlob(backup.zip)
create an allocation with [3] initial primary recoveries and [1] concurrent recoveries
create an allocation with [7] initial primary recoveries and [4] concurrent recoveries
create an allocation with [1] initial primary recoveries and [3] concurrent recoveries
create an allocation with [8] initial primary recoveries and [2] concurrent recoveries
create an allocation with [6] initial primary recoveries and [5] concurrent recoveries
create an allocation with [2] initial primary recoveries and [4] concurrent recoveries
create an allocation with [4] initial primary recoveries and [1] concurrent recoveries
create an allocation with [9] initial primary recoveries and [3] concurrent recoveries
create an allocation with [3] initial primary recoveries and [2] concurrent recoveries
create an allocation with [7] initial primary recoveries and [5] concurrent recoveries
create an allocation with [1] initial primary recoveries and [4] concurrent recoveries
create an allocation with [6] initial primary recoveries and [2] concurrent recoveries
create an allocation with [5] initial primary recoveries and [3] concurrent recoveries
Extra id [456]
Extra id [789]
Extra id [987]
Extra id [654]
Extra id [321]
Extra id [987]
Extra id [654]
Extra id [321]
Extra id [123]
Extra id [456]
Extra id [789]
Extra id [987]
Extra id [654]
no index mapper found for field: title returning default postings format
no index mapper found for field: author returning default postings format
no index mapper found for field: content returning default postings format
no index mapper found for field: date returning default postings format
no index mapper found for field: description returning default postings format
no index mapper found for field: tags returning default postings format
no index mapper found for field: rating returning default postings format
no index mapper found for field: price returning default postings format
no index mapper found for field: quantity returning default postings format
no index mapper found for field: image returning default postings format
no index mapper found for field: category returning default postings format
no index mapper found for field: title returning default postings format
no index mapper found for field: author returning default postings format
no instance found for project [my_project_2], zones [us-central]
no instance found for project [my_project_3], zones [us-east]
no instance found for project [my_project_4], zones [eu-west]
no instance found for project [my_project_5], zones [eu-central]
no instance found for project [my_project_6], zones [eu-east]
no instance found for project [my_project_7], zones [ap-south]
no instance found for project [my_project_8], zones [ap-east]
no instance found for project [my_project_9], zones [ap-north]
no instance found for project [my_project_10], zones [sa-east]
no instance found for project [my_project_11], zones [af-central]
no instance found for project [my_project_12], zones [na-central]
no instance found for project [my_project_13], zones [na-west]
no instance found for project [my_project_14], zones [na-east]
ip of current node: [10.0.0.2]
ip of current node: [172.16.0.3]
ip of current node: [192.168.1.4]
ip of current node: [10.0.0.5]
ip of current node: [172.16.0.6]
ip of current node: [192.168.1.7]
ip of current node: [10.0.0.8]
ip of current node: [172.16.0.9]
ip of current node: [192.168.1.10]
ip of current node: [10.0.0.11]
ip of current node: [172.16.0.12]
ip of current node: [192.168.1.13]
ip of current node: [10.0.0.14]
--> followers get disconnect event for leader serverB
--> followers get disconnect event for leader serverC
--> followers get disconnect event for leader serverD
--> followers get disconnect event for leader serverE
--> followers get disconnect event for leader serverF
--> followers get disconnect event for leader serverG
--> followers get disconnect event for leader serverH
--> followers get disconnect event for leader serverI
--> followers get disconnect event for leader serverJ
--> followers get disconnect event for leader serverK
--> followers get disconnect event for leader serverL
--> followers get disconnect event for leader serverM
--> followers get disconnect event for leader serverN
cannot parse the specified url [http://test.com]
cannot parse the specified url [ftp://files.com]
cannot parse the specified url [ws://socket.io]
cannot parse the specified url [sftp://secure-files.com]
cannot parse the specified url [http://api.example.com]
cannot parse the specified url [https://cdn.example.com]
cannot parse the specified url [ftp://data.com]
cannot parse the specified url [ws://chatsocket.com]
cannot parse the specified url [sftp://secure-data.com]
cannot parse the specified url [http://api.test.com]
cannot parse the specified url [https://cdn.test.com]
cannot parse the specified url [ftp://staticfiles.com]
cannot parse the specified url [ws://socketserver.com]
--> iteration 2 flushing index
--> iteration 3 flushing index
--> iteration 4 flushing index
--> iteration 5 flushing index
--> iteration 6 flushing index
--> iteration 7 flushing index
--> iteration 8 flushing index
--> iteration 9 flushing index
--> iteration 10 flushing index
--> iteration 11 flushing index
--> iteration 12 flushing index
--> iteration 13 flushing index
--> iteration 14 flushing index
children of task 2 are already finished, nothing to rethrottle
children of task 3 are already finished, nothing to rethrottle
children of task 4 are already finished, nothing to rethrottle
children of task 5 are already finished, nothing to rethrottle
children of task 6 are already finished, nothing to rethrottle
children of task 7 are already finished, nothing to rethrottle
children of task 8 are already finished, nothing to rethrottle
children of task 9 are already finished, nothing to rethrottle
children of task 10 are already finished, nothing to rethrottle
children of task 11 are already finished, nothing to rethrottle
children of task 12 are already finished, nothing to rethrottle
children of task 13 are already finished, nothing to rethrottle
children of task 14 are already finished, nothing to rethrottle
---> created: response2
---> created: response3
---> created: response4
---> created: response5
---> created: response6
---> created: response7
---> created: response8
---> created: response9
---> created: response10
---> created: response11
---> created: response12
---> created: response13
---> created: response14
|Completed Task 1
|Error Encountered
|Database Connection Established
|User Logged In
|File Saved
|Data Successfully Updated
|Resource Not Found
|Request Processed
|Connection Closed
|Operation Completed
|Session Expired
|File Uploaded
|Task Failed
|Permission Denied
adding retention [20] leases
adding retention [30] leases
adding retention [40] leases
adding retention [50] leases
adding retention [60] leases
adding retention [70] leases
adding retention [80] leases
adding retention [90] leases
adding retention [100] leases
adding retention [110] leases
adding retention [120] leases
adding retention [130] leases
adding retention [140] leases
Starting rounds [2]
Starting rounds [3]
Starting rounds [4]
Starting rounds [5]
Starting rounds [6]
Starting rounds [7]
Starting rounds [8]
Starting rounds [9]
Starting rounds [10]
Starting rounds [11]
Starting rounds [12]
Starting rounds [13]
Starting rounds [14]
register child node node2 task taskId2
register child node node3 task taskId3
register child node node4 task taskId4
register child node node5 task taskId5
register child node node6 task taskId6
register child node node7 task taskId7
register child node node8 task taskId8
register child node node9 task taskId9
register child node node10 task taskId10
register child node node11 task taskId11
register child node node12 task taskId12
register child node node13 task taskId13
register child node node14 task taskId14
ERROR: javadoc empty but method overrides another, skipping.
INFO: javadoc empty but method overrides another, skipping.
WARNING: javadoc empty but method overrides another, skipping.
ERROR: javadoc empty but method overrides another, skipping.
INFO: javadoc empty but method overrides another, skipping.
WARNING: javadoc empty but method overrides another, skipping.
ERROR: javadoc empty but method overrides another, skipping.
INFO: javadoc empty but method overrides another, skipping.
WARNING: javadoc empty but method overrides another, skipping.
ERROR: javadoc empty but method overrides another, skipping.
INFO: javadoc empty but method overrides another, skipping.
WARNING: javadoc empty but method overrides another, skipping.
ERROR: javadoc empty but method overrides another, skipping.
--> starting a cluster with 5 nodes
--> starting a cluster with 7 nodes
--> starting a cluster with 10 nodes
--> starting a cluster with 8 nodes
--> starting a cluster with 2 nodes
--> starting a cluster with 6 nodes
--> starting a cluster with 4 nodes
--> starting a cluster with 9 nodes
--> starting a cluster with 12 nodes
--> starting a cluster with 15 nodes
--> starting a cluster with 11 nodes
--> starting a cluster with 14 nodes
backup was aborted before starting
task was aborted before starting
operation was aborted before starting
download was aborted before starting
upload was aborted before starting
installation was aborted before starting
scan was aborted before starting
update was aborted before starting
migration was aborted before starting
execution was aborted before starting
process was aborted before starting
transaction was aborted before starting
request was aborted before starting
job was aborted before starting
Registered new Setting: setting2 successfully
Registered new Setting: setting3 successfully
Registered new Setting: setting4 successfully
Registered new Setting: setting5 successfully
Registered new Setting: setting6 successfully
Registered new Setting: setting7 successfully
Registered new Setting: setting8 successfully
Registered new Setting: setting9 successfully
Registered new Setting: setting10 successfully
Registered new Setting: setting11 successfully
Registered new Setting: setting12 successfully
Registered new Setting: setting13 successfully
Registered new Setting: setting14 successfully
--> node D received new cluster state: E and had previous cluster state: F
--> node G received new cluster state: H and had previous cluster state: I
--> node J received new cluster state: K and had previous cluster state: L
--> node M received new cluster state: N and had previous cluster state: O
--> node P received new cluster state: Q and had previous cluster state: R
--> node S received new cluster state: T and had previous cluster state: U
--> node V received new cluster state: W and had previous cluster state: X
--> node Y received new cluster state: Z and had previous cluster state: AA
--> node BB received new cluster state: CC and had previous cluster state: DD
--> node EE received new cluster state: FF and had previous cluster state: GG
--> node HH received new cluster state: II and had previous cluster state: JJ
--> node KK received new cluster state: LL and had previous cluster state: MM
--> node NN received new cluster state: OO and had previous cluster state: PP
Cluster state update after successful shard clone repoShardId_2 failed
Cluster state update after successful shard clone repoShardId_3 failed
Cluster state update after successful shard clone repoShardId_4 failed
Cluster state update after successful shard clone repoShardId_5 failed
Cluster state update after successful shard clone repoShardId_6 failed
Cluster state update after successful shard clone repoShardId_7 failed
Cluster state update after successful shard clone repoShardId_8 failed
Cluster state update after successful shard clone repoShardId_9 failed
Cluster state update after successful shard clone repoShardId_10 failed
Cluster state update after successful shard clone repoShardId_11 failed
Cluster state update after successful shard clone repoShardId_12 failed
Cluster state update after successful shard clone repoShardId_13 failed
Cluster state update after successful shard clone repoShardId_14 failed
Iterated 2 times for 1634332860000 using HOURS
Iterated 3 times for 1634332920000 using SECONDS
Iterated 4 times for 1634332980000 using DAYS
Iterated 5 times for 1634333040000 using MILLISECONDS
Iterated 6 times for 1634333100000 using MICROSECONDS
Iterated 7 times for 1634333160000 using NANOSECONDS
Iterated 8 times for 1634333220000 using MONTHS
Iterated 9 times for 1634333280000 using YEARS
Iterated 10 times for 1634333340000 using WEEKS
Iterated 11 times for 1634333400000 using TIMESTAMPS
Iterated 12 times for 1634333460000 using DURATION
Iterated 13 times for 1634333520000 using CHRONO_UNIT
Iterated 14 times for 1634333580000 using TEMPORAL_UNIT
--> deleting the shard data [Ljava.lang.String;@39e8b2db/]
--> deleting the shard data [Ljava.lang.String;@283c3f0d/]
--> deleting the shard data [Ljava.lang.String;@79283213/]
--> deleting the shard data [Ljava.lang.String;@245d053f/]
--> deleting the shard data [Ljava.lang.String;@77be77d0/]
--> deleting the shard data [Ljava.lang.String;@704d6e83/]
--> deleting the shard data [Ljava.lang.String;@54115726/]
--> deleting the shard data [Ljava.lang.String;@79323d11/]
--> deleting the shard data [Ljava.lang.String;@3e59edae/]
--> deleting the shard data [Ljava.lang.String;@59617fab/]
--> deleting the shard data [Ljava.lang.String;@4e23e7a7/]
--> deleting the shard data [Ljava.lang.String;@71efeaf4/]
--> deleting the shard data [Ljava.lang.String;@5c2258b7/]
Component 2:
Component 3:
Component 4:
Component 5:
Component 6:
Component 7:
Component 8:
Component 9:
Component 10:
Component 11:
Component 12:
Component 13:
Component 14:
Unknown client type mobile
Unknown client type desktop
Unknown client type tablet
Unknown client type smart tv
Unknown client type wearable
Unknown client type game console
Unknown client type virtual reality
Unknown client type internet of things
Unknown client type voice assistant
Unknown client type robotics
Unknown client type drones
Unknown client type automotive
Unknown client type medical device
Trial run 2/15
Trial run 3/15
Trial run 4/15
Trial run 5/15
Trial run 6/15
Trial run 7/15
Trial run 8/15
Trial run 9/15
Trial run 10/15
Trial run 11/15
Trial run 12/15
Trial run 13/15
Trial run 14/15
The specified location [/home/user] doesn't start with any repository paths specified by the path.repo setting: [/var/backup]
The specified location [/tmp] doesn't start with any repository paths specified by the path.repo setting: [/var/backup,/backup]
The specified location [/var/www] doesn't start with any repository paths specified by the path.repo setting: [/backup,/var/backup]
The specified location [/usr/local] doesn't start with any repository paths specified by the path.repo setting: [/var/backup,/backup,/usr/backup]
The specified location [/var/log] doesn't start with any repository paths specified by the path.repo setting: [/backup,/usr/backup,/var/backup]
The specified location [/opt/data] doesn't start with any repository paths specified by the path.repo setting: [/var/backup,/backup,/usr/backup,/var/share]
The specified location [/var/www/public] doesn't start with any repository paths specified by the path.repo setting: [/backup,/usr/backup,/var/backup]
The specified location [/tmp/media] doesn't start with any repository paths specified by the path.repo setting: [/var/backup,/backup]
The specified location [/user/photos] doesn't start with any repository paths specified by the path.repo setting: [/backup]
The specified location [/data/public] doesn't start with any repository paths specified by the path.repo setting: [/var/backup]
The specified location [/mnt/NAS] doesn't start with any repository paths specified by the path.repo setting: [/var/backup]
The specified location [/usr/share] doesn't start with any repository paths specified by the path.repo setting: [/backup,/usr/backup]
The specified location [/var/tmp] doesn't start with any repository paths specified by the path.repo setting: [/usr/backup]
Repository [repo2] writing new index generational blob [blob2]
Repository [repo3] writing new index generational blob [blob3]
Repository [repo4] writing new index generational blob [blob4]
Repository [repo5] writing new index generational blob [blob5]
Repository [repo6] writing new index generational blob [blob6]
Repository [repo7] writing new index generational blob [blob7]
Repository [repo8] writing new index generational blob [blob8]
Repository [repo9] writing new index generational blob [blob9]
Repository [repo10] writing new index generational blob [blob10]
Repository [repo11] writing new index generational blob [blob11]
Repository [repo12] writing new index generational blob [blob12]
Repository [repo13] writing new index generational blob [blob13]
Repository [repo14] writing new index generational blob [blob14]
high disk watermark [80%] exceeded on node02, shards will be relocated away from this node; currently relocating away shards totalling [800MB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [85%] exceeded on node03, shards will be relocated away from this node; currently relocating away shards totalling [500MB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [95%] exceeded on node04, shards will be relocated away from this node; currently relocating away shards totalling [1.5GB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [75%] exceeded on node05, shards will be relocated away from this node; currently relocating away shards totalling [650MB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [90%] exceeded on node06, shards will be relocated away from this node; currently relocating away shards totalling [1.1GB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [80%] exceeded on node07, shards will be relocated away from this node; currently relocating away shards totalling [850MB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [85%] exceeded on node08, shards will be relocated away from this node; currently relocating away shards totalling [450MB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [95%] exceeded on node09, shards will be relocated away from this node; currently relocating away shards totalling [1.4GB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [75%] exceeded on node10, shards will be relocated away from this node; currently relocating away shards totalling [700MB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [90%] exceeded on node11, shards will be relocated away from this node; currently relocating away shards totalling [1.3GB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [80%] exceeded on node12, shards will be relocated away from this node; currently relocating away shards totalling [900MB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [85%] exceeded on node13, shards will be relocated away from this node; currently relocating away shards totalling [550MB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [95%] exceeded on node14, shards will be relocated away from this node; currently relocating away shards totalling [1.6GB] bytes; the node is expected to be below the high disk watermark when these relocations are complete
high disk watermark [90%] exceeded on /dev/sdb1, shards will be relocated away from this node; currently relocating away shards totalling [1.8GB] bytes
high disk watermark [80%] exceeded on /dev/nvme0n1p1, shards will be relocated away from this node; currently relocating away shards totalling [3.6GB] bytes
high disk watermark [95%] exceeded on /dev/sdc1, shards will be relocated away from this node; currently relocating away shards totalling [1.2GB] bytes
high disk watermark [87%] exceeded on /dev/nvme1n1p1, shards will be relocated away from this node; currently relocating away shards totalling [2.6GB] bytes
high disk watermark [83%] exceeded on /dev/sdd1, shards will be relocated away from this node; currently relocating away shards totalling [1.9GB] bytes
high disk watermark [92%] exceeded on /dev/sde1, shards will be relocated away from this node; currently relocating away shards totalling [2.7GB] bytes
high disk watermark [75%] exceeded on /dev/sdf1, shards will be relocated away from this node; currently relocating away shards totalling [2.1GB] bytes
high disk watermark [88%] exceeded on /dev/mmcblk0p1, shards will be relocated away from this node; currently relocating away shards totalling [1.5GB] bytes
high disk watermark [81%] exceeded on /dev/sdg1, shards will be relocated away from this node; currently relocating away shards totalling [1.3GB] bytes
high disk watermark [93%] exceeded on /dev/sdh1, shards will be relocated away from this node; currently relocating away shards totalling [2.2GB] bytes
high disk watermark [77%] exceeded on /dev/sdi1, shards will be relocated away from this node; currently relocating away shards totalling [1.7GB] bytes
high disk watermark [89%] exceeded on /dev/sdj1, shards will be relocated away from this node; currently relocating away shards totalling [1.6GB] bytes
high disk watermark [82%] exceeded on /dev/sdk1, shards will be relocated away from this node; currently relocating away shards totalling [2.4GB] bytes
low disk watermark [10%] exceeded on /dev/sdb1, replicas will not be assigned to this node
low disk watermark [5%] exceeded on /dev/sdc1, replicas will not be assigned to this node
low disk watermark [20%] exceeded on /dev/sdd1, replicas will not be assigned to this node
low disk watermark [15%] exceeded on /dev/sde1, replicas will not be assigned to this node
low disk watermark [25%] exceeded on /dev/sdf1, replicas will not be assigned to this node
low disk watermark [12%] exceeded on /dev/sdg1, replicas will not be assigned to this node
low disk watermark [18%] exceeded on /dev/sdh1, replicas will not be assigned to this node
low disk watermark [8%] exceeded on /dev/sdi1, replicas will not be assigned to this node
low disk watermark [22%] exceeded on /dev/sdj1, replicas will not be assigned to this node
low disk watermark [28%] exceeded on /dev/sdk1, replicas will not be assigned to this node
low disk watermark [32%] exceeded on /dev/sdl1, replicas will not be assigned to this node
low disk watermark [14%] exceeded on /dev/sdm1, replicas will not be assigned to this node
low disk watermark [17%] exceeded on /dev/sdn1, replicas will not be assigned to this node
Node: node02 can still accept shards, retaining it in queue - decision02
Node: node03 can still accept shards, retaining it in queue - decision03
Node: node04 can still accept shards, retaining it in queue - decision04
Node: node05 can still accept shards, retaining it in queue - decision05
Node: node06 can still accept shards, retaining it in queue - decision06
Node: node07 can still accept shards, retaining it in queue - decision07
Node: node08 can still accept shards, retaining it in queue - decision08
Node: node09 can still accept shards, retaining it in queue - decision09
Node: node10 can still accept shards, retaining it in queue - decision10
Node: node11 can still accept shards, retaining it in queue - decision11
Node: node12 can still accept shards, retaining it in queue - decision12
Node: node13 can still accept shards, retaining it in queue - decision13
Node: node14 can still accept shards, retaining it in queue - decision14
recovery [phase2]: sending transaction log operations (from [300] to [400])
recovery [phase2]: sending transaction log operations (from [500] to [600])
recovery [phase2]: sending transaction log operations (from [700] to [800])
recovery [phase2]: sending transaction log operations (from [900] to [1000])
recovery [phase2]: sending transaction log operations (from [1100] to [1200])
recovery [phase2]: sending transaction log operations (from [1300] to [1400])
recovery [phase2]: sending transaction log operations (from [1500] to [1600])
recovery [phase2]: sending transaction log operations (from [1700] to [1800])
recovery [phase2]: sending transaction log operations (from [1900] to [2000])
recovery [phase2]: sending transaction log operations (from [2100] to [2200])
recovery [phase2]: sending transaction log operations (from [2300] to [2400])
recovery [phase2]: sending transaction log operations (from [2500] to [2600])
recovery [phase2]: sending transaction log operations (from [2700] to [2800])
recovery phase1: took [5 minutes]
recovery phase1: took [2 hours]
recovery phase1: took [500 milliseconds]
recovery phase1: took [1 second]
recovery phase1: took [1.5 hours]
recovery phase1: took [30 minutes]
recovery phase1: took [100 milliseconds]
recovery phase1: took [2 minutes]
recovery phase1: took [1.2 seconds]
recovery phase1: took [3 hours]
recovery phase1: took [10 minutes]
recovery phase1: took [20 seconds]
recovery phase1: took [50 milliseconds]
index 3 has been blocked before closing and is already closed, ignoring
index 4 has been blocked before closing and is already closed, ignoring
index 5 has been blocked before closing and is already closed, ignoring
index 6 has been blocked before closing and is already closed, ignoring
index 7 has been blocked before closing and is already closed, ignoring
index 8 has been blocked before closing and is already closed, ignoring
index 9 has been blocked before closing and is already closed, ignoring
index 10 has been blocked before closing and is already closed, ignoring
index 11 has been blocked before closing and is already closed, ignoring
index 12 has been blocked before closing and is already closed, ignoring
index 13 has been blocked before closing and is already closed, ignoring
index 14 has been blocked before closing and is already closed, ignoring
using node query cache with size [50] max filter count [500]
using node query cache with size [20] max filter count [200]
using node query cache with size [30] max filter count [300]
using node query cache with size [40] max filter count [400]
using node query cache with size [60] max filter count [600]
using node query cache with size [70] max filter count [700]
using node query cache with size [80] max filter count [800]
using node query cache with size [90] max filter count [900]
using node query cache with size [110] max filter count [1100]
using node query cache with size [120] max filter count [1200]
using node query cache with size [130] max filter count [1300]
using node query cache with size [140] max filter count [1400]
using node query cache with size [160] max filter count [1600]
using node query cache with size [170] max filter count [1700]
successfully removed decommissioned cluster manager eligible nodes [5678] from voting config
successfully removed decommissioned cluster manager eligible nodes [91011] from voting config
successfully removed decommissioned cluster manager eligible nodes [121314] from voting config
successfully removed decommissioned cluster manager eligible nodes [151617] from voting config
successfully removed decommissioned cluster manager eligible nodes [181920] from voting config
successfully removed decommissioned cluster manager eligible nodes [212223] from voting config
successfully removed decommissioned cluster manager eligible nodes [242526] from voting config
successfully removed decommissioned cluster manager eligible nodes [272829] from voting config
successfully removed decommissioned cluster manager eligible nodes [303132] from voting config
successfully removed decommissioned cluster manager eligible nodes [333435] from voting config
successfully removed decommissioned cluster manager eligible nodes [363738] from voting config
successfully removed decommissioned cluster manager eligible nodes [394041] from voting config
successfully removed decommissioned cluster manager eligible nodes [424344] from voting config
configuration: \n Hello world
configuration: \r\n Error: invalid input
configuration: \n Starting the program
configuration: \r\n Loading the data
configuration: \n Exiting the program
configuration: \r\n Warning: low memory
configuration: \n Processing the request
configuration: \r\n Success: operation completed
configuration: \n Reading the file
configuration: \r\n Exception: file not found
configuration: \n Writing the file
configuration: \r\n Permission denied
configuration: \n Connecting to the server
configuration: \r\n Timeout: connection failed
configuration: \n Disconnecting from the server
configuration: \r\n Closed: connection terminated
shardId 0 creating using an existing path /home/user/data
shardId 1 creating using an existing path /home/user/config
shardId 2 creating using an existing path /home/user/logs
shardId 3 creating using an existing path /home/user/cache
shardId 4 creating using an existing path /home/user/temp
shardId 5 creating using an existing path /var/lib/mysql
shardId 6 creating using an existing path /var/log/nginx
shardId 7 creating using an existing path /var/www/html
shardId 8 creating using an existing path /opt/java
shardId 9 creating using an existing path /opt/tomcat
shardId 10 creating using an existing path /mnt/sda1
shardId 11 creating using an existing path /mnt/sdb1
shardId 12 creating using an existing path /mnt/sdc1
shardId 13 creating using an existing path /mnt/sdd1
Updated repository generation from [0.5] to [0.6]
Updated repository generation from [0.7] to [0.8]
Updated repository generation from [0.4] to [0.5]
Updated repository generation from [0.6] to [0.7]
Updated repository generation from [0.8] to [0.9]
Updated repository generation from [0.9] to [1.0]
Updated repository generation from [1.0] to [1.1]
Updated repository generation from [1.1] to [1.2]
Updated repository generation from [1.2] to [1.3]
Updated repository generation from [1.3] to [1.4]
Updated repository generation from [1.4] to [1.5]
Updated repository generation from [1.5] to [1.6]
Updated repository generation from [1.6] to [1.7]
Updated repository generation from [1.7] to [1.8]
skipping task 1, already processed
skipping task 7, already processed
skipping task 12, already processed
skipping task 5, already processed
skipping task 9, already processed
skipping task 3, already processed
skipping task 10, already processed
skipping task 4, already processed
skipping task 8, already processed
skipping task 6, already processed
skipping task 2, already processed
skipping task 11, already processed
skipping task 13, already processed
skipping task 14, already processed
Ran: [java, -jar, app.jar] SUCCESS
Ran: [python, script.py, -v] ERROR
Ran: [gcc, main.c, -o, main] SUCCESS
Ran: [rm, -rf, /] FAILURE
Ran: [ping, google.com] TIMEOUT
Ran: [ls, -l, /home/user] SUCCESS
Ran: [curl, https://bing.com] SUCCESS
Ran: [git, clone, https://github.com/microsoft/Bing.git] FAILURE
Ran: [npm, install, express] SUCCESS
Ran: [docker, run, -it, ubuntu] SUCCESS
Ran: [mvn, clean, install] FAILURE
Ran: [node, index.js] ERROR
Ran: [psql, -U, postgres, -d, testdb] SUCCESS
Ran: [tar, -xvf, backup.tar.gz] SUCCESS
Ran: [make, all] FAILURE
--> counts: total: 100, unassigned: 10, initializing: 5, relocating: 2, started: 83
--> counts: total: 120, unassigned: 15, initializing: 7, relocating: 3, started: 95
--> counts: total: 80, unassigned: 8, initializing: 4, relocating: 1, started: 67
--> counts: total: 90, unassigned: 12, initializing: 6, relocating: 2, started: 70
--> counts: total: 110, unassigned: 14, initializing: 8, relocating: 4, started: 84
--> counts: total: 105, unassigned: 13, initializing: 7, relocating: 3, started: 82
--> counts: total: 95, unassigned: 11, initializing: 6, relocating: 2, started: 76
--> counts: total: 85, unassigned: 9, initializing: 5, relocating: 2, started: 69
--> counts: total: 115, unassigned: 16, initializing: 9, relocating: 4, started: 86
--> counts: total: 125, unassigned: 18, initializing: 10, relocating: 5, started: 92
--> counts: total: 75, unassigned: 7, initializing: 3, relocating: 1, started: 64
--> counts: total: 100, unassigned: 10, initializing: 5, relocating: 3, started: 82
--> counts: total: 105, unassigned: 12, initializing: 6, relocating: 4, started: 83
--> counts: total: 95, unassigned: 9, initializing: 4, relocating: 2, started: 80
Rounding error at 2023-10-22 15:15:15 / 2023-10-22 , timezone UTC , interval: 5 previousRoundedValue 2023-10-22 15:10:00 / 0.001
Rounding error at 2023-10-22 15:16:23 / 2023-10-22 , timezone PST , interval: 10 previousRoundedValue 2023-10-22 15:10:00 / -0.002
Rounding error at 2023-10-22 15:17:45 / 2023-10-22 , timezone EST , interval: 15 previousRoundedValue 2023-10-22 15:15:00 / 0.003
Rounding error at 2023-10-22 15:18:12 / 2023-10-22 , timezone CST , interval: 20 previousRoundedValue 2023-10-22 15:00:00 / -0.004
Rounding error at 2023-10-22 15:19:34 / 2023-10-22 , timezone GMT , interval: 30 previousRoundedValue 2023-10-22 15:00:00 / 0.005
Rounding error at 2023-10-22 15:20:56 / 2023-10-22 , timezone JST , interval: 60 previousRoundedValue 2023-10-22 14:00:00 / -0.006
Rounding error at 2023-10-22 15:21:23 / 2023-10-22 , timezone IST , interval: 120 previousRoundedValue 2023-10-22 14:00:00 / -0.007
Rounding error at 2023-10-22 15:22:45 / 2023-10-22 , timezone CET , interval: 180 previousRoundedValue 2023-10-22 12:00:00 / -0.008
--> starting [node_2] ...
--> starting [node_3] ...
--> starting [node_4] ...
--> starting [node_5] ...
--> starting [node_6] ...
--> starting [node_7] ...
--> starting [node_8] ...
--> starting [node_9] ...
--> starting [node_10] ...
--> starting [node_11] ...
--> starting [node_12] ...
--> starting [node_13] ...
--> starting [node_14] ...
can not access [image.jpg] in container {Container2}: File not found
can not access [document.docx] in container {Container3}: Access denied
can not access [data.csv] in container {Container4}: Permission denied
can not access [script.js] in container {Container5}: File is locked
can not access [video.mp4] in container {Container6}: File corrupted
can not access [backup.sql] in container {Container7}: Database connection failed
can not access [report.pdf] in container {Container8}: Insufficient storage
can not access [music.mp3] in container {Container9}: Invalid file permissions
can not access [presentation.pptx] in container {Container10}: File is read-only
can not access [code.java] in container {Container11}: File already exists
can not access [image.png] in container {Container12}: File is empty
can not access [configuration.xml] in container {Container13}: Malformed XML
can not access [stylesheet.css] in container {Container14}: File is locked by another process
--> DONE search test round 2 2022-07-16 false
--> DONE search test round 3 2022-07-17 true
--> DONE search test round 4 2022-07-18 false
--> DONE search test round 5 2022-07-19 true
--> DONE search test round 6 2022-07-20 false
--> DONE search test round 7 2022-07-21 true
--> DONE search test round 8 2022-07-22 false
--> DONE search test round 9 2022-07-23 true
--> DONE search test round 10 2022-07-24 false
--> DONE search test round 11 2022-07-25 true
--> DONE search test round 12 2022-07-26 false
--> DONE search test round 13 2022-07-27 true
--> DONE search test round 14 2022-07-28 false
using explicit ec2 endpoint [https://api.example.com]
using explicit ec2 endpoint [http://sandbox.example.com]
using explicit ec2 endpoint [https://sandbox.example.com]
using explicit ec2 endpoint [http://staging.example.com]
using explicit ec2 endpoint [https://staging.example.com]
using explicit ec2 endpoint [http://develop.example.com]
using explicit ec2 endpoint [https://develop.example.com]
using explicit ec2 endpoint [http://test.example.com]
using explicit ec2 endpoint [https://test.example.com]
using explicit ec2 endpoint [http://prod.example.com]
using explicit ec2 endpoint [https://prod.example.com]
using explicit ec2 endpoint [http://uat.example.com]
using explicit ec2 endpoint [https://uat.example.com]
fetching nodes from IMDS (instance-states=terminated, availability-zones=us-west-2, tags=name:Mars)
fetching nodes from IMDS (instance-states=stopped, availability-zones=eu-central-1, tags=name:Venus)
fetching nodes from IMDS (instance-states=running, availability-zones=ap-northeast-2, tags=name:Mercury)
fetching nodes from IMDS (instance-states=pending, availability-zones=sa-east-1, tags=name:Saturn)
fetching nodes from IMDS (instance-states=shutting-down, availability-zones=ca-central-1, tags=name:Neptune)
fetching nodes from IMDS (instance-states=stopping, availability-zones=ap-southeast-1, tags=name:Pluto)
fetching nodes from IMDS (instance-states=terminated, availability-zones=ap-southeast-2, tags=name:Uranus)
fetching nodes from IMDS (instance-states=running, availability-zones=us-west-1, tags=name:Earth)
fetching nodes from IMDS (instance-states=pending, availability-zones=ap-northeast-1, tags=name:Moon)
fetching nodes from IMDS (instance-states=shutting-down, availability-zones=eu-west-1, tags=name:Jupiter)
fetching nodes from IMDS (instance-states=pending, availability-zones=us-east-2, tags=name:Mars)
fetching nodes from IMDS (instance-states=running, availability-zones=sa-east-2, tags=name:Venus)
fetching nodes from IMDS (instance-states=stopping, availability-zones=ca-central-1, tags=name:Mercury)
[INFO] found metadata for deleted index [folder2]
[INFO] found metadata for deleted index [folder3]
[INFO] found metadata for deleted index [folder4]
[INFO] found metadata for deleted index [folder5]
[INFO] found metadata for deleted index [folder6]
[INFO] found metadata for deleted index [folder7]
[INFO] found metadata for deleted index [folder8]
[INFO] found metadata for deleted index [folder9]
[INFO] found metadata for deleted index [folder10]
[INFO] found metadata for deleted index [folder11]
[INFO] found metadata for deleted index [folder12]
[INFO] found metadata for deleted index [folder13]
[INFO] found metadata for deleted index [folder14]
Retrying [2] times : https://www.example.com
Retrying [3] times : https://www.example.com
Retrying [4] times : https://www.example.com
Retrying [5] times : https://www.example.com
Retrying [6] times : https://www.example.com
Retrying [7] times : https://www.example.com
Retrying [8] times : https://www.example.com
Retrying [9] times : https://www.example.com
Retrying [10] times : https://www.example.com
Retrying [11] times : https://www.example.com
Retrying [12] times : https://www.example.com
Retrying [13] times : https://www.example.com
Retrying [14] times : https://www.example.com
--> indexing [100] more docs to be truncated
--> indexing [200] more docs to be truncated
--> indexing [300] more docs to be truncated
--> indexing [400] more docs to be truncated
--> indexing [500] more docs to be truncated
--> indexing [600] more docs to be truncated
--> indexing [700] more docs to be truncated
--> indexing [800] more docs to be truncated
--> indexing [900] more docs to be truncated
--> indexing [1000] more docs to be truncated
--> indexing [1100] more docs to be truncated
--> indexing [1200] more docs to be truncated
--> indexing [1300] more docs to be truncated
acquiring node shardlock on shard2, timeout 2000, details Lock acquisition failed
acquiring node shardlock on shard3, timeout 500, details Lock acquisition successful
acquiring node shardlock on shard4, timeout 1500, details Lock acquisition failed
acquiring node shardlock on shard5, timeout 3000, details Lock acquisition successful
acquiring node shardlock on shard6, timeout 800, details Lock acquisition successful
acquiring node shardlock on shard7, timeout 2500, details Lock acquisition failed
acquiring node shardlock on shard8, timeout 1200, details Lock acquisition successful
acquiring node shardlock on shard9, timeout 1800, details Lock acquisition failed
acquiring node shardlock on shard10, timeout 600, details Lock acquisition successful
acquiring node shardlock on shard11, timeout 2700, details Lock acquisition failed
acquiring node shardlock on shard12, timeout 1400, details Lock acquisition successful
acquiring node shardlock on shard13, timeout 2200, details Lock acquisition successful
acquiring node shardlock on shard14, timeout 700, details Lock acquisition failed
WARNING: attempting connection
ERROR: attempting connection
DEBUG: attempting connection
INFO: attempting connection
WARNING: attempting connection
ERROR: attempting connection
DEBUG: attempting connection
INFO: attempting connection
WARNING: attempting connection
ERROR: attempting connection
DEBUG: attempting connection
INFO: attempting connection
WARNING: attempting connection
checking strictWarningsMode=false and warnings=Unused import statement
checking strictWarningsMode=true and warnings=Type safety unchecked cast
checking strictWarningsMode=false and warnings=Unnecessary parentheses
checking strictWarningsMode=true and warnings=Resource leak
checking strictWarningsMode=false and warnings=Overriding method without super invocations
checking strictWarningsMode=true and warnings=Missing switch default case
checking strictWarningsMode=false and warnings=Invalid regular expression
checking strictWarningsMode=true and warnings=Incompatible types
checking strictWarningsMode=false and warnings=Final parameter cannot be assigned
checking strictWarningsMode=true and warnings=Dead store to local variable
checking strictWarningsMode=false and warnings=Custom unchecked exception
checking strictWarningsMode=true and warnings=Comparison of incompatible types
checking strictWarningsMode=false and warnings=Array references non-existent array
INFO New used memory 4.8 GB for data of cache would be larger than configured breaker: 3 GB, breaking
INFO New used memory 1.2 GB for data of logs would be larger than configured breaker: 1 GB, breaking
INFO New used memory 3.3 GB for data of application would be larger than configured breaker: 2 GB, breaking
INFO New used memory 0.9 GB for data of user would be larger than configured breaker: 0.8 GB, breaking
INFO New used memory 2.1 GB for data of database would be larger than configured breaker: 1.5 GB, breaking
INFO New used memory 1.8 GB for data of cache would be larger than configured breaker: 1.2 GB, breaking
INFO New used memory 3.6 GB for data of index would be larger than configured breaker: 2 GB, breaking
INFO New used memory 2.9 GB for data of application would be larger than configured breaker: 1.8 GB, breaking
INFO New used memory 1.3 GB for data of logs would be larger than configured breaker: 1 GB, breaking
INFO New used memory 1.5 GB for data of user would be larger than configured breaker: 0.8 GB, breaking
INFO New used memory 2.3 GB for data of index would be larger than configured breaker: 1.5 GB, breaking
INFO New used memory 2.4 GB for data of cache would be larger than configured breaker: 1.2 GB, breaking
INFO New used memory 3.1 GB for data of application would be larger than configured breaker: 1.8 GB, breaking
Running 'run.py' in '/var/app' for production env: production
Running 'test.sh' in '/opt/tests' for testing env: testing
Running 'deploy.jar' in '/usr/deploy' for staging env: staging
Running 'setup.py' in '/home/user/setup' for development env: local
Running 'build.sh' in '/var/project' for production env: production
Running 'test.py' in '/opt/tests' for testing env: testing
Running 'deploy.zip' in '/usr/deploy' for staging env: staging
Running 'start.sh' in '/home/user' for development env: local
Running 'run.py' in '/var/app' for production env: production
Running 'test.sh' in '/opt/tests' for testing env: testing
Running 'deploy.jar' in '/usr/deploy' for staging env: staging
Running 'setup.py' in '/home/user/setup' for development env: local
Running 'build.sh' in '/var/project' for production env: production
Index: [DEF] has target pool: [Pool2]. Cannot allocate on node: [Node2] with target pool: [Pool3]
Index: [GHI] has target pool: [Pool3]. Cannot allocate on node: [Node3] with target pool: [Pool4]
Index: [JKL] has target pool: [Pool4]. Cannot allocate on node: [Node4] with target pool: [Pool5]
Index: [MNO] has target pool: [Pool5]. Cannot allocate on node: [Node5] with target pool: [Pool6]
Index: [PQR] has target pool: [Pool6]. Cannot allocate on node: [Node6] with target pool: [Pool7]
Index: [STU] has target pool: [Pool7]. Cannot allocate on node: [Node7] with target pool: [Pool8]
Index: [VWX] has target pool: [Pool8]. Cannot allocate on node: [Node8] with target pool: [Pool9]
Index: [YZA] has target pool: [Pool9]. Cannot allocate on node: [Node9] with target pool: [Pool10]
Index: [BCD] has target pool: [Pool10]. Cannot allocate on node: [Node10] with target pool: [Pool11]
Index: [EFG] has target pool: [Pool11]. Cannot allocate on node: [Node11] with target pool: [Pool12]
Index: [HIJ] has target pool: [Pool12]. Cannot allocate on node: [Node12] with target pool: [Pool13]
Index: [KLM] has target pool: [Pool13]. Cannot allocate on node: [Node13] with target pool: [Pool14]
Index: [NOP] has target pool: [Pool14]. Cannot allocate on node: [Node14] with target pool: [Pool15]
Index: [QRS] has target pool: [Pool15]. Cannot allocate on node: [Node15] with target pool: [Pool16]
less than the required 1500 free bytes threshold (700 free) on node 2, but allowing allocation because primary has never been allocated
less than the required 1200 free bytes threshold (600 free) on node 3, but allowing allocation because primary has never been allocated
less than the required 900 free bytes threshold (400 free) on node 4, but allowing allocation because primary has never been allocated
less than the required 1300 free bytes threshold (650 free) on node 5, but allowing allocation because primary has never been allocated
less than the required 1400 free bytes threshold (750 free) on node 6, but allowing allocation because primary has never been allocated
less than the required 1100 free bytes threshold (550 free) on node 7, but allowing allocation because primary has never been allocated
less than the required 1000 free bytes threshold (500 free) on node 8, but allowing allocation because primary has never been allocated
less than the required 1600 free bytes threshold (800 free) on node 9, but allowing allocation because primary has never been allocated
less than the required 1700 free bytes threshold (850 free) on node 10, but allowing allocation because primary has never been allocated
less than the required 1800 free bytes threshold (900 free) on node 11, but allowing allocation because primary has never been allocated
less than the required 1200 free bytes threshold (600 free) on node 12, but allowing allocation because primary has never been allocated
less than the required 800 free bytes threshold (300 free) on node 13, but allowing allocation because primary has never been allocated
less than the required 1500 free bytes threshold (700 free) on node 14, but allowing allocation because primary has never been allocated
Excluded Node Count: 5, Eligible Node Count: 30, Throttled Node Count: 2
Excluded Node Count: 20, Eligible Node Count: 70, Throttled Node Count: 5
Excluded Node Count: 15, Eligible Node Count: 60, Throttled Node Count: 1
Excluded Node Count: 8, Eligible Node Count: 42, Throttled Node Count: 3
Excluded Node Count: 3, Eligible Node Count: 25, Throttled Node Count: 4
Excluded Node Count: 18, Eligible Node Count: 67, Throttled Node Count: 6
Excluded Node Count: 12, Eligible Node Count: 55, Throttled Node Count: 2
Excluded Node Count: 6, Eligible Node Count: 35, Throttled Node Count: 1
Excluded Node Count: 22, Eligible Node Count: 75, Throttled Node Count: 0
Excluded Node Count: 9, Eligible Node Count: 48, Throttled Node Count: 4
Excluded Node Count: 4, Eligible Node Count: 28, Throttled Node Count: 3
Excluded Node Count: 19, Eligible Node Count: 69, Throttled Node Count: 1
Excluded Node Count: 14, Eligible Node Count: 58, Throttled Node Count: 5